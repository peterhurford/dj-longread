{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "582\n",
      "582\n",
      "582\n",
      "582\n",
      "582\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs_from_text(tab_text):\n",
    "    tabs = tab_text.split('\\n')\n",
    "    print('{} tabs opened!'.format(len(tabs)))\n",
    "    for t in tabs:\n",
    "        open_tab(t.split('|')[0].strip())\n",
    "        \n",
    "print('Loaded')\n",
    "\n",
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5fddf1-e942-4059-b414-48e28bdc58f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabs! (582)\n",
      "-\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://80000hours.org/problem-profiles/great-power-conflict/ | Great power conflict - 80,000 Hours\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities – AI Impacts\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://arxiv.org/abs/2306.12001 | [2306.12001] An Overview of Catastrophic AI Risks\n",
      "https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety | A Field Guide to AI Safety—Asterisk\n",
      "https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are | Are We Smart Enough to Know How Smart AIs Are?—Asterisk\n",
      "https://asteriskmag.com/issues/03/emotional-intelligence-amplification | Emotional Intelligence Amplification—Asterisk\n",
      "https://asteriskmag.com/issues/03/how-we-can-regulate-ai | How We Can Regulate AI—Asterisk\n",
      "https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth | The Great Inflection? A Debate About AI and Explosive Growth\n",
      "https://asteriskmag.com/issues/03/through-a-glass-darkly | Through a Glass Darkly—Asterisk\n",
      "https://asteriskmag.com/issues/1/how-to-prevent-the-next-pandemic | How to Prevent the Next Pandemic—Asterisk\n",
      "https://asteriskmag.com/issues/1/making-sense-of-moral-change | Making Sense of Moral Change—Asterisk\n",
      "https://asteriskmag.com/issues/1/modeling-the-end-of-monkeypox | Modeling the End of Monkeypox—Asterisk\n",
      "https://asteriskmag.com/issues/1/rebuilding-after-the-replication-crisis | Rebuilding After the Replication Crisis—Asterisk\n",
      "https://asteriskmag.com/issues/1/why-isn-t-the-whole-world-rich | Why Isn’t the Whole World Rich?—Asterisk\n",
      "https://asteriskmag.com/issues/2/feeding-the-world-without-sunlight | Feeding the World Without Sunlight—Asterisk\n",
      "https://asteriskmag.com/issues/2/my-primal-scream-of-rage-the-big-alcohol-study-that-didn-t-happen | My Primal Scream of Rage: The Big Alcohol Study That Didn't Happen—Asterisk\n",
      "https://asteriskmag.com/issues/2/what-comes-after-covid | What Comes After COVID—Asterisk\n",
      "https://axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://bloomberg.com/opinion/articles/2023-06-18/i-95-repair-in-philadelphia-why-can-t-all-projects-be-this-fast?utm_campaign=socialflow-organic&utm_content=view&utm_source=twitter&cmpid%3D=socialflow-twitter-view&utm_medium=social&leadSource=uverify%20wall | I-95 Repair in Philadelphia: Why Can't All Projects Be This Fast? - Bloomberg\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://coda.io/d/Nonlinear-Network_d2zmoRh9wTR/Improving-institutional-societal-decision-making_sumF-#_luOOZ | Nonlinear Network · Improving institutional / societal decision-making\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://csis.org/events/sen-chuck-schumer-launches-safe-innovation-ai-age-csis | Sen. Chuck Schumer Launches SAFE Innovation in the AI Age at CSIS  CSIS Events\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://docs.google.com/document/d/10Alxne5NLtN8Ggwcnsj9R9D-WaA1-uDdJ_WQlp8zYdQ/edit | Ashwin <> JueYan - Google Docs\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities’ Strategy: 2024 – 2025 - Google Docs\n",
      "https://docs.google.com/document/d/13Y803dvtZuhURiXKq5zZSmrnDtHJC_EcIdeWvGWnQNM/edit#heading=h.q4tgd1ai4pex | Jonas Schuett <> Renan Araujo - 2023-05-24 on XST strategy - Google Docs\n",
      "https://docs.google.com/document/d/13tdTHfCU2JaYW0jrbIYDhoTPfQ1rtWIQJ9VBvGrfY8U/edit | Media Training for AI Safety - notes by Renan - Google Docs\n",
      "https://docs.google.com/document/d/15NjS-daWFjJPFOCX8UzAvLOueH-STrCfPQ7GW4RgRns/edit#heading=h.bjudb4kzpqqu | Manual of Me: Comms Edition - Google Docs\n",
      "https://docs.google.com/document/d/16Rzr6EnH3BHE8kUACDmCu57AyPgby9uaHfkNkqJ2_tc/edit#heading=h.ej16jqti74hb | EA Infosec fieldbuilding post 2023-Jun-9 - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1BnI-FYzz0Coti2nV5t63w8Ga6WWiFSK_kYjE9T2SjLc/edit#heading=h.dcdsb7ob0lnc | * COLLECTION: Positive feedback / signals / praise for XST - Google Docs\n",
      "https://docs.google.com/document/d/1CN7c8rft3RZ-lwzVB_MziKbixQatTbhsRaikt3v83PE/edit | [public] RP US AI regulations team 2-pager (June-Aug 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1HlkOSn7HGkRIffkwMQS2ZtCcvCRHn5Akt2ptfidwLso/edit | Maybe if time permits get more advice on how I can be more helpful to Michael + AIGS - Google Docs\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://docs.google.com/document/d/1I6PEBNI1qC2ezMw_Tzi-4u098_5QjAn-hR61gRr6Tjc/edit | LTFF application for XST 2023-06 - Google Docs\n",
      "https://docs.google.com/document/d/1I9Fw8Y3tdQWEIOIdFRRIvYBISLg0_uKLZgOSn09-9aU/edit#heading=h.lqtiq1w77guj | Training Process Transparency through Gradient Interpretability: Some preliminary results for toy language models\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1Kqqv2_OidYijdQUJ24YW39aackvu6-q-LdDaC23Ori8/edit | Docs since January - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit#heading=h.mfc0g6vdbaom | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1OToyPO8IH3eRAfBpY_zhYp0uPmDbs88RioSEfwHB0DE/edit#heading=h.7oseyc1v098r | [draft] base XST+AIPLUS SFF speculation grant application H1 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Oqj1aK9aVEsUnTyOQDaYOmfKv6zyh16foAsR8beFLL0/edit | Motivations & milestones for valence studies - Google Docs\n",
      "https://docs.google.com/document/d/1P2J7Jys4rZR2joQipPHTCVr7HPqUohtGQsicq9loA8k/edit#heading=h.rqhy3k5812zd | AIGS SFF June 2023 application notes - Google Docs\n",
      "https://docs.google.com/document/d/1PZ7ZVTfIt0T_TgOBTQTLOOne7iakfQDW6uBjEyFMhQo/edit#heading=h.x8vizs97cm8 | AIGS June 2023 comms materials for review - Google Docs\n",
      "https://docs.google.com/document/d/1QHr0oko6Eg0wA4xw8ZjzI9AlQxTIJXxhkSs9wfw1JpU/edit | Reactive availability restrictions for deployed AI models [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://docs.google.com/document/d/1RL3ymf5Q_lcdF5TbHg9KDDM6B4fi8OAuAJmQGHYBszU/edit | Present to LT squad + other leadership on AIGS + XST plans (including AIGS rebrand) - Google Docs\n",
      "https://docs.google.com/document/d/1RMjcOgNwZWvBzfu5oB_llwAThk15QpGTLxy_eLBwVLE/edit | WIT Sequence #1 - Google Docs\n",
      "https://docs.google.com/document/d/1R_yudIhkh8YJXRO20vDgGUkbklXpg2MrWF8bxAtcugo/edit#heading=h.tcmcuy30mpts | Julia’s takes on movement-wide codes of conduct\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1Tsp_wK6GoJAgUCYoZmMN_H7vy3eG3r68IUAWjg5Qy6Y/edit | Management Copy - Bob Fischer 2023 May/June - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://docs.google.com/document/d/1WbINVhU5MtNGsb7bWM9pHPQYpW18aZJ9fVDVtHV5ZAA/edit | 2023-06 SFF long-form attachment for AIGS - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1XsSriKA4YWqD6KRqcUg6CvxhaE1SPVYo_O-QCZEazoQ/edit#heading=h.1u4lkskbhszs | Lionheart AI safety fund feasibility study v0.2 - Google Docs\n",
      "https://docs.google.com/document/d/1ZCMSk2s0ylDsKJ2JMuDIxgVrJE9VfuSSrp2vrzE3iuE/edit#heading=h.y0srbz710jxs | Call notes: Jam-Jake Swett [19 June 2023] Topic: AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.9ick7xqcwurb | RP’s AI Governance & Strategy team - 2-pager - Google Docs\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings – 2023 Q2-Q3 - Google Docs\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1egHpma3StcmGUIm3osmRZefquvbsanitSNSMq2J3IS4/edit | Possibly Making Aesthetically Pleasing PDF RP Reports - Google Docs\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1gJImzAEBg7idY5FrwGisK6BYo2NLW1WYcGPrs1I2ESY/edit | AIGS rebranding working group - meeting notes - Google Docs\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://docs.google.com/document/d/1hLQ4Ce5raaPVUGq0_V1qPdcnn29kJ081w4XE0n0lHw4/edit#heading=h.bd3vtecb3ctx | Proposal: Information Security Fund - Google Docs\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://docs.google.com/document/d/1lrs-UuqZYTzcSvqRR73kDyT6nKzr_EQ2Ex4zvmynCjI/edit | Proposal for how comms and fundraising should work when AIGS rebrands - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1p7xqop2FlIF8Kw45za0NnJPwvUA70Mb1UzjijMRKRr8/edit#heading=h.deq8lzwofh50 | Cost-Effectiveness Analysis of Animal Ballot Initiatives - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://docs.google.com/document/d/1rKcUmCDDB-0Kp759ylO4uNIZzrehSDNeta6PrM888uo/edit | [Shared w/ SFF] Internal Notes from DC meetings - Google Docs\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1rwLFr15536l08wKslhMF6ZHOGvIQ4DIION1jK25_oIE/edit#heading=h.jl93l1npdui2 | [Ashwin evaluating Oliver] - July 2023 - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1uD9b-lrczR2r4LxppInaDQhOSvN0YYDi7MfuSyp1b-w/edit#heading=h.pn9w2hrth81s | Metaculus AI tournament analysis - Google Docs\n",
      "https://docs.google.com/document/d/1vGie3lHRR606-blefv7TGm09n1LF9arbDYxDNgtCeI8/edit#heading=h.f4mc3t2ytr | AI/ChatGPT/LLM Use Guidelines - Google Docs\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://docs.google.com/document/d/1ziNrskp-v_jWihUakPIhSLqdu6WJY-mA0152RUcLqQc/edit | AIGS Leads notes (Michael, Peter, Zoe, often Ashwin) - 2023 May-Sep - Google Docs\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/presentation/d/1dKeyVbNLfaO7QCYTSSleXicRGK8qAestfheQ_8ORrF4/edit#slide=id.g2546af80730_0_214 | Peter's lightning talks - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1DQ5_kPO4MNSunBNuhk_8yEOQkEVy4addPyV5NV3EIvM/edit#gid=458139455 | Caro Career Comparison Table\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1Q-bgYcX5Wa06Hxzj46AaPsj4G_KtkLlEyVpj8fs6HNU/edit#gid=0 | 2023-06 AIGS budget [SFF] - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1SEMBvi9lZaCyTncBADOHyIjGdlfkRDkNagOSIA3x4js/edit#gid=0 | Blog calendar\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1fI6JUcI796OKohKILyJQ_xpU2vY25egUq6A-wX_OUjo/edit#gid=0 | Streaming services - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1fk6jAn4rpbx1T9kKYl-3C9TJHQA8ZC6lFNpT5QawNbs/edit#gid=1486977631 | 2023 Stats - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1g_xBccR_HTFfg-VIEE5MKsooC_aDz0BZ0AJV_XzSX2Q/edit#gid=1359765821 | 2023 June Lights - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://ealifestyles.substack.com/p/will-macaskill-names-17-senior-figures | Will MacAskill names 17 \"senior figures\" in EA\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain’s AI dreams reality\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://encultured.ai/ | Encultured AI\n",
      "https://engelsbergideas.com/notebook/russia-a-short-history-of-failed-coups/ | Russia: a short history of failed coups - Engelsberg ideas\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://eukaryotewritesblog.com/2023/06/24/chronic-wasting-disease/?fbclid=IwAR2RthzoTuDj9cpeUcgh6KYnfgt0HGtcq8K5wM35L_i1upzFDgifSgFTqqM | Will the growing deer prion epidemic spread to humans? Why not?  Eukaryote Writes Blog\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3499475277034032&hoisted_section_header_type=recently_seen | Dank EA Memes  Facebook\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://facebook.com/messages/t/5611182/ | Messenger  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid02xnCGBCSDooHD73pexpgwr3rUJ8mSvYq8aGVzrww1vRkXCk9yasLQh6nkZ7xf4kvbl | Ozzie Gooen - One factor that destroys organizational transparency...  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid0KsTRs5YSTfGh2s8wia8Ji3tuYSKM5DqDMJ64WQWGzj7cjKtDNHd5A4aegn6V6Agpl | Ozzie Gooen - Meta has been doing really well since its low in Nov...  Facebook\n",
      "https://facebook.com/photo/?fbid=658421726326436&set=a.497682632400347 | Facebook\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://facebook.com/taiyanghua3/posts/pfbid07vXQvuz3PZsHfzVLWQbZBX6KywagtRKs2ycew7GejKtQnhntPqLzUFghHzc1DGrPl | facebook.com/taiyanghua3/posts/pfbid07vXQvuz3PZsHfzVLWQbZBX6KywagtRKs2ycew7GejKtQnhntPqLzUFghHzc1DGrPl\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection · Getting started with tpot\n",
      "https://fly.io/blog/we-raised-a-bunch-of-money/ | We Raised A Bunch Of Money · Fly\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion’s AI Benefactor Has A History Of Exaggeration\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power’s Staying Power\n",
      "https://foreignpolicy.com/2023/06/19/us-china-ai-race-regulation-artificial-intelligence/ | AI Is Winning the U.S.-China AI Race\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge — Forgotten Trek\n",
      "https://forum.effectivealtruism.org/events/TmeXfqjWqtpuWJnjr/ea-taskmaster-2023 | EA Taskmaster 2023 - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/4rp8rRjPAE6Hzs5ef/mathiaskb-s-shortform?commentId=72jKEA37fF8ro5LeQ | Why you should buy a desk treadmill\n",
      "https://forum.effectivealtruism.org/posts/5inarAxrymywW6JPC/everything-i-didn-t-know-about-fertilizers-1 | Everything I didn't know about fertilizers — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/AdouuTH7esiDQPExz/announcing-ce-s-new-research-training-program-apply-now | Announcing CE’s new Research Training Program - Apply Now! — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/CEtKAP5Gr7QrTXHRW/on-focusing-resources-more-on-particular-fields-vs-ea-per-se | On focusing resources more on particular fields vs. EA per se - considerations and takes - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DdSszj5NXk45MhQoq/decision-making-and-decentralisation-in-ea | Decision-making and decentralisation in EA - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EEMpNRJK5qqCw6zqH/a-cost-effectiveness-analysis-of-historical-farmed-animal | A Cost-Effectiveness Analysis of Historical Farmed Animal Welfare Ballot Initiatives - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/GCaRhu84NuCdBiRz8/ea-s-success-no-one-cares-about | EA’s success no one cares about - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/GmDmE2pxjTjHMHNK8/thoughts-about-ai-safety-field-building-in-lmic | Thoughts about AI safety field-building in LMIC\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/K7F8pF38SKnrxDsza/crisis-boot-camp-lessons-learned-and-implications-for-ea | Crisis Boot Camp: lessons learned and implications for EA - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KE4Ga3zHQsczooQi7/correctly-calibrated-trust | Correctly Calibrated Trust - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KYApMdtPsveYPAoZk/longtermists-are-perceived-as-power-seeking | Longtermists are perceived as power-seeking - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/LEEcSn4gt7nBwBghk/munk-ai-debate-confusions-and-possible-cruxes | Munk AI debate: confusions and possible cruxes — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MMM24repKAzYxZqjn/my-tentative-best-guess-on-how-eas-and-rationalists | My tentative best guess on how EAs and Rationalists sometimes turn crazy - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/SZJBE3fuk2majqwJQ/principles-for-ai-welfare-research | Principles for AI Welfare Research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/YpADfSeSccsEkaetk/ai-safety-field-building-vs-ea-cb | AI Safety Field Building vs. EA CB — Effective Altruism Forum\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ZnPLPFC49nJym7y8g/agi-x-animal-welfare-a-high-ev-outreach-opportunity | AGI x Animal Welfare: A High-EV Outreach Opportunity? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/cJLsd2TYxv8KCzHvg/announcing-the-aipolicyideas-com-database | Announcing the AIPolicyIdeas.com Database - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/chqv4wneoXHpHzdQk/ce-rigorously-prioritizing-the-top-health-security | CE: Rigorously prioritizing the top health security (biosecurity) ideas — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/czsP5iWmz3wLtz7LT/question-and-answer-based-ea-communities | Question and Answer-based EA Communities - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/dikcpP32Q3cg6tvdA/ai-incident-sharing-best-practices-from-other-fields-and-a | AI Incident Sharing - Best practices from other fields and a comprehensive list of existing platforms — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/p6oP854ZCZ6skojx6/juan-b-garcia-martinez-on-tackling-many-causes-at-once-and | Juan B. García Martínez on tackling many causes at once and his journey into EA — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/qAbKiFYc2Skg3r5at/short-bios-of-17-senior-figures-in-ea | Short bios of 17 \"senior figures\" in EA — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/rLLRo9C4efeJMYWFM/welfare-ranges-per-calorie-consumption | Welfare ranges per calorie consumption - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/sFoqCw6BnZmJNxFda/an-update-on-the-spanish-speaking-ea-community | An update on the Spanish-speaking EA community — Effective Altruism Forum\n",
      "https://forum.effectivealtruism.org/posts/t9e6enPXcH6HFzQku/why-altruists-can-t-have-nice-things | Why Altruists Can't Have Nice Things - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | We must slow down the race to God-like AI\n",
      "https://ft.com/content/44947c05-5217-4593-86d7-1ea52dcbafb9?accessToken=zwAF_xxJIaCIkc9ElHwFUhdFk9OG1x6lLcuvuQ.MEUCIQC4xP6ypi_P50ek77bezs0HmXO6BqIHYNTfrZ4A4q9_BgIgKBrZIgcJJAWK5ondCDrdIIp26NXYc3wF2RcsXCPzuf0&sharetype=gift&token=ebe2e5f7-d5f2-4388-a9b9-0e3fbbef1797 | Russia drops uprising charges and says Wagner will hand over weapons  Financial Times\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://futureoflife.org/our-work/grantmaking-work/?fbclid=IwAR0o6_markFfphRleDNfVw3R_CdMUfZRv6cdY5OQay7K-uVpLXqIEBCImrk | Grantmaking work - Future of Life Institute\n",
      "https://gaingels.com/gaingels-letter | The Gaingels Letter\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://gizmodo.com.au/2023/06/deepmind-co-founder-turing-test-ai/ | DeepMind Co-Founder Wants the 'New Turing Test' to Be Based on How Good an AI Is at Getting Rich\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://google.com/search?q=beyond+this+moment&rlz=1C5CHFA_enGB1058GB1058&oq=beyond+this+moment&aqs=chrome.0.0i355i512j46i512j0i512j46i512j0i512j46i340i512j0i512j0i22i30l3.2523j0j1&sourceid=chrome&ie=UTF-8 | beyond this moment - Google Search\n",
      "https://google.com/search?q=codependent+no+more&rlz=1C5CHFA_enGB1058GB1058&oq=codependent+no+more&aqs=chrome.0.0i271j46i131i433i512j46i512j0i512j46i512j0i512l5.2139j0j1&sourceid=chrome&ie=UTF-8 | codependent no more - Google Search\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://google.com/search?q=honest+trailers+john+wick+2&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+john+sick&gs_lcrp=EgZjaHJvbWUqCQgDEAAYDRiABDIGCAAQRRg5MgkIARAAGA0YgAQyCQgCEAAYDRiABDIJCAMQABgNGIAE0gEIOTUxNGowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers john wick 2 - Google Search\n",
      "https://google.com/search?q=honest+trailers+star+trek&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+tre&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIKCAMQABiGAxiKBTIKCAQQABiGAxiKBdIBCDY1MTFqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star trek - Google Search\n",
      "https://google.com/search?q=honest+trailers+star+wars&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+wars&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQLhiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjIICAUQABgWGB4yCAgGEAAYFhgeMggIBxAAGBYYHjIICAgQABgWGB4yCggJEAAYhgMYigXSAQkxMTc2NmowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star wars - Google Search\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://guarded-everglades-89687.herokuapp.com/?url=&title=&aggregator=-Custom&before=&after=&page=1&sort=&starred= | Upcoming Links\n",
      "https://gwern.net/fiction/clippy | It Looks Like You’re Trying To Take Over The World\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://jeffsebodotnet.files.wordpress.com/2023/06/moral-consideration-for-ai-systems-by-2030-4.pdf | Moral Consideration for AI Systems by 2030.docx\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model – Deconfusion Device – Failing to understand the world, learning a little along the way\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://lesswrong.com/posts/4gDbqL3Tods8kHDqs/limits-to-legibility | Limits to Legibility — LessWrong\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson’s latest AI risk position statement - LessWrong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://lesswrong.com/posts/HCAyiuZe9wz8tG6EF/my-tentative-best-guess-on-how-eas-and-rationalists#comments | My tentative best guess on how EAs and Rationalists sometimes turn crazy - LessWrong\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://lesswrong.com/posts/f3kM7NM5eGMTp3KtZ/lessons-on-how-to-get-things-right-on-the-first-try | Lessons On How To Get Things Right On The First Try - LessWrong\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://lesswrong.com/posts/t5W87hQF5gKyTofQB/ufo-betting-put-up-or-shut-up | UFO Betting: Put Up or Shut Up\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/ | LLM Powered Autonomous Agents  Lil'Log\n",
      "https://linkedin.com/in/vishalmaini/ | (99+) Vishal Maini  LinkedIn\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out …\" - Mastodon\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://medium.com/@sefashapiro/a-community-warning-about-ziz-76c100180509 | A community alert about Ziz. Police investigations, violence, and…  by SefaShapiro  Medium\n",
      "https://metaculus.com/ai/ | The Metaculus Lens on AI\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://metaculus.com/questions/14260/average-us-cpi-in-2023-over-4/#comment-126125 | Average US CPI in 2023 over 4%?  Metaculus\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://metaculus.com/questions/17418/most-expensive-ai-training-run-by-year/ | Most Expensive AI Training Run by Year  Metaculus\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://metaculus.com/questions/17569/prigozhin-leads-wagner-on-june-30-2023/ | Prigozhin leads Wagner on June 30, 2023?  Metaculus\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://metaculus.com/tournament/biosecurity-tournament/ | Biosecurity Tournament - Metaculus\n",
      "https://metaculus.com/tournament/future-of-china/ | China and Global Cooperation - Metaculus\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know/ | The Many Ways that Digital Minds can Know – Ryan Moulton's Articles\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D | Baby steps in evaluating the capacities of large language models  Nature Reviews Psychology\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://niplav.site/ | Content – niplav\n",
      "https://noahpinion.blog/p/four-reasons-china-cant-reset-the | Four reasons China can't reset the world - by Noah Smith\n",
      "https://noahpinion.blog/p/indiamerica?sd=pf | Indiamerica - by Noah Smith - Noahpinion\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://ntia.gov/issues/artificial-intelligence/request-for-comments | AI Accountability Policy Request for Comment  National Telecommunications and Information Administration\n",
      "https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html | Inside the AI Factory: The Humans That Make Tech Seem Human\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://openai.com/blog/insights-from-global-conversations | Insights from global conversations\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://philpapers.org/rec/BOTRRG | Christopher Bottomley & Timothy Luke Williamson, Rational risk‐aversion: Good things come to those who weight - PhilPapers\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://reddit.com/r/truerateme/ | reddit.com/r/truerateme/\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact — Rethink Priorities\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 – Rodney Brooks\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It’s infuriatingly hard to understand how closed models train on their input\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://spylab.ai/blog/chatbot-adversarial-examples/ | Adversarial examples in the age of ChatGPT  SPY Lab\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women’s Pleasure\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://tellingthefuture.substack.com/p/we-must-live-together-or-perish | We Must Live Together Or Perish - by Robert de Neufville\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI’s Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://theintrinsicperspective.com/p/stop-trying-to-make-a-good-social | Stop trying to make a \"good\" social media site\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-dial-of-progress | The Dial of Progress - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com® - USPS Tracking® Results\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://twitter.com/8teAPi/status/1671519543003422721 | Ate-a-Pi on Twitter: \"MSFT moves closer to human teaching a transformer Textbooks are All You Need - tiny model, 1% the size of GPT3, achieving x perf - first they examined the standard code dataset everyone trains on, The Stack - found it was confusing for an early learner. Lots of examples of… t.co/Xpg6Lcp1DB\" / Twitter\n",
      "https://twitter.com/AlecStapp/status/1674519565231964161 | Alec Stapp on Twitter: \"New white paper from @IFP: Everything you ever wanted to know about indoor air quality. t.co/rIcUHJjs33\" / Twitter\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | αlpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://twitter.com/AndyMasley/status/1673810959008186370 | Andy Masley on Twitter: \"Didn't expect keeping myself mildly hungry to be such a productivity hack but wow I recommend it.\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1674461614056292353 | (1) Anthropic on Twitter: \"We develop a method to test global opinions represented in language models. We find the opinions represented by the models are most similar to those of the participants in USA, Canada, and some European countries. We also show the responses are steerable in separate experiments. t.co/QzHmRPNqSl\" / Twitter\n",
      "https://twitter.com/BasilHalperin/status/1673822832193679365 | Basil Halperin on Twitter: \"IMO this is the best compendium of available arguments that ‘the singularity is not (too) near (probably)’… great piece\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won’t)🧵 t.co/23ErIoRIsk\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1673897147110924291 | Dmitri Alperovitch on Twitter: \"Com­merce De­pt could move as soon as next month to stop ship­ments of AI chips made by Nvidia and others to China. “New restrictions be­ing con­tem­plated by the de­part­ment would ban the sale of even A800 chips with­out a li­cense”t.co/HhsaIF5RSn\" / Twitter\n",
      "https://twitter.com/DavidSKrueger/status/1672082616672047109 | (1) David Krueger on Twitter: \"My slides from EAG London talk, IYI: t.co/k58MoowgGb And resharing the link to video: t.co/ZDAgCpvW2i\" / Twitter\n",
      "https://twitter.com/DavidSKrueger/status/1672232506991542272 | (1) David Krueger on Twitter: \"EAGx Cambridge fireside chat (I love this format!) t.co/53Qd9YqINx\" / Twitter\n",
      "https://twitter.com/DavidSKrueger/status/1672464907957149696 | David Krueger on Twitter: \"58% expressed some level of agreement. 26% expressed some level of disagreement.\" / Twitter\n",
      "https://twitter.com/DrRyanBurnell/status/1671465666740666370 | Ryan Burnell on Twitter: \"How are the capabilities of large language models structured? In our new paper, we find that three broad abilities can explain most of the variance in performance across a wide range of LLMs and a broad set of cognitive tasks. Pre-print here: t.co/r1lycQG59R\" / Twitter\n",
      "https://twitter.com/EAheadlines/status/1673764181789556737 | EA Lifestyles on Twitter: \"okay I finally looked up all the people on Will's list of senior figures in ea and I have a lot of feeeeeelings\" / Twitter\n",
      "https://twitter.com/EthanJPerez/status/1671222828518227968 | twitter.com/EthanJPerez/status/1671222828518227968\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | Jeffrey Ladish on Twitter: \"I really appreciate that @RishiSunak is explicitly acknowledge the existential and catastrophic risks faced by AI. To have a competent global response we have to start here Also, accelerating AI development ⏩ is probably the single most dangerous thing you can do in the world\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1673149979828039680 | (1) Jeffrey Ladish on Twitter: \"It pains me to say it, because I have a lot of respect for much of what @AnthropicAI has done and I've appreciated collaborating with them on safety and security (spent over a year working on security there), but I agree with @Simeon_Cps here. If governments can't directly…\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1673469056882728960 | Jeffrey Ladish on Twitter: \"How dangerous is it that a LM can direct a robot to synthesize molecules like this with only a tiny bit of code scaffolding and a couple sentences of a prompt? Two key questions 1) How many people can do this right now? 2) What is the trajectory of AI capabilities like these?\" / Twitter\n",
      "https://twitter.com/JonasSandbrink/status/1674043107841568769 | Jonas Sandbrink on Twitter: \"How can AI exacerbate biosecurity risks? My new preprint gives an overview of crucial considerations and possible interventions. t.co/4DYupGyopU 🧵1/9\" / Twitter\n",
      "https://twitter.com/Kirsten3531/status/1560374030611361792 | Kirsten on Twitter: \"Assorted things I learned from teaching that are super helpful working in an office:\" / Twitter\n",
      "https://twitter.com/Kirsten3531/status/1673948741374472198 | Kirsten on Twitter: \"Three tools your brain can use if it sees you trying to do something really hard with a low chance of success (like write the next great American novel):\" / Twitter\n",
      "https://twitter.com/Lance_Ying42/status/1674411924187152384 | Lance Ying on Twitter: \"Can LLMs perform social reasoning? In this paper with @xuanalogue @katie_m_collins @MeganJWei, Lionel Wang, Cedegao Zhang, @adrian_weller and Josh Tenenbaum, we propose a model using LLM as a semantic parser and inverse planning as an inference engine. t.co/qW9otezTtI t.co/HeesmziMbY\" / Twitter\n",
      "https://twitter.com/LongResilience/status/1671793646385917954 | (1) The Centre for Long-Term Resilience on Twitter: \"Our Head of AI Policy, @jesswhittles, was recently interviewed for this @TIME article on @RishiSunak’s ambition for the UK to be a global leader in AI regulation. A 🧵 on key points from the piece: t.co/p682NhXThy 1/4\" / Twitter\n",
      "https://twitter.com/LuiseWoehlke/status/1670430498387111936 | Luise Wöhlke on Twitter: \"☀️🌴 I wrote a much-needed update to my June 2022 post on spending summer in the Bay Area, aka my love letter to the Bay. ☀️🌴 If you've read it and are considering going, I recommend you read the updates which strike a more critical note! :) t.co/y9UxkTqLLV t.co/9eY3R3LjZY\" / Twitter\n",
      "https://twitter.com/LukeyEllsberg/status/1670153020795936771 | lukey on Twitter: \"May my grandfather @DanielEllsberg’s memory be a blessing in the only way that would have matter to him - as an example of how we may all rise to the challenge of responsibility &amp; love for humanity. t.co/QODXZnSO97\" / Twitter\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok 🏗️🚀 on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1671375922870759424 | Matthew Barnett on Twitter: \"I'm happy about regulating AI eventually. Heuristic: we regulate people strictly, and AI will be even more powerful than people. But I'm really averse to messaging that suggests GPT-4 is dangerous. I think we're still basically at the harmless tool stage.\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1673408808998297600 | Matthew Barnett on Twitter: \"In which I outline my AI 'optimism' story, which is the version of the future I find most likely: t.co/N0cixmrcyM\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1671908426736103424 | Nathan on Twitter: \"Went to the gym for ~ the first time in my life. Felt great for several hours afterwards. graph gonna graph I guess. I used the StrongLifts app which told me what to do t.co/Ov1KG4tEus\" / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1672017323849560065 | (1) Neel Nanda on Twitter: \"Does superposition happen in real language models? In a new paper walkthrough, @wesg52 and I discuss his paper on Finding Neurons In A Haystack, and the evidence we've found. I helped supervise this paper, and am excited to explore it in detail! t.co/ZRkSoJifmF\" / Twitter\n",
      "https://twitter.com/NiklasLauffer/status/1670854905513512960 | Niklas Lauffer on Twitter: \"🤝🤔𝙒𝙝𝙖𝙩 𝙙𝙤 𝙬𝙚 𝙣𝙚𝙚𝙙 𝙩𝙤 𝙠𝙣𝙤𝙬 𝙖𝙗𝙤𝙪𝙩 𝙚𝙖𝙘𝙝 𝙤𝙩𝙝𝙚𝙧 𝙩𝙤 𝙨𝙪𝙘𝙘𝙚𝙨𝙨𝙛𝙪𝙡𝙡𝙮 𝙘𝙤𝙡𝙡𝙖𝙗𝙤𝙧𝙖𝙩𝙚?? In our new ICML paper, we provide a method that determines exactly the information you need to be an optimal teammate in multiagent games. [1/10] t.co/DERhRtguLd\" / Twitter\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith 🐇🇺🇦 on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://twitter.com/Noahpinion/status/1671280226070941698 | Noah Smith 🐇🇺🇦 on Twitter: \"1/I disagree with some of @delong's China theses! t.co/LCXXF5CYrG\" / Twitter\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://twitter.com/SSGamblers/status/1674675424356442112 | Star Spangled Gamblers on Twitter: \"New Podcast Episode @WineMomPI, @GaetenD, and @TheWinner2875 discuss: — Dating advice for political gamblers — A new Title Belt challenge on Trump’s nicknames for @RonDeSantis — When Trump will show up to a @GOP debate and who he will attack t.co/oQfN4ENInT\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1673281020139913220 | Siméon on Twitter: \"Here's a more comprehensive list of what Anthropic &amp; OpenAI did best and worst at IMO. What OpenAI (OA) did well: 1) Sam Altman publicly voicing existential risk concerns before ~everyone else + now pushing for policies close from the right degree of ambition of what needs to…\" / Twitter\n",
      "https://twitter.com/SpecialPuppy1/status/1671249200326012928 | Special Puppy 🧦🐵 on Twitter: \"How are you a mom of 4 at 22?!? (I feel really bad for this woman, but idk how she put herself in this situation)\" / Twitter\n",
      "https://twitter.com/StefanFSchubert/status/1671633702865043457 | Stefan Schubert on Twitter: \". @MatthewJBar arguing against the view that because \"OpenAI’s strategy assumes that short timelines and a slow, continuous takeoff is the safest path to AGI, it is a path we’re likely to take.\" I agree with his reasoning. t.co/em5WndQhN7 t.co/VOospw2zNm\" / Twitter\n",
      "https://twitter.com/StefanFSchubert/status/1672175939524984835 | Stefan Schubert on Twitter: \"\"Should Effective Altruists Focus On Air Pollution?\" I liked this talk by @FoundersPledge's Tom Barnes. From EAGx Cambridge (all videos just went up). t.co/SE1qGDgI3X t.co/hyxP11ocf3\" / Twitter\n",
      "https://twitter.com/TechFTC/status/1674485450621198338 | (1) FTC's Office of Technology on Twitter: \"In blog post, FTC staff identifies a few of the essential technical building blocks of generative AI and discusses competition concerns potentially raised by generative AI. t.co/Tyeu4M4Zza\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1673297049180160000 | Zvi Mowshowitz on Twitter: \"This link to Google labs seems to work instantly to give you GMail generative AI access: t.co/sxtnX2OalE\" / Twitter\n",
      "https://twitter.com/TiffanyYongTQ/status/1672956356976865280 | Tiffany Yong on Twitter: \"issuing a Internet Search Query for my white whale: the world’s Most Perfect bucket list, which i chanced upon a few months ago and promptly lost the link for. I’ve been searching for it intermittently, and if you saw this incredible list, you would too. details below ⬇️\" / Twitter\n",
      "https://twitter.com/TmarcoH/status/1674063185010147330 | Marco Hernandez on Twitter: \"The advance of the Ukrainian counteroffensive must face great challenges to advance on the ground occupied by the Russians. I did some illustrations to explain it better: t.co/tdiM0247G5 #UkraineWar t.co/ePHBTsVoFU\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/acritschristoph/status/1673034164973764608 | Alex Crits-Christoph @alexcc@mstdn.science on Twitter: \"There has been much recent misinformation about COVID-19 origins that we can now debunk. A thread on 2 topics: A. How the ODNI report debunks multiple lab origins rumors. B. Where these inaccurate media reports originated, and why we knew they were wrong. t.co/5XMugelzoz\" / Twitter\n",
      "https://twitter.com/amasad/status/1670473919504220160 | Amjad Masad on Twitter: \"There is a non-zero chance BabyAGI will self-replicate inside Replit and take over our cloud. If it happens it happens.\" / Twitter\n",
      "https://twitter.com/andrewwhite01/status/1670794000398184451 | Andrew White on Twitter: \"We report a model that can go from natural language instructions, to robot actions, to synthesized molecule with an LLM. We synthesized catalysts, a novel dye, and insect repellent from 1-2 sentence instructions. This has been a seemingly unreachable goal for years! 1/3 t.co/vl65FqSHN2\" / Twitter\n",
      "https://twitter.com/araujonrenan/status/1672558931581759489 | Renan Araujo on Twitter: \"I think the strategy behind building the field of AI safety in LMIC has changed a lot over the last year, and I tried to articulate this in this post. t.co/jTdRIxMswL\" / Twitter\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://twitter.com/base_rate_times/status/1671715701034479617 | The Base Rate Times on Twitter: \"There is a News tab on @ManifoldMarkets now! This is what their Russia-Ukraine coverage looks like. Check it out t.co/B3izRnCmT7\" / Twitter\n",
      "https://twitter.com/benedictcooney/status/1670693039327649792 | (1) Benedict Cooney on Twitter: \"We did say a shake-up was necessary t.co/i36Z87oNRs\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://twitter.com/bill_drexel/status/1671197788024057857 | (1) Bill Drexel on Twitter: \"I'm biased, but @paul_scharre's new piece in @ForeignPolicy seems to me to give the most comprehensive and readable overview available of the stakes and policy levers around advanced AI development. If you want to get up to speed quickly, read below: t.co/npX1t8mCSG\" / Twitter\n",
      "https://twitter.com/blader/status/1670578014508433410 | Siqi Chen on Twitter: \"Terence Tao on his experience with GPT4 in mathematical research: \"The 2023-level AI can already generate suggestive hints and promising leads to a working mathematician and participate actively in the decision-making process.\" t.co/C0VnX8QZxY t.co/rhEJ3yXp8K\" / Twitter\n",
      "https://twitter.com/business/status/1673877471819878400 | Bloomberg on Twitter: \"🇨🇳THREAD: 1) China is trying to catch up to the US in the AI arms race, but here's why it has a long way to go ⬇️ t.co/rOCJZnaGfn\" / Twitter\n",
      "https://twitter.com/catehall/status/1674837401829769216 | twitter.com/catehall/status/1674837401829769216\n",
      "https://twitter.com/contextdogs/status/1672760515074879491 | out of context dogs on Twitter: \"t.co/LTNWZVENEV\" / Twitter\n",
      "https://twitter.com/daniel_271828/status/1672788522665914368 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"If you're wondering what AI researchers who talk about extinction risk actually mean by \"extinction\", here are quotes from a few of the more prominent researchers on their worries: t.co/OIgTjW96ag\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1673293480762699776 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"Building a Safety Culture for AI - 🧵 I wrote a new paper. Link: t.co/MI2MRl9Eho To start, culture matters, and the culture in AI is not one that currently treats risks and failures seriously. As AI becomes even more widely used and powerful, that's very bad.\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://twitter.com/glpat99/status/1672230720662560768 | Gemma (6/15 blog posts published) on Twitter: \"I agree with all of these claims from @SjirHoeijmakers but curious where people disagree? Polls below (i've also added a claim of my own) ⬇ t.co/FCWFCWLjgX\" / Twitter\n",
      "https://twitter.com/goodside/status/1672806305885552640 | Riley Goodside on Twitter: \"SequenceMatch is a good read — TLDR: LLMs are only trained to continue real text, but used to continue their own. errors compound; text goes OOD so, add a backspace key; train on fake backspaced errors and use 𝜒² over MLE. better output, higher MAUVE t.co/697Ntmtwou t.co/XxALGSH8ez\" / Twitter\n",
      "https://twitter.com/gunsnrosesgirl3/status/1670471946679492610 | Science girl on Twitter: \"Seals have short front flippers and un-rotatable rear flipper so cannot walk on land, they propel themselves forward and achieve locomotion by a method called galumphing t.co/Mm9HY3X6Yi\" / Twitter\n",
      "https://twitter.com/gwern/status/1674597983633956867 | (1) 𝔊𝔴𝔢𝔯𝔫 on Twitter: \"@MWCvitkovic Another entry in the 'you can just do things' files: t.co/jnKEomt49q\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://twitter.com/jankulveit/status/1670735364707721216 | Jan Kulveit on Twitter: \"Fascinating &amp; seems reproducible! Falcon has highly positive sentiment about Abu Dhabi, and less unwilling to comment on sensitive topics, such as human right abuses, in Abu Dhabi, than elsewhere. Could have various causes, but it's an important reminder that open source-model… t.co/kWtUqU55fN\" / Twitter\n",
      "https://twitter.com/jerryjliu0/status/1670466808384745472 | Jerry Liu on Twitter: \"Agents 🤖 built with the @OpenAI function API can do advanced data analysis out of the box 🕵️ We’re excited to introduce a brand-new cookbook highlighting these tasks + limitations! 🧑‍🍳👇 - Vector db auto-retrieval - Joint Text-to-SQL + Semantic Search t.co/keofhxZ5tX\" / Twitter\n",
      "https://twitter.com/jesswhittles/status/1674729420240703488 | Jess Whittlestone on Twitter: \"I've got an op ed in @timesredbox today on what the UK government needs to do if it wants to truly establish itself as a leader in global AI governance. t.co/jcHAmFjRZg I suggest three key things need attention - summarised in 🧵 below:\" / Twitter\n",
      "https://twitter.com/jordanschnyc/status/1673847803691368448 | Jordan Schneider on Twitter: \"big if true. t.co/4tZYXCVF8y\" / Twitter\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1645459383554568193 | Michael C. Frank on Twitter: \"What does it mean for a large language model (LLM) to \"have\" a particular ability? Developmental psychologists argue about these questions all the time and have for decades. There are some ground rules. 🧵 t.co/NxcgKwHxGO\" / Twitter\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://twitter.com/messages/25776739-128178067 | twitter.com/messages/25776739-128178067\n",
      "https://twitter.com/messages/25776739-1631315348 | Ted / Twitter\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://twitter.com/messages/25776739-757517000 | twitter.com/messages/25776739-757517000\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/michael_nielsen/status/1671265487056162823 | Michael Nielsen on Twitter: \"A thoroughly fascinating table, from: t.co/kZ10mzerVW t.co/ofJTJN99sl\" / Twitter\n",
      "https://twitter.com/michael_nielsen/status/1671370867228676097 | Michael Nielsen on Twitter: \"If you'd like to keep yourself awake very late tonight: t.co/eWuUwqBIiv\" / Twitter\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://twitter.com/ohlennart/status/1671203769357414412 | Lennart Heim on Twitter: \"We submitted a response to the NTIA's requests for comments on AI Accountability Policy. We focused on audits and assessments of foundation models. 🧵 t.co/r8lpRsMXjW t.co/FrFdVPG0Im\" / Twitter\n",
      "https://twitter.com/oziadias/status/1671953107180478464 | (2) Ziad Obermeyer on Twitter: \"Those of us building health AI products have a problem: Our algorithms look great—in our own data But how will they perform elsewhere? On other machines? On diverse patients? We’ve built a way to find out, at @Dandelion_AI4H: A free, public service for algorithm audits t.co/mduBOUtON1\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | Peter Wildeford on Twitter: \"RT @hearthisidea: → Why focus on reducing existential risk from AI? → How could we come up with plans for doing that? What are some promisi…\" / Twitter\n",
      "https://twitter.com/pgodfreysmith/status/1673114925995261952 | Peter Godfrey-Smith on Twitter: \"\"Finding Consciousness in Phylogenetically Distant Organisms\" – a thread with a few slides and references from my talk at @ASSC26nyc this afternoon. 1/ t.co/Tgboy6QAhU\" / Twitter\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://twitter.com/random_walker/status/1672244743219077123 | Arvind Narayanan on Twitter: \"Billions of people doing clickwork for AI sounds more dystopian than most of the AI safety risk scenarios that have been proposed tbh t.co/jmEdpp4pxJ\" / Twitter\n",
      "https://twitter.com/random_walker/status/1673894212490735616 | Arvind Narayanan on Twitter: \"Yup. I wonder how many people in the AI safety debate are familiar with the Crypto(graphy) Wars and the immense, permanent damage caused by the US gov's maddeningly misguided and ultimately futile effort to regulate cryptography as munitions. t.co/UNcblAPgfr\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1671832924771983368 | (1) Robert Wiblin on Twitter: \"Carl Shulman's interview on The Lunar Society Podcast is one of the best things produced on AI this year. Challenging and assumes substantial existing knowledge — but mandatory listening for people sincerely trying to understand these issues IMO: t.co/uc25oBnIV5\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1672178211336204288 | Robert Wiblin on Twitter: \"I speak with @ohlennart: \"If compute governance is only a temporary phase between the era of difficult-to-train superhuman AI models and the time when such models are widely accessible — what can we do to prevent misuse of AI systems after that point?\" t.co/XY9jRJLeCj\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1674421368560156675 | (1) Robert Wiblin on Twitter: \"This is very good IMO: \"Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support. ... Our goal is to work with defenders to change the power dynamics of cybersecurity through AI\" t.co/S5q9CoUE8h\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1674787966928195586 | twitter.com/robertwiblin/status/1674787966928195586\n",
      "https://twitter.com/robinhanson/status/1671664705255927811 | Robin Hanson on Twitter: \"Software is 75 years old today: \"The very first time a stored-program computer held a piece of software in electronic memory and executed it successfully, was 11 am 21 June 1948, at the University of Manchester, on the Manchester Baby computer.\" t.co/UJydWK8gRa\" / Twitter\n",
      "https://twitter.com/sdorkenw/status/1674859033076072448 | Sven Dorkenwald on Twitter: \"We are releasing a whole-brain connectome of the fruit fly, including ~130k annotated neurons and tens of millions of typed synapses! Explore the connectome: t.co/EWcwRiO0Oz Reconstruction paper: t.co/wCI3hASUfD Annotation paper: t.co/3bPTNK9hRk 1/6 t.co/dxyZIhSITg\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | Séb Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here’s a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. 🏛 t.co/1Grjv93laf\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1671194525988003840 | Séb Krier on Twitter: \"Forgot how good this @WaqarHZaidi &amp; @AllanDafoe paper is. Very relevant and lots of fascinating insights throughout. t.co/8otOY8wLqv t.co/Rq0afRYpen\" / Twitter\n",
      "https://twitter.com/shashj/status/1673960802808627202 | Shashank Joshi on Twitter: \"“The administration is also considering restricting leasing of cloud services to Chinese AI companies, which have used such arrangements to skirt the export bans on advanced chips, some of the people familiar with the discussions say.” t.co/KcQWpW4U8h\" / Twitter\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I’m honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://twitter.com/stephenclare_/status/1674425999646408708 | Stephen Clare on Twitter: \"Preventing conflict between the world’s most powerful countries is one of the world’s most pressing problems. I make this case in a new article for @80000hours (thread 🧵) t.co/sie4QKgKAU\" / Twitter\n",
      "https://twitter.com/teortaxesTex/status/1663897107642630145 | Teortaxes on Twitter: \"Rationalists are unable to inspect their abnormality. They are moral cripples who have stumbled on a crutch in the form of quasi-economic theory of maximizing utility, found that it fits, and reasoned that they're smart, ergo it's convergent for *all* intelligent entities. t.co/kAPYisWPOn\" / Twitter\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://twitter.com/tmkadamcz/status/1674052524184154117 | Tom Adamczewski on Twitter: \"I work a _lot_ with SciPy probability distributions, and have developed a set of tools over time I've now released many of them in a package: ✨rvtools🔨 t.co/ciBruBxLjD Useful shortcuts, additional distributions, and some opinionated changes to SciPy APIs t.co/7Rg7ytXgsu\" / Twitter\n",
      "https://twitter.com/tomascodes/status/1674020711453675520 | tomas ✨ on Twitter: \"Every couple of months I check this website out again and remember why its my favourite website ever t.co/92xslmwuNe\" / Twitter\n",
      "https://twitter.com/tomgoldsteincs/status/1670893835793186816 | Tom Goldstein on Twitter: \"Training an LLM takes about 1 trillion words. That’s about 30,000 years of typing. But where does this data come from? And what does this have to do with the Reddit protests? Here’s how OpenAI trains models on “the entire internet.” 🧵📜\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1567926384676450304 | (3) xuan (ɕɥɛn / sh-yen) on Twitter: \"Gave another talk on AI alignment, this time at #EAGxSingapore last week -- appreciated the chance to condense my recent thinking about what it means to \"align\" AI in a world with a diversity of people &amp; values by asking \"What Should AI Owe To Us?\" (1/11) t.co/UBBnr13Vw7 t.co/7RH0o3T80f\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1674410315432247297 | xuan (ɕɥɛn / sh-yen) on Twitter: \"How do we infer the goals &amp; plans of others from both their actions &amp; words? In this paper with @Lance_Ying42, we infer a team's goal via inverse planning (aka \"inverse RL\"), using LMs* as likelihood functions over utterances! (*GPT-3 Curie 6.7B, but smaller LMs may also work!)\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1672647224696684545 | (((ل()(ل() 'yoav))))👾 on Twitter: \"\"in 1 hour\"? these MIT students are kinda slow... t.co/2Le4l7Fq0V\" / Twitter\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://washingtonpost.com/technology/2023/06/28/openai-chatgpt-lawsuit-class-action/ | ChatGPT maker OpenAI faces class action lawsuit over data to train AI - The Washington Post\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://wikiwand.com/en/Silo_(TV_series) | Silo (TV series) - Wikiwand\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won’t take it over by playing “3-dimensional chess”. – Windows On Theory\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak – Windows On Theory\n",
      "https://worksinprogress.co/issue/asteroid-spotting | Asteroid spotting - Works in Progress\n",
      "https://worksinprogress.co/issue/better-eats | Better eats - Works in Progress\n",
      "https://worksinprogress.co/issue/biases-the-wrong-model | We don’t have a hundred biases, we have the wrong model - Works in Progress\n",
      "https://worksinprogress.co/issue/buyers-of-first-resort | Buyers of first resort - Works in Progress\n",
      "https://worksinprogress.co/issue/developing-the-science-of-science | Developing the science of science - Works in Progress\n",
      "https://worksinprogress.co/issue/every-grain-of-rice | Every grain of rice - Works in Progress\n",
      "https://worksinprogress.co/issue/history-is-in-the-making | History is in the making - Works in Progress\n",
      "https://worksinprogress.co/issue/how-covid-brought-the-future-back | How Covid brought the future back - Works in Progress\n",
      "https://worksinprogress.co/issue/how-dc-densified | How DC densified - Works in Progress\n",
      "https://worksinprogress.co/issue/how-trust-undermines-science | How trust undermines science - Works in Progress\n",
      "https://worksinprogress.co/issue/how-we-fixed-the-ozone-layer | How we fixed the ozone layer - Works in Progress\n",
      "https://worksinprogress.co/issue/innovation-is-not-linear | Innovation is not linear - Works in Progress\n",
      "https://worksinprogress.co/issue/markets-in-fact-checking | Markets in fact-checking - Works in Progress\n",
      "https://worksinprogress.co/issue/on-the-origins-of-empathy-for-other-species | On the origins of empathy for other species - Works in Progress\n",
      "https://worksinprogress.co/issue/pandemic-prevention-as-fire-fighting | Pandemic prevention as fire-fighting - Works in Progress\n",
      "https://worksinprogress.co/issue/parenting-as-a-public-good | Parenting as a public good - Works in Progress\n",
      "https://worksinprogress.co/issue/practical-veganism | Practical veganism - Works in Progress\n",
      "https://worksinprogress.co/issue/real-peer-review | Real peer review has never been tried - Works in Progress\n",
      "https://worksinprogress.co/issue/securing-posterity | Securing posterity - Works in Progress\n",
      "https://worksinprogress.co/issue/seeing-on-the-far-side-of-the-moon | Seeing on the far side of the moon - Works in Progress\n",
      "https://worksinprogress.co/issue/taming-the-stars | Taming the stars - Works in Progress\n",
      "https://worksinprogress.co/issue/the-elements-of-scientific-style | The elements of scientific style - Works in Progress\n",
      "https://worksinprogress.co/issue/the-end-of-acid-rain | The end of acid rain - Works in Progress\n",
      "https://worksinprogress.co/issue/the-evolution-of-psychiatry | The evolution of psychiatry - Works in Progress\n",
      "https://worksinprogress.co/issue/the-future-of-weight-loss | The future of weight loss - Works in Progress\n",
      "https://worksinprogress.co/issue/the-housing-theory-of-everything | The housing theory of everything - Works in Progress\n",
      "https://worksinprogress.co/issue/the-most-dangerous-substance-known-to-man | The most dangerous substance known to man - Works in Progress\n",
      "https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab | The rise and fall of the industrial R&D lab - Works in Progress\n",
      "https://worksinprogress.co/issue/this-is-what-peak-culture-looks-like | This is what peak culture looks like - Works in Progress\n",
      "https://worksinprogress.co/issue/thomas-edison-tinkerer | Thomas Edison, tinkerer - Works in Progress\n",
      "https://worksinprogress.co/issue/what-ails-the-social-sciences | What ails the social sciences - Works in Progress\n",
      "https://worksinprogress.co/issue/why-britain-doesnt-build | Why Britain doesn’t build - Works in Progress\n",
      "https://worksinprogress.co/issue/why-didnt-suicides-rise-during-covid | Why didn't suicides rise during Covid? - Works in Progress\n",
      "https://worksinprogress.co/issue/why-innovation-prizes-fail | Why innovation prizes fail - Works in Progress\n",
      "https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/ | FAQ on Catastrophic AI Risks\n",
      "https://youtube.com/playlist?list=PLwp9xeoX5p8MbksBvu_R_IOz6kD4H7ytC | EA Global: London 2023 - YouTube\n"
     ]
    }
   ],
   "source": [
    "tabs = ['https://' + t for t in sorted([t.replace('http://', '').replace('https://', '').replace('www.', '') for t in tabs])]\n",
    "\n",
    "print('Tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df311d-c9c6-4ace-a7c9-7ed21b34d78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled tabs! (582)\n",
      "-\n",
      "https://docs.google.com/document/d/1hLQ4Ce5raaPVUGq0_V1qPdcnn29kJ081w4XE0n0lHw4/edit#heading=h.bd3vtecb3ctx | Proposal: Information Security Fund - Google Docs\n",
      "https://twitter.com/TiffanyYongTQ/status/1672956356976865280 | Tiffany Yong on Twitter: \"issuing a Internet Search Query for my white whale: the world’s Most Perfect bucket list, which i chanced upon a few months ago and promptly lost the link for. I’ve been searching for it intermittently, and if you saw this incredible list, you would too. details below ⬇️\" / Twitter\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://linkedin.com/in/vishalmaini/ | (99+) Vishal Maini  LinkedIn\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://twitter.com/AndyMasley/status/1673810959008186370 | Andy Masley on Twitter: \"Didn't expect keeping myself mildly hungry to be such a productivity hack but wow I recommend it.\" / Twitter\n",
      "https://docs.google.com/document/d/1vGie3lHRR606-blefv7TGm09n1LF9arbDYxDNgtCeI8/edit#heading=h.f4mc3t2ytr | AI/ChatGPT/LLM Use Guidelines - Google Docs\n",
      "https://gaingels.com/gaingels-letter | The Gaingels Letter\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities’ Strategy: 2024 – 2025 - Google Docs\n",
      "https://twitter.com/davidmanheim/status/1673293480762699776 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"Building a Safety Culture for AI - 🧵 I wrote a new paper. Link: t.co/MI2MRl9Eho To start, culture matters, and the culture in AI is not one that currently treats risks and failures seriously. As AI becomes even more widely used and powerful, that's very bad.\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | Peter Wildeford on Twitter: \"RT @hearthisidea: → Why focus on reducing existential risk from AI? → How could we come up with plans for doing that? What are some promisi…\" / Twitter\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1673149979828039680 | (1) Jeffrey Ladish on Twitter: \"It pains me to say it, because I have a lot of respect for much of what @AnthropicAI has done and I've appreciated collaborating with them on safety and security (spent over a year working on security there), but I agree with @Simeon_Cps here. If governments can't directly…\" / Twitter\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://twitter.com/shashj/status/1673960802808627202 | Shashank Joshi on Twitter: \"“The administration is also considering restricting leasing of cloud services to Chinese AI companies, which have used such arrangements to skirt the export bans on advanced chips, some of the people familiar with the discussions say.” t.co/KcQWpW4U8h\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1645459383554568193 | Michael C. Frank on Twitter: \"What does it mean for a large language model (LLM) to \"have\" a particular ability? Developmental psychologists argue about these questions all the time and have for decades. There are some ground rules. 🧵 t.co/NxcgKwHxGO\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1DQ5_kPO4MNSunBNuhk_8yEOQkEVy4addPyV5NV3EIvM/edit#gid=458139455 | Caro Career Comparison Table\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://forum.effectivealtruism.org/posts/MMM24repKAzYxZqjn/my-tentative-best-guess-on-how-eas-and-rationalists | My tentative best guess on how EAs and Rationalists sometimes turn crazy - EA Forum\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://google.com/search?q=codependent+no+more&rlz=1C5CHFA_enGB1058GB1058&oq=codependent+no+more&aqs=chrome.0.0i271j46i131i433i512j46i512j0i512j46i512j0i512l5.2139j0j1&sourceid=chrome&ie=UTF-8 | codependent no more - Google Search\n",
      "https://coda.io/d/Nonlinear-Network_d2zmoRh9wTR/Improving-institutional-societal-decision-making_sumF-#_luOOZ | Nonlinear Network · Improving institutional / societal decision-making\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://docs.google.com/document/d/13Y803dvtZuhURiXKq5zZSmrnDtHJC_EcIdeWvGWnQNM/edit#heading=h.q4tgd1ai4pex | Jonas Schuett <> Renan Araujo - 2023-05-24 on XST strategy - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/t9e6enPXcH6HFzQku/why-altruists-can-t-have-nice-things | Why Altruists Can't Have Nice Things - EA Forum\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://philpapers.org/rec/BOTRRG | Christopher Bottomley & Timothy Luke Williamson, Rational risk‐aversion: Good things come to those who weight - PhilPapers\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://twitter.com/DrRyanBurnell/status/1671465666740666370 | Ryan Burnell on Twitter: \"How are the capabilities of large language models structured? In our new paper, we find that three broad abilities can explain most of the variance in performance across a wide range of LLMs and a broad set of cognitive tasks. Pre-print here: t.co/r1lycQG59R\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1674421368560156675 | (1) Robert Wiblin on Twitter: \"This is very good IMO: \"Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support. ... Our goal is to work with defenders to change the power dynamics of cybersecurity through AI\" t.co/S5q9CoUE8h\" / Twitter\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1671375922870759424 | Matthew Barnett on Twitter: \"I'm happy about regulating AI eventually. Heuristic: we regulate people strictly, and AI will be even more powerful than people. But I'm really averse to messaging that suggests GPT-4 is dangerous. I think we're still basically at the harmless tool stage.\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1SEMBvi9lZaCyTncBADOHyIjGdlfkRDkNagOSIA3x4js/edit#gid=0 | Blog calendar\n",
      "https://tellingthefuture.substack.com/p/we-must-live-together-or-perish | We Must Live Together Or Perish - by Robert de Neufville\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak – Windows On Theory\n",
      "https://twitter.com/Kirsten3531/status/1673948741374472198 | Kirsten on Twitter: \"Three tools your brain can use if it sees you trying to do something really hard with a low chance of success (like write the next great American novel):\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… t.co/Nikto4prZV\" / Twitter\n",
      "https://worksinprogress.co/issue/the-end-of-acid-rain | The end of acid rain - Works in Progress\n",
      "https://asteriskmag.com/issues/2/feeding-the-world-without-sunlight | Feeding the World Without Sunlight—Asterisk\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/ | FAQ on Catastrophic AI Risks\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I’m honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith 🐇🇺🇦 on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1674787966928195586 | twitter.com/robertwiblin/status/1674787966928195586\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge — Forgotten Trek\n",
      "https://worksinprogress.co/issue/parenting-as-a-public-good | Parenting as a public good - Works in Progress\n",
      "https://twitter.com/8teAPi/status/1671519543003422721 | Ate-a-Pi on Twitter: \"MSFT moves closer to human teaching a transformer Textbooks are All You Need - tiny model, 1% the size of GPT3, achieving x perf - first they examined the standard code dataset everyone trains on, The Stack - found it was confusing for an early learner. Lots of examples of… t.co/Xpg6Lcp1DB\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://docs.google.com/document/d/1BnI-FYzz0Coti2nV5t63w8Ga6WWiFSK_kYjE9T2SjLc/edit#heading=h.dcdsb7ob0lnc | * COLLECTION: Positive feedback / signals / praise for XST - Google Docs\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out …\" - Mastodon\n",
      "https://guarded-everglades-89687.herokuapp.com/?url=&title=&aggregator=-Custom&before=&after=&page=1&sort=&starred= | Upcoming Links\n",
      "https://forum.effectivealtruism.org/posts/4rp8rRjPAE6Hzs5ef/mathiaskb-s-shortform?commentId=72jKEA37fF8ro5LeQ | Why you should buy a desk treadmill\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model – Deconfusion Device – Failing to understand the world, learning a little along the way\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact — Rethink Priorities\n",
      "https://openai.com/blog/insights-from-global-conversations | Insights from global conversations\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://twitter.com/NeelNanda5/status/1672017323849560065 | (1) Neel Nanda on Twitter: \"Does superposition happen in real language models? In a new paper walkthrough, @wesg52 and I discuss his paper on Finding Neurons In A Haystack, and the evidence we've found. I helped supervise this paper, and am excited to explore it in detail! t.co/ZRkSoJifmF\" / Twitter\n",
      "https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety | A Field Guide to AI Safety—Asterisk\n",
      "https://twitter.com/DAlperovitch/status/1673897147110924291 | Dmitri Alperovitch on Twitter: \"Com­merce De­pt could move as soon as next month to stop ship­ments of AI chips made by Nvidia and others to China. “New restrictions be­ing con­tem­plated by the de­part­ment would ban the sale of even A800 chips with­out a li­cense”t.co/HhsaIF5RSn\" / Twitter\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power’s Staying Power\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://futureoflife.org/our-work/grantmaking-work/?fbclid=IwAR0o6_markFfphRleDNfVw3R_CdMUfZRv6cdY5OQay7K-uVpLXqIEBCImrk | Grantmaking work - Future of Life Institute\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://asteriskmag.com/issues/1/why-isn-t-the-whole-world-rich | Why Isn’t the Whole World Rich?—Asterisk\n",
      "https://twitter.com/blader/status/1670578014508433410 | Siqi Chen on Twitter: \"Terence Tao on his experience with GPT4 in mathematical research: \"The 2023-level AI can already generate suggestive hints and promising leads to a working mathematician and participate actively in the decision-making process.\" t.co/C0VnX8QZxY t.co/rhEJ3yXp8K\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/DdSszj5NXk45MhQoq/decision-making-and-decentralisation-in-ea | Decision-making and decentralisation in EA - EA Forum\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://twitter.com/teortaxesTex/status/1663897107642630145 | Teortaxes on Twitter: \"Rationalists are unable to inspect their abnormality. They are moral cripples who have stumbled on a crutch in the form of quasi-economic theory of maximizing utility, found that it fits, and reasoned that they're smart, ergo it's convergent for *all* intelligent entities. t.co/kAPYisWPOn\" / Twitter\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://theintrinsicperspective.com/p/stop-trying-to-make-a-good-social | Stop trying to make a \"good\" social media site\n",
      "https://metaculus.com/questions/17569/prigozhin-leads-wagner-on-june-30-2023/ | Prigozhin leads Wagner on June 30, 2023?  Metaculus\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://twitter.com/catehall/status/1674837401829769216 | twitter.com/catehall/status/1674837401829769216\n",
      "https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab | The rise and fall of the industrial R&D lab - Works in Progress\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://forum.effectivealtruism.org/posts/sFoqCw6BnZmJNxFda/an-update-on-the-spanish-speaking-ea-community | An update on the Spanish-speaking EA community — Effective Altruism Forum\n",
      "https://worksinprogress.co/issue/innovation-is-not-linear | Innovation is not linear - Works in Progress\n",
      "https://google.com/search?q=honest+trailers+john+wick+2&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+john+sick&gs_lcrp=EgZjaHJvbWUqCQgDEAAYDRiABDIGCAAQRRg5MgkIARAAGA0YgAQyCQgCEAAYDRiABDIJCAMQABgNGIAE0gEIOTUxNGowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers john wick 2 - Google Search\n",
      "https://worksinprogress.co/issue/the-housing-theory-of-everything | The housing theory of everything - Works in Progress\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://docs.google.com/document/d/1P2J7Jys4rZR2joQipPHTCVr7HPqUohtGQsicq9loA8k/edit#heading=h.rqhy3k5812zd | AIGS SFF June 2023 application notes - Google Docs\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://washingtonpost.com/technology/2023/06/28/openai-chatgpt-lawsuit-class-action/ | ChatGPT maker OpenAI faces class action lawsuit over data to train AI - The Washington Post\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://twitter.com/gwern/status/1674597983633956867 | (1) 𝔊𝔴𝔢𝔯𝔫 on Twitter: \"@MWCvitkovic Another entry in the 'you can just do things' files: t.co/jnKEomt49q\" / Twitter\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://noahpinion.blog/p/indiamerica?sd=pf | Indiamerica - by Noah Smith - Noahpinion\n",
      "https://twitter.com/jordanschnyc/status/1673847803691368448 | Jordan Schneider on Twitter: \"big if true. t.co/4tZYXCVF8y\" / Twitter\n",
      "https://twitter.com/StefanFSchubert/status/1672175939524984835 | Stefan Schubert on Twitter: \"\"Should Effective Altruists Focus On Air Pollution?\" I liked this talk by @FoundersPledge's Tom Barnes. From EAGx Cambridge (all videos just went up). t.co/SE1qGDgI3X t.co/hyxP11ocf3\" / Twitter\n",
      "https://twitter.com/StefanFSchubert/status/1671633702865043457 | Stefan Schubert on Twitter: \". @MatthewJBar arguing against the view that because \"OpenAI’s strategy assumes that short timelines and a slow, continuous takeoff is the safest path to AGI, it is a path we’re likely to take.\" I agree with his reasoning. t.co/em5WndQhN7 t.co/VOospw2zNm\" / Twitter\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://twitter.com/Lance_Ying42/status/1674411924187152384 | Lance Ying on Twitter: \"Can LLMs perform social reasoning? In this paper with @xuanalogue @katie_m_collins @MeganJWei, Lionel Wang, Cedegao Zhang, @adrian_weller and Josh Tenenbaum, we propose a model using LLM as a semantic parser and inverse planning as an inference engine. t.co/qW9otezTtI t.co/HeesmziMbY\" / Twitter\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion’s AI Benefactor Has A History Of Exaggeration\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://worksinprogress.co/issue/thomas-edison-tinkerer | Thomas Edison, tinkerer - Works in Progress\n",
      "https://twitter.com/JeffLadish/status/1673469056882728960 | Jeffrey Ladish on Twitter: \"How dangerous is it that a LM can direct a robot to synthesize molecules like this with only a tiny bit of code scaffolding and a couple sentences of a prompt? Two key questions 1) How many people can do this right now? 2) What is the trajectory of AI capabilities like these?\" / Twitter\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://twitter.com/messages/25776739-1631315348 | Ted / Twitter\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://twitter.com/JonasSandbrink/status/1674043107841568769 | Jonas Sandbrink on Twitter: \"How can AI exacerbate biosecurity risks? My new preprint gives an overview of crucial considerations and possible interventions. t.co/4DYupGyopU 🧵1/9\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | Jeffrey Ladish on Twitter: \"I really appreciate that @RishiSunak is explicitly acknowledge the existential and catastrophic risks faced by AI. To have a competent global response we have to start here Also, accelerating AI development ⏩ is probably the single most dangerous thing you can do in the world\" / Twitter\n",
      "https://csis.org/events/sen-chuck-schumer-launches-safe-innovation-ai-age-csis | Sen. Chuck Schumer Launches SAFE Innovation in the AI Age at CSIS  CSIS Events\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://twitter.com/sebkrier/status/1671194525988003840 | Séb Krier on Twitter: \"Forgot how good this @WaqarHZaidi &amp; @AllanDafoe paper is. Very relevant and lots of fascinating insights throughout. t.co/8otOY8wLqv t.co/Rq0afRYpen\" / Twitter\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://docs.google.com/document/d/1QHr0oko6Eg0wA4xw8ZjzI9AlQxTIJXxhkSs9wfw1JpU/edit | Reactive availability restrictions for deployed AI models [WiP] - Google Docs\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://twitter.com/MatthewJBar/status/1673408808998297600 | Matthew Barnett on Twitter: \"In which I outline my AI 'optimism' story, which is the version of the future I find most likely: t.co/N0cixmrcyM\" / Twitter\n",
      "https://worksinprogress.co/issue/how-trust-undermines-science | How trust undermines science - Works in Progress\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://facebook.com/photo/?fbid=658421726326436&set=a.497682632400347 | Facebook\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://worksinprogress.co/issue/on-the-origins-of-empathy-for-other-species | On the origins of empathy for other species - Works in Progress\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://twitter.com/bill_drexel/status/1671197788024057857 | (1) Bill Drexel on Twitter: \"I'm biased, but @paul_scharre's new piece in @ForeignPolicy seems to me to give the most comprehensive and readable overview available of the stakes and policy levers around advanced AI development. If you want to get up to speed quickly, read below: t.co/npX1t8mCSG\" / Twitter\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://facebook.com/taiyanghua3/posts/pfbid07vXQvuz3PZsHfzVLWQbZBX6KywagtRKs2ycew7GejKtQnhntPqLzUFghHzc1DGrPl | facebook.com/taiyanghua3/posts/pfbid07vXQvuz3PZsHfzVLWQbZBX6KywagtRKs2ycew7GejKtQnhntPqLzUFghHzc1DGrPl\n",
      "https://forum.effectivealtruism.org/posts/p6oP854ZCZ6skojx6/juan-b-garcia-martinez-on-tackling-many-causes-at-once-and | Juan B. García Martínez on tackling many causes at once and his journey into EA — EA Forum\n",
      "https://worksinprogress.co/issue/developing-the-science-of-science | Developing the science of science - Works in Progress\n",
      "https://twitter.com/yoavgo/status/1672647224696684545 | (((ل()(ل() 'yoav))))👾 on Twitter: \"\"in 1 hour\"? these MIT students are kinda slow... t.co/2Le4l7Fq0V\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://forum.effectivealtruism.org/posts/SZJBE3fuk2majqwJQ/principles-for-ai-welfare-research | Principles for AI Welfare Research - EA Forum\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://twitter.com/robinhanson/status/1671664705255927811 | Robin Hanson on Twitter: \"Software is 75 years old today: \"The very first time a stored-program computer held a piece of software in electronic memory and executed it successfully, was 11 am 21 June 1948, at the University of Manchester, on the Manchester Baby computer.\" t.co/UJydWK8gRa\" / Twitter\n",
      "https://asteriskmag.com/issues/03/how-we-can-regulate-ai | How We Can Regulate AI—Asterisk\n",
      "https://twitter.com/LongResilience/status/1671793646385917954 | (1) The Centre for Long-Term Resilience on Twitter: \"Our Head of AI Policy, @jesswhittles, was recently interviewed for this @TIME article on @RishiSunak’s ambition for the UK to be a global leader in AI regulation. A 🧵 on key points from the piece: t.co/p682NhXThy 1/4\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://docs.google.com/document/d/1rwLFr15536l08wKslhMF6ZHOGvIQ4DIION1jK25_oIE/edit#heading=h.jl93l1npdui2 | [Ashwin evaluating Oliver] - July 2023 - RP Performance Evaluation - Google Docs\n",
      "https://asteriskmag.com/issues/1/how-to-prevent-the-next-pandemic | How to Prevent the Next Pandemic—Asterisk\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://twitter.com/ohlennart/status/1671203769357414412 | Lennart Heim on Twitter: \"We submitted a response to the NTIA's requests for comments on AI Accountability Policy. We focused on audits and assessments of foundation models. 🧵 t.co/r8lpRsMXjW t.co/FrFdVPG0Im\" / Twitter\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://ft.com/content/44947c05-5217-4593-86d7-1ea52dcbafb9?accessToken=zwAF_xxJIaCIkc9ElHwFUhdFk9OG1x6lLcuvuQ.MEUCIQC4xP6ypi_P50ek77bezs0HmXO6BqIHYNTfrZ4A4q9_BgIgKBrZIgcJJAWK5ondCDrdIIp26NXYc3wF2RcsXCPzuf0&sharetype=gift&token=ebe2e5f7-d5f2-4388-a9b9-0e3fbbef1797 | Russia drops uprising charges and says Wagner will hand over weapons  Financial Times\n",
      "https://metaculus.com/questions/14260/average-us-cpi-in-2023-over-4/#comment-126125 | Average US CPI in 2023 over 4%?  Metaculus\n",
      "https://twitter.com/LuiseWoehlke/status/1670430498387111936 | Luise Wöhlke on Twitter: \"☀️🌴 I wrote a much-needed update to my June 2022 post on spending summer in the Bay Area, aka my love letter to the Bay. ☀️🌴 If you've read it and are considering going, I recommend you read the updates which strike a more critical note! :) t.co/y9UxkTqLLV t.co/9eY3R3LjZY\" / Twitter\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://encultured.ai/ | Encultured AI\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection · Getting started with tpot\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://gwern.net/fiction/clippy | It Looks Like You’re Trying To Take Over The World\n",
      "https://twitter.com/robertwiblin/status/1672178211336204288 | Robert Wiblin on Twitter: \"I speak with @ohlennart: \"If compute governance is only a temporary phase between the era of difficult-to-train superhuman AI models and the time when such models are widely accessible — what can we do to prevent misuse of AI systems after that point?\" t.co/XY9jRJLeCj\" / Twitter\n",
      "https://metaculus.com/tournament/future-of-china/ | China and Global Cooperation - Metaculus\n",
      "https://lesswrong.com/posts/f3kM7NM5eGMTp3KtZ/lessons-on-how-to-get-things-right-on-the-first-try | Lessons On How To Get Things Right On The First Try - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/chqv4wneoXHpHzdQk/ce-rigorously-prioritizing-the-top-health-security | CE: Rigorously prioritizing the top health security (biosecurity) ideas — EA Forum\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://worksinprogress.co/issue/how-we-fixed-the-ozone-layer | How we fixed the ozone layer - Works in Progress\n",
      "https://twitter.com/LukeyEllsberg/status/1670153020795936771 | lukey on Twitter: \"May my grandfather @DanielEllsberg’s memory be a blessing in the only way that would have matter to him - as an example of how we may all rise to the challenge of responsibility &amp; love for humanity. t.co/QODXZnSO97\" / Twitter\n",
      "https://eukaryotewritesblog.com/2023/06/24/chronic-wasting-disease/?fbclid=IwAR2RthzoTuDj9cpeUcgh6KYnfgt0HGtcq8K5wM35L_i1upzFDgifSgFTqqM | Will the growing deer prion epidemic spread to humans? Why not?  Eukaryote Writes Blog\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://reddit.com/r/truerateme/ | reddit.com/r/truerateme/\n",
      "https://lesswrong.com/posts/HCAyiuZe9wz8tG6EF/my-tentative-best-guess-on-how-eas-and-rationalists#comments | My tentative best guess on how EAs and Rationalists sometimes turn crazy - LessWrong\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won’t)🧵 t.co/23ErIoRIsk\" / Twitter\n",
      "https://asteriskmag.com/issues/03/emotional-intelligence-amplification | Emotional Intelligence Amplification—Asterisk\n",
      "https://forum.effectivealtruism.org/posts/EEMpNRJK5qqCw6zqH/a-cost-effectiveness-analysis-of-historical-farmed-animal | A Cost-Effectiveness Analysis of Historical Farmed Animal Welfare Ballot Initiatives - EA Forum\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://worksinprogress.co/issue/what-ails-the-social-sciences | What ails the social sciences - Works in Progress\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/ | LLM Powered Autonomous Agents  Lil'Log\n",
      "https://twitter.com/messages/25776739-757517000 | twitter.com/messages/25776739-757517000\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.9ick7xqcwurb | RP’s AI Governance & Strategy team - 2-pager - Google Docs\n",
      "https://twitter.com/Kirsten3531/status/1560374030611361792 | Kirsten on Twitter: \"Assorted things I learned from teaching that are super helpful working in an office:\" / Twitter\n",
      "https://noahpinion.blog/p/four-reasons-china-cant-reset-the | Four reasons China can't reset the world - by Noah Smith\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://twitter.com/oziadias/status/1671953107180478464 | (2) Ziad Obermeyer on Twitter: \"Those of us building health AI products have a problem: Our algorithms look great—in our own data But how will they perform elsewhere? On other machines? On diverse patients? We’ve built a way to find out, at @Dandelion_AI4H: A free, public service for algorithm audits t.co/mduBOUtON1\" / Twitter\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It’s infuriatingly hard to understand how closed models train on their input\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://forum.effectivealtruism.org/posts/LEEcSn4gt7nBwBghk/munk-ai-debate-confusions-and-possible-cruxes | Munk AI debate: confusions and possible cruxes — EA Forum\n",
      "https://ealifestyles.substack.com/p/will-macaskill-names-17-senior-figures | Will MacAskill names 17 \"senior figures\" in EA\n",
      "https://worksinprogress.co/issue/the-most-dangerous-substance-known-to-man | The most dangerous substance known to man - Works in Progress\n",
      "https://docs.google.com/document/d/1PZ7ZVTfIt0T_TgOBTQTLOOne7iakfQDW6uBjEyFMhQo/edit#heading=h.x8vizs97cm8 | AIGS June 2023 comms materials for review - Google Docs\n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI’s Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | We must slow down the race to God-like AI\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://bloomberg.com/opinion/articles/2023-06-18/i-95-repair-in-philadelphia-why-can-t-all-projects-be-this-fast?utm_campaign=socialflow-organic&utm_content=view&utm_source=twitter&cmpid%3D=socialflow-twitter-view&utm_medium=social&leadSource=uverify%20wall | I-95 Repair in Philadelphia: Why Can't All Projects Be This Fast? - Bloomberg\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://docs.google.com/document/d/13tdTHfCU2JaYW0jrbIYDhoTPfQ1rtWIQJ9VBvGrfY8U/edit | Media Training for AI Safety - notes by Renan - Google Docs\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://thezvi.substack.com/p/the-dial-of-progress | The Dial of Progress - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://twitter.com/tomgoldsteincs/status/1670893835793186816 | Tom Goldstein on Twitter: \"Training an LLM takes about 1 trillion words. That’s about 30,000 years of typing. But where does this data come from? And what does this have to do with the Reddit protests? Here’s how OpenAI trains models on “the entire internet.” 🧵📜\" / Twitter\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://twitter.com/TechFTC/status/1674485450621198338 | (1) FTC's Office of Technology on Twitter: \"In blog post, FTC staff identifies a few of the essential technical building blocks of generative AI and discusses competition concerns potentially raised by generative AI. t.co/Tyeu4M4Zza\" / Twitter\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://foreignpolicy.com/2023/06/19/us-china-ai-race-regulation-artificial-intelligence/ | AI Is Winning the U.S.-China AI Race\n",
      "https://twitter.com/xuanalogue/status/1674410315432247297 | xuan (ɕɥɛn / sh-yen) on Twitter: \"How do we infer the goals &amp; plans of others from both their actions &amp; words? In this paper with @Lance_Ying42, we infer a team's goal via inverse planning (aka \"inverse RL\"), using LMs* as likelihood functions over utterances! (*GPT-3 Curie 6.7B, but smaller LMs may also work!)\" / Twitter\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://forum.effectivealtruism.org/posts/czsP5iWmz3wLtz7LT/question-and-answer-based-ea-communities | Question and Answer-based EA Communities - EA Forum\n",
      "https://twitter.com/michael_nielsen/status/1671265487056162823 | Michael Nielsen on Twitter: \"A thoroughly fascinating table, from: t.co/kZ10mzerVW t.co/ofJTJN99sl\" / Twitter\n",
      "https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html | Inside the AI Factory: The Humans That Make Tech Seem Human\n",
      "https://docs.google.com/document/d/1R_yudIhkh8YJXRO20vDgGUkbklXpg2MrWF8bxAtcugo/edit#heading=h.tcmcuy30mpts | Julia’s takes on movement-wide codes of conduct\n",
      "https://twitter.com/pgodfreysmith/status/1673114925995261952 | Peter Godfrey-Smith on Twitter: \"\"Finding Consciousness in Phylogenetically Distant Organisms\" – a thread with a few slides and references from my talk at @ASSC26nyc this afternoon. 1/ t.co/Tgboy6QAhU\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ - EA Forum\n",
      "https://asteriskmag.com/issues/1/making-sense-of-moral-change | Making Sense of Moral Change—Asterisk\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://docs.google.com/document/d/15NjS-daWFjJPFOCX8UzAvLOueH-STrCfPQ7GW4RgRns/edit#heading=h.bjudb4kzpqqu | Manual of Me: Comms Edition - Google Docs\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://worksinprogress.co/issue/better-eats | Better eats - Works in Progress\n",
      "https://twitter.com/messages/25776739-128178067 | twitter.com/messages/25776739-128178067\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit#heading=h.mfc0g6vdbaom | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes - Google Docs\n",
      "https://twitter.com/AnthropicAI/status/1674461614056292353 | (1) Anthropic on Twitter: \"We develop a method to test global opinions represented in language models. We find the opinions represented by the models are most similar to those of the participants in USA, Canada, and some European countries. We also show the responses are steerable in separate experiments. t.co/QzHmRPNqSl\" / Twitter\n",
      "https://docs.google.com/document/d/1p7xqop2FlIF8Kw45za0NnJPwvUA70Mb1UzjijMRKRr8/edit#heading=h.deq8lzwofh50 | Cost-Effectiveness Analysis of Animal Ballot Initiatives - Google Docs\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://google.com/search?q=honest+trailers+star+wars&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+wars&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQLhiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjIICAUQABgWGB4yCAgGEAAYFhgeMggIBxAAGBYYHjIICAgQABgWGB4yCggJEAAYhgMYigXSAQkxMTc2NmowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star wars - Google Search\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings – 2023 Q2-Q3 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://lesswrong.com/posts/t5W87hQF5gKyTofQB/ufo-betting-put-up-or-shut-up | UFO Betting: Put Up or Shut Up\n",
      "https://twitter.com/jankulveit/status/1670735364707721216 | Jan Kulveit on Twitter: \"Fascinating &amp; seems reproducible! Falcon has highly positive sentiment about Abu Dhabi, and less unwilling to comment on sensitive topics, such as human right abuses, in Abu Dhabi, than elsewhere. Could have various causes, but it's an important reminder that open source-model… t.co/kWtUqU55fN\" / Twitter\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://docs.google.com/document/d/1I6PEBNI1qC2ezMw_Tzi-4u098_5QjAn-hR61gRr6Tjc/edit | LTFF application for XST 2023-06 - Google Docs\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://asteriskmag.com/issues/1/rebuilding-after-the-replication-crisis | Rebuilding After the Replication Crisis—Asterisk\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid02xnCGBCSDooHD73pexpgwr3rUJ8mSvYq8aGVzrww1vRkXCk9yasLQh6nkZ7xf4kvbl | Ozzie Gooen - One factor that destroys organizational transparency...  Facebook\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://lesswrong.com/posts/4gDbqL3Tods8kHDqs/limits-to-legibility | Limits to Legibility — LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1g_xBccR_HTFfg-VIEE5MKsooC_aDz0BZ0AJV_XzSX2Q/edit#gid=1359765821 | 2023 June Lights - Google Sheets\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://worksinprogress.co/issue/seeing-on-the-far-side-of-the-moon | Seeing on the far side of the moon - Works in Progress\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://worksinprogress.co/issue/biases-the-wrong-model | We don’t have a hundred biases, we have the wrong model - Works in Progress\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://docs.google.com/document/d/1I9Fw8Y3tdQWEIOIdFRRIvYBISLg0_uKLZgOSn09-9aU/edit#heading=h.lqtiq1w77guj | Training Process Transparency through Gradient Interpretability: Some preliminary results for toy language models\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://worksinprogress.co/issue/practical-veganism | Practical veganism - Works in Progress\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://niplav.site/ | Content – niplav\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/5inarAxrymywW6JPC/everything-i-didn-t-know-about-fertilizers-1 | Everything I didn't know about fertilizers — EA Forum\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://worksinprogress.co/issue/why-britain-doesnt-build | Why Britain doesn’t build - Works in Progress\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://twitter.com/daniel_271828/status/1672788522665914368 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"If you're wondering what AI researchers who talk about extinction risk actually mean by \"extinction\", here are quotes from a few of the more prominent researchers on their worries: t.co/OIgTjW96ag\" / Twitter\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://docs.google.com/document/d/1Oqj1aK9aVEsUnTyOQDaYOmfKv6zyh16foAsR8beFLL0/edit | Motivations & milestones for valence studies - Google Docs\n",
      "https://docs.google.com/document/d/1RL3ymf5Q_lcdF5TbHg9KDDM6B4fi8OAuAJmQGHYBszU/edit | Present to LT squad + other leadership on AIGS + XST plans (including AIGS rebrand) - Google Docs\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://worksinprogress.co/issue/asteroid-spotting | Asteroid spotting - Works in Progress\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1567926384676450304 | (3) xuan (ɕɥɛn / sh-yen) on Twitter: \"Gave another talk on AI alignment, this time at #EAGxSingapore last week -- appreciated the chance to condense my recent thinking about what it means to \"align\" AI in a world with a diversity of people &amp; values by asking \"What Should AI Owe To Us?\" (1/11) t.co/UBBnr13Vw7 t.co/7RH0o3T80f\" / Twitter\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fI6JUcI796OKohKILyJQ_xpU2vY25egUq6A-wX_OUjo/edit#gid=0 | Streaming services - Google Sheets\n",
      "https://twitter.com/benedictcooney/status/1670693039327649792 | (1) Benedict Cooney on Twitter: \"We did say a shake-up was necessary t.co/i36Z87oNRs\" / Twitter\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://metaculus.com/questions/17418/most-expensive-ai-training-run-by-year/ | Most Expensive AI Training Run by Year  Metaculus\n",
      "https://arxiv.org/abs/2306.12001 | [2306.12001] An Overview of Catastrophic AI Risks\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://asteriskmag.com/issues/2/what-comes-after-covid | What Comes After COVID—Asterisk\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://worksinprogress.co/issue/this-is-what-peak-culture-looks-like | This is what peak culture looks like - Works in Progress\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://worksinprogress.co/issue/taming-the-stars | Taming the stars - Works in Progress\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://twitter.com/jesswhittles/status/1674729420240703488 | Jess Whittlestone on Twitter: \"I've got an op ed in @timesredbox today on what the UK government needs to do if it wants to truly establish itself as a leader in global AI governance. t.co/jcHAmFjRZg I suggest three key things need attention - summarised in 🧵 below:\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://forum.effectivealtruism.org/posts/CEtKAP5Gr7QrTXHRW/on-focusing-resources-more-on-particular-fields-vs-ea-per-se | On focusing resources more on particular fields vs. EA per se - considerations and takes - EA Forum\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid0KsTRs5YSTfGh2s8wia8Ji3tuYSKM5DqDMJ64WQWGzj7cjKtDNHd5A4aegn6V6Agpl | Ozzie Gooen - Meta has been doing really well since its low in Nov...  Facebook\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://twitter.com/random_walker/status/1672244743219077123 | Arvind Narayanan on Twitter: \"Billions of people doing clickwork for AI sounds more dystopian than most of the AI safety risk scenarios that have been proposed tbh t.co/jmEdpp4pxJ\" / Twitter\n",
      "https://80000hours.org/problem-profiles/great-power-conflict/ | Great power conflict - 80,000 Hours\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://twitter.com/SpecialPuppy1/status/1671249200326012928 | Special Puppy 🧦🐵 on Twitter: \"How are you a mom of 4 at 22?!? (I feel really bad for this woman, but idk how she put herself in this situation)\" / Twitter\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 – Rodney Brooks\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://docs.google.com/document/d/1OToyPO8IH3eRAfBpY_zhYp0uPmDbs88RioSEfwHB0DE/edit#heading=h.7oseyc1v098r | [draft] base XST+AIPLUS SFF speculation grant application H1 2023 - Google Docs\n",
      "https://twitter.com/DavidSKrueger/status/1672464907957149696 | David Krueger on Twitter: \"58% expressed some level of agreement. 26% expressed some level of disagreement.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/AdouuTH7esiDQPExz/announcing-ce-s-new-research-training-program-apply-now | Announcing CE’s new Research Training Program - Apply Now! — EA Forum\n",
      "https://twitter.com/SSGamblers/status/1674675424356442112 | Star Spangled Gamblers on Twitter: \"New Podcast Episode @WineMomPI, @GaetenD, and @TheWinner2875 discuss: — Dating advice for political gamblers — A new Title Belt challenge on Trump’s nicknames for @RonDeSantis — When Trump will show up to a @GOP debate and who he will attack t.co/oQfN4ENInT\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/rLLRo9C4efeJMYWFM/welfare-ranges-per-calorie-consumption | Welfare ranges per calorie consumption - EA Forum\n",
      "https://docs.google.com/document/d/1Tsp_wK6GoJAgUCYoZmMN_H7vy3eG3r68IUAWjg5Qy6Y/edit | Management Copy - Bob Fischer 2023 May/June - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://twitter.com/tmkadamcz/status/1674052524184154117 | Tom Adamczewski on Twitter: \"I work a _lot_ with SciPy probability distributions, and have developed a set of tools over time I've now released many of them in a package: ✨rvtools🔨 t.co/ciBruBxLjD Useful shortcuts, additional distributions, and some opinionated changes to SciPy APIs t.co/7Rg7ytXgsu\" / Twitter\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D | Baby steps in evaluating the capacities of large language models  Nature Reviews Psychology\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://docs.google.com/document/d/1ZCMSk2s0ylDsKJ2JMuDIxgVrJE9VfuSSrp2vrzE3iuE/edit#heading=h.y0srbz710jxs | Call notes: Jam-Jake Swett [19 June 2023] Topic: AIPLUS - Google Docs\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://docs.google.com/document/d/1lrs-UuqZYTzcSvqRR73kDyT6nKzr_EQ2Ex4zvmynCjI/edit | Proposal for how comms and fundraising should work when AIGS rebrands - Google Docs\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://twitter.com/EAheadlines/status/1673764181789556737 | EA Lifestyles on Twitter: \"okay I finally looked up all the people on Will's list of senior figures in ea and I have a lot of feeeeeelings\" / Twitter\n",
      "https://google.com/search?q=beyond+this+moment&rlz=1C5CHFA_enGB1058GB1058&oq=beyond+this+moment&aqs=chrome.0.0i355i512j46i512j0i512j46i512j0i512j46i340i512j0i512j0i22i30l3.2523j0j1&sourceid=chrome&ie=UTF-8 | beyond this moment - Google Search\n",
      "https://docs.google.com/document/d/1ziNrskp-v_jWihUakPIhSLqdu6WJY-mA0152RUcLqQc/edit | AIGS Leads notes (Michael, Peter, Zoe, often Ashwin) - 2023 May-Sep - Google Docs\n",
      "https://docs.google.com/document/d/1Kqqv2_OidYijdQUJ24YW39aackvu6-q-LdDaC23Ori8/edit | Docs since January - Google Docs\n",
      "https://google.com/search?q=honest+trailers+star+trek&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+tre&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIKCAMQABiGAxiKBTIKCAQQABiGAxiKBdIBCDY1MTFqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star trek - Google Search\n",
      "https://twitter.com/DavidSKrueger/status/1672082616672047109 | (1) David Krueger on Twitter: \"My slides from EAG London talk, IYI: t.co/k58MoowgGb And resharing the link to video: t.co/ZDAgCpvW2i\" / Twitter\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://metaculus.com/ai/ | The Metaculus Lens on AI\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://forum.effectivealtruism.org/posts/qAbKiFYc2Skg3r5at/short-bios-of-17-senior-figures-in-ea | Short bios of 17 \"senior figures\" in EA — EA Forum\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://forum.effectivealtruism.org/events/TmeXfqjWqtpuWJnjr/ea-taskmaster-2023 | EA Taskmaster 2023 - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety\n",
      "https://worksinprogress.co/issue/history-is-in-the-making | History is in the making - Works in Progress\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://jeffsebodotnet.files.wordpress.com/2023/06/moral-consideration-for-ai-systems-by-2030-4.pdf | Moral Consideration for AI Systems by 2030.docx\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok 🏗️🚀 on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://worksinprogress.co/issue/how-covid-brought-the-future-back | How Covid brought the future back - Works in Progress\n",
      "https://forum.effectivealtruism.org/posts/K7F8pF38SKnrxDsza/crisis-boot-camp-lessons-learned-and-implications-for-ea | Crisis Boot Camp: lessons learned and implications for EA - EA Forum\n",
      "https://docs.google.com/document/d/1rKcUmCDDB-0Kp759ylO4uNIZzrehSDNeta6PrM888uo/edit | [Shared w/ SFF] Internal Notes from DC meetings - Google Docs\n",
      "https://docs.google.com/document/d/1HlkOSn7HGkRIffkwMQS2ZtCcvCRHn5Akt2ptfidwLso/edit | Maybe if time permits get more advice on how I can be more helpful to Michael + AIGS - Google Docs\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://docs.google.com/document/d/1egHpma3StcmGUIm3osmRZefquvbsanitSNSMq2J3IS4/edit | Possibly Making Aesthetically Pleasing PDF RP Reports - Google Docs\n",
      "https://twitter.com/NiklasLauffer/status/1670854905513512960 | Niklas Lauffer on Twitter: \"🤝🤔𝙒𝙝𝙖𝙩 𝙙𝙤 𝙬𝙚 𝙣𝙚𝙚𝙙 𝙩𝙤 𝙠𝙣𝙤𝙬 𝙖𝙗𝙤𝙪𝙩 𝙚𝙖𝙘𝙝 𝙤𝙩𝙝𝙚𝙧 𝙩𝙤 𝙨𝙪𝙘𝙘𝙚𝙨𝙨𝙛𝙪𝙡𝙡𝙮 𝙘𝙤𝙡𝙡𝙖𝙗𝙤𝙧𝙖𝙩𝙚?? In our new ICML paper, we provide a method that determines exactly the information you need to be an optimal teammate in multiagent games. [1/10] t.co/DERhRtguLd\" / Twitter\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain’s AI dreams reality\n",
      "https://spylab.ai/blog/chatbot-adversarial-examples/ | Adversarial examples in the age of ChatGPT  SPY Lab\n",
      "https://twitter.com/base_rate_times/status/1671715701034479617 | The Base Rate Times on Twitter: \"There is a News tab on @ManifoldMarkets now! This is what their Russia-Ukraine coverage looks like. Check it out t.co/B3izRnCmT7\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KE4Ga3zHQsczooQi7/correctly-calibrated-trust | Correctly Calibrated Trust - EA Forum\n",
      "https://twitter.com/random_walker/status/1673894212490735616 | Arvind Narayanan on Twitter: \"Yup. I wonder how many people in the AI safety debate are familiar with the Crypto(graphy) Wars and the immense, permanent damage caused by the US gov's maddeningly misguided and ultimately futile effort to regulate cryptography as munitions. t.co/UNcblAPgfr\" / Twitter\n",
      "https://docs.google.com/document/d/1RMjcOgNwZWvBzfu5oB_llwAThk15QpGTLxy_eLBwVLE/edit | WIT Sequence #1 - Google Docs\n",
      "https://docs.google.com/document/d/1gJImzAEBg7idY5FrwGisK6BYo2NLW1WYcGPrs1I2ESY/edit | AIGS rebranding working group - meeting notes - Google Docs\n",
      "https://asteriskmag.com/issues/03/through-a-glass-darkly | Through a Glass Darkly—Asterisk\n",
      "https://youtube.com/playlist?list=PLwp9xeoX5p8MbksBvu_R_IOz6kD4H7ytC | EA Global: London 2023 - YouTube\n",
      "https://docs.google.com/document/d/1XsSriKA4YWqD6KRqcUg6CvxhaE1SPVYo_O-QCZEazoQ/edit#heading=h.1u4lkskbhszs | Lionheart AI safety fund feasibility study v0.2 - Google Docs\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities – AI Impacts\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women’s Pleasure\n",
      "https://twitter.com/amasad/status/1670473919504220160 | Amjad Masad on Twitter: \"There is a non-zero chance BabyAGI will self-replicate inside Replit and take over our cloud. If it happens it happens.\" / Twitter\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://twitter.com/BasilHalperin/status/1673822832193679365 | Basil Halperin on Twitter: \"IMO this is the best compendium of available arguments that ‘the singularity is not (too) near (probably)’… great piece\" / Twitter\n",
      "https://twitter.com/contextdogs/status/1672760515074879491 | out of context dogs on Twitter: \"t.co/LTNWZVENEV\" / Twitter\n",
      "https://twitter.com/andrewwhite01/status/1670794000398184451 | Andrew White on Twitter: \"We report a model that can go from natural language instructions, to robot actions, to synthesized molecule with an LLM. We synthesized catalysts, a novel dye, and insect repellent from 1-2 sentence instructions. This has been a seemingly unreachable goal for years! 1/3 t.co/vl65FqSHN2\" / Twitter\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://twitter.com/sdorkenw/status/1674859033076072448 | Sven Dorkenwald on Twitter: \"We are releasing a whole-brain connectome of the fruit fly, including ~130k annotated neurons and tens of millions of typed synapses! Explore the connectome: t.co/EWcwRiO0Oz Reconstruction paper: t.co/wCI3hASUfD Annotation paper: t.co/3bPTNK9hRk 1/6 t.co/dxyZIhSITg\" / Twitter\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://ntia.gov/issues/artificial-intelligence/request-for-comments | AI Accountability Policy Request for Comment  National Telecommunications and Information Administration\n",
      "https://twitter.com/TheZvi/status/1673297049180160000 | Zvi Mowshowitz on Twitter: \"This link to Google labs seems to work instantly to give you GMail generative AI access: t.co/sxtnX2OalE\" / Twitter\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1fk6jAn4rpbx1T9kKYl-3C9TJHQA8ZC6lFNpT5QawNbs/edit#gid=1486977631 | 2023 Stats - Google Sheets\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://docs.google.com/document/d/16Rzr6EnH3BHE8kUACDmCu57AyPgby9uaHfkNkqJ2_tc/edit#heading=h.ej16jqti74hb | EA Infosec fieldbuilding post 2023-Jun-9 - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://worksinprogress.co/issue/the-future-of-weight-loss | The future of weight loss - Works in Progress\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://twitter.com/TmarcoH/status/1674063185010147330 | Marco Hernandez on Twitter: \"The advance of the Ukrainian counteroffensive must face great challenges to advance on the ground occupied by the Russians. I did some illustrations to explain it better: t.co/tdiM0247G5 #UkraineWar t.co/ePHBTsVoFU\" / Twitter\n",
      "https://engelsbergideas.com/notebook/russia-a-short-history-of-failed-coups/ | Russia: a short history of failed coups - Engelsberg ideas\n",
      "https://asteriskmag.com/issues/2/my-primal-scream-of-rage-the-big-alcohol-study-that-didn-t-happen | My Primal Scream of Rage: The Big Alcohol Study That Didn't Happen—Asterisk\n",
      "https://forum.effectivealtruism.org/posts/dikcpP32Q3cg6tvdA/ai-incident-sharing-best-practices-from-other-fields-and-a | AI Incident Sharing - Best practices from other fields and a comprehensive list of existing platforms — EA Forum\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://fly.io/blog/we-raised-a-bunch-of-money/ | We Raised A Bunch Of Money · Fly\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://twitter.com/business/status/1673877471819878400 | Bloomberg on Twitter: \"🇨🇳THREAD: 1) China is trying to catch up to the US in the AI arms race, but here's why it has a long way to go ⬇️ t.co/rOCJZnaGfn\" / Twitter\n",
      "https://twitter.com/goodside/status/1672806305885552640 | Riley Goodside on Twitter: \"SequenceMatch is a good read — TLDR: LLMs are only trained to continue real text, but used to continue their own. errors compound; text goes OOD so, add a backspace key; train on fake backspaced errors and use 𝜒² over MLE. better output, higher MAUVE t.co/697Ntmtwou t.co/XxALGSH8ez\" / Twitter\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://twitter.com/araujonrenan/status/1672558931581759489 | Renan Araujo on Twitter: \"I think the strategy behind building the field of AI safety in LMIC has changed a lot over the last year, and I tried to articulate this in this post. t.co/jTdRIxMswL\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://twitter.com/acritschristoph/status/1673034164973764608 | Alex Crits-Christoph @alexcc@mstdn.science on Twitter: \"There has been much recent misinformation about COVID-19 origins that we can now debunk. A thread on 2 topics: A. How the ODNI report debunks multiple lab origins rumors. B. Where these inaccurate media reports originated, and why we knew they were wrong. t.co/5XMugelzoz\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://twitter.com/robertwiblin/status/1671832924771983368 | (1) Robert Wiblin on Twitter: \"Carl Shulman's interview on The Lunar Society Podcast is one of the best things produced on AI this year. Challenging and assumes substantial existing knowledge — but mandatory listening for people sincerely trying to understand these issues IMO: t.co/uc25oBnIV5\" / Twitter\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are | Are We Smart Enough to Know How Smart AIs Are?—Asterisk\n",
      "https://docs.google.com/spreadsheets/d/1Q-bgYcX5Wa06Hxzj46AaPsj4G_KtkLlEyVpj8fs6HNU/edit#gid=0 | 2023-06 AIGS budget [SFF] - Google Sheets\n",
      "https://docs.google.com/document/d/1WbINVhU5MtNGsb7bWM9pHPQYpW18aZJ9fVDVtHV5ZAA/edit | 2023-06 SFF long-form attachment for AIGS - Google Docs\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth | The Great Inflection? A Debate About AI and Explosive Growth\n",
      "https://twitter.com/jerryjliu0/status/1670466808384745472 | Jerry Liu on Twitter: \"Agents 🤖 built with the @OpenAI function API can do advanced data analysis out of the box 🕵️ We’re excited to introduce a brand-new cookbook highlighting these tasks + limitations! 🧑‍🍳👇 - Vector db auto-retrieval - Joint Text-to-SQL + Semantic Search t.co/keofhxZ5tX\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://worksinprogress.co/issue/why-innovation-prizes-fail | Why innovation prizes fail - Works in Progress\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won’t take it over by playing “3-dimensional chess”. – Windows On Theory\n",
      "https://worksinprogress.co/issue/real-peer-review | Real peer review has never been tried - Works in Progress\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know/ | The Many Ways that Digital Minds can Know – Ryan Moulton's Articles\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | αlpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://worksinprogress.co/issue/securing-posterity | Securing posterity - Works in Progress\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://worksinprogress.co/issue/every-grain-of-rice | Every grain of rice - Works in Progress\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | Séb Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here’s a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. 🏛 t.co/1Grjv93laf\" / Twitter\n",
      "https://worksinprogress.co/issue/pandemic-prevention-as-fire-fighting | Pandemic prevention as fire-fighting - Works in Progress\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://forum.effectivealtruism.org/posts/cJLsd2TYxv8KCzHvg/announcing-the-aipolicyideas-com-database | Announcing the AIPolicyIdeas.com Database - EA Forum\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://medium.com/@sefashapiro/a-community-warning-about-ziz-76c100180509 | A community alert about Ziz. Police investigations, violence, and…  by SefaShapiro  Medium\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://worksinprogress.co/issue/markets-in-fact-checking | Markets in fact-checking - Works in Progress\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson’s latest AI risk position statement - LessWrong\n",
      "https://twitter.com/glpat99/status/1672230720662560768 | Gemma (6/15 blog posts published) on Twitter: \"I agree with all of these claims from @SjirHoeijmakers but curious where people disagree? Polls below (i've also added a claim of my own) ⬇ t.co/FCWFCWLjgX\" / Twitter\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/GmDmE2pxjTjHMHNK8/thoughts-about-ai-safety-field-building-in-lmic | Thoughts about AI safety field-building in LMIC\n",
      "https://gizmodo.com.au/2023/06/deepmind-co-founder-turing-test-ai/ | DeepMind Co-Founder Wants the 'New Turing Test' to Be Based on How Good an AI Is at Getting Rich\n",
      "https://twitter.com/tomascodes/status/1674020711453675520 | tomas ✨ on Twitter: \"Every couple of months I check this website out again and remember why its my favourite website ever t.co/92xslmwuNe\" / Twitter\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://twitter.com/AlecStapp/status/1674519565231964161 | Alec Stapp on Twitter: \"New white paper from @IFP: Everything you ever wanted to know about indoor air quality. t.co/rIcUHJjs33\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1671908426736103424 | Nathan on Twitter: \"Went to the gym for ~ the first time in my life. Felt great for several hours afterwards. graph gonna graph I guess. I used the StrongLifts app which told me what to do t.co/Ov1KG4tEus\" / Twitter\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://worksinprogress.co/issue/why-didnt-suicides-rise-during-covid | Why didn't suicides rise during Covid? - Works in Progress\n",
      "https://docs.google.com/document/d/10Alxne5NLtN8Ggwcnsj9R9D-WaA1-uDdJ_WQlp8zYdQ/edit | Ashwin <> JueYan - Google Docs\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://docs.google.com/presentation/d/1dKeyVbNLfaO7QCYTSSleXicRGK8qAestfheQ_8ORrF4/edit#slide=id.g2546af80730_0_214 | Peter's lightning talks - Google Slides\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3499475277034032&hoisted_section_header_type=recently_seen | Dank EA Memes  Facebook\n",
      "https://forum.effectivealtruism.org/posts/GCaRhu84NuCdBiRz8/ea-s-success-no-one-cares-about | EA’s success no one cares about - EA Forum\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com® - USPS Tracking® Results\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://twitter.com/gunsnrosesgirl3/status/1670471946679492610 | Science girl on Twitter: \"Seals have short front flippers and un-rotatable rear flipper so cannot walk on land, they propel themselves forward and achieve locomotion by a method called galumphing t.co/Mm9HY3X6Yi\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KYApMdtPsveYPAoZk/longtermists-are-perceived-as-power-seeking | Longtermists are perceived as power-seeking - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/YpADfSeSccsEkaetk/ai-safety-field-building-vs-ea-cb | AI Safety Field Building vs. EA CB — Effective Altruism Forum\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://metaculus.com/tournament/biosecurity-tournament/ | Biosecurity Tournament - Metaculus\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://facebook.com/messages/t/5611182/ | Messenger  Facebook\n",
      "https://docs.google.com/document/d/1CN7c8rft3RZ-lwzVB_MziKbixQatTbhsRaikt3v83PE/edit | [public] RP US AI regulations team 2-pager (June-Aug 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://worksinprogress.co/issue/the-elements-of-scientific-style | The elements of scientific style - Works in Progress\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://twitter.com/DavidSKrueger/status/1672232506991542272 | (1) David Krueger on Twitter: \"EAGx Cambridge fireside chat (I love this format!) t.co/53Qd9YqINx\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1673281020139913220 | Siméon on Twitter: \"Here's a more comprehensive list of what Anthropic &amp; OpenAI did best and worst at IMO. What OpenAI (OA) did well: 1) Sam Altman publicly voicing existential risk concerns before ~everyone else + now pushing for policies close from the right degree of ambition of what needs to…\" / Twitter\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://wikiwand.com/en/Silo_(TV_series) | Silo (TV series) - Wikiwand\n",
      "https://forum.effectivealtruism.org/posts/ZnPLPFC49nJym7y8g/agi-x-animal-welfare-a-high-ev-outreach-opportunity | AGI x Animal Welfare: A High-EV Outreach Opportunity? — EA Forum\n",
      "https://asteriskmag.com/issues/1/modeling-the-end-of-monkeypox | Modeling the End of Monkeypox—Asterisk\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://worksinprogress.co/issue/the-evolution-of-psychiatry | The evolution of psychiatry - Works in Progress\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://worksinprogress.co/issue/buyers-of-first-resort | Buyers of first resort - Works in Progress\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://twitter.com/stephenclare_/status/1674425999646408708 | Stephen Clare on Twitter: \"Preventing conflict between the world’s most powerful countries is one of the world’s most pressing problems. I make this case in a new article for @80000hours (thread 🧵) t.co/sie4QKgKAU\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://worksinprogress.co/issue/how-dc-densified | How DC densified - Works in Progress\n",
      "https://docs.google.com/document/d/1uD9b-lrczR2r4LxppInaDQhOSvN0YYDi7MfuSyp1b-w/edit#heading=h.pn9w2hrth81s | Metaculus AI tournament analysis - Google Docs\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://twitter.com/michael_nielsen/status/1671370867228676097 | Michael Nielsen on Twitter: \"If you'd like to keep yourself awake very late tonight: t.co/eWuUwqBIiv\" / Twitter\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://twitter.com/EthanJPerez/status/1671222828518227968 | twitter.com/EthanJPerez/status/1671222828518227968\n",
      "https://twitter.com/Noahpinion/status/1671280226070941698 | Noah Smith 🐇🇺🇦 on Twitter: \"1/I disagree with some of @delong's China theses! t.co/LCXXF5CYrG\" / Twitter\n"
     ]
    }
   ],
   "source": [
    "print('Shuffled tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "random.shuffle(tabs)\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7eece4-8649-45d2-bd1f-5d0e2554c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tabs opened!\n"
     ]
    }
   ],
   "source": [
    "open_tabs_from_text(\"\"\"\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
