{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs(tabs, page=1, per_page=10):\n",
    "    page_start = (page - 1) * per_page\n",
    "    total_pages = int(np.ceil(len(tabs) / per_page))\n",
    "    if page > total_pages:\n",
    "        raise ValueError('Cannot open page {}, only have {} pages'.format(page, total_pages))\n",
    "    page_end = page * per_page\n",
    "    if page_end > len(tabs):\n",
    "        page_end = len(tabs)\n",
    "    paged_tabs = tabs[page_start:page_end]\n",
    "    print('Opening page {}/{} (tabs {}-{} of {})'.format(page, total_pages, page_start, page_end, len(tabs)))\n",
    "    \n",
    "    for tab in paged_tabs:\n",
    "        open_tab(tab)\n",
    "\n",
    "        \n",
    "def open_random_n_tabs(tabs, n=5):\n",
    "    tabs = random.sample(tabs, len(tabs))\n",
    "    open_tabs(tabs, page=1, per_page=n)\n",
    "    return tabs[5:]\n",
    "\n",
    "        \n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n",
      "699\n",
      "696\n",
      "696\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Messages ## (3 tabs)\n",
      "\n",
      "https://twitter.com/messages/25776739-779118444440592384 | Tom Liptay / Twitter\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower())], label='Messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c2b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Facebook ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if 'facebook.com' in t.lower() and 'messages' not in t.lower()], label='Facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d6e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Twitter ## (148 tabs)\n",
      "\n",
      "https://twitter.com/JeffLadish/status/1628503073755906049 | Jeffrey Ladish on Twitter: \"I think the AI situation is pretty dire right now. And at the same time, I feel pretty motivated to pull together and go out there and fight for a good world / galaxy / universe @So8res has a great post called \"detach the grim-o-meter\", where he recommends not feeling obligated‚Ä¶\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://twitter.com/T_Goody3/status/1638203321704955904 | Trey on Twitter: \"I used code-davinci-002 recently to do a simple dev task, and it began responding with occasional eery, uncomfortable, human-like mental breakdowns in the comments (see attached). Completely unprompted, @OpenAI have you seen this? https://t.co/1qWyrpYsc9\" / Twitter\n",
      "https://twitter.com/emollick/status/1645432299587026944 | https://twitter.com/emollick/status/1645432299587026944\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://twitter.com/yonashav/status/1633494288624484353 | Yo Shavit on Twitter: \"Ah shit this is actually very fun, but GPT-3.5-scale LMs shouldn‚Äôt be able to intuitively sample the space of fun emergent game mechanics yet‚Ä¶ right? https://t.co/lrjSTHqPPi\" / Twitter\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/NathanpmYoung/status/1637874864089341957 | Nathan is at EAGx Camüîç (join convos I'm in üëã) on Twitter: \"@StefanFSchubert I guess the likelihood is already included in timeline forecasts, right? To forecast impact I guess we'd need specific actions that might a cause a slow down?\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643167977372815360 | https://twitter.com/MatthewJBar/status/1643167977372815360\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/EpistemicHope/status/1633341593531961345 | Eli Tyre on Twitter: \"Sometimes, people say, \"Wow! given LLMs, and other recent AI develpments, it looks like we're at the start of a slow takeoff.\" I think that's only half right.\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://twitter.com/davidchalmers42/status/1640334105941344261 | David Chalmers on Twitter: \"my slides for last friday's #phildeeplearning debate on \"do language models need sensory grounding for meaning and understanding\" are now online at https://t.co/Ffl1hIzp30. i was on the \"no\" side. my final summary slide with a slightly more nuanced view is below. https://t.co/t2QELGHUXf\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://twitter.com/mattyglesias/status/1635936611937517583 | Matthew Yglesias on Twitter: \"A lot of talk about how tech is viewed by non-tech people, but this survey has 31% of active machine learning researchers saying AI work is going to make the world worse. Median respondent says 5% odds of human extinction. https://t.co/BxwFnevki7 https://t.co/nxx1dCnSYI\" / Twitter\n",
      "https://twitter.com/SolarxPvP/status/1635866783763636225 | SolarxPvPü•ã on Twitter: \"Why aren't AI doomer people scared of extraterrestrial AIs? Earlier civilizations could have developed them, and if there were earlier ones, they already should have gotten here. AIs wouldn't get bored or need money for the long trip. They would get here faster.\" / Twitter\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://twitter.com/natalia__coelho/status/1636609751902744577 | Nat√°lia üîç on Twitter: \"People have high expectations for GPT-12 \"Will a game of Pong be played with a galaxy as the ball before 2040?\" https://t.co/dC1ZjX2cp8 https://t.co/PlTWzdEUt9\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://twitter.com/birchlse/status/1628736918362923008 | Jonathan Birch on Twitter: \"I've written an @aeonmag piece on animal and AI sentience with @KristinAndrewz. It's the first time I've written about what I see as the hardest problem in the AI case, the \"gaming problem\". üßµ(1/5) https://t.co/pCOijaMI5D\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1639397697084874752 | alex lawsen on Twitter: \"\"Why would you think AI might end up displaying [deception/power-seeking/other scary thing]?\" \"People will design them to\" \"But those theorems might not apply to the real wo.... WAIT WHAT?\" \"People will design them to\"\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1640379280990560258 | Michael C. Frank on Twitter: \"The take-home here is that we are off by 4-5 orders of input magnitude in the emergence of adaptive behaviors. (That's the figure from above). The big broad cognitive science question is - which factors account for that gap? I'll think about four broad ones. https://t.co/QZfUiwJO8X\" / Twitter\n",
      "https://twitter.com/MelMitchell1 | (7) Melanie Mitchell (@MelMitchell1) / Twitter\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | https://twitter.com/SullyOmarr/status/1645205292756418562\n",
      "https://twitter.com/QualyThe/status/1637817473801105413 | Qualy the lightbulb on Twitter: \"arguing with a rationalist like üòä https://t.co/o9vXAH6MOt\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://twitter.com/JeffLadish/status/1639194473350717442 | Jeffrey Ladish on Twitter: \"AI takeover is very likely üßµ This is true even if AI alignment turns out to be relatively easy. I do not think it will be easy, but this would not change the conclusion All you need to conclude AI takeover is that future AI systems will be very powerful and agentic...\" / Twitter\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://twitter.com/gwern/status/1636739854586335232 | https://twitter.com/gwern/status/1636739854586335232\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://twitter.com/HamishDoodles/status/1636088496086474758 | Hamish McDoodles on Twitter: \"@peterwildeford @JacobPeacock1 But it's what I actually believe is the correct answer to your question, so if I'm actually missing something then expressing how I think about this and getting roasted is a good way to find that out.\" / Twitter\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it üëè - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://twitter.com/Jsevillamol/status/1640997070650720256 | Jaime Sevilla on Twitter: \"I share a big part of Matthew's frustration, though I disagree with the bottom line and I have signed the letter. Why? I explain below üßµ\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/srush_nlp/status/1645534519083016193 | https://twitter.com/srush_nlp/status/1645534519083016193\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://twitter.com/swift_centre | The Swift Centre (@swift_centre) / Twitter\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | (1) Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643385498092834817 | Jeffrey Ladish on Twitter: \"This is exactly it. I don't pretend to know exactly how this transition will go. I'm confused about agents and goals and optimization. But we are talking about rapidly filling the world with things we don't begin to understand that will be far, far smarter than us\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1636508502498897921 | Jeffrey Ladish on Twitter: \"I've decided to donate $240 to both GovAI and MIRI to offset the $480 I plan to spend on ChatGPT Plus over the next two years ($20/month). I don't have a super strong view on ethical offsets but they feel right to me in this case. One reason is that it seems useful to actually‚Ä¶\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://twitter.com/davidchalmers42/status/1640357701417938945 | David Chalmers on Twitter: \"@rgblong in the terms i used, it arguably doesn't have an e-understanding of unicorns, e.g. knowing what it's like to see a unicorn. it arguably has a b-understanding (behavior) and r-understanding (recognitional) on performance-based readings. i-understanding (inferential) is tricky.\" / Twitter\n",
      "https://twitter.com/benparr/status/1635684322261729282 | Ben Parr on Twitter: \"üö® HUGE news in AI: Google just launched Generative AI across ALL of Google Workspace -- Gmail, Docs, Sheets, Slides, Images -- EVERYTHING. They made a video showing off the new AI's capabilities. It's AWESOME. https://t.co/bL9uxafrvW\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1630961114375761922 | Daniel Paleka on Twitter: \"No one sees ChatGPT for the first time and thinks \"just some n-gram correlations\" or \"no real knowledge inside\". Those unintuitive beliefs trickle down from some experts, who should know better than to teach their controversial theories as established fact: üßµ (1/12)\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1643496690740068357 | (1) JgaltTweets on Twitter: \"I'd like to see a variation on this in which participants are presented with 10-20 actual &amp; potential dangers and asked to rank them according to how much of a threat they think they pose to the human race; should include things like climate change, nukes, terrorism, aliens, etc\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639040220191678464 | Rob Bensinger üîç on Twitter: \"Actions are definitely not \"where the bad things could happen\", unless you're also treating text outputs as \"actions\". Which you probably should. Talking to people is not in a different magisterium from \"acting on the world\", and unaligned ASI with a text channel is not safe.\" / Twitter\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1641463526291312643 | Anthropic on Twitter: \"Today we are releasing the new Claude App for @SlackHQ, in beta. Now every company in the world has the chance to have a ‚Äúvirtual teammate‚Äù who can help make work more fun and productive. https://t.co/YNpIH5caBP\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://twitter.com/Rainmaker1973/status/1644248670160801792 | Massimo on Twitter: \"When traffic cones along a road in New Zealand began mysteriously moving around, the Transport Agency set up a CCTV to pin down the culprits It turned out a Kea parrot moved them to get attention from humans &amp; get fed [read more: https://t.co/U2cecFOeXh] https://t.co/mqGE37IIpr\" / Twitter\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://twitter.com/leopoldasch | https://twitter.com/leopoldasch\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://twitter.com/patentbuzz/status/1645418703889092608 | https://twitter.com/patentbuzz/status/1645418703889092608\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://twitter.com/YosarianTwo/status/1635780666632687617 | Yosarian2 on Twitter: \"Holy shit. GPT-4, on it's own; was able to hire a human TaskRabbit worker to solve a CAPACHA for it and convinced the human to go along with it. https://t.co/xVuQnyUUry\" / Twitter\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1640379247373197313 | Michael C. Frank on Twitter: \"How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. üßµ https://t.co/hayhUU5Iv6\" / Twitter\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine‚Äôs Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://twitter.com/TaylorWWebb/status/1641172201792761856 | (1) Taylor Webb on Twitter: \"Major update to our paper on emergent analogy in LLMs, with a number of additional tests and behavioral experiments, and a preliminary test of GPT-4. https://t.co/mvzvIJh1dI\" / Twitter\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://twitter.com/harries_matthew/status/1630493459499941892 | Matthew Harries on Twitter: \"I seem to be in a minority of one on this, and I'm aware I don't know what's happening behind closed doors, but based on the public evidence I am very sceptical about the idea that China's language on nuclear threats in its Ukraine paper is a clear win. /1 https://t.co/9dQei78al5\" / Twitter\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://twitter.com/robbensinger/status/1639061235164659712 | Rob Bensinger üîç on Twitter: \"@RosieCampbell OK, I was partly kidding. I do think most likely AI surprises look pessimistic, but some would look optimistic. See https://t.co/IS2jxBQHXd Links: 1. https://t.co/htpadcWU1v 2. https://t.co/6TbJACvNsa 3. https://t.co/StpwXHREvn. https://t.co/nHZpEm0Yg5\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://twitter.com/SSGamblers | Star Spangled Gamblers (@SSGamblers) / Twitter\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://twitter.com/ozyfrantz | (1) ozy brennan ü¶ô (@ozyfrantz) / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter ‰∏äÁöÑ Boaz BarakÔºö\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://twitter.com/douglasmack/status/1638705593258061826 | (1) Doug Mack on Twitter: \"30 years after this was published, it still might be my favorite lede of all time https://t.co/vfxH2I0zOs\" / Twitter\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n"
     ]
    }
   ],
   "source": [
    "twitter_tabs = sorted([t for t in tabs if 'twitter.com' in t.lower() and 'messages' not in t.lower()])\n",
    "print_tabs(twitter_tabs, label='Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8d623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(twitter_tabs, page=1, per_page=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4635d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google Docs ## (270 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://docs.google.com/document/d/1Dl567qFbzH9uqqwdVOWw3npjLSNohMdIWlRMwxVa3LI/edit | 2022-Jan-18 Longtermism fundraising coordination meeting - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://docs.google.com/document/d/1v14aMi7GhpNhk5ahmqgZVeYCKVvSdf9Bsoz8yfR6MpM/edit | The AI playbook as I see it - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://docs.google.com/document/d/1PmUuUro7BN_5qJgsZgvTzu64nEk1Zdcu8Wv58cDs9FA/edit | Robert de Neufville ‚Äì Evaluation (EAIF) ‚Äì 63d3561a97b4f8799801fb48 - Google Docs\n",
      "https://docs.google.com/document/d/1fNQ5ycBbZL-Qo0LuXBM0otPPUHGpXW_F98WNlFjekGE/edit | DiD Redrafted Proposal for Jonas - Google Docs\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://docs.google.com/document/d/1VyQJK2dIwvz0yelzT4GjBPXFwdS6PCCwMjFTHTEAAsQ/edit | How does bee learning compare with machine learning? [Public] - Google Docs\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://docs.google.com/document/d/18hsS6rsQmnZcOZJ7Lz2K9jhgosNtS-NXhle7w_BVRLA/edit | AI Safety - Half Year Summary - Google Docs\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1OMeHukuwa9ghOe_ZaPusNMnBwzkDSq7yRto_IkGl5tM/edit | [final draft] Project idea solicitation plan - Google Docs\n",
      "https://docs.google.com/document/d/1YSgdVuvYWnBE4CAPvMRA3pfsSlZTl-93uYji5n6zC3Q/edit | [Forum experiment] Strategy investigation: Cause area intersections - Google Docs\n",
      "https://docs.google.com/document/d/1gn77WcyIeuTK3ZKAgWdD-3VTUYcx4cNhbSSieE1rSN4/edit | RP LT work-in-progress (WiP) sessions: Session notes [internal] - Google Docs\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1cRIjKlYIlAOEUChV-1BU9qzepYVYijKs1tEdxU1k6Hk/edit | [Shareable] OECD AI governance plans - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://docs.google.com/document/d/1XIT-avqFFFO9RnzSJz1BOT3Rw_MzsAwJipxLEoe4YWU/edit | Key points from my conversations w/ people about longtermist incubation - Google Docs\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://docs.google.com/document/d/1mWa6pM65MqVnWgpMLSv0IejP526_0OjGCMbNbDz89jg/edit | Mike McCormick <> Renan/Linch on LT entrepreneurialism - Google Docs\n",
      "https://docs.google.com/document/d/1hYo758MviVBd_C_OTaFZ4jfG2ZzUyU6dO-WdfCWv81Q/edit | [STUB] Mechanisms for Coordinating Resource Allocation - Google Docs\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit | Brainstorming on RP as a brand\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://docs.google.com/document/d/1wo__OjZaQ4skvw-Rqoz-9LyXQPBv7XY3UuAd4BVaODw/edit | Longtermist incubation Q1+Q2 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://docs.google.com/document/d/1nxylL1-BwIrg7-G0vDk3K4COpAIpjmIAfwkaN5V1fwk/edit | AIs and moral patienthood - Google Docs\n",
      "https://docs.google.com/document/d/1mrmbcjLfpubTdEs6l0QIqXYiJz3006oE6-IvuDD8Mu8/edit | Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1xiOtTn_3RhvrMHIwRWehbI-Sx3DU0AoveemMF9LQi3c/edit | Onni Aarne's research agenda for 2023 - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://docs.google.com/document/d/1I6I3qEBhk8hHacJW7ufBZV_-plFq5SDcy_EGw3941ZQ/edit | 2023-02-09 Peter Wildeford - Google Docs\n",
      "https://docs.google.com/document/d/1J4TK6twjcF3hop5ZoEVR-_FVnnRdABFSm0WZkuuhU6c/edit | EPE'22 Process Debrief - Google Docs\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://docs.google.com/document/d/1zeKyneX_8hcmmDq467FuIR9y6Zxz0iQNicOcCz_dcfw/edit | AW Department changes & updates\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://docs.google.com/document/d/1G3MsnzEmMQ11RzJeGe8WChbFRIHhi_yWVDW_tW1EdD0/edit | Coordinating AI development around a moving bright line - Google Docs\n",
      "https://docs.google.com/presentation/d/1yRLDkc7sxGa5eNPB6_IGoEy7dvoPVS6K0EYTd_VceF0/edit | IR Game Rules Intro - Google Slides\n",
      "https://docs.google.com/document/d/1nZVNE5jLAh0E9n9B2uIe4K-XNLylicnUXmr07jpXtCc/edit | Possible directions for USG-AI project - Google Docs\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://docs.google.com/document/d/1y8qqleaBMDg3QnBSzmUY4mkZPZoPOaC3fF-vSSkskWY/edit#heading=h.b9zrlpr5ztu9 | Comments on the default approach - Google Docs\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://docs.google.com/document/d/1YdtearE-rcd8UA34IPe4uW_pBSUzPjOeGOjc68oZfEQ/edit# | [PUBLIC] Marketing data visualisations - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1af7rhUUr0hhtnkl3VjXmFEA6W_DlG_V4sVfc1jL4sng/edit | [shared] T3A: 2023-02 Investor pitch - Google Docs\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jdYBDLrhBgVaf1WqjIlFiksyTemD-U9eIka1Amtwkno/edit | 2023 Jan Lights - Google Sheets\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://docs.google.com/document/d/1ZG0XIP6ItkSBfWPaH6n2Fd0J7A6dvYtfFAy1S7YyhSY/edit | Biggest Mistakes we‚Äôre making - Google Docs\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [Funder Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1CbS0ofRMI83BH-Y8moiaLLchUNRtNglLeqkvrmztxso/edit | memo: moratorium on AI scaling? - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1IkJyu-mO0cdCptxKzBD_DaUk3jW7JhKaSoEGSs9P5rY/edit | Updating my EA community building takes after recent scandals and reduced funding - Google Docs\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1gBy6iOa2xt5O8FfbImBqOsMgOL3NBorQPsN2uKOfcSM/edit#gid=0 | LAISR 2022 Invitees, with emails (for ops staff) - Google Sheets\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://docs.google.com/document/d/1BZv1lRGmS6k_WsMzOLeu9gVIJc9C6nEQKByT5I0UnyI/edit | Project idea: Backgrounder on AI lab safety processes - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://docs.google.com/document/d/1qa1QkVQzDMQ-q_xvXuqYLToKwePoCOyPlo-8ydfzEcg/edit | 6219476ee801e140e5433082   Patchd, Inc.  2023-03-02T01:05:24Z - Google Docs\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security\n",
      "https://docs.google.com/document/d/1JlEfNtOWdRJC4t_5lyMKGmIxVIIe143oYYQNxWKEM7g/edit#heading=h.g4t1dqegifc2 | [v. C] Intermediate goals suggested by survey respondents ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit | Survey team time allocations - Google Sheets\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register - April 2023 Finalized\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://docs.google.com/document/d/1zhi1NypU0hUE2JM-ewUsC7Tkvw25eLbQPnpUrDjsq48/edit | Meeting Notes - Peter/Zoe 1-1s - Google Docs\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://docs.google.com/document/d/1e9vWPSCfuMD_elWVFdVdLJhqwWSiQBQKHu-8mvfxAHk/edit | How GLT can work with Mike McCormick and possible strategy updates from that - Google Docs\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1nI4Sg7-80bStu0HlkH7ZEfn1OXAZUjfGSqKd9VwGFAE/edit | [summit copy] Defense against misaligned AI - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1Bk25Q7Om8UjnOoua0Zq5pXlzfqK1mwY9Dx1QGvAXemo/edit | Ben‚Äôs GLT strategy work stack - Google Sheets\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1nOlvwsgDNqsz3bilB1VX7Ml9EokMf_4QQMxIktzQCHE/edit | Projects to increase transparency, cooperation and trustworthiness of top AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1WY2DmyvKrHQmRBQFGo04HTXMnCIJQs1nhm2UkjLTBGw/edit | Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://docs.google.com/document/d/1Bp-95XalxsgQQ1q1-PCW030oXaWUP5Dpkdj4TnbNfF0/edit | [mini-copy for my discussion table] What I think the AI plan is - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1qVXta8izrX3gmPVSX-QjuDTCg3TSkjbrWkKPm6PdBPQ/edit | RP Copy of Projects Alex would be excited about - March 2023\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://docs.google.com/document/d/1DIExQFqzkJdngxPUPn1txvBNUuBJeSrE19hwgLUZAgs/edit | PW Self Reflection Nov 2022 - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1p7KAFI8_oQVHS3nXNAaWqIPExb87MsBWo9pS98gcQQc/edit | RP AIGS project options spreadsheet - Google Sheets\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://docs.google.com/document/d/1qV_mNjkpTZEbvS6VUAbTuOYziRgnmAkQcU6zyku_St8/edit | Ben‚Äôs longtermist incubator notes 2022-12-19 - Google Docs\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | 04a - Hypothetical \"success stories\" to accompany \"Nearcast-based 'deployment problem' analysis\" - Google Docs\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://docs.google.com/document/d/1tNDNbjg63Vx03w0iV5Cy3Lyw9azZBuevRQFowcWTG1E/edit#heading=h.oopq92wv47s1 | Prioritization of different kinds of technical compute governance research [shared] - Google Docs\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://docs.google.com/document/d/1PidPXJWKKqCbWGzWQ7IySDnOkiK5rX0n2naaSjz7q3g/edit#heading=h.6ytgvt3dfnpe | Kieran Greig Copy of Oct-Nov - RP Performance Evaluation Template - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://docs.google.com/document/d/1gHzQovSnLHxbRalowex0eCAOVgvN5tafvpG2gEMKNH4/edit | Cost-of-living adjustments - Google Docs\n",
      "https://docs.google.com/document/d/1oKQc5QKfEjRQHPU2g6kQBUadhOmFwTg40NH-EW_nrjU/edit#heading=h.za992j72817 | [Shareable] Coordination between labs - LAISR discn summary - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success Without Dignity - Google Docs\n",
      "https://docs.google.com/document/d/1o54DtHVMc0uvgRv3K_eO0wWxV46Jk8B7HBhu_IiWfm8/edit | [summit copy] Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit | Jannik Schilling <> Ben 2023-03-27\n",
      "https://docs.google.com/document/d/1EtQjv-YFS3LD8YfW8RpmlD03XmIZrStTBEXerLqWp0o/edit#heading=h.ssso4t7fjkoa | Deliberative Decision Making Procedures (v1) - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1btLsQqXy5eiaqYKlWEg7FSXbisAblw1PgQtVCJz5l3c/edit | Good cop bad cop in AI safety advocacy - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/document/d/1oInPr-bzqtAULzonDajiT8M10LF50WNfiuaaIkElk4g/edit#heading=h.217anus74gpx | [Shareable] Cost-effectiveness of boosting US AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://docs.google.com/document/d/1SYBPKllt9Etbbi3ymB4LwWHI6ZiFjlTrthuGSaDBLNs/edit | Main summary: International safety agreements - Google Docs\n",
      "https://docs.google.com/document/d/1YAJ0uVLDHb887LQKMd0HNSF167eksCjSkhKVo9rvEfg/edit | [West] Thoughts on recent PRC statements on international AI ethics and governance - Google Doc\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1fXTIN6goXqEmGA8Hyg5oeD6MK3En7dtF0lTFz8MDxKs/edit | GLT Strategy for 2023 v0.4 2023-03-30\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://docs.google.com/document/d/17Dd7kdgx6TGExC6UtrwiXl4UkrJzTBx8LDmZsdILF9I/edit | AIGS strategy proposal for Q2 2023 [AIGS Leads discussion notes] - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://docs.google.com/document/d/1bue7VzQPZ9Uy7drOShVdF1h0_uSAB9wQsSA4gcBvPGg/edit | Takeaways from EAGx Cambridge convos about GLT‚Äôs strategy (mostly entrepreneurship stuff) - Google Docs\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://docs.google.com/document/d/15HUEdn4MIQDZLmfhnR0Lhobp8c9YFkIKQI0bFloy32M/edit | USG involvement in advanced AI [shared with RP, Epoch, etc.] - Google Docs\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://docs.google.com/document/d/1cgyL0QbR26XWqbR8GoUOe2nMcAy_rXK1eKKhrwBHyc8/edit | EA Scandal Risk Write-up 2 - Google Docs\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1Yg0xcj24B6h_wqSGu2_6sv4CJGKGsLL4OhioKBZBwZw/edit | Will the US or a closely allied government control and/or heavily resource the first successful TAI project?\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/document/d/1mCHfBSUPOCDktuh52foodKy0hiRC5CzRl4C5sAGHto0/edit | 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/1s3QGFJ8Ochosksl4JgQCWekJrsY3YFAfGgEiEt6zFpA/edit | How Will the AI Supply Chain Evolve? v4 - Google Docs\n",
      "https://docs.google.com/document/d/18bOeTikuNvI0G34UCgZQkySi87_3lqhLDF9JGkTxUl0/edit | [2023.02.12 (Feb)] Defense-in-Depth Compiled Report [Master Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1uVi0jGpFU6qstOGTVrC8ZRnARa79HDw7L6t_A0nVWOg/edit | EA Crisis Management - Google Docs\n",
      "https://docs.google.com/document/d/1Psa11UEeLNsJ8XpT8R44GeyW0nhUfuDmZK6JA72mP_A/edit | v2 AI Safety Bounties - Google Docs\n"
     ]
    }
   ],
   "source": [
    "doc_tabs = sorted([t for t in tabs if ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower())])\n",
    "print_tabs(doc_tabs, label='Google Docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(doc_tabs, page=1, per_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479f45a0-d63f-474d-aa76-2ddab5a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = copy(doc_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e71249-4e0e-47aa-9fcd-69b9219f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = open_random_n_tabs(doc_tabs_, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6311fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google search ## (3 tabs)\n",
      "\n",
      "https://www.google.com/search?q=chaos+gpt&rlz=1C1GCEA_enGB993GB993&sxsrf=APwXEdfDrsc7CTFBEUhij_z8R-U-YNslqg:1681232294309&source=lnms&tbm=vid&sa=X&ved=2ahUKEwjksL-tpqL-AhXMWMAKHUc6BTUQ_AUoAnoECAEQBA&biw=767&bih=732&dpr=1.25 | chaos gpt - Google Search\n",
      "https://www.google.com/search?q=learn+how+to+seduce&rlz=1CDGOYI_enUS715US715&oq=learn+how+to+seduce&aqs=chrome..69i57j0i15i22i30i625j0i22i30l2j0i15i22i30.6783j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | learn how to seduce - Google Search\n",
      "https://www.google.com/search?q=2024+eclipse&rlz=1C5CHFA_enUS925US925&oq=2024+ecl&aqs=chrome.0.0i131i433i512l2j69i57j0i512l7.1363j0j1&sourceid=chrome&ie=UTF-8 | 2024 eclipse - Google Search\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('google.com' in t.lower() and 'search' in t.lower() and\n",
    "                                   not ('docs.google' in t.lower() or 'sheets.google' in t.lower()))]),\n",
    "           label='Google search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b9762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EAFo/LW ## (24 tabs)\n",
      "\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & ‚ÄúThe correct response to uncertainty is *not* half-speed‚Äù - EA Forum\n",
      "https://www.lesswrong.com/posts/bceeKEnPHSQqgyr36/request-to-agi-organizations-share-your-views-on-pausing-ai | Request to AGI organizations: Share your views on pausing AI progress - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/5n7tnfrKAJfAkwMv5/i-just-launched-pepper-looking-for-input | I just launched Pepper, looking for input! - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/fxMuRGzXvXc446Shz/being-at-peace-with-doom | Being at peace with Doom - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/akn2BFhhM9CzwpLEA/wisdom-of-the-crowd-vs-the-best-of-the-best-of-the-best | Wisdom of the Crowd vs. \"the Best of the Best of the Best\" - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zQ7b9ghv3Tkd2LLNL/an-ea-s-guide-to-washington-dc | An EA's Guide to Washington DC - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gmzrYzpR9zb8um5FK/ea-rationality-sexual-assault-and-liability | EA, Rationality, Sexual Assault, and Liability - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DJoRnQg8jDnHK7QKp/why-simulator-ais-want-to-be-active-inference-ais | Why Simulator AIs want to be Active Inference AIs - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/a2KEyLaXzBADb8jgg/can-we-evaluate-the-tool-versus-agent-agi-prediction | Can we evaluate the \"tool versus agent\" AGI prediction?\n"
     ]
    }
   ],
   "source": [
    "ea_fo_tabs = sorted([t for t in tabs if ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower())])\n",
    "print_tabs(ea_fo_tabs, label='EAFo/LW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffa8f80-4aa6-4afe-8c6a-59194d69895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(ea_fo_tabs, page=1, per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ae2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metaculus etc. ## (26 tabs)\n",
      "\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://www.metaculus.com/questions/13045/per-capita-primary-energy-consumption/ | Per Capita Primary Energy Consumption  Metaculus\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://www.metaculus.com/questions/12997/world-population/ | World Population  Metaculus\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://manifold.markets/IsaacKing/if-we-survive-general-artificial-in?r=RWxpZXplcll1ZGtvd3NreQ | If we survive general artificial intelligence, what will be the reason?  Manifold Markets\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://www.metaculus.com/questions/12991/us-gdp-per-hour-worked-productivity/ | US GDP Per Hour Worked (Productivity)  Metaculus\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://www.metaculus.com/questions/13003/oecd-trust-in-government/ | OECD Trust in Government  Metaculus\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://www.metaculus.com/questions/13021/cagr-gdp-growth-per-capita/ | CAGR GDP Growth Per Capita  Metaculus\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower())]), label='Metaculus etc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72bdaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Wikipedia ## (12 tabs)\n",
      "\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://www.wikiwand.com/en/Superbad#Reception | Superbad - Wikiwand\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Kaleidoscope_(American_TV_series) | Kaleidoscope (American TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('wikipedia' in t.lower() or 'wikiwand' in t.lower())]), label='Wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reddit ## (6 tabs)\n",
      "\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://www.reddit.com/r/CPTSD/comments/11fl8s4/comment/jak7abx/?utm_source=reddit&utm_medium=web2x&context=3 | (4) Did any of the abusers or people who caused chaos in your life that contributed to the ptsd ever change or recognise what they did? : CPTSD\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://indianexpress.com/article/technology/reddit-users-are-jailbreaking-chatgpt-and-calling-it-dan-do-anything-now/ | Reddit users are jailbreaking ChatGPT and calling it DAN ‚Äî Do Anything Now  Technology News,The Indian Express\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'reddit' in t.lower()]), label='Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedf293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## localhost ## (1 tabs)\n",
      "\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()]), label='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677f610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Chores ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instacart' in t.lower()]), label='Chores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fce865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Amazon ## (5 tabs)\n",
      "\n",
      "https://smile.amazon.com/Retractable-Keychain/s?k=Retractable+Keychain&sa-no-redirect=1 | Amazon.com : Retractable Keychain\n",
      "https://smile.amazon.com/How-Calm-Your-Mind-Productivity-ebook/dp/B09WM9PTD9?ref_=ast_sto_dp&sa-no-redirect=1 | AmazonSmile: How to Calm Your Mind: Finding Presence and Productivity in Anxious Times eBook : Bailey, Chris: Kindle Store\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'amazon.com' in t.lower()]), label='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d46af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Morning Dispatch ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'morning' in t.lower() and 'dispatch' in t.lower()]), label='Morning Dispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "108d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GitHub ## (12 tabs)\n",
      "\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://github.com/peterhurford/future-assessment-model/blob/main/(3A)%20Initial%20TAI%20Spend%20Model.ipynb | future-assessment-model/(3A) Initial TAI Spend Model.ipynb at main ¬∑ peterhurford/future-assessment-model\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'github.com' in t.lower()]), label='GitHub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d911bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube ## (16 tabs)\n",
      "\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n",
      "https://www.youtube.com/watch?v=xtNrm-EXRjI | Markus Anderljung Regulating increasingly advanced AI some hypotheses - YouTube\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=Iv9vphCwsaU | https://www.youtube.com/watch?v=Iv9vphCwsaU\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://www.youtube.com/watch?v=gI5SOUrW7Nc | https://www.youtube.com/watch?v=gI5SOUrW7Nc\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'yout' in t.lower()]), label='YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2649c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instagram ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instagram.com' in t.lower()]), label='Instagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab0e02f2-e275-486f-98d3-37d3218dc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asana ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'app.asana.com' in t.lower()]), label='Asana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc70c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Other ## (176 tabs)\n",
      "\n",
      "https://www.cold-takes.com/high-level-hopes-for-ai-alignment/ | High-level hopes for AI alignment\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/#fnref1 | What we're doing here\n",
      "https://www.rei.com/blog/climb/new-survey-finds-nearly-one-third-of-respondents-have-experienced-sexual-harassment-or-assault-while-climbing?utm_source=Sailthru&utm_medium=email&utm_campaign=Future%20Perfect%20Wednesday:%202/15/23&utm_term=Future%20Perfect | Survey Reveals Sexual Harassment & Assault While Climbing - REI Co-op Journal\n",
      "https://www.pasteurscube.com/notes-on-managing-to-change-the-world/ | Notes on \"Managing to Change the World\"\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity‚Äôs demise: ‚Äúwe must eliminate them‚Äù - Dexerto\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://www.governance.ai/research-paper/thinking-about-risks-from-ai-accidents-misuse-and-structure | Thinking About Risks From AI: Accidents, Misuse and Structure  GovAI\n",
      "https://www.planned-obsolescence.org/training-ais-to-help-us-align-ais/ | Training AIs to help us align AIs\n",
      "https://www.alignmentforum.org/posts/etNJcXCsKC6izQQZj/pivotal-outcomes-and-pivotal-processes | Pivotal outcomes and pivotal processes - AI Alignment Forum\n",
      "https://confido.institute/ | https://confido.institute/\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage‚àÜ\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://thehill.com/policy/technology/3872614-us-copyright-office-rules-ai-generated-artwork-content-not-legally-protected/ | US Copyright Office rules AI-generated artwork, content not legally protected  The Hill\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://garymarcus.substack.com/p/this-week-in-ai-doublespeak | This Week in AI Doublespeak - by Gary Marcus\n",
      "https://rodneybrooks.com/what-will-transformers-transform/ | What Will Transformers Transform? ‚Äì Rodney Brooks\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai | The secret history of Elon Musk, Sam Altman, and OpenAI  Semafor\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://thebulletin.org/2023/01/researchers-hacked-a-labs-pathogen-containment-system-was-it-a-good-idea-to-publish-the-results/ | Researchers hacked a lab's pathogen containment system. Was it a good idea to publish the results? - Bulletin of the Atomic Scientists\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://astralcodexten.substack.com/p/half-an-hour-before-dawn-in-san-francisco | Half An Hour Before Dawn In San Francisco\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://garymarcus.substack.com/p/the-sparks-of-agi-or-the-end-of-science | The Sparks of AGI? Or the End of Science?\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://80000hours.org/about/credibility/evaluations/mistakes/ | Our mistakes - 80,000 Hours\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://magazine.sebastianraschka.com/p/ahead-of-ai-4-a-big-year-for-ai | Ahead of AI #4: A Big Year For AI - by Sebastian Raschka\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://www.oneusefulthing.org/p/my-class-required-ai-heres-what-ive?fbclid=IwAR03DvA57jfUfx2R27nHDMSybKiPsMIFyLTnC43l-Kj4jiCCsGUIElXPH7s | My class required AI. Here's what I've learned so far.\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://cdn.openai.com/papers/gpt-4-system-card.pdf | gpt-4-system-card.pdf\n",
      "https://www.oneusefulthing.org/p/how-to-use-chatgpt-to-boost-your | How to... use ChatGPT to boost your writing\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://world.hey.com/dhh/inspiration-is-perishable-f2c8652e | Inspiration is perishable\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://tellingthefuture.substack.com/p/new-year-new-forecasts | New Year, New Forecasts - by Robert de Neufville\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://arxiv.org/pdf/2303.12712.pdf | 2303.12712.pdf\n",
      "https://oneusefulthing.substack.com/p/the-practical-guide-to-using-ai-to | The practical guide to using AI to do stuff\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n",
      "http://shfhs.org/ | http://shfhs.org/\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://onthinktanks.org/ | On Think Tanks  Independent research, ideas and advice\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://www.planned-obsolescence.org/is-it-time-for-a-pause/ | Is it time for a pause?\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://openai.com/blog/planning-for-agi-and-beyond/?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://www.economist.com/briefing/2023/03/30/americas-commercial-sanctions-on-china-could-get-much-worse | America‚Äôs commercial sanctions on China could get much worse  The Economist\n",
      "https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/ | In defense of prompt engineering\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://ealifestyles.substack.com/p/welcome-to-the-ea-lifestyles-substack?utm_source=twitter&utm_campaign=auto_share&r=242xrl | welcome to the ea lifestyles substack - EA Lifestyles\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://www.personalhackathon.com/ | Personal Hackathon - A day dedicated to maximizing your productivity\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://osf.io/458cx | OSF\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://astralcodexten.substack.com/p/openais-planning-for-agi-and-beyond | OpenAI's \"Planning For AGI And Beyond\" - by Scott Alexander\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://www.bryantresearch.co.uk/insights/institutional-change?fbclid=IwAR2kEV1sDJpgiiTKhWLAz4JqY3WTwdqShDuVg_4Z-ZMiv7h_TpXwhNj1YG4 | Bryant Research - Institutional Change\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022)\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://sites.google.com/view/adaptive-agent/ | Human-Timescale Adaptation in an Open-Ended Task Space\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?sd=pf | What did they know, and when did they know it? The Microsoft Bing edition.\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://laion.ai/blog/petition/ | Petition for keeping up the progress tempo on AI research while securing its transparency and safety.  LAION\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://www.washingtonpost.com/archive/opinions/1987/04/12/sexpionage-why-we-cant-resist-those-kgb-sirens/900e1e59-1a7b-455f-93cf-22e67394512b/ | SEXPIONAGE WHY WE CAN'T RESIST THOSE KGB SIRENS - The Washington Post\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://newsletter.safe.ai/ | https://newsletter.safe.ai/\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://garymarcus.substack.com/p/the-first-known-chatbot-associated | The first known chatbot associated death - by Gary Marcus\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://aisnakeoil.substack.com/p/people-keep-anthropomorphizing-ai?r=1vxw01&utm_campaign=post&utm_medium=email | People keep anthropomorphizing AI. Here‚Äôs why\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ | Update on ARC's recent eval efforts\n",
      "https://thefuturesociety.org/new-year-new-tfs/ | New year. New TFS. - The Future Society\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://nymag.com/intelligencer/2023/03/on-with-kara-swisher-sam-altman-on-the-ai-revolution.html | ‚ÄòOn With Kara Swisher‚Äô: Sam Altman on the GPT-4 Revolution\n",
      "https://staging.bsky.app/ | https://staging.bsky.app/\n",
      "https://nunosempere.com/blog/2023/03/15/fit-beta/ | Find a beta distribution that fits your desired confidence interval\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://www.nytimes.com/2022/11/08/upshot/poll-experiment-wisconsin-trump.html | Are the Polls Still Missing ‚ÄòHidden‚Äô Republicans? Here‚Äôs What We‚Äôre Doing to Find Out.\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n"
     ]
    }
   ],
   "source": [
    "tabs_ = [t for t in tabs if (not ('google.com' in t.lower() and 'search' in t.lower() and not ('docs.google' in t.lower() or 'sheets.google' in t.lower())) and\n",
    "                             not ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower()) and\n",
    "                             not 'facebook.com' in t.lower() and\n",
    "                             not 'twitter.com' in t.lower() and\n",
    "                             not ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower()) and\n",
    "                             not ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower()) and\n",
    "                             not ('wikipedia' in t.lower() or 'wikiwand' in t.lower()) and\n",
    "                             not 'reddit' in t.lower() and\n",
    "                             not 'instagram.com' in t.lower() and\n",
    "                             not ('guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()) and\n",
    "                             not 'instacart' in t.lower() and\n",
    "                             not ('morning' in t.lower() and 'dispatch' in t.lower()) and\n",
    "                             not 'amazon.com' in t.lower() and\n",
    "                             not 'github' in t.lower() and\n",
    "                             not 'calendar.google' in t.lower() and\n",
    "                             not 'yout' in t.lower() and\n",
    "                             not 'app.asana.com' in t.lower() and\n",
    "                             not ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower()))]\n",
    "tabs_ = sorted(tabs_)\n",
    "print_tabs(tabs_, label='Other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a2a7bb-86f9-45bd-b8d6-ed8889caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(tabs_, page=1, per_page=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c128ee3-03e2-4cfb-bfd1-0dfc84775af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shuffled all tabs ## (695 tabs)\n",
      "\n",
      "https://www.metaculus.com/questions/13045/per-capita-primary-energy-consumption/ | Per Capita Primary Energy Consumption  Metaculus\n",
      "https://www.metaculus.com/questions/12991/us-gdp-per-hour-worked-productivity/ | US GDP Per Hour Worked (Productivity)  Metaculus\n",
      "https://astralcodexten.substack.com/p/openais-planning-for-agi-and-beyond | OpenAI's \"Planning For AGI And Beyond\" - by Scott Alexander\n",
      "https://twitter.com/YosarianTwo/status/1635780666632687617 | Yosarian2 on Twitter: \"Holy shit. GPT-4, on it's own; was able to hire a human TaskRabbit worker to solve a CAPACHA for it and convinced the human to go along with it. https://t.co/xVuQnyUUry\" / Twitter\n",
      "https://docs.google.com/document/d/1EtQjv-YFS3LD8YfW8RpmlD03XmIZrStTBEXerLqWp0o/edit#heading=h.ssso4t7fjkoa | Deliberative Decision Making Procedures (v1) - Google Docs\n",
      "http://shfhs.org/ | http://shfhs.org/\n",
      "https://twitter.com/JeffLadish/status/1639194473350717442 | Jeffrey Ladish on Twitter: \"AI takeover is very likely üßµ This is true even if AI alignment turns out to be relatively easy. I do not think it will be easy, but this would not change the conclusion All you need to conclude AI takeover is that future AI systems will be very powerful and agentic...\" / Twitter\n",
      "https://nymag.com/intelligencer/2023/03/on-with-kara-swisher-sam-altman-on-the-ai-revolution.html | ‚ÄòOn With Kara Swisher‚Äô: Sam Altman on the GPT-4 Revolution\n",
      "https://cdn.openai.com/papers/gpt-4-system-card.pdf | gpt-4-system-card.pdf\n",
      "https://docs.google.com/presentation/d/1yRLDkc7sxGa5eNPB6_IGoEy7dvoPVS6K0EYTd_VceF0/edit | IR Game Rules Intro - Google Slides\n",
      "https://docs.google.com/document/d/1WY2DmyvKrHQmRBQFGo04HTXMnCIJQs1nhm2UkjLTBGw/edit | Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://docs.google.com/document/d/1gHzQovSnLHxbRalowex0eCAOVgvN5tafvpG2gEMKNH4/edit | Cost-of-living adjustments - Google Docs\n",
      "https://twitter.com/messages/25776739-779118444440592384 | Tom Liptay / Twitter\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://forum.effectivealtruism.org/posts/5n7tnfrKAJfAkwMv5/i-just-launched-pepper-looking-for-input | I just launched Pepper, looking for input! - EA Forum\n",
      "https://twitter.com/MatthewJBar/status/1643167977372815360 | https://twitter.com/MatthewJBar/status/1643167977372815360\n",
      "https://twitter.com/SolarxPvP/status/1635866783763636225 | SolarxPvPü•ã on Twitter: \"Why aren't AI doomer people scared of extraterrestrial AIs? Earlier civilizations could have developed them, and if there were earlier ones, they already should have gotten here. AIs wouldn't get bored or need money for the long trip. They would get here faster.\" / Twitter\n",
      "https://docs.google.com/document/d/1XIT-avqFFFO9RnzSJz1BOT3Rw_MzsAwJipxLEoe4YWU/edit | Key points from my conversations w/ people about longtermist incubation - Google Docs\n",
      "https://docs.google.com/document/d/1fXTIN6goXqEmGA8Hyg5oeD6MK3En7dtF0lTFz8MDxKs/edit | GLT Strategy for 2023 v0.4 2023-03-30\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit | Survey team time allocations - Google Sheets\n",
      "https://www.youtube.com/watch?v=gI5SOUrW7Nc | https://www.youtube.com/watch?v=gI5SOUrW7Nc\n",
      "https://twitter.com/dpaleka/status/1630961114375761922 | Daniel Paleka on Twitter: \"No one sees ChatGPT for the first time and thinks \"just some n-gram correlations\" or \"no real knowledge inside\". Those unintuitive beliefs trickle down from some experts, who should know better than to teach their controversial theories as established fact: üßµ (1/12)\" / Twitter\n",
      "https://docs.google.com/document/d/18hsS6rsQmnZcOZJ7Lz2K9jhgosNtS-NXhle7w_BVRLA/edit | AI Safety - Half Year Summary - Google Docs\n",
      "https://twitter.com/mattyglesias/status/1635936611937517583 | Matthew Yglesias on Twitter: \"A lot of talk about how tech is viewed by non-tech people, but this survey has 31% of active machine learning researchers saying AI work is going to make the world worse. Median respondent says 5% odds of human extinction. https://t.co/BxwFnevki7 https://t.co/nxx1dCnSYI\" / Twitter\n",
      "https://twitter.com/QualyThe/status/1637817473801105413 | Qualy the lightbulb on Twitter: \"arguing with a rationalist like üòä https://t.co/o9vXAH6MOt\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1639397697084874752 | alex lawsen on Twitter: \"\"Why would you think AI might end up displaying [deception/power-seeking/other scary thing]?\" \"People will design them to\" \"But those theorems might not apply to the real wo.... WAIT WHAT?\" \"People will design them to\"\" / Twitter\n",
      "https://twitter.com/douglasmack/status/1638705593258061826 | (1) Doug Mack on Twitter: \"30 years after this was published, it still might be my favorite lede of all time https://t.co/vfxH2I0zOs\" / Twitter\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://astralcodexten.substack.com/p/half-an-hour-before-dawn-in-san-francisco | Half An Hour Before Dawn In San Francisco\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://twitter.com/leopoldasch | https://twitter.com/leopoldasch\n",
      "https://docs.google.com/document/d/1xiOtTn_3RhvrMHIwRWehbI-Sx3DU0AoveemMF9LQi3c/edit | Onni Aarne's research agenda for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit | Brainstorming on RP as a brand\n",
      "https://docs.google.com/document/d/1DIExQFqzkJdngxPUPn1txvBNUuBJeSrE19hwgLUZAgs/edit | PW Self Reflection Nov 2022 - Google Docs\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://docs.google.com/document/d/1Dl567qFbzH9uqqwdVOWw3npjLSNohMdIWlRMwxVa3LI/edit | 2022-Jan-18 Longtermism fundraising coordination meeting - Google Docs\n",
      "https://www.reddit.com/r/CPTSD/comments/11fl8s4/comment/jak7abx/?utm_source=reddit&utm_medium=web2x&context=3 | (4) Did any of the abusers or people who caused chaos in your life that contributed to the ptsd ever change or recognise what they did? : CPTSD\n",
      "https://www.economist.com/briefing/2023/03/30/americas-commercial-sanctions-on-china-could-get-much-worse | America‚Äôs commercial sanctions on China could get much worse  The Economist\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://www.alignmentforum.org/posts/etNJcXCsKC6izQQZj/pivotal-outcomes-and-pivotal-processes | Pivotal outcomes and pivotal processes - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1o54DtHVMc0uvgRv3K_eO0wWxV46Jk8B7HBhu_IiWfm8/edit | [summit copy] Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1nZVNE5jLAh0E9n9B2uIe4K-XNLylicnUXmr07jpXtCc/edit | Possible directions for USG-AI project - Google Docs\n",
      "https://docs.google.com/document/d/1nOlvwsgDNqsz3bilB1VX7Ml9EokMf_4QQMxIktzQCHE/edit | Projects to increase transparency, cooperation and trustworthiness of top AI labs - Google Docs\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/#fnref1 | What we're doing here\n",
      "https://docs.google.com/document/d/1zhi1NypU0hUE2JM-ewUsC7Tkvw25eLbQPnpUrDjsq48/edit | Meeting Notes - Peter/Zoe 1-1s - Google Docs\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://www.cold-takes.com/high-level-hopes-for-ai-alignment/ | High-level hopes for AI alignment\n",
      "https://twitter.com/robbensinger/status/1639040220191678464 | Rob Bensinger üîç on Twitter: \"Actions are definitely not \"where the bad things could happen\", unless you're also treating text outputs as \"actions\". Which you probably should. Talking to people is not in a different magisterium from \"acting on the world\", and unaligned ASI with a text channel is not safe.\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1643496690740068357 | (1) JgaltTweets on Twitter: \"I'd like to see a variation on this in which participants are presented with 10-20 actual &amp; potential dangers and asked to rank them according to how much of a threat they think they pose to the human race; should include things like climate change, nukes, terrorism, aliens, etc\" / Twitter\n",
      "https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai | The secret history of Elon Musk, Sam Altman, and OpenAI  Semafor\n",
      "https://www.planned-obsolescence.org/is-it-time-for-a-pause/ | Is it time for a pause?\n",
      "https://docs.google.com/spreadsheets/d/1gBy6iOa2xt5O8FfbImBqOsMgOL3NBorQPsN2uKOfcSM/edit#gid=0 | LAISR 2022 Invitees, with emails (for ops staff) - Google Sheets\n",
      "https://twitter.com/davidchalmers42/status/1640334105941344261 | David Chalmers on Twitter: \"my slides for last friday's #phildeeplearning debate on \"do language models need sensory grounding for meaning and understanding\" are now online at https://t.co/Ffl1hIzp30. i was on the \"no\" side. my final summary slide with a slightly more nuanced view is below. https://t.co/t2QELGHUXf\" / Twitter\n",
      "https://docs.google.com/document/d/1tNDNbjg63Vx03w0iV5Cy3Lyw9azZBuevRQFowcWTG1E/edit#heading=h.oopq92wv47s1 | Prioritization of different kinds of technical compute governance research [shared] - Google Docs\n",
      "https://docs.google.com/document/d/1hYo758MviVBd_C_OTaFZ4jfG2ZzUyU6dO-WdfCWv81Q/edit | [STUB] Mechanisms for Coordinating Resource Allocation - Google Docs\n",
      "https://docs.google.com/document/d/1y8qqleaBMDg3QnBSzmUY4mkZPZoPOaC3fF-vSSkskWY/edit#heading=h.b9zrlpr5ztu9 | Comments on the default approach - Google Docs\n",
      "https://github.com/peterhurford/future-assessment-model/blob/main/(3A)%20Initial%20TAI%20Spend%20Model.ipynb | future-assessment-model/(3A) Initial TAI Spend Model.ipynb at main ¬∑ peterhurford/future-assessment-model\n",
      "https://twitter.com/EpistemicHope/status/1633341593531961345 | Eli Tyre on Twitter: \"Sometimes, people say, \"Wow! given LLMs, and other recent AI develpments, it looks like we're at the start of a slow takeoff.\" I think that's only half right.\" / Twitter\n",
      "https://docs.google.com/document/d/1Yg0xcj24B6h_wqSGu2_6sv4CJGKGsLL4OhioKBZBwZw/edit | Will the US or a closely allied government control and/or heavily resource the first successful TAI project?\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://docs.google.com/document/d/1JlEfNtOWdRJC4t_5lyMKGmIxVIIe143oYYQNxWKEM7g/edit#heading=h.g4t1dqegifc2 | [v. C] Intermediate goals suggested by survey respondents ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://staging.bsky.app/ | https://staging.bsky.app/\n",
      "https://thefuturesociety.org/new-year-new-tfs/ | New year. New TFS. - The Future Society\n",
      "https://docs.google.com/document/d/1qV_mNjkpTZEbvS6VUAbTuOYziRgnmAkQcU6zyku_St8/edit | Ben‚Äôs longtermist incubator notes 2022-12-19 - Google Docs\n",
      "https://docs.google.com/document/d/1nI4Sg7-80bStu0HlkH7ZEfn1OXAZUjfGSqKd9VwGFAE/edit | [summit copy] Defense against misaligned AI - Google Docs\n",
      "https://docs.google.com/document/d/1SYBPKllt9Etbbi3ymB4LwWHI6ZiFjlTrthuGSaDBLNs/edit | Main summary: International safety agreements - Google Docs\n",
      "https://rodneybrooks.com/what-will-transformers-transform/ | What Will Transformers Transform? ‚Äì Rodney Brooks\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security\n",
      "https://www.google.com/search?q=2024+eclipse&rlz=1C5CHFA_enUS925US925&oq=2024+ecl&aqs=chrome.0.0i131i433i512l2j69i57j0i512l7.1363j0j1&sourceid=chrome&ie=UTF-8 | 2024 eclipse - Google Search\n",
      "https://twitter.com/JeffLadish/status/1628503073755906049 | Jeffrey Ladish on Twitter: \"I think the AI situation is pretty dire right now. And at the same time, I feel pretty motivated to pull together and go out there and fight for a good world / galaxy / universe @So8res has a great post called \"detach the grim-o-meter\", where he recommends not feeling obligated‚Ä¶\" / Twitter\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://docs.google.com/document/d/1YSgdVuvYWnBE4CAPvMRA3pfsSlZTl-93uYji5n6zC3Q/edit | [Forum experiment] Strategy investigation: Cause area intersections - Google Docs\n",
      "https://sites.google.com/view/adaptive-agent/ | Human-Timescale Adaptation in an Open-Ended Task Space\n",
      "https://laion.ai/blog/petition/ | Petition for keeping up the progress tempo on AI research while securing its transparency and safety.  LAION\n",
      "https://docs.google.com/document/d/1btLsQqXy5eiaqYKlWEg7FSXbisAblw1PgQtVCJz5l3c/edit | Good cop bad cop in AI safety advocacy - Google Docs\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://docs.google.com/document/d/1IkJyu-mO0cdCptxKzBD_DaUk3jW7JhKaSoEGSs9P5rY/edit | Updating my EA community building takes after recent scandals and reduced funding - Google Docs\n",
      "https://twitter.com/birchlse/status/1628736918362923008 | Jonathan Birch on Twitter: \"I've written an @aeonmag piece on animal and AI sentience with @KristinAndrewz. It's the first time I've written about what I see as the hardest problem in the AI case, the \"gaming problem\". üßµ(1/5) https://t.co/pCOijaMI5D\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/fxMuRGzXvXc446Shz/being-at-peace-with-doom | Being at peace with Doom - EA Forum\n",
      "https://docs.google.com/document/d/1af7rhUUr0hhtnkl3VjXmFEA6W_DlG_V4sVfc1jL4sng/edit | [shared] T3A: 2023-02 Investor pitch - Google Docs\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://docs.google.com/document/d/1OMeHukuwa9ghOe_ZaPusNMnBwzkDSq7yRto_IkGl5tM/edit | [final draft] Project idea solicitation plan - Google Docs\n",
      "https://docs.google.com/document/d/1cRIjKlYIlAOEUChV-1BU9qzepYVYijKs1tEdxU1k6Hk/edit | [Shareable] OECD AI governance plans - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1Psa11UEeLNsJ8XpT8R44GeyW0nhUfuDmZK6JA72mP_A/edit | v2 AI Safety Bounties - Google Docs\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://twitter.com/HamishDoodles/status/1636088496086474758 | Hamish McDoodles on Twitter: \"@peterwildeford @JacobPeacock1 But it's what I actually believe is the correct answer to your question, so if I'm actually missing something then expressing how I think about this and getting roasted is a good way to find that out.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://twitter.com/MelMitchell1 | (7) Melanie Mitchell (@MelMitchell1) / Twitter\n",
      "https://forum.effectivealtruism.org/posts/a2KEyLaXzBADb8jgg/can-we-evaluate-the-tool-versus-agent-agi-prediction | Can we evaluate the \"tool versus agent\" AGI prediction?\n",
      "https://tellingthefuture.substack.com/p/new-year-new-forecasts | New Year, New Forecasts - by Robert de Neufville\n",
      "https://docs.google.com/spreadsheets/d/1Bk25Q7Om8UjnOoua0Zq5pXlzfqK1mwY9Dx1QGvAXemo/edit | Ben‚Äôs GLT strategy work stack - Google Sheets\n",
      "https://ealifestyles.substack.com/p/welcome-to-the-ea-lifestyles-substack?utm_source=twitter&utm_campaign=auto_share&r=242xrl | welcome to the ea lifestyles substack - EA Lifestyles\n",
      "https://aisnakeoil.substack.com/p/people-keep-anthropomorphizing-ai?r=1vxw01&utm_campaign=post&utm_medium=email | People keep anthropomorphizing AI. Here‚Äôs why\n",
      "https://docs.google.com/document/d/1CbS0ofRMI83BH-Y8moiaLLchUNRtNglLeqkvrmztxso/edit | memo: moratorium on AI scaling? - Google Docs\n",
      "https://docs.google.com/document/d/1mrmbcjLfpubTdEs6l0QIqXYiJz3006oE6-IvuDD8Mu8/edit | Proposal: We should do more EA movement building research - Google Docs\n",
      "https://twitter.com/AnthropicAI/status/1641463526291312643 | Anthropic on Twitter: \"Today we are releasing the new Claude App for @SlackHQ, in beta. Now every company in the world has the chance to have a ‚Äúvirtual teammate‚Äù who can help make work more fun and productive. https://t.co/YNpIH5caBP\" / Twitter\n",
      "https://twitter.com/Jsevillamol/status/1640997070650720256 | Jaime Sevilla on Twitter: \"I share a big part of Matthew's frustration, though I disagree with the bottom line and I have signed the letter. Why? I explain below üßµ\" / Twitter\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://twitter.com/JeffLadish/status/1643385498092834817 | Jeffrey Ladish on Twitter: \"This is exactly it. I don't pretend to know exactly how this transition will go. I'm confused about agents and goals and optimization. But we are talking about rapidly filling the world with things we don't begin to understand that will be far, far smarter than us\" / Twitter\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://smile.amazon.com/Retractable-Keychain/s?k=Retractable+Keychain&sa-no-redirect=1 | Amazon.com : Retractable Keychain\n",
      "https://docs.google.com/document/d/1qa1QkVQzDMQ-q_xvXuqYLToKwePoCOyPlo-8ydfzEcg/edit | 6219476ee801e140e5433082   Patchd, Inc.  2023-03-02T01:05:24Z - Google Docs\n",
      "https://docs.google.com/document/d/1fNQ5ycBbZL-Qo0LuXBM0otPPUHGpXW_F98WNlFjekGE/edit | DiD Redrafted Proposal for Jonas - Google Docs\n",
      "https://docs.google.com/document/d/1zeKyneX_8hcmmDq467FuIR9y6Zxz0iQNicOcCz_dcfw/edit | AW Department changes & updates\n",
      "https://docs.google.com/document/d/1s3QGFJ8Ochosksl4JgQCWekJrsY3YFAfGgEiEt6zFpA/edit | How Will the AI Supply Chain Evolve? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1wo__OjZaQ4skvw-Rqoz-9LyXQPBv7XY3UuAd4BVaODw/edit | Longtermist incubation Q1+Q2 2023 - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1637874864089341957 | Nathan is at EAGx Camüîç (join convos I'm in üëã) on Twitter: \"@StefanFSchubert I guess the likelihood is already included in timeline forecasts, right? To forecast impact I guess we'd need specific actions that might a cause a slow down?\" / Twitter\n",
      "https://docs.google.com/document/d/1PmUuUro7BN_5qJgsZgvTzu64nEk1Zdcu8Wv58cDs9FA/edit | Robert de Neufville ‚Äì Evaluation (EAIF) ‚Äì 63d3561a97b4f8799801fb48 - Google Docs\n",
      "https://garymarcus.substack.com/p/the-first-known-chatbot-associated | The first known chatbot associated death - by Gary Marcus\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | (1) Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit | Jannik Schilling <> Ben 2023-03-27\n",
      "https://confido.institute/ | https://confido.institute/\n",
      "https://docs.google.com/document/d/1VyQJK2dIwvz0yelzT4GjBPXFwdS6PCCwMjFTHTEAAsQ/edit | How does bee learning compare with machine learning? [Public] - Google Docs\n",
      "https://docs.google.com/document/d/1nxylL1-BwIrg7-G0vDk3K4COpAIpjmIAfwkaN5V1fwk/edit | AIs and moral patienthood - Google Docs\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022)\n",
      "https://twitter.com/yonashav/status/1633494288624484353 | Yo Shavit on Twitter: \"Ah shit this is actually very fun, but GPT-3.5-scale LMs shouldn‚Äôt be able to intuitively sample the space of fun emergent game mechanics yet‚Ä¶ right? https://t.co/lrjSTHqPPi\" / Twitter\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it üëè - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://docs.google.com/document/d/1Bp-95XalxsgQQ1q1-PCW030oXaWUP5Dpkdj4TnbNfF0/edit | [mini-copy for my discussion table] What I think the AI plan is - Google Docs\n",
      "https://docs.google.com/document/d/1e9vWPSCfuMD_elWVFdVdLJhqwWSiQBQKHu-8mvfxAHk/edit | How GLT can work with Mike McCormick and possible strategy updates from that - Google Docs\n",
      "https://www.metaculus.com/questions/12997/world-population/ | World Population  Metaculus\n",
      "https://twitter.com/T_Goody3/status/1638203321704955904 | Trey on Twitter: \"I used code-davinci-002 recently to do a simple dev task, and it began responding with occasional eery, uncomfortable, human-like mental breakdowns in the comments (see attached). Completely unprompted, @OpenAI have you seen this? https://t.co/1qWyrpYsc9\" / Twitter\n",
      "https://www.google.com/search?q=learn+how+to+seduce&rlz=1CDGOYI_enUS715US715&oq=learn+how+to+seduce&aqs=chrome..69i57j0i15i22i30i625j0i22i30l2j0i15i22i30.6783j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | learn how to seduce - Google Search\n",
      "https://manifold.markets/IsaacKing/if-we-survive-general-artificial-in?r=RWxpZXplcll1ZGtvd3NreQ | If we survive general artificial intelligence, what will be the reason?  Manifold Markets\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | https://twitter.com/SullyOmarr/status/1645205292756418562\n",
      "https://docs.google.com/document/d/15HUEdn4MIQDZLmfhnR0Lhobp8c9YFkIKQI0bFloy32M/edit | USG involvement in advanced AI [shared with RP, Epoch, etc.] - Google Docs\n",
      "https://twitter.com/gwern/status/1636739854586335232 | https://twitter.com/gwern/status/1636739854586335232\n",
      "https://twitter.com/harries_matthew/status/1630493459499941892 | Matthew Harries on Twitter: \"I seem to be in a minority of one on this, and I'm aware I don't know what's happening behind closed doors, but based on the public evidence I am very sceptical about the idea that China's language on nuclear threats in its Ukraine paper is a clear win. /1 https://t.co/9dQei78al5\" / Twitter\n",
      "https://arxiv.org/pdf/2303.12712.pdf | 2303.12712.pdf\n",
      "https://openai.com/blog/planning-for-agi-and-beyond/?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://docs.google.com/document/d/1gn77WcyIeuTK3ZKAgWdD-3VTUYcx4cNhbSSieE1rSN4/edit | RP LT work-in-progress (WiP) sessions: Session notes [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://twitter.com/natalia__coelho/status/1636609751902744577 | Nat√°lia üîç on Twitter: \"People have high expectations for GPT-12 \"Will a game of Pong be played with a galaxy as the ball before 2040?\" https://t.co/dC1ZjX2cp8 https://t.co/PlTWzdEUt9\" / Twitter\n",
      "https://twitter.com/swift_centre | The Swift Centre (@swift_centre) / Twitter\n",
      "https://docs.google.com/document/d/1mCHfBSUPOCDktuh52foodKy0hiRC5CzRl4C5sAGHto0/edit | 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://twitter.com/benparr/status/1635684322261729282 | Ben Parr on Twitter: \"üö® HUGE news in AI: Google just launched Generative AI across ALL of Google Workspace -- Gmail, Docs, Sheets, Slides, Images -- EVERYTHING. They made a video showing off the new AI's capabilities. It's AWESOME. https://t.co/bL9uxafrvW\" / Twitter\n",
      "https://docs.google.com/document/d/17Dd7kdgx6TGExC6UtrwiXl4UkrJzTBx8LDmZsdILF9I/edit | AIGS strategy proposal for Q2 2023 [AIGS Leads discussion notes] - Google Docs\n",
      "https://indianexpress.com/article/technology/reddit-users-are-jailbreaking-chatgpt-and-calling-it-dan-do-anything-now/ | Reddit users are jailbreaking ChatGPT and calling it DAN ‚Äî Do Anything Now  Technology News,The Indian Express\n",
      "https://www.metaculus.com/questions/13021/cagr-gdp-growth-per-capita/ | CAGR GDP Growth Per Capita  Metaculus\n",
      "https://www.governance.ai/research-paper/thinking-about-risks-from-ai-accidents-misuse-and-structure | Thinking About Risks From AI: Accidents, Misuse and Structure  GovAI\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://world.hey.com/dhh/inspiration-is-perishable-f2c8652e | Inspiration is perishable\n",
      "https://docs.google.com/document/d/1BZv1lRGmS6k_WsMzOLeu9gVIJc9C6nEQKByT5I0UnyI/edit | Project idea: Backgrounder on AI lab safety processes - Google Docs\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://docs.google.com/document/d/1uVi0jGpFU6qstOGTVrC8ZRnARa79HDw7L6t_A0nVWOg/edit | EA Crisis Management - Google Docs\n",
      "https://oneusefulthing.substack.com/p/the-practical-guide-to-using-ai-to | The practical guide to using AI to do stuff\n",
      "https://forum.effectivealtruism.org/posts/DJoRnQg8jDnHK7QKp/why-simulator-ais-want-to-be-active-inference-ais | Why Simulator AIs want to be Active Inference AIs - EA Forum\n",
      "https://thehill.com/policy/technology/3872614-us-copyright-office-rules-ai-generated-artwork-content-not-legally-protected/ | US Copyright Office rules AI-generated artwork, content not legally protected  The Hill\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | 04a - Hypothetical \"success stories\" to accompany \"Nearcast-based 'deployment problem' analysis\" - Google Docs\n",
      "https://docs.google.com/document/d/1I6I3qEBhk8hHacJW7ufBZV_-plFq5SDcy_EGw3941ZQ/edit | 2023-02-09 Peter Wildeford - Google Docs\n",
      "https://twitter.com/Rainmaker1973/status/1644248670160801792 | Massimo on Twitter: \"When traffic cones along a road in New Zealand began mysteriously moving around, the Transport Agency set up a CCTV to pin down the culprits It turned out a Kea parrot moved them to get attention from humans &amp; get fed [read more: https://t.co/U2cecFOeXh] https://t.co/mqGE37IIpr\" / Twitter\n",
      "https://www.washingtonpost.com/archive/opinions/1987/04/12/sexpionage-why-we-cant-resist-those-kgb-sirens/900e1e59-1a7b-455f-93cf-22e67394512b/ | SEXPIONAGE WHY WE CAN'T RESIST THOSE KGB SIRENS - The Washington Post\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?sd=pf | What did they know, and when did they know it? The Microsoft Bing edition.\n",
      "https://newsletter.safe.ai/ | https://newsletter.safe.ai/\n",
      "https://www.wikiwand.com/en/Kaleidoscope_(American_TV_series) | Kaleidoscope (American TV series) - Wikiwand\n",
      "https://www.youtube.com/watch?v=xtNrm-EXRjI | Markus Anderljung Regulating increasingly advanced AI some hypotheses - YouTube\n",
      "https://www.nytimes.com/2022/11/08/upshot/poll-experiment-wisconsin-trump.html | Are the Polls Still Missing ‚ÄòHidden‚Äô Republicans? Here‚Äôs What We‚Äôre Doing to Find Out.\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://docs.google.com/document/d/1J4TK6twjcF3hop5ZoEVR-_FVnnRdABFSm0WZkuuhU6c/edit | EPE'22 Process Debrief - Google Docs\n",
      "https://www.bryantresearch.co.uk/insights/institutional-change?fbclid=IwAR2kEV1sDJpgiiTKhWLAz4JqY3WTwdqShDuVg_4Z-ZMiv7h_TpXwhNj1YG4 | Bryant Research - Institutional Change\n",
      "https://www.wikiwand.com/en/Superbad#Reception | Superbad - Wikiwand\n",
      "https://docs.google.com/spreadsheets/d/1p7KAFI8_oQVHS3nXNAaWqIPExb87MsBWo9pS98gcQQc/edit | RP AIGS project options spreadsheet - Google Sheets\n",
      "https://www.metaculus.com/questions/13003/oecd-trust-in-government/ | OECD Trust in Government  Metaculus\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://nunosempere.com/blog/2023/03/15/fit-beta/ | Find a beta distribution that fits your desired confidence interval\n",
      "https://smile.amazon.com/How-Calm-Your-Mind-Productivity-ebook/dp/B09WM9PTD9?ref_=ast_sto_dp&sa-no-redirect=1 | AmazonSmile: How to Calm Your Mind: Finding Presence and Productivity in Anxious Times eBook : Bailey, Chris: Kindle Store\n",
      "https://twitter.com/TaylorWWebb/status/1641172201792761856 | (1) Taylor Webb on Twitter: \"Major update to our paper on emergent analogy in LLMs, with a number of additional tests and behavioral experiments, and a preliminary test of GPT-4. https://t.co/mvzvIJh1dI\" / Twitter\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [Funder Copy] - Google Docs\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://garymarcus.substack.com/p/the-sparks-of-agi-or-the-end-of-science | The Sparks of AGI? Or the End of Science?\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://twitter.com/ozyfrantz | (1) ozy brennan ü¶ô (@ozyfrantz) / Twitter\n",
      "https://docs.google.com/document/d/1YAJ0uVLDHb887LQKMd0HNSF167eksCjSkhKVo9rvEfg/edit | [West] Thoughts on recent PRC statements on international AI ethics and governance - Google Doc\n",
      "https://www.lesswrong.com/posts/bceeKEnPHSQqgyr36/request-to-agi-organizations-share-your-views-on-pausing-ai | Request to AGI organizations: Share your views on pausing AI progress - LessWrong\n",
      "https://thebulletin.org/2023/01/researchers-hacked-a-labs-pathogen-containment-system-was-it-a-good-idea-to-publish-the-results/ | Researchers hacked a lab's pathogen containment system. Was it a good idea to publish the results? - Bulletin of the Atomic Scientists\n",
      "https://docs.google.com/document/d/1cgyL0QbR26XWqbR8GoUOe2nMcAy_rXK1eKKhrwBHyc8/edit | EA Scandal Risk Write-up 2 - Google Docs\n",
      "https://www.oneusefulthing.org/p/how-to-use-chatgpt-to-boost-your | How to... use ChatGPT to boost your writing\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://www.pasteurscube.com/notes-on-managing-to-change-the-world/ | Notes on \"Managing to Change the World\"\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage‚àÜ\n",
      "https://docs.google.com/document/d/1bue7VzQPZ9Uy7drOShVdF1h0_uSAB9wQsSA4gcBvPGg/edit | Takeaways from EAGx Cambridge convos about GLT‚Äôs strategy (mostly entrepreneurship stuff) - Google Docs\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment\n",
      "https://twitter.com/patentbuzz/status/1645418703889092608 | https://twitter.com/patentbuzz/status/1645418703889092608\n",
      "https://garymarcus.substack.com/p/this-week-in-ai-doublespeak | This Week in AI Doublespeak - by Gary Marcus\n",
      "https://docs.google.com/document/d/1oKQc5QKfEjRQHPU2g6kQBUadhOmFwTg40NH-EW_nrjU/edit#heading=h.za992j72817 | [Shareable] Coordination between labs - LAISR discn summary - Google Docs\n",
      "https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/ | In defense of prompt engineering\n",
      "https://osf.io/458cx | OSF\n",
      "https://magazine.sebastianraschka.com/p/ahead-of-ai-4-a-big-year-for-ai | Ahead of AI #4: A Big Year For AI - by Sebastian Raschka\n",
      "https://docs.google.com/document/d/1ZG0XIP6ItkSBfWPaH6n2Fd0J7A6dvYtfFAy1S7YyhSY/edit | Biggest Mistakes we‚Äôre making - Google Docs\n",
      "https://docs.google.com/document/d/1mWa6pM65MqVnWgpMLSv0IejP526_0OjGCMbNbDz89jg/edit | Mike McCormick <> Renan/Linch on LT entrepreneurialism - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success Without Dignity - Google Docs\n",
      "https://twitter.com/srush_nlp/status/1645534519083016193 | https://twitter.com/srush_nlp/status/1645534519083016193\n",
      "https://www.youtube.com/watch?v=Iv9vphCwsaU | https://www.youtube.com/watch?v=Iv9vphCwsaU\n",
      "https://www.planned-obsolescence.org/training-ais-to-help-us-align-ais/ | Training AIs to help us align AIs\n",
      "https://twitter.com/robbensinger/status/1639061235164659712 | Rob Bensinger üîç on Twitter: \"@RosieCampbell OK, I was partly kidding. I do think most likely AI surprises look pessimistic, but some would look optimistic. See https://t.co/IS2jxBQHXd Links: 1. https://t.co/htpadcWU1v 2. https://t.co/6TbJACvNsa 3. https://t.co/StpwXHREvn. https://t.co/nHZpEm0Yg5\" / Twitter\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://twitter.com/mcxfrank/status/1640379280990560258 | Michael C. Frank on Twitter: \"The take-home here is that we are off by 4-5 orders of input magnitude in the emergence of adaptive behaviors. (That's the figure from above). The big broad cognitive science question is - which factors account for that gap? I'll think about four broad ones. https://t.co/QZfUiwJO8X\" / Twitter\n",
      "https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ | Update on ARC's recent eval efforts\n",
      "https://docs.google.com/document/d/18bOeTikuNvI0G34UCgZQkySi87_3lqhLDF9JGkTxUl0/edit | [2023.02.12 (Feb)] Defense-in-Depth Compiled Report [Master Copy] - Google Docs\n",
      "https://www.oneusefulthing.org/p/my-class-required-ai-heres-what-ive?fbclid=IwAR03DvA57jfUfx2R27nHDMSybKiPsMIFyLTnC43l-Kj4jiCCsGUIElXPH7s | My class required AI. Here's what I've learned so far.\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/akn2BFhhM9CzwpLEA/wisdom-of-the-crowd-vs-the-best-of-the-best-of-the-best | Wisdom of the Crowd vs. \"the Best of the Best of the Best\" - EA Forum\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://www.rei.com/blog/climb/new-survey-finds-nearly-one-third-of-respondents-have-experienced-sexual-harassment-or-assault-while-climbing?utm_source=Sailthru&utm_medium=email&utm_campaign=Future%20Perfect%20Wednesday:%202/15/23&utm_term=Future%20Perfect | Survey Reveals Sexual Harassment & Assault While Climbing - REI Co-op Journal\n",
      "https://docs.google.com/document/d/1PidPXJWKKqCbWGzWQ7IySDnOkiK5rX0n2naaSjz7q3g/edit#heading=h.6ytgvt3dfnpe | Kieran Greig Copy of Oct-Nov - RP Performance Evaluation Template - Google Docs\n",
      "https://twitter.com/SSGamblers | Star Spangled Gamblers (@SSGamblers) / Twitter\n",
      "https://onthinktanks.org/ | On Think Tanks  Independent research, ideas and advice\n",
      "https://docs.google.com/document/d/1qVXta8izrX3gmPVSX-QjuDTCg3TSkjbrWkKPm6PdBPQ/edit | RP Copy of Projects Alex would be excited about - March 2023\n",
      "https://twitter.com/davidchalmers42/status/1640357701417938945 | David Chalmers on Twitter: \"@rgblong in the terms i used, it arguably doesn't have an e-understanding of unicorns, e.g. knowing what it's like to see a unicorn. it arguably has a b-understanding (behavior) and r-understanding (recognitional) on performance-based readings. i-understanding (inferential) is tricky.\" / Twitter\n",
      "https://docs.google.com/document/d/1v14aMi7GhpNhk5ahmqgZVeYCKVvSdf9Bsoz8yfR6MpM/edit | The AI playbook as I see it - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jdYBDLrhBgVaf1WqjIlFiksyTemD-U9eIka1Amtwkno/edit | 2023 Jan Lights - Google Sheets\n",
      "https://docs.google.com/document/d/1oInPr-bzqtAULzonDajiT8M10LF50WNfiuaaIkElk4g/edit#heading=h.217anus74gpx | [Shareable] Cost-effectiveness of boosting US AI progress - Google Docs\n",
      "https://www.personalhackathon.com/ | Personal Hackathon - A day dedicated to maximizing your productivity\n",
      "https://twitter.com/mcxfrank/status/1640379247373197313 | Michael C. Frank on Twitter: \"How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. üßµ https://t.co/hayhUU5Iv6\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1636508502498897921 | Jeffrey Ladish on Twitter: \"I've decided to donate $240 to both GovAI and MIRI to offset the $480 I plan to spend on ChatGPT Plus over the next two years ($20/month). I don't have a super strong view on ethical offsets but they feel right to me in this case. One reason is that it seems useful to actually‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1G3MsnzEmMQ11RzJeGe8WChbFRIHhi_yWVDW_tW1EdD0/edit | Coordinating AI development around a moving bright line - Google Docs\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "https://aypan17.github.io/machiavelli/ | The MACHIAVELLI Benchmark\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & ‚ÄúThe correct response to uncertainty is *not* half-speed‚Äù - EA Forum\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://twitter.com/leopoldasch/status/1643384705088364544 | Leopold Aschenbrenner on Twitter: \"GPT-4 can encode secret messages (and hide them from a user) (!!)\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://80000hours.org/about/credibility/evaluations/mistakes/ | Our mistakes - 80,000 Hours\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://docs.google.com/document/d/1YdtearE-rcd8UA34IPe4uW_pBSUzPjOeGOjc68oZfEQ/edit# | [PUBLIC] Marketing data visualisations - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register - April 2023 Finalized\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity‚Äôs demise: ‚Äúwe must eliminate them‚Äù - Dexerto\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/gmzrYzpR9zb8um5FK/ea-rationality-sexual-assault-and-liability | EA, Rationality, Sexual Assault, and Liability - EA Forum\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine‚Äôs Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://www.google.com/search?q=chaos+gpt&rlz=1C1GCEA_enGB993GB993&sxsrf=APwXEdfDrsc7CTFBEUhij_z8R-U-YNslqg:1681232294309&source=lnms&tbm=vid&sa=X&ved=2ahUKEwjksL-tpqL-AhXMWMAKHUc6BTUQ_AUoAnoECAEQBA&biw=767&bih=732&dpr=1.25 | chaos gpt - Google Search\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter ‰∏äÁöÑ Boaz BarakÔºö\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/zQ7b9ghv3Tkd2LLNL/an-ea-s-guide-to-washington-dc | An EA's Guide to Washington DC - EA Forum\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://twitter.com/emollick/status/1645432299587026944 | https://twitter.com/emollick/status/1645432299587026944\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tabs)\n",
    "print_tabs(tabs, label='Shuffled all tabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875f10-ecdd-43fd-b849-196c6bd1977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
