{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "1361\n",
      "1360\n",
      "1347\n",
      "1299\n",
      "1291\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs_from_text(tab_text):\n",
    "    tabs = tab_text.split('\\n')\n",
    "    print('{} tabs opened!'.format(len(tabs) - 2))\n",
    "    for t in tabs:\n",
    "        open_tab(t.split('|')[0].strip())\n",
    "        \n",
    "print('Loaded')\n",
    "\n",
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5fddf1-e942-4059-b414-48e28bdc58f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted tabs! (1291)\n",
      "-\n",
      "https://80000hours.org/career-reviews/ai-safety-researcher/ | AI safety technical research - Career review\n",
      "https://80000hours.org/career-reviews/working-at-an-ai-lab/?source=email&uni_id=0&utm_source=80%2C000+Hours+mailing+list&utm_campaign=3964985d12-EMAIL_CAMPAIGN_2023_07_19_12_43&utm_medium=email&utm_term=0_43bc1ae55c-7c70354392-%5BLIST_EMAIL_ID%5D | Should you work at a leading AI lab? - Career review\n",
      "https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/ | Ajeya Cotra on accidentally teaching AI models to deceive us - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://80000hours.org/podcast/episodes/christopher-brown-slavery-abolition/ | Christopher Brown on why slavery abolition wasn't inevitable - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/elie-hassenfeld-givewell-critiques-and-lessons/ | Elie Hassenfeld on two big picture critiques of GiveWell's approach, and six lessons from their recent work - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/ezra-klein-ai-and-dc/ | EzraKleinonexistentialriskfromAIandwhatDCcoulddoabout it\n",
      "https://80000hours.org/podcast/episodes/holden-karnofsky-how-ai-could-take-over-the-world/ | Holden Karnofsky on how AIs might take over even if they're no smarter than humans, and his four-part playbook for AI risk - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/jan-leike-superalignment/ | Jan Leike on OpenAI's massive push to make superintelligence safe in 4 years or less - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/jeffrey-lewis-common-misconceptions-about-nuclear-weapons/ | Jeffrey Lewis on the most common misconceptions about nuclear weapons - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/joe-carlsmith-navigating-serious-philosophical-confusion/ | Joe Carlsmith on navigating serious philosophical confusion - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/lennart-heim-compute-governance/ | LennartHeimonthecomputegovernanceeraandwhathastocome after\n",
      "https://80000hours.org/podcast/episodes/markus-anderljung-regulating-cutting-edge-ai/ | Markus Anderljung on how to regulate cutting-edge AI models - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/richard-ngo-large-language-models/ | Richard Ngo on large language models, OpenAI, and striving to make the future go well - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://80000hours.org/problem-profiles/great-power-conflict/ | Great power conflict - 80,000 Hours\n",
      "https://a16z.com/2011/04/14/peacetime-ceo-wartime-ceo/ | Peacetime CEO/Wartime CEO  Andreessen Horowitz\n",
      "https://abcnews.go.com/Technology/wireStory/council-hold-meeting-potential-threats-artificial-intelligence-global-100637416 | UN council to hold first meeting on potential threats of artificial intelligence to global peace - ABC News\n",
      "https://ai-risk-discussions.org/ | ai-risk-discussions.org/\n",
      "https://ai.google/ | Google AI\n",
      "https://ai.meta.com/ | Meta AI\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://aifuturesfellowship.org/ | AI Futures Fellowship\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://aipolicy.us/ | Center for AI Policy\n",
      "https://aisafetychina.substack.com/p/ai-safety-in-china-1 | (1) AI Safety in China #1 - AI Safety in China\n",
      "https://alignment-workshop.com/ | Alignment Workshop 2023\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://aminrb.me/blog/extra-work/ | Navigating Extra Work in Programming Teams  Amin Rashidbeigi\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://anthropic.com/index/frontier-threats-red-teaming-for-ai-safety | Frontier Threats Red Teaming for AI Safety\n",
      "https://apolloresearch.ai/blog/security | Security at Apollo Research — Apollo Research\n",
      "https://apricitas.io/p/the-semiconductor-trade-war | The Semiconductor Trade War - by Joseph Politano\n",
      "https://arbresearch.com/files/gen_bio.pdf | genbio\n",
      "https://arena-ch1-transformers.streamlit.app/ | arena-ch1-transformers.streamlit.app/\n",
      "https://arxiv.org/abs/2001.00463 | The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI Research Reduce Misuse?\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://arxiv.org/abs/2303.11341 | [2303.11341] What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://arxiv.org/abs/2304.03442 | Generative Agents: Interactive Simulacra of Human Behavior\n",
      "https://arxiv.org/abs/2304.05376 | ChemCrow: Augmenting large-language models with chemistry tools\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://arxiv.org/abs/2306.09983 | Evaluating Superhuman Models with Consistency Checks\n",
      "https://arxiv.org/abs/2306.12001 | [2306.12001] An Overview of Catastrophic AI Risks\n",
      "https://arxiv.org/abs/2307.00175 | [2307.00175] Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks\n",
      "https://arxiv.org/abs/2307.00682 | Tools for Verifying Neural Models' Training Data\n",
      "https://arxiv.org/abs/2307.04699 | [2307.04699] International Institutions for Advanced AI\n",
      "https://arxiv.org/abs/2307.08823 | [2307.08823] Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries\n",
      "https://arxiv.org/abs/2308.01404 | [2308.01404] Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models\n",
      "https://arxiv.org/abs/2308.08708 | [2308.08708] Consciousness in Artificial Intelligence: Insights from the Science of Consciousness\n",
      "https://arxiv.org/pdf/2303.09001.pdf | Reclaiming the Digital Commons: A Public Data Trust for Training Data\n",
      "https://arxiv.org/pdf/2306.03809.pdf | LLM StF manuscript\n",
      "https://arxiv.org/pdf/2306.10062.pdf | 2306.10062.pdf\n",
      "https://arxiv.org/pdf/2307.03718.pdf | 2307.03718.pdf\n",
      "https://arxiv.org/pdf/2308.09045.pdf | 2308.09045.pdf\n",
      "https://arxiv.org/pdf/2308.14752.pdf | AI Deception: A Survey of Examples, Risks, and Potential Solutions\n",
      "https://askamanager.org/2022/04/my-employee-wastes-a-huge-amount-of-everyones-time-with-helpful-suggestions-and-questioning.html | my employee wastes a huge amount of everyone's time with \"helpful\" suggestions and questioning — Ask a Manager\n",
      "https://asteriskmag.com/issues/01/modeling-the-end-of-monkeypox | Modeling the End of Monkeypox—Asterisk\n",
      "https://asteriskmag.com/issues/01/why-isn-t-the-whole-world-rich | Why Isn’t the Whole World Rich?—Asterisk\n",
      "https://asteriskmag.com/issues/02/what-comes-after-covid | What Comes After COVID—Asterisk\n",
      "https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety | A Field Guide to AI Safety—Asterisk\n",
      "https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are | Are We Smart Enough to Know How Smart AIs Are?—Asterisk\n",
      "https://asteriskmag.com/issues/03/how-we-can-regulate-ai | How We Can Regulate AI—Asterisk\n",
      "https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth | The Great Inflection? A Debate About AI and Explosive Growth—Asterisk\n",
      "https://astralcodexten.substack.com/p/your-book-review-safe-enough | Your Book Review: Safe Enough? - by a reader\n",
      "https://axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://axios.com/2023/08/15/eric-braverman-leaves-ceo-schmidt-futures | Eric Braverman leaves as CEO of Schmidt Futures to start new venture\n",
      "https://badgirlsbible.com/sex-bucket-list | Sex Bucket List: 243 Sexual Things To Do Before Your Die\n",
      "https://baseratesblog.substack.com/p/lukewarm-takes-on-ai-risk | Lukewarm takes on AI risk\n",
      "https://bayesshammai.substack.com/p/model-care-execution | Model, Care, Execution - by Ricki Heicklen - Bayes Shammai\n",
      "https://bbc.com/news/technology-65779181 | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://ben-evans.com/benedictevans/2023/7/2/working-with-ai | AI and the automation of work\n",
      "https://beta.character.ai/ | character.ai\n",
      "https://betonit.substack.com/p/the_social_andhtml | The Social and Political Realities of Immigration: A Reply to Hoste\n",
      "https://bitsaboutmoney.com/archive/the-waste-stream-of-consumer-finance/ | Credit card debt collection\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/ | Squeeze the hell out of the system you have – Dan Slimmon\n",
      "https://blog.heim.xyz/the-case-for-pre-emptive-authorizations/ | The Case for Pre-emptive Authorizations for AI Training\n",
      "https://blog.heim.xyz/this-cant-go-on-compute-training-costs/ | This can't go on(?) - AI Training Compute Costs\n",
      "https://blog.jakegloudemans.com/archive | Archive - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/10-predictions-2 | Predictions #2 - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/11-links-7-11-2023 | Tuesday Links - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/12-adversarial-policies-go | Go AIs have surprising vulnerabilities - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/13-predictions-3 | Predictions #3 - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/14-dangerous | Things usually get less dangerous, not more - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/15-links-7-26-2023 | Wednesday Links - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/16-predictions-4 | Predictions #4 - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/17-predictions-5 | Predictions #5 - Jake Gloudemans\n",
      "https://blog.jakegloudemans.com/post/19-my-2023-ace-forecast | Interactive Chart - 2023 ACE Forecast - Jake Gloudemans\n",
      "https://blog.jonasmoss.com/posts/quantiles/quantiles.html | Deriving distributions from quantiles\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://bloomberg.com/news/articles/2023-06-27/ai-is-next-tech-battle-for-us-and-china-on-chatgpt-frenzy?srnd=premium-asia#xj4y7vzkg | Billionaires and Bureaucrats Mobilize China for AI Race With US\n",
      "https://bloomberg.com/news/articles/2023-08-08/stability-ai-s-lead-threatened-by-departures-concerns-over-ceo?in_source=embedded-checkout-banner&utm_source=substack&utm_medium=email#xj4y7vzkg | Stability AI’s Lead Threatened by Departures, Concerns Over CEO - Bloomberg\n",
      "https://bloomberg.com/news/articles/2023-08-14/china-tries-to-regulate-ai-with-state-control-support-for-tech-companies?utm_source=substack&utm_medium=email#xj4y7vzkg | China Tries to Regulate AI With State Control, Support for Tech Companies - Bloomberg\n",
      "https://bonobology.com/jealousy-in-polyamory/ | Dealing With Jealousy In Polyamorous Relationships\n",
      "https://bostonglobe.com/2023/07/06/opinion/ai-safety-human-extinction-dan-hendrycks-cais/ | Dan Hendrycks of the Center for AI Safety hopes he can prevent a catastrophe\n",
      "https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/ | What will GPT-2030 look like?\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://businessinsider.com/ed-sheeran-ai-music-warn-tech-chatgpt-generative-ai-2023-8?r=US&IR=T&utm_source=substack&utm_medium=email | Ed Sheeran Says He Finds 'AI a Bit Weird' and Worries About Job Losses\n",
      "https://bustle.com/articles/188094-7-polyamorous-people-on-overcoming-jealousy | 7 Polyamorous People On Overcoming Jealousy\n",
      "https://cambridge.org/core/journals/international-organization/article/hacking-nuclear-stability-wargaming-technology-uncertainty-and-escalation/B4D81871FC0115882AA42A0C1055C732 | Hacking Nuclear Stability: Wargaming Technology, Uncertainty, and Escalation  International Organization  Cambridge Core\n",
      "https://carnegieendowment.org/2023/07/10/how-climate-change-challenges-u.s.-nuclear-deterrent-pub-90130 | How Climate Change Challenges the U.S. Nuclear Deterrent - Carnegie Endowment for International Peace\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://cfactual.com/ | cfactual.com/\n",
      "https://chinatalk.media/p/the-cias-cold-war-china-forecasting | CIA Cold War China Forecasting - by Nicholas Welch\n",
      "https://chineseperspectives.ai/ | chineseperspectives.ai/\n",
      "https://coda.io/d/Nonlinear-Network_d2zmoRh9wTR/Improving-institutional-societal-decision-making_sumF-#_luOOZ | Nonlinear Network · Improving institutional / societal decision-making\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://consciouspolyamory.org/2016/02/06/envy-and-the-secondary/ | Envy and the Secondary – Conscious Polyamory: A blog about loving more than one\n",
      "https://contextual.ai/plotting-progress-in-ai/ | Plotting Progress in AI - Contextual AI\n",
      "https://cooperativeai.com/job-listing/managing-director | Cooperative AI\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf | CSET-AI-Triad-Report.pdf\n",
      "https://cyberscoop.com/white-house-executive-order-artificial-intelligence/ | White House is fast-tracking executive order on artificial intelligence  CyberScoop\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://deepmind.com/blog/exploring-institutions-for-global-ai-governance | Exploring institutions for global AI governance\n",
      "https://defcon.org/html/links/dc-about.html | DEF CON® Hacking Conference - About\n",
      "https://dietrichvollrath.substack.com/p/will-ai-cause-explosive-economic | Will AI cause explosive economic growth?\n",
      "https://discoursemagazine.com/ | Discourse  Home\n",
      "https://docs.google.com/document/d/1-87ePz2QqrtS2ty6Oo2280rFe5g1A6llnjyyZ-A_NAc/edit | Slowing Down AI - Google Docs\n",
      "https://docs.google.com/document/d/1-KYHVu8_tl3KwZHnRasI95UMup5TRIOdVpNrVl7jCwQ/edit#heading=h.rgncuqae7xa4 | Two RAND media-related policies\n",
      "https://docs.google.com/document/d/10X2_z_woKInzGcYCjCdSdauln3Es-Mmxnp5S9R5LihU/edit | AIGS comms & stakeholder-relationships tasks - Google Docs\n",
      "https://docs.google.com/document/d/10ZiN68NxrJjtroPO9Rf6DPeDAbwBKTQrGkML6vg94JM/edit#heading=h.vbjoylhp5m9w | Project idea: Republican-focused AI outreach (REFO) - Google Docs\n",
      "https://docs.google.com/document/d/11-4fkBN6nydyE1EKEYj4d9DNXN398iu-b-rLfTrS3qQ/edit?pli=1 | 2023 RP application to Open Philanthropy for AW 2024 - 2026\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/11izXrENe0_IAor93e4-Gbgr18JAjzS7yIltVuxFaR1U/edit | Scaling Well - Google Docs\n",
      "https://docs.google.com/document/d/12g1eG74WT-NbX-e6jNDrpRxDwhgI-I6taAz-fYt4f7o/edit | Problems with MWs given moral uncertainty\n",
      "https://docs.google.com/document/d/12zdjWUq-R9bZAEbUa2iqFGCxZE7gGULtexI09bs0H44/edit | AIGS staff temporarily working at / embedding in other institutions\n",
      "https://docs.google.com/document/d/14FbYykjB93Xt3ddroSgS1xFg_-BKG9adOtw_fbt5wRU/edit#heading=h.wydrvf8wjwnl | RP case studies - for input from Cullen\n",
      "https://docs.google.com/document/d/16HmGQ2sSGdGZsY-FrZxzFTf_uj4Jj8TE7SW_qEw7wRw/edit | Peter W time management - Google Docs\n",
      "https://docs.google.com/document/d/16yGPyJ7mHyKNhDJNRvNGqt9pjEWyn7123Ud7A1pnMAM/edit | ERA Hiring note - Google Docs\n",
      "https://docs.google.com/document/d/17QTfO_7kcs84N3cMImkY_1K6HFWLUOKa_tTqYlcxgvI/edit#heading=h.r9pyekg8gxd | Kyle Gracey (Future Matters) <> Jam: AIPLUS\n",
      "https://docs.google.com/document/d/17k-MBAD4TrtqjbQ3sNlyDEF_QEnQ5prT87zNyMIa2RE/edit#heading=h.wfl3wbuv35qt | Difference-Making Risk-Averse Expected Value\n",
      "https://docs.google.com/document/d/17kWbF4sWEaQengbahms4W5zVMD_VeVBDiUxXf2Zt_rA/edit | Federal Select Agents Program ~ case study for OAI - Emma Williamson - Google Docs\n",
      "https://docs.google.com/document/d/18KMqTKbJCvfNHIh7yMdGs-GN-NflsTOijD-6tYKnxuY/edit#heading=h.shuwelnrazfc | Refactoring Years Credit Calculations - Google Docs\n",
      "https://docs.google.com/document/d/18Q-Mn0mKrPxYTC38eBqyctR5jHuKjJ-thMDGuJ-OXC8/edit#heading=h.nilb5yn0fc6s | [2023.07.31] Defense-in-Depth Framing Piece - Google Docs\n",
      "https://docs.google.com/document/d/19EBpy5fZNf-kOEUbyT8JY_EfNMANkZC5PLNtq-7-QFs/edit#heading=h.apkacljs0r | Ashwin brief takes: where to go next with AI case studies? - Google Docs\n",
      "https://docs.google.com/document/d/19TtG9VmjhrBDsKovBH4zm7n-zLwiSqYa6C4ZgmYKdqI/edit#heading=h.5b4arlm5x51v | Elika Somani <> Jam: UFO and Careers advice program\n",
      "https://docs.google.com/document/d/19f2eqUx3zP8Z8234poDJmNid1ot4i9cTViPNBI6se6g/edit#heading=h.e4yozfynvf7 | Pinpoint Factsheet: Rubrics & Scoring - Google Docs\n",
      "https://docs.google.com/document/d/19iVuL9Vt3hHjB0Eb0zs-5rVcw-VvVF5_A3n1h26WG1A/edit | Risks and Animals Draft\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/19rKkgNqaMPRISPqjJGU48GfXxNzZYjrtds-FTI52Dlc/edit | Peter <> Michael - 1-1s - 2023 Q3-4 - Google Docs\n",
      "https://docs.google.com/document/d/19zi--DczOvP1mf8Mf3T4PpsOBx2evVpnXBqk9y53lrE/edit | EA Forum Impact Assessment Proposal\n",
      "https://docs.google.com/document/d/1AcQqV3M-TXpJ4NfjxofmenSdhgdD9FIp_Dp3_mNoBdA/edit#heading=h.xwwwlf2won0k | Ben's August review of XST incubation - Google Docs\n",
      "https://docs.google.com/document/d/1B-VGwlk-EWDWeNnMxtOm4jEsKlGfYh5Iuufijm8qGZ0/edit | [shared] Good actions for labs - Google Docs\n",
      "https://docs.google.com/document/d/1BCdfRWnsePZMYJqe7mErgmPJhWSl3kZ9p2-d5r4jnVE/edit#heading=h.q0n380umtiqg | Possible projects on EA reform - for reform Slack - Google Docs\n",
      "https://docs.google.com/document/d/1BnI-FYzz0Coti2nV5t63w8Ga6WWiFSK_kYjE9T2SjLc/edit#heading=h.dcdsb7ob0lnc | * COLLECTION: Positive feedback / signals / praise for XST - Google Docs\n",
      "https://docs.google.com/document/d/1CN7c8rft3RZ-lwzVB_MziKbixQatTbhsRaikt3v83PE/edit | [public] RP US AI regulations team 2-pager (June-Aug 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1CTOTiOhh0uZw7wwwqbFDpq7qakMVEUkAtEecVSfRmcU/edit#heading=h.k19pb4a7ch8m | Expertise within licensing authorities\n",
      "https://docs.google.com/document/d/1CaF6_qyMfn98T5xkGz8yxjBUBUKkv22MQ8q-0Syx0pU/edit | Niki Iliadis <> Ashwin Acharya - 2023-07-11\n",
      "https://docs.google.com/document/d/1CcsOyHJRB_sHMvVq6cKaKT94SEnffAk2xYgGAWRchCQ/edit#heading=h.sja5ou1zlohi | FCC case study for OAI - Patrick - Google Docs\n",
      "https://docs.google.com/document/d/1CpO25iV38hXESPRQZmv15bLjBB_hrAYgAkvfHoJbngE/edit#heading=h.j9owozbw0x7p | Layer - Safety Culture - Google Docs\n",
      "https://docs.google.com/document/d/1DD39bXAjzLpKVNC6MHHOBJuoXIzW9rA276gsW-vqF-M/edit#heading=h.ro1jy37s9d8f | Notes - Gabriel Weil and Ashwin Acharya - Google Docs\n",
      "https://docs.google.com/document/d/1DJOwiyhbeYgwOc40d1DAf7tLYO2DC-OkEoHKY6b6EAQ/edit#heading=h.qym1zou1p9i | Ben Garfinkel's takes on what it's good vs bad to share with aligned people at labs - Google Docs\n",
      "https://docs.google.com/document/d/1DU9OEpypkOWqBtuqAB7-ZAsjWTNMU6a3_djj0ceoj7E/edit#heading=h.70hct81u0agh | Extreme risk eval responses\n",
      "https://docs.google.com/document/d/1E7kOVl710IUeryiKSLMSifzvJmb-ONwfEfaWDQ4vXJk/edit | Risk-Weighted Expected Utility Implementation Methodology - Google Docs\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://docs.google.com/document/d/1F6LKH0pIuLieB-ftedt8IoIEO1KDXjiskv4NgHGvejM/edit#heading=h.geusbjtw9km | [RP/OP only] Notes from Aug 9th AIXR advocacy and lobbying info-sharing call - Google Docs\n",
      "https://docs.google.com/document/d/1FAKQ066uTnavdCggCaaonZlcypprzTJq1shGIvaW2y0/edit | Anjay Friedman <> RP AIGS (Lab Governance)\n",
      "https://docs.google.com/document/d/1FawqcfCuZqkfZBnjPF4SIgciHTyEz5qElYpYT_jN1mo/edit#heading=h.r1usdwqumjih | Risk-uncertainty in regulatory agencies\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1Gkh3hbsURR9xJkvunr8PKtshM230uSG5WmyAQVMj4FQ/edit#heading=h.n1nw4b3u8t9s | 2023-04-13 Compute Scaling Methods at Companies - Google Docs\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://docs.google.com/document/d/1H5BwxHaER62rqvIG051YK5VoFPM8dZefv2yhePWzzKw/edit#heading=h.kof73g10f1qh | RP AI regs team - survey suggestions - Google Docs\n",
      "https://docs.google.com/document/d/1HSltd_J8-C_Jje8pniWZY2xt9WZMqhPS8PeYDwRI-Dw/edit#heading=h.xw0gyniluvvi | [RP only] Prep for infosharing call AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1HlkOSn7HGkRIffkwMQS2ZtCcvCRHn5Akt2ptfidwLso/edit | Maybe if time permits get more advice on how I can be more helpful to Michael + AIGS - Google Docs\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://docs.google.com/document/d/1I6PEBNI1qC2ezMw_Tzi-4u098_5QjAn-hR61gRr6Tjc/edit | LTFF application for XST 2023-06 - Google Docs\n",
      "https://docs.google.com/document/d/1I9Fw8Y3tdQWEIOIdFRRIvYBISLg0_uKLZgOSn09-9aU/edit#heading=h.lqtiq1w77guj | Training Process Transparency through Gradient Interpretability: Some preliminary results for toy language models\n",
      "https://docs.google.com/document/d/1IJvZp1Cg3Oybhm4hqaT0fR1GUQ8FqyyKtOZHNL0RxZs/edit | Notes - WIT Weekly Meeting\n",
      "https://docs.google.com/document/d/1IN7QqjeMbW7b4-oCUeZ9v6C397n-Hcl3q6Ig9FuWI-U/edit#heading=h.34g6myoeaex8 | 2023 AW Research & Projects Agenda [final] - Google Docs\n",
      "https://docs.google.com/document/d/1Iu2iAz-S1BewDYhI05-9fkM8LNoDQeesjrIpvOu54lY/edit | AI Safety at Google - Google Docs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1KTE-9sq_7ig7Sohphwwk1epBFHietzcCOixBMerBH5w/edit#heading=h.j35uzjbkgmnb | Leveraging hardware security features for AI governance [shared widely] - Google Docs\n",
      "https://docs.google.com/document/d/1KUdK1GwwzI0wBmeGKE0nmgHRPtUIUx-j7wHUxJCIe_E/edit | Will humanity achieve its full potential, as long as existential catastrophe is prevented? [semi-public] - Google Docs\n",
      "https://docs.google.com/document/d/1Km37KtOAut89_ZxTPg0zlk7KgrNDlL1REiQBn26uJqs/edit | Yet another Caro doc for 2023 Jul 22 meeting - Google Docs\n",
      "https://docs.google.com/document/d/1LLzrTxtqsUtkmYbaqeAl26NT2fFJeYDEks1Mv_gcAQA/edit#heading=h.kydrosfseiym | Nuclear Regulatory Commission case study - Ashwin - Google Docs\n",
      "https://docs.google.com/document/d/1Lmpvblvj8Gbr6kmnaBsE73GUyulwAtUGCeAmc2YuMaA/edit | Proposed changes to current competencies model - Google Docs\n",
      "https://docs.google.com/document/d/1MCfucZSVvIrPmLwa5PMw_umH8iyA5c-v9EbnUSZgH1c/edit | 2023 Q2 Project Research – Retrospective\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit#heading=h.mfc0g6vdbaom | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1NSAzsjSUakyD4V8xbqvBbv417ipR5Et0et6V_jl0pV4/edit#heading=h.j0g8zpixkwc3 | Braindump on preserving option value for careers in the UK government and international orgs - Google Docs\n",
      "https://docs.google.com/document/d/1NaDQWBLJwqBJAfJJ4sjmioZNk_ULSdkGOc_lj085ACg/edit#heading=h.sja5ou1zlohi | NHTSA - case study for OAI - Bill Anderson-Samways - Google Docs\n",
      "https://docs.google.com/document/d/1NnAZ5HH27BPHg8o7Kn9zA_z1jA03Y2nz9eEs5sJ4d84/edit#heading=h.uf8ilpq04z6u | AIPLUS Meeting Notes\n",
      "https://docs.google.com/document/d/1NyoN5wVQvJemeukV60T1LTUqTOguP6fRVvUW6FhVRg8/edit#heading=h.qhot0f2kle3x | Marie's DC trip – meeting notes masterdoc - Google Docs\n",
      "https://docs.google.com/document/d/1O14SkpysPGl5DaWYLuRcHIhAAKcK9HgRkCFkQy8R888/edit | USG & AI Project Retrospective - Google Docs\n",
      "https://docs.google.com/document/d/1OeaAALrSkjIyRy0vl5Ljhf1HIMwY_wzTtxwhPiC8JCo/edit#heading=h.ou91fmqchcm2 | Overview of IAPS's track record as of Aug 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1OkXIPftvJwAQn7BbbsRqQCbvxpYoqlTQnp3aGgkxSM8/edit#heading=h.xsij1kkvzxdb | Development-phase regulation: lessons for AI\n",
      "https://docs.google.com/document/d/1OlKlUwevSOMqyHqVjxEuR0QuZfX-SVZY-iidVAGfriw/edit#heading=h.fyqmhmgqjz1e | The Researcher's Guide to Comms - Google Docs\n",
      "https://docs.google.com/document/d/1OmKOmMfbmBnjxGGHetfN2VQ1az4Zox0Y-4f5xTlRzhw/edit#heading=h.g2xot74rmmug | Maybe let’s focus more on non-extinction ways that a lot of the potential value of the future could be lost? [quick notes] - Google Docs\n",
      "https://docs.google.com/document/d/1Oq9kWiesSTPb550uJqAP_I45cztL1CQNwOBMHfixSoU/edit#heading=h.yb91hy414ys0 | Darius Meissner <> Michael Aird - 2023-Jul-20 - Horizon + AIGS updates and intersections - Google Docs\n",
      "https://docs.google.com/document/d/1PZ7ZVTfIt0T_TgOBTQTLOOne7iakfQDW6uBjEyFMhQo/edit#heading=h.x8vizs97cm8 | AIGS June 2023 comms materials for review - Google Docs\n",
      "https://docs.google.com/document/d/1R7-1EMjnu1meonCE11BJ-fz8dKPil5hUzwjYLGEYMiE/edit#heading=h.h8jeam77skkl | What are the main AI regulation proposals in course in the US [HAIKU study notes]\n",
      "https://docs.google.com/document/d/1R9jnOAmZC0XGmJJPYrzUq8N_825SB1fzsd0yco7TbPA/edit#heading=h.5g5p4s3snxj0 | AI Governance overview - Google Docs\n",
      "https://docs.google.com/document/d/1RGt4t1Xl5trlH7WipeQIwrO_WE4Evskx99bh1lMcYjU/edit | How does Lobbying in the US work? [HAIKU study notes]\n",
      "https://docs.google.com/document/d/1R_yudIhkh8YJXRO20vDgGUkbklXpg2MrWF8bxAtcugo/edit#heading=h.tcmcuy30mpts | Julia’s takes on movement-wide codes of conduct - Google Docs\n",
      "https://docs.google.com/document/d/1SHtQfxe4EJziNjs0dBXnWwfMnYA2XKkcN6xN5n0HK5Q/edit | AIGS Meeting Reflections\n",
      "https://docs.google.com/document/d/1SJLINzoGi_F7LkiQDc3FibhNqbCQRddYepLyKDCBq7o/edit#heading=h.l4v8jsytq7ii | Henri + AIGS/XST meetings re LT fundraising - Google Docs\n",
      "https://docs.google.com/document/d/1SUgGftOMKO4GVSBzOa3wMDcAhM4UrOGAjYVPnALxKY4/edit#heading=h.ldo1rytwm7ve | Let’s incentivise AIs to prevent AI takeover\n",
      "https://docs.google.com/document/d/1Sf3mKWn6v7wp2tor4CaRhceBQ6EdRk-beA-BqlZdgag/edit#heading=h.jlb1cymowl8x | How to do research speedruns (EAGxNYC workshop)\n",
      "https://docs.google.com/document/d/1Sg9jfESsMx2T8Q16UoKOnIR0qba5gJ5J81zjtPXB0LQ/edit#heading=h.95onznz2devl | 1-pager: AIXR advocacy and lobbying info-sharing by Rethink Priorities XST - Google Docs\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://docs.google.com/document/d/1SsZq3IB0iKUUw7NJSWaprSkCC5WZgktU0Tx4qGlepo0/edit | Safety Culture - Framing Thoughts\n",
      "https://docs.google.com/document/d/1TEfxH_KeXC6hFg8nSm8BvhoYVrG4OPZlWsWfG70Lzos/edit | Ashwin, assessed by MA - 2023 July - RP Performance Evaluation\n",
      "https://docs.google.com/document/d/1TMQuWueZlDuUC_kezuG7PSZfQCDa7nAdWh3mnwHsntg/edit#heading=h.cxwu8u88x6jl | Rethink Priorities Animal Welfare Department 2024-2026 Strategy\n",
      "https://docs.google.com/document/d/1TOCUCg8oTxTPBEuPu5Vk41578kLuNbcm7XXkSkYrxR0/edit | CEA AI Issue Framing\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1Tsp_wK6GoJAgUCYoZmMN_H7vy3eG3r68IUAWjg5Qy6Y/edit | Management Copy - Bob Fischer 2023 May/June - RP Performance Evaluation - Google Docs\\\n",
      "https://docs.google.com/document/d/1U28BUEzpFkqDZgoQnUXznD25RpDsPPo5dZqMeIODy58/edit#heading=h.z8jlehglcsvt | Michael, self-eval - 2023 July - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1U4OqEJdjSwjun2ihDZfibjE3Bin6eJomdlASlkQ4eQ0/edit#heading=h.6ytgvt3dfnpe | Michael Aird - May 2023 - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1UerPByrxKBGfjflk3x3G2TEfKCTPOn1m4Xx1OFOSiOQ/edit | AI labs' statements on risk/progress - Google Docs\n",
      "https://docs.google.com/document/d/1V54T5iUvieVhIDihTXvSDnN6g97xv-kXK-LTOwlcvOc/edit | Thoughts about GW <> RP relationship moving forward - Google Docs\n",
      "https://docs.google.com/document/d/1VtttPKviEY2FM9RP5XUP_CK4bA6mj6Creq03-iQg5CI/edit | What XST has heard back from funders as of 2023-08-15 - Google Docs\n",
      "https://docs.google.com/document/d/1W5VKmUG_6QXHXPUoJkegPcooocO4jepWm_dVtxY-veE/edit#heading=h.bbl8wvrg7bsz | Researcher Gap Analysis 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1WD-3q2eEAj2YLlmyXrm8c-XshSvrr9ffUP4vGz1rDf4/edit#heading=h.go4ebkohvjyy | Jide Alaga <> RP\n",
      "https://docs.google.com/document/d/1WOdF0zCWgqA9wK2Ze0DCb7KqKVThohNvmavoJLEZtqs/edit | NGDP Futures Strategy\n",
      "https://docs.google.com/document/d/1WbINVhU5MtNGsb7bWM9pHPQYpW18aZJ9fVDVtHV5ZAA/edit | 2023-06 SFF long-form attachment for AIGS - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://docs.google.com/document/d/1WqLe5cE9Pozp5C9FlgG2ei_TwlOkVMYRMLJUuB_5A-o/edit | CONFIDENTIAL: Notes on Alexander, internal OP politics, and potential upshots (Shared w/ WIT) - Google Docs\n",
      "https://docs.google.com/document/d/1Wyd6GyK02vPaJHczfAx3oOvBc32nthRI9pwMcGE0sJY/edit#heading=h.q6o2gdl48ntd | [Draft] What do you have to believe for \"minimal longtermism\" to beat GHD and cage-free campaigns? - Google Docs\n",
      "https://docs.google.com/document/d/1XmptIBukbISLXYmfz_BYb5OExrZB2yi4AsndJ0-qqQA/edit#heading=h.p6arli3f7jlb | Insights from Jack Clark's Newsletters - Google Docs\n",
      "https://docs.google.com/document/d/1XsSriKA4YWqD6KRqcUg6CvxhaE1SPVYo_O-QCZEazoQ/edit#heading=h.1u4lkskbhszs | Lionheart AI safety fund feasibility study v0.2 - Google Docs\n",
      "https://docs.google.com/document/d/1XtlN8nttvKA29BNE1fq8nC5HAnW1a6IT_lXl852d47A/edit#heading=h.yc58d8t72780 | 2023-Jan-27 - MA questions to Abraham - ops budget etc. - Google Docs\n",
      "https://docs.google.com/document/d/1XvA5FJozJi2_9YtNDrGw9HyRSYJ2FdANS4-OBHOjIyI/edit#heading=h.kbwddz1jya9u | Value of RP's Research in GHD and Animal Welfare - Google Docs\n",
      "https://docs.google.com/document/d/1Y8XuNs35IIm-RH1yWpHoBQ2GDoK5s83yEdcI0nvKiBA/edit#heading=h.xajd3x788e16 | Hamza Chaudry <> Jam: AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1YcTPqQZi7GwcoukRvqRIKNoz35G8ffSR4gOduHybFxo/edit#heading=h.53syq9goshna | Misc notes on AI CPR - Google Docs\n",
      "https://docs.google.com/document/d/1ZCMSk2s0ylDsKJ2JMuDIxgVrJE9VfuSSrp2vrzE3iuE/edit#heading=h.y0srbz710jxs | Call notes: Jam-Jake Swett [19 June 2023] Topic: AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1ZY87TRXNcSoAgcDzug7LytwOXMY_2YmxQ5KCjjB2Cdg/edit#heading=h.6ytgvt3dfnpe | [Ashwin evaluating Patrick] July - RP Performance Evaluation Template - Google Docs\n",
      "https://docs.google.com/document/d/1ZZUpQwqJQ2BaZGA7uvUfuf0HwvBvro4EIKDiumYuxp8/edit | Rollbacks and shutdowns for deployed AI models\n",
      "https://docs.google.com/document/d/1Zaham8weNwUXbOnwgLogkVjK_4CP_2DOCc62XtHzgic/edit#heading=h.cfc2feh3bxhs | Intervention Pages Proposal - Google Docs\n",
      "https://docs.google.com/document/d/1Zi0sDYIdBhXc7RN9Exj2BlhaDMF5mIo6Hg7tY07MhAU/edit#heading=h.4guks8uuunh5 | [Speedrun] Evals: How can we reduce the risk of regulatory capture? Learning from case-studies of other high-stakes technological domains - Google Docs\n",
      "https://docs.google.com/document/d/1_965EVS7j7DluNqWKpbnw5lUtdrnuwmZNxCs9ec-Ups/edit | Ashwin - 2023: May - RP Performance Evaluation Template [self-evaluation]\n",
      "https://docs.google.com/document/d/1_bljply8Xk_WaZ8umdqRmMP1V-5emk3S1v_Ppy_vkw0/edit#heading=h.6eucefmsv0x9 | Project idea: China AI think tank\n",
      "https://docs.google.com/document/d/1_fuEAdXwbl4bgCfH5EqsKs2rUazv_FB0jGkD5s3tfag/edit | Notes - Forecasting RP Fundraising - Google Docs\n",
      "https://docs.google.com/document/d/1aHXiPAGvIoD1AfjvHM9XLf1j_LD6eYCBVzMK51M1H7w/edit#heading=h.namprdhlc75p | 2023_06_30_XRisk_Cost_Curves_ZDFG - Google Docs\n",
      "https://docs.google.com/document/d/1avCcDdjHX-I6HjWubGPlk0MbEZDiK1V2Yk_-uLzvEKM/edit | Quick investigation: Field building for AI policy\n",
      "https://docs.google.com/document/d/1avCcDdjHX-I6HjWubGPlk0MbEZDiK1V2Yk_-uLzvEKM/edit#heading=h.miibfeew6vyi | Quick investigation: Field building for AI policy - Google Docs\n",
      "https://docs.google.com/document/d/1bQDkuz8vBmvQtlWrrXDeeI6hM3Fz-WL1c8Ub-p34-4M/edit#heading=h.6pru7lwg7vv | ERA for Peter - Job Opening Kick Off Form - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1bgMwiex8jHDnlIDrtH8OqVGaYstDr3KDPdyAQgJumro/edit#heading=h.a89fxjj9aldj | Potentially useful books on how the USG works\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.9ick7xqcwurb | RP’s AI Governance & Strategy team - 2-pager - Google Docs\n",
      "https://docs.google.com/document/d/1c2ULYMzqf6lGB91V3kjVlixNYGKO9NpV8_dwmCCsH5U/edit | neglectedness is a search heuristic, not a criteria\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1cvmPmzq3Cn52UNKN4uzUMgXhERFGmob6e6cSILdACik/edit#heading=h.osty8jeclpyn | Shrimp Welfare: A summary of lessons learned and future directions\n",
      "https://docs.google.com/document/d/1dGNGZbJWkj8hT-hd6w0mdg6MpteZOaA_r9r8Lhd3I7I/edit#heading=h.fgx8olg8cwoz | Troy Perry (Omidyar Network) <> Renan, Jam (2023-08-02) - Google Docs\n",
      "https://docs.google.com/document/d/1d_3U-cEUvQoc5yUz2ZFO2uk7HQmfQWisC6OYo-QGtns/edit | Lessons Learned  2023 Mid-Year Fundraiser - Google Docs\n",
      "https://docs.google.com/document/d/1dxqRdJqufyguiCuxj0aEN6P9G-khVR4y80cw88Eb-U8/edit#heading=h.lzlp3cfhsbxy | Skip-level meeting template - Google Docs\n",
      "https://docs.google.com/document/d/1e3uGtwoOnhnt2M5c_gAM06BI44zzeucpLZ6Ss335ne4/edit#heading=h.ooxvfpkwfmzx | Implications of the chance that most technical AI safety work will be done by AIs? [notes + research proposal] - Google Docs\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | \"Crazy AI might be soon\" - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1eO_-UjygEZOsQfMtRUv-12FnN0oGVNQi_gr6qNU3a5U/edit | Lab Governance Workstream - 2-Pager (External) - Google Docs\n",
      "https://docs.google.com/document/d/1ezY0JAqh_Tb2cxXduvpWsnDpIqRt01dY6e5bhiXsZEM/edit#heading=h.9fg7hspx4pom | RP Compute Governance Workstream 1-pager [shared] - Google Docs\n",
      "https://docs.google.com/document/d/1fJndg74yOJz0SsTHztV2uSpT152cnkd3y752Uj2bjKg/edit#heading=h.z4a1n8yhj2ak | 2023 Monthly Leadership Meeting - Google Docs\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1gN2WmfPcWEdvuFfGAS7gwDjE4NQo1vxZWjcSvC_pqeE/edit | Notes for Caro conversation on June 26 - Google Docs\n",
      "https://docs.google.com/document/d/1gb_gyi_7nTwTRpOFKk9iOoRlNrHXKtC2D1LKunGc9HI/edit#heading=h.1nrhqxslzwok | All Hands Meetings - Best Practice - Google Docs\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://docs.google.com/document/d/1h1A3ArU8_umBooZ2qaiwjW2YHaLatZrU8GkAL6QIHqE/edit | Kat's 80/20 fundraising advice - Google Docs\n",
      "https://docs.google.com/document/d/1h8e4UTNPnFOwfmdhH24vPF6p2qij_J0yop1m9AkmN-A/edit#heading=h.v1qlzyj9qjyf | AI Technical Alignment overview - Google Docs\n",
      "https://docs.google.com/document/d/1hGGLSodwN_VopFioDahMkgslDm9-BQ4ckuqwwtcvjf0/edit | [Draft]: Rollbacks and shutdowns for deployed AI models\n",
      "https://docs.google.com/document/d/1hGGLSodwN_VopFioDahMkgslDm9-BQ4ckuqwwtcvjf0/edit#heading=h.ixh4wexqguvf | [DRAFT] Rollbacks and shutdowns for deployed AI models - Google Docs\n",
      "https://docs.google.com/document/d/1hLQ4Ce5raaPVUGq0_V1qPdcnn29kJ081w4XE0n0lHw4/edit#heading=h.bd3vtecb3ctx | Proposal: Information Security Fund - Google Docs\n",
      "https://docs.google.com/document/d/1hqit18idYVMmBHbcGgSUccCZqIPphZ-Sdqd9wZ024fM/edit#heading=h.2an3fqbhybwy | Quick evaluation of Bill's competencies (Ashwin, June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1hthTB-zc5UDTNBnkncXRMQZ-536Wtc3PPJR2HpjssT8/edit#heading=h.yrivgqgvn4eh | Gladstone AI (Edouard Harris) <> RP AIGS (Michael Aird) - 2023-Jun-30\n",
      "https://docs.google.com/document/d/1i5qQteGLrvokces6rEWTUfY3khe-LJMOIobrDREcd2w/edit | Peter's takes on some big strategic variables - Google Docs\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://docs.google.com/document/d/1irLA7VAE4Zk5uilt3R4RxJZDKCQR4yKskGPOoKaBp34/edit#heading=h.ozcv1fnsad2k | How AIGS intends to handle (appearances of) relations with labs, political parties, and AI ethics\n",
      "https://docs.google.com/document/d/1isVebPhVRMssrQ6T5N0hYgF1s0csKLGqkX1scDjf4EE/edit#heading=h.fpykg9xqqa6b | *Masterdoc: Info on projects we're considering incubating (2023) - Google Docs\n",
      "https://docs.google.com/document/d/1jahnlyDS7u5lrgbPt_KcAHOyt-CtRf_DVK9xp0HeRY0/edit#heading=h.iqjzsh71i645 | Risto Uuk <> Zoe Williams, 2023-07-13 - Google Docs\n",
      "https://docs.google.com/document/d/1jkeVr9rw1Uksgg1yKyEStHxBVPhovRON9vPC7GXHMnE/edit#heading=h.iu5m9zwyeqnb | Various takes on prospects for major AI regulation in the US - Google Docs\n",
      "https://docs.google.com/document/d/1kUPU0z5vXqEEg5JaiQ7IuDBRGc28eY_ZSK6zUudjxC4/edit#heading=h.ty86qub5wnwc | RP China workstream research agenda\n",
      "https://docs.google.com/document/d/1kWVb9DR5OPpMLS6sWki_WnmeL2lMCmkyGz-DzaEdh7Y/edit#heading=h.uib0vits1wgt | FAA case study - Google Docs\n",
      "https://docs.google.com/document/d/1kv2_Y36gD300QwOOmgd5kd6kD1lnMIv-xtViewYZmdw/edit | MCF Biosecurity Memo - ASB 2023\n",
      "https://docs.google.com/document/d/1lrs-UuqZYTzcSvqRR73kDyT6nKzr_EQ2Ex4zvmynCjI/edit | Proposal for how comms and fundraising should work when AIGS rebrands - Google Docs\n",
      "https://docs.google.com/document/d/1miPCZ4z7yjUnnYMGG8dp3M3L6x5_i7w_ttynW14y2jg/edit#heading=h.rs6pwjwea99k | AIGS comms strategy - initial notes - Google Docs\n",
      "https://docs.google.com/document/d/1mkZf0WFux1ApFAdbFYe4V5Tf-YZt_wro0VtOl_J16ZA/edit#heading=h.55yvur9i1wcv | 2023-04-15 Implications of Increased Compute Efficiency - Performance and Access Effect for Compute - Google Docs\n",
      "https://docs.google.com/document/d/1mn2PfqYzoRgUWDiEBxMsVDb9aU-zl2Sx80SZF5nJW2s/edit | Questions for Luke’s team from RP AIGS [Aug 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1pAOApQlP4nXopMTGLT5F5fDsWpSGljc0fN5CtoyGtgw/edit | What Happens When A Model Fails an Eval? - Google Docs\n",
      "https://docs.google.com/document/d/1q33V1zB3bcZwduhRqWj2aVFJWbPMZ_A0CZLmuucZ6to/edit#heading=h.qgtddipmvmv6 | Project memo: University-focused field building for AI policy in the US - Google Docs\n",
      "https://docs.google.com/document/d/1q9qKlZ2KU59lqbV4jcLE4V2jeBFAHOd9DejNM_Abyvw/edit#heading=h.sja5ou1zlohi | FDA case study - Patrick - Google Docs\n",
      "https://docs.google.com/document/d/1qmQbmDv59AMPJ3RdGvzSg6HDZ-3NgAGb31q7ZeAoiLQ/edit | Timeline: Launching AI policy university field-building (UFO)\n",
      "https://docs.google.com/document/d/1qmQbmDv59AMPJ3RdGvzSg6HDZ-3NgAGb31q7ZeAoiLQ/edit#heading=h.av7lzo8ofz1z | Timeline: Launching AI policy university field-building (UFO) - Google Docs\n",
      "https://docs.google.com/document/d/1qrf_sGnD9YDimH9l1LYpY7Iib9LosCtz41tZ8fBbgGI/edit#heading=h.whjku1dsy2f3 | 2023-07-04 Lab Statements on AI Regulation - Google Docs\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://docs.google.com/document/d/1rKAcZ7MsbFc3dL90xeRs8FDeDEeSHrWTTKt5zoRnYw0/edit | Risk Outline - Google Docs\n",
      "https://docs.google.com/document/d/1rKcUmCDDB-0Kp759ylO4uNIZzrehSDNeta6PrM888uo/edit | [Shared w/ SFF] Internal Notes from DC meetings - Google Docs\n",
      "https://docs.google.com/document/d/1rKeGoKdua4FV0XNWlDsatcd2biiiDqK-etSa_Wdhm28/edit#heading=h.i8626abq1vig | Collecting input on what US Regs should do (for August-October 2023)\n",
      "https://docs.google.com/document/d/1rP-g6gQtUnusfmah-bZ4yvglFIDJO3Uk_PtWtKGG7A0/edit | GHD Director Draft Skills Assessment Questions - Google Docs\n",
      "https://docs.google.com/document/d/1rRz9lyfEvZji46PRxXI8YH6XBJ114c0mJag86aF--8Y/edit | 2023-Jul-05 - Crisis Wednesday - Overview and Plan - Google Docs\n",
      "https://docs.google.com/document/d/1rkIv1IOpUC0riVTfLn74Au77t14whGMVXfRDPdx6-N0/edit | RP AI Survey Planning Workshop - Google Docs\n",
      "https://docs.google.com/document/d/1rl60P4UO79-pA0RaHKILtISIuLwTDudJXk5xuSQgR9E/edit#heading=h.q52a7f8v1vd | draft update 2023-08-01 -- Two-pager on RP's Existential Security Team - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1rwLFr15536l08wKslhMF6ZHOGvIQ4DIION1jK25_oIE/edit#heading=h.jl93l1npdui2 | [Ashwin evaluating Oliver] - July 2023 - RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/1rzD2eWFypVLt_p6yX50s_mDm7r19WqRb-QUxpwL9wyA/edit | Mapping the AI governance landscape [HAIKU study notes]\n",
      "https://docs.google.com/document/d/1sQI-udA4x-kHj79yb3HlO0Kcc-Dd1WMT0jiqiPBgszE/edit#heading=h.j7a78oivkty6 | XST Meta Charity Funders application August 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1sab5pa0kqrcrj5dAZUupO3_gfF3p9OBUm1Xv7o0E_Bk/edit#heading=h.6ytgvt3dfnpe | (managee copy) Patrick Levermore 2023: July - RP Performance Evaluation Template\n",
      "https://docs.google.com/document/d/1sb3naVl0an_KyP8bVuaqxOBf2GC_4iHlTV-Onx3M2To/edit#heading=h.ambkheo9pub | [Forum version] Overview of standards in biosafety and biosecurity - Google Docs\n",
      "https://docs.google.com/document/d/1sjgT0Ezwcpsy7T7z2fFENvCz99cWflncAJRDKmyewP8/edit#heading=h.sja5ou1zlohi | Chartering for US commercial banks - case study for OAI - Bill Anderson-Samways - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1t-mtfaTHWAycw5swPsrXiJHwptMlns3eCC6uDN5B7JY/edit#heading=h.djrqti4gjs0v | How hardware-enabled mechanisms could reduce existential risk - Google Docs\n",
      "https://docs.google.com/document/d/1tXKpH1fPmQKeExPM2CUzBWfeByDCBkTNPySyboeUzjg/edit#heading=h.2j0u2dbkn1lv | Politico Pro subscription (meeting notes) - Google Docs\n",
      "https://docs.google.com/document/d/1tnrh-kglWSGHcL4rvQB3LDJrZJ_fiYjGYzliy0eiJ2s/edit#heading=h.6ha0t8tpgiiw | [Michael's copy] LAISR 2023 Seminar 1 – Luke Muehlhauser [Notes] - Google Docs\n",
      "https://docs.google.com/document/d/1tq9rY1TCs49XHckWtzOowYz_xHXFnRpOZq8r0lE5JSQ/edit#heading=h.z7flydhghql5 | Where should I move? - Google Docs\n",
      "https://docs.google.com/document/d/1uNF5687rCUBJucJGgT22QQkm0H_EzmIpzt2arWH-WOY/edit#heading=h.osty8jeclpyn | Forecasting China’s ability to indigenously produce AI chips - Google Docs\n",
      "https://docs.google.com/document/d/1udFQ--BgWVi3a9Ng-Rp6oUiR7k1KOeoTePBmvol6F00/edit | David Rhys Bernard: Manual of Me - Google Docs\n",
      "https://docs.google.com/document/d/1utecRz-1Mx-jXjGAvEeEi_XvBGTguA6flx7lkIS7cS8/edit#heading=h.xjb1j3y7702q | [WiP] How much compute is there? A review - Google Docs\n",
      "https://docs.google.com/document/d/1vGie3lHRR606-blefv7TGm09n1LF9arbDYxDNgtCeI8/edit#heading=h.f4mc3t2ytr | AI/ChatGPT/LLM Use Guidelines\n",
      "https://docs.google.com/document/d/1vXb0rRqjBIMh38M4m775MsFK1VKyABQXJODBjJw0c5w/edit#heading=h.n4kqnt7mgbuw | AVA 2023 notes on OP Worldview Diversification from Lewis Bollard conversation\n",
      "https://docs.google.com/document/d/1vgAWq2s3o4oYl61AiLJJYuiKLtrE20Fv4FG_qGZX_SU/edit | Rethink Priorites: Position Description, Chief Executive Officer\n",
      "https://docs.google.com/document/d/1wZATymY7IfC3DeBCtJeZrJ1f5w6GPaErx7cPHP-yZAQ/edit#heading=h.uc606df5qy4k | Bioanchors mini project - Google Docs\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://docs.google.com/document/d/1wehezUuPcfHwcAiJGlnVjIx_SFxKu5Qg-ADYOfH04LI/edit#heading=h.ebmljdh2jjem | *Project idea research: Weekly coordination meeting - Google Docs\n",
      "https://docs.google.com/document/d/1wmQJt0m6Z_I3QvmEvphmnQN1Qf5C-2YmCdEOtW8TF_0/edit#heading=h.pk2nps9jyyz6 | Mini-speedrun #2: 6 projects that seem exciting and feasible - Google Docs\n",
      "https://docs.google.com/document/d/1wpWUl62_4mNbSohnss57qtraxcArrTHY4NoRTDh7fSw/edit | Caro-Peter: Oxford, The Magical Retreat - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://docs.google.com/document/d/1yeIXYJ6YZorRfe8Ei3Dg-mO-A6GgiiUOezra3Vv0Ayg/edit#heading=h.mz5p5xx8q7a2 | [shared] Rethink Priorities Existential Security Team Fundraising Proposal 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1ysnPyONduClyhRxFapZ8Wupn-B7-kGHvlXm5IOxw9ug/edit#heading=h.ieytf2ylg1lh | Hiring SOP - Managers, Committee and Operations Guide [living document] - Google Docs\n",
      "https://docs.google.com/document/d/1z5Ltl2dDQlD0fd39wBK0Dffg7Cm4bKfj8XSXzwJrrW0/edit | [Public] China workstream two-pager - Google Docs\n",
      "https://docs.google.com/document/d/1zCYPAq1WA9UqAF11Fraqenyymz-YMYuwbHnqUvT5Ntk/edit | Trying to understand OpenAI's strategic thinking: Our understanding of the case for short timelines and continuous takeoff as the safest path to AGI - Google Docs\n",
      "https://docs.google.com/document/d/1zEfb_gtceMnJabsOGVjNWUviQ5ARJ9oo5h_SrJ95Gv0/edit#heading=h.nm0ae28am02o | Overview of the AI lobbying and advocacy space - Google Docs\n",
      "https://docs.google.com/document/d/1zJRIp64pkDCK8FfZkbOxyNo4pODBXIWbu7A8Yhh8U_A/edit#heading=h.osty8jeclpyn | AI chip smuggling into China - Google Docs\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://docs.google.com/document/d/1zUVdUeOHfaTWyBgVC8ZRUNZ2tmix35dFSIgRSxSY5rk/edit?pli=1 | GHD round table brainstorm - Google Docs\n",
      "https://docs.google.com/presentation/d/1CEYIastEhq-Y9TuJJjtBRK3_eqoFrFkkp2PM3-GHfjc/edit | 2023-07-04 What are good US AI policy ideas? - HAIKU - Renan\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/presentation/d/1HuXNx7EGhrimuQwB6uBbSCLo2LpfS7M4KuUHmjkP6Lk/edit#slide=id.ge24bea79ec_0_130 | Rethink Priorities TAI Strategy - Google Slides\n",
      "https://docs.google.com/presentation/d/1Rc9JhKBXjO-eRTXx1sCx2gObnfjYob3idHI8a296xtE/edit#slide=id.g201946b620b_0_112 | 2023 July RP Fundraising Forecast Update - Google Slides\n",
      "https://docs.google.com/presentation/d/1dKeyVbNLfaO7QCYTSSleXicRGK8qAestfheQ_8ORrF4/edit#slide=id.g2546af80730_0_214 | Peter's lightning talks - Google Slides\n",
      "https://docs.google.com/presentation/d/1rzmKcrKlO0Awp2YI8cATFajgpt7IczlHsvGaZQa3juQ/edit#slide=id.g247fe72e4a3_0_69 | EAG London 2023 - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/11ZlsgliiaOa92s9PkoSW244QbfxWZbw8cIW4TF_TTKU/edit#gid=2073652358 | Special Elections 2023/2024 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1AnM_-TnTiSUMbhQ123d6Prayj1MkOA4bB5rng78KxlM/edit#gid=1126958881 | 2023 September Lights - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1CErMKxBbAHfbyQjmYxJE_R8Ip8MzUrsVsTySfqZov8M/edit#gid=0 | [Draft] Budget: Field building in universities for AI policy careers in the US - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1D9OaeKTSUDtsu5L88pu5TE__tPCkJH63trQ2u4TVOBc/edit#gid=0 | Workshop tracker\n",
      "https://docs.google.com/spreadsheets/d/1EFT7QgTlxOV7b1ubxus2qAHIkIamvXM7aslCECszz6o/edit#gid=0 | Ranking exercise: AI-related surveys - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1QrYysZVHrRzputht9FEyT2fHiRvBpCo1YQfh6E20AtA/edit#gid=375874685 | Referral Ads Sheet - 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1YvAWJJ7mco96cm482Pg3YqObDgV5ELIdvlhU4Ze10fM/edit#gid=1010051430 | Decision Theory Axioms and Consequences - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1_i8ctyK-HYjJMDuSRZ-CZ4EqDa73cQNiIyTkQqOloPI/edit#gid=631790216 | RP Permanent Staff Start Dates - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1_l-mRnuZJckKFXGmbz0m9vPpcVc7w9PMW-8aR1ppYHg/edit#gid=374295678 | XST timetable and milestones June 2023- - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1eAh3VrG7fKDsO4BBd1c1DjUw19IMSa00GQOOPh2OTaY/edit | Proposals AIGS endorses and/or has views on\n",
      "https://docs.google.com/spreadsheets/d/1fI6JUcI796OKohKILyJQ_xpU2vY25egUq6A-wX_OUjo/edit#gid=0 | Streaming services - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1hUVfvY0PUD8NzOnt7s7UPpHls6M-ypRESY9voF-MKfM/edit#gid=508560312 | GHD ROI scrap - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://docs.google.com/spreadsheets/d/1ni_FE4MQkfbikiLUHKSLLIst8Y08iJKp5NPlCcJLVJA/edit#gid=0 | 2023 August Lights - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1pm6YEqSRfpjM3W5sTxOVfda67J5Ib4Byw35gi9A7WUQ/edit#gid=20746289 | Animal ROI scrap - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1qEsXG6I6hR2rhYxnuAtpHI-YcCAyPNt1uNYK5LT7CPc/edit#gid=593902022 | Peter's ERA - Rubric - 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1sbt38w8NHqTUQc5VsFRsLEElLBGjXRSM/edit#gid=1553840207 | Town Hall Zoom Attendee Report.xlsx - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1t_7AkXxH1IIQC6TuQFSrLkNoQOwDRWU1ICDbt-G1XHc/edit#gid=760967507 | DC team capacity planning - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1tpXZ60EDokTLnNk1gSNWwshMmenNgLBf10mPJL2RVcE/edit#gid=0 | RP Animal Welfare Department - List of publications (2021-2023) [Internal] - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1u4aYpGu5YRMCGWLaVBcVFI06B0-YDFU6DPuRNQC77kE/edit#gid=0 | DiD Framing Piece Progress Chart - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1xSnY6TNAuALyS_NyTD5ETbv5PtKhbz4XEauTtrDPu-Q/edit#gid=0 | Marie DC/NYC August 2023 – outreach tracker - Google Sheets\n",
      "https://docsend.com/view/6cbe77fw4pdizvr7 | Crowdvocate I\n",
      "https://docsend.com/view/dvnnx4mu9xx9k99k | Crowdvocate long form\n",
      "https://docsend.com/view/pj2ehvke2stwpeew | Crowdvocate II\n",
      "https://doingwestminsterbetter.substack.com/p/ai-summit-semiconductor-trade-policy | (1) AI summit, semiconductor trade policy, and a green light for alternative proteins\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://dwarkeshpatel.com/p/carl-shulman-2#details | Carl Shulman (Pt 2) - AI Takeover, Bio & Cyber Attacks, Detecting Deception, & Humanity's Far Future\n",
      "https://dynomight.net/aspartame-brouhaha/ | WHO aspartame brouhaha\n",
      "https://ealifestyles.substack.com/p/i-made-my-home-office-super-bright?utm_source=substack&utm_medium=email | (1) I made my home office super bright and I kind of regretted it\n",
      "https://ealifestyles.substack.com/p/is-forecasting-actually-effectivealtruistic?utm_source=post-email-title&publication_id=1393327&post_id=135823813&isFreemail=false&utm_medium=email | is forecasting actually effective/altruistic or am I just getting nerd-sniped?\n",
      "https://ealifestyles.substack.com/p/your-next-forum-post-should-be-more?utm_source=post-email-title&publication_id=1393327&post_id=136021207&isFreemail=false&utm_medium=email | your next forum post should be more like a children's book\n",
      "https://economics.mit.edu/sites/default/files/2023-07/Regulating%20Transformative%20Technologies.pdf | Regulating Transformative Technologies.pdf\n",
      "https://economist.com/graphic-detail/2023/09/01/ukraines-counter-offensive-is-speeding-up | Ukraine’s counter-offensive is speeding up\n",
      "https://economist.com/special-report/2023/07/03/how-ukraines-enemy-is-also-learning-lessons-albeit-slowly | How Ukraine’s enemy is also learning lessons, albeit slowly\n",
      "https://economist.com/special-report/2023/07/03/the-war-in-ukraine-shows-how-technology-is-changing-the-battlefield | The war in Ukraine shows how technology is changing the battlefield\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems | Trends in the dollar training cost of machine learning systems\n",
      "https://eshoo.house.gov/media/press-releases/ai-caucus-leaders-introduce-bipartisan-bill-expand-access-ai-research | AI Caucus Leaders Introduce Bipartisan Bill to Expand Access to AI Research  Congresswoman Anna Eshoo\n",
      "https://estimaker.app/ai | Estimaker\n",
      "https://everydayfeminism.com/2016/02/polyamorous-dealing-jealousy/ | Polyamorous Dating: 5 Tips For Dealing With Jealousy - Everyday Feminism\n",
      "https://evite.com/event/01213UVRMYOQFEPEWEPOF747GTU3EI/?gid=028ERGJHWYLUZYA54EPOF75ZLDU5IY&emhm5=7124688b9c89a1ba55205b881c080771&emhs1=9454c2641193aa6507e3d9a556ca5376864844a7&emhs2=53148bb72992717b638418d71150d850ce60abb38e78ff8ad805df8a955eeddc&utm_campaign=view_invitation_bt&utm_content=ProjectBeauty_Email_T1_V2%3A1&utm_medium=email&utm_source=GUEST_INVITE_EVENT | Evite: Online Invitations, Greeting Cards & Party Ideas\n",
      "https://experimental-history.com/p/an-invitation-to-a-secret-society | An invitation to a secret society - by Adam Mastroianni\n",
      "https://facebook.com/RethinkPriorities/posts/pfbid0mQA5pYeyuMQCbTwoNxvmZfpph4EajwG5xqs8WeebisE2pDJScMxKHYJeLMUP3P3xl | RP partner @open_phil is one of the largest... - Rethink Priorities  Facebook\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid02NqUoTQVk9mGV8ujTFvihCSVLh55gay12khp4Cw92ieucSW4HTHiCfWvPhxgdzqHUl | We’re hosting a Barbenheimer party tomorrow... - Caroline Jeanmaire  Facebook\n",
      "https://facebook.com/caroline.jeanmaire/videos/10208937381858299 | Facebook\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3516416492006577&hoisted_section_header_type=recently_seen | Dank EA Memes  Facebook\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3525480504433509&hoisted_section_header_type=recently_seen | facebook.com/groups/1479475219034058/?multi_permalinks=3525480504433509&hoisted_section_header_type=recently_seen\n",
      "https://facebook.com/groups/1781724435404945/?multi_permalinks=3542137902696914&hoisted_section_header_type=recently_seen | Bountied Rationality  Facebook\n",
      "https://facebook.com/julia.wise.71/posts/pfbid02yTS7fpzxu76vE9qzJ4oazrCND3XKc44Ka3ioWLgJy8h9qerSYP4BjW1vFNp8xuAFl | facebook.com/julia.wise.71/posts/pfbid02yTS7fpzxu76vE9qzJ4oazrCND3XKc44Ka3ioWLgJy8h9qerSYP4BjW1vFNp8xuAFl\n",
      "https://facebook.com/katxiowoods/posts/pfbid02PDsQftmwpqYPTHzqMnBGoF9R6UAoMCw2K6TCArt9ZKD2aA96YoLL2qnEDnifGxdXl | facebook.com/katxiowoods/posts/pfbid02PDsQftmwpqYPTHzqMnBGoF9R6UAoMCw2K6TCArt9ZKD2aA96YoLL2qnEDnifGxdXl\n",
      "https://facebook.com/katxiowoods/posts/pfbid0xeoL56nksybJz9B2HdeTuYbwQNvT775xesm1yXZAEaEFQNes5WHoLa9BXWRoUzjQl | facebook.com/katxiowoods/posts/pfbid0xeoL56nksybJz9B2HdeTuYbwQNvT775xesm1yXZAEaEFQNes5WHoLa9BXWRoUzjQl\n",
      "https://facebook.com/messages/t/1056637367/ | Messenger  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid07jjqaCHVhCKvsvGVtcwJtTYvzTugRznHnB4n5YhMH5GAvENG519pRrVVPxotHuLvl | facebook.com/ozzie.gooen/posts/pfbid07jjqaCHVhCKvsvGVtcwJtTYvzTugRznHnB4n5YhMH5GAvENG519pRrVVPxotHuLvl\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://facebook.com/photo/?fbid=10154650283731541&set=a.394326071540 | facebook.com/photo/?fbid=10154650283731541&set=a.394326071540\n",
      "https://facebook.com/photo/?fbid=10230872885743855&set=a.4146526419648 | facebook.com/photo/?fbid=10230872885743855&set=a.4146526419648\n",
      "https://facebook.com/tee.r.barnett/posts/pfbid0wTf2GXDJCJYyXyAsUU1wTeUBkBJidJTUQMFGRJK1rXVby7ofRLoLU4QNv91ysATdl | Tee Barnett - How I structure my schedule on a weekly basis for...  Facebook\n",
      "https://facebook.com/topher.t.brennan/posts/pfbid0Hna8QqgYansstQBGHZim3mHJCzya62UNbdpMhPFkw8qw3qv7r9dmRqhKLrEXUAbTl | facebook.com/topher.t.brennan/posts/pfbid0Hna8QqgYansstQBGHZim3mHJCzya62UNbdpMhPFkw8qw3qv7r9dmRqhKLrEXUAbTl\n",
      "https://fas.org/accelerator/bio-ai-policy-sprint/?utm_source=substack&utm_medium=email | Bio x AI Policy Development Sprint - Federation of American Scientists\n",
      "https://fast.ai/posts/2023-11-07-dislightenment.html | AI Safety and the Age of Dislightenment\n",
      "https://fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://fivethirtyeight.com/features/16-states-made-it-harder-to-vote-this-year-but-26-made-it-easier/ | 16 States Made It Harder To Vote This Year. But 26 Made It Easier.  FiveThirtyEight\n",
      "https://fivethirtyeight.com/features/mississippi-governor-lieutenant-governor-primary-election-2023-preview/ | Could A Democrat Actually Win Mississippi’s Governorship?  FiveThirtyEight\n",
      "https://fivethirtyeight.com/features/rfk-jr-democrat-republican-primary-favorability/ | If RFK Jr. Wants To Be President, He’s Running In The Wrong Primary  FiveThirtyEight\n",
      "https://fluentin3months.com/fluent-in-3-years/?expand_article=1 | Fluent in 3 years?! What I Learned From a 1,033 Day Duolingo Streak -- Plus How to Actually Learn a Language Fast\n",
      "https://forecasting.quarto.pub/book/other-option.html?ref=bounded-regret.ghost.io | Forecasting: Lecture Notes - 7  The “Other” Option\n",
      "https://foreignaffairs.com/china/china-flirting-ai-catastrophe | China Is Flirting With Artificial Intelligence Catastrophe\n",
      "https://foreignaffairs.com/ukraine/russia-war-beyond-ukraines-offensive | Beyond Ukraine’s Offensive\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity\n",
      "https://foreignaffairs.com/world/how-prevent-ai-catastrophe-artificial-intelligence | How to Prevent an AI Catastrophe  Foreign Affairs\n",
      "https://foreignpolicy.com/2023/06/19/ai-regulation-development-us-china-competition-technology/?tpcc=recirc_latest062921 | AI’s Gatekeepers Aren’t Prepared for What’s Coming\n",
      "https://forum.effectivealtruism.org/posts/2rRsjdrL9BEWC3d7C/personal-reflections-on-longtermism | Personal Reflections on Longtermism — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/2yQX4szjAj24tFRj8/mesa-optimization-explain-it-like-i-m-10-edition | Mesa-Optimization: Explain it like I'm 10 Edition — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/3a6QWDhxYTz5dEMag/how-can-we-improve-infohazard-governance-in-ea-biosecurity | How can we improve Infohazard Governance in EA Biosecurity? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/3kMQTjtdWqkxGuWxB/update-on-cause-area-focus-working-group | Update on cause area focus working group — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/4rp8rRjPAE6Hzs5ef/mathiaskb-s-shortform?commentId=72jKEA37fF8ro5LeQ | Why you should buy a desk treadmill\n",
      "https://forum.effectivealtruism.org/posts/5hprBzprm7JjJTHNX/reasons-i-ve-been-hesitant-about-high-levels-of-near-ish-ai-1 | Reasons I’ve been hesitant about high levels of near-ish AI risk — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/67zFQT4GeJdgvdFuk/partial-transcript-of-recent-senate-hearing-discussing-ai-x | Partial Transcript of Recent Senate Hearing Discussing AI X-Risk — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/6sykvCXRC5rjgtoQt/the-productivity-fallacy | The Productivity Fallacy — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding#If_LTFF_raises__100_000 | What Does a Marginal Grant at LTFF Look Like? Funding Priorities and Grantmaking Thresholds at the Long-Term Future Fund — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/7Tvc3N7nFa32ekuGA/forum-feature-update-reactions-improved-search-updated-post | Forum feature update: reactions, improved search, updated post pages and more (July 2023) — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/9tG7daTLzyxArfQev/era-s-theory-of-change | ERA's Theory of Change — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund | Reflections on my time on the Long-Term Future Fund — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/AJJTRmW7zhvXrmD5s/apply-to-ceealar-to-do-agi-moratorium-work | Apply to CEEALAR to do AGI moratorium work\n",
      "https://forum.effectivealtruism.org/posts/AfXC5CDtSKezpiyf6/ce-incubation-programs-2024-applications-are-now-open-our | CE Incubation Programs 2024 applications are now open! + Our top ideas in mass media — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/BLqJdZAgsvyWX7fug/local-charity-evaluation-lessons-from-the-maximum-impact | Local charity evaluation: Lessons from the \"Maximum Impact\" Program in Israel\n",
      "https://forum.effectivealtruism.org/posts/Bg6qxLGhsn7pQzHGX/progress-report-on-cea-s-search-for-a-new-ceo | Progress report on CEA’s search for a new CEO — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/CmAexqqvnRLcBojpB/electric-shrimp-stunning-a-potential-high-impact-donation | Electric Shrimp Stunning: a Potential High-Impact Donation Opportunity — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/CtACh7xRBFnpK3NW4/guide-to-safe-and-inclusive-events-by-gwwc-and-oftw | Guide to Safe and Inclusive Events by GWWC and OFTW — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DJEbnY4P5gcEaN3WA/manifolio-the-tool-for-making-kelly-optimal-bets-on-manifold | Manifolio: The tool for making Kelly optimal bets on Manifold Markets — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DPfGxeWFLQaWEgBTj/how-many-people-are-neartermist-and-have-high-p-doom | How many people are neartermist and have high P(doom)? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DdSszj5NXk45MhQoq/decision-making-and-decentralisation-in-ea | Decision-making and decentralisation in EA — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Doa69pezbZBqrcucs/shaping-humanity-s-longterm-trajectory | Shaping Humanity's Longterm Trajectory — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EEMpNRJK5qqCw6zqH/a-cost-effectiveness-analysis-of-historical-farmed-animal | A Cost-Effectiveness Analysis of Historical Farmed Animal Welfare Ballot Initiatives — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EFpKcbaZNyZNk4qWD/jonas-vollmer-s-shortform?commentId=hjqzE7ki2hdYwjZZB | Jonas Vollmer's Quick takes — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EHTynQaSN8ubjCbm9/how-much-is-reducing-catastrophic-and-extinction-risk-worth | How much is reducing catastrophic and extinction risk worth, assuming XPT forecasts? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EhPKbX5JkwxvhfGhC/link-post-ai-should-be-terrified-of-humans | [link post] AI Should Be Terrified of Humans — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ExpBagkng6QSqcN8d/a-model-based-approach-to-ai-existential-risk | A model-based approach to AI Existential Risk\n",
      "https://forum.effectivealtruism.org/posts/FWmnwCcKiBLstFtYL/career-conversations-week-on-the-forum-8-15-september | Career Conversations Week on the Forum (8-15 September) — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/FtLkQ77rxvEbWDtpz/longtermist-causes-is-a-tricky-classification | “Longtermist causes” is a tricky classification — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/FzoMPHtXzTig8pXuh/general-support-for-general-ea | General support for “General EA” — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/J7nmbqcWncPMZFhGC/want-to-make-a-difference-on-policy-and-governance-become-an | Want to make a difference on policy and governance? Become an expert in something specific and boring — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1 | What do XPT forecasts tell us about AI risk? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KmiR4T8ha7LbA8eJn/dyusha-s-quick-takes?commentId=pn5724GNby3mqday7 | dyusha's Quick takes — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L8kEmQgghxS9LXF3H/ea-is-underestimating-intelligence-agencies-and-this-is | EA is underestimating intelligence agencies and this is dangerous\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/N4LKrktopDs5Qdqgn/an-introduction-to-critiques-of-prominent-ai-safety | An Introduction to Critiques of prominent AI safety organizations — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/PChvstTKnf6iAP36F/effective-altruism-and-the-strategic-ambiguity-of-doing-good | Effective Altruism and the strategic ambiguity of ‘doing good’ — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/QNdG4msZS3G29uG5X/biosafety-in-bsl-3-bsl-3-and-bsl-4-laboratories-mapping-and | Biosafety in BSL-3, BSL-3+ and BSL-4 Laboratories: Mapping and Recommendations for Latin America — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/SCKg5N9oHdBDxHvEM/getting-into-an-ea-aligned-organisation-mid-career | Getting into an EA-aligned organisation mid-career — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo | [JOB] Opportunity to found Charity Entrepreneurship NGO (outside of the incubation program): Tobacco taxation advocacy — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ScGZdyGNXoEBAQazR/winners-of-ai-alignment-awards-research-contest | Winners of AI Alignment Awards Research Contest — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Tshx6oH2vN6Nszqoj/matt_lerner-s-shortform?commentId=puWM6XqdLbuv88Spc | Has there been any formal probabilistic risk assessment on AI X-risk? e.g. fault tree analysis or event tree analysis — anything of that sort?\n",
      "https://forum.effectivealtruism.org/posts/TxrzhfRr6EXiZHv4G/agi-battle-royale-why-slow-takeover-scenarios-devolve-into-a | AGI Battle Royale: Why “slow takeover” scenarios devolve into a chaotic multi-AGI fight to the death\n",
      "https://forum.effectivealtruism.org/posts/WJGsb3yyNprAsDNBd/ea-orgs-need-to-tabletop-more | EA orgs need to tabletop more. — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/WYsLjeJzh7tZqe6Lo/implications-of-evidential-cooperation-in-large-worlds | Implications of evidential cooperation in large worlds — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/WxqyXbyQiEjiAsoJr/the-seeker-s-game-vignettes-from-the-bay | The Seeker’s Game – Vignettes from the Bay — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Xd9ZZuPCKAvKpzvdB/empowering-numbers-fem-since-2021 | Empowering Numbers: FEM since 2021 — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XdhwXppfqrpPL2YDX/an-overview-of-the-ai-safety-funding-situation | An Overview of the AI Safety Funding Situation — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Xw98osdN4mEGbRDiR/aaron-bergman-s-shortform?commentId=cAKQz2fhyeuKkpBzd | forum.effectivealtruism.org/posts/Xw98osdN4mEGbRDiR/aaron-bergman-s-shortform?commentId=cAKQz2fhyeuKkpBzd\n",
      "https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biorisk | An overview of standards in biosafety and biorisk\n",
      "https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biosecurity | An overview of standards in biosafety and biosecurity — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Ykqh8ku7NHN9CGkdC/modeling-the-impact-of-ai-safety-field-building-programs | Modeling the impact of AI safety field-building programs — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Yq6yKgBtaMgkgyetm/an-ea-s-guide-to-visiting-new-york-city | An EA's Guide to Visiting New York City — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously | Eliezer Yudkowsky Is Frequently, Confidently, Egregiously Wrong — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/aTSoxTcSjyBWem3Xz/ea-survey-2022-how-people-get-involved-in-ea | EA Survey 2022: How People Get Involved in EA — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/awmsvYwXk2yjCN3uT/mistakes-in-the-moral-mathematics-of-existential-risk-part-2 | Mistakes in the moral mathematics of existential risk (Part 2: Ignoring background risk) - Reflective altruism — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/bmrr8DFufz5Yh8yRC/thresholds-1-what-does-good-look-like-for-longtermism | Thresholds #1: What does good look like for longtermism? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/c5m8vAxpJgJJ2XGFu/an-overview-of-who-prequalification-process-usage-and | An overview of WHO Prequalification: Process, usage, and potential improvements — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/dBdNoSAbkG4k98GT9/evidence-of-effectiveness-and-transparency-of-a-few | Evidence of effectiveness and transparency of a few effective giving organisations — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/dikcpP32Q3cg6tvdA/ai-incident-sharing-best-practices-from-other-fields-and-a | AI Incident Sharing - Best practices from other fields and a comprehensive list of existing platforms — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/dpjCwMwKEPqK3TPnC/notes-on-managing-to-change-the-world | Notes on \"Managing to Change the World\"\n",
      "https://forum.effectivealtruism.org/posts/dqpR2E4Bw9KEEaWoK/announcing-the-existential-infosec-forum | Announcing the Existential InfoSec Forum — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ee8Pamunhqabucwjq/long-term-future-fund-ask-us-anything-september-2023 | Long-Term Future Fund Ask Us Anything (September 2023) — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/euzDpFvbLqPdwCnXF/university-ea-groups-need-fixing#comments | forum.effectivealtruism.org/posts/euzDpFvbLqPdwCnXF/university-ea-groups-need-fixing#comments\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/g4TcehspjDumGXucx/my-ea-journey | My EA Journey — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/hEwtb9Zjt5qwc2ygH/3-levels-of-threat-obfuscation | 3 levels of threat obfuscation — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/iSemZYz5KyepYcksN/an-expert-survey-on-social-movements-and-protest-5 | An expert survey on social movements and protest — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idjzaqfGguEAaC34j/?commentId=ybbvrLt2sNHpvvE5D#ybbvrLt2sNHpvvE5D | If your AGI x-risk estimates are low, what scenarios make up the bulk of your expectations for an OK outcome? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idp4GEqWp24ocgfes/the-hinge-of-history-hypothesis-reply-to-macaskill-andreas | The Hinge of History Hypothesis: Reply to MacAskill (Andreas Mogensen) — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/jWvgcLikfZj9MWhon/linkpost-eric-schwitzgebel-ai-systems-must-not-confuse-users | [Linkpost] Eric Schwitzgebel: AI systems must not confuse users about their sentience or moral status — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/k7NjuGEKdRSrrJHmZ/deep-report-on-hypertension | Deep Report on Hypertension — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/kwxE7HYjRpYwSEiKb/underwater-torture-chambers-the-horror-of-fish-farming | Underwater Torture Chambers: The Horror Of Fish Farming — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/mrAZFnEjsQAQPJvLh/using-points-to-rate-different-kinds-of-evidence | Using Points to Rate Different Kinds of Evidence — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/n5GJEP3tMrzdfYPGG/how-much-do-eags-cost-and-why | How much do EAGs cost (and why)?\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/o5fbhWrwEH4YyT9AY/new-jury-analysis-of-the-smithfield-piglet-rescue-trial | New Jury Analysis of the Smithfield Piglet Rescue Trial\n",
      "https://forum.effectivealtruism.org/posts/o5vJ9aNvc7twdqDxv/the-mental-health-challenges-that-come-with-trying-to-have-a | The mental health challenges that come with trying to have a big impact (Hannah Boettcher on the 80k After Hours Podcast) — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/oPao8avpq48GPvzDZ/two-years-community-building-ten-lessons-re-learned | Two Years Community Building, Ten Lessons (Re)Learned — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work\n",
      "https://forum.effectivealtruism.org/posts/pbMfYGjBqrhmmmDSo/nuclear-winter-reviewing-the-evidence-the-complexities-and | Nuclear winter - Reviewing the evidence, the complexities, and my conclusions — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/qwSRzAaQdquERuv27/how-my-view-on-using-games-for-ea-has-changed | How my view on using games for EA has changed — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/qzQ24rbZ4kMFDswDK/does-ea-bring-out-the-best-in-me | Does EA bring out the best in me? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/rK3NgqLg3HHDzyLah/announcing-squiggle-hub | Announcing Squiggle Hub — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/rLiCjrAv9D8chCoG5/dimensions-of-pain-workshop-summary-and-updated-conclusions | “Dimensions of Pain” workshop: Summary and updated conclusions\n",
      "https://forum.effectivealtruism.org/posts/rPj6Fh4ZTEpRah3uf/problems-with-free-services-for-ea-projects | Problems with free services for EA projects\n",
      "https://forum.effectivealtruism.org/posts/sBJLPeYdybSCiGpGh/impact-obsession-feeling-like-you-never-do-enough-good | Impact obsession: Feeling like you never do enough good — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/saAXc8zsFgZuxFM6L/xpt-forecasts-on-some-direct-approach-model-inputs | XPT forecasts on (some) Direct Approach model inputs\n",
      "https://forum.effectivealtruism.org/posts/tk2YWPKNqeCDWData/ea-germany-community-health-documents-and-processes | EA Germany Community Health Documents & Processes — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/to34jb5LuWo4fM9gC/taking-prioritisation-within-ea-seriously | Taking prioritisation within 'EA' seriously — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/u5serAwnrrFSJonoF/4-things-givedirectly-got-right-and-wrong-sending-cash-to | 4 things GiveDirectly got right and wrong sending cash to flood survivors — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/uYF5rLjH7tbJmFSbQ/linkpost-can-we-confidently-dismiss-the-existence-of-near | [Linkpost] Can we confidently dismiss the existence of near aliens? Probabilities and implications — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/un42vaZgyX7ch2kaj/announcing-forecasting-existential-risks-evidence-from-a | Announcing \"Forecasting Existential Risks: Evidence from a Long-Run Forecasting Tournament\" — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/vqPy7TkBbzrAkxCf7/updates-to-the-flow-of-funding-in-ea-movement-building-post | Updates to the flow of funding in EA movement building post — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/xSvTArtzxBcnrD6tk/cea-still-doing-cea-things | CEA: still doing CEA things\n",
      "https://forum.effectivealtruism.org/posts/xu45Sq8gZ4iy9iHXa/nuclear-safety-security-why-doesn-t-ea-prioritize-it-more | Nuclear safety/security: Why doesn't EA prioritize it more? — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/yKWGkcuke577ReBPW/you-can-also-help-animals-by-earning-more-in-other-career | You Can Also Help Animals By Earning (More) in Other Career Paths and Donating — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/z8ZWwm4xeHBAiLZ6d/thoughts-on-far-uvc-after-working-in-the-field-for-8-months | Thoughts on far-UVC after working in the field for 8 months — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zYSAFtjasxsfm3nmh/cost-effectiveness-of-student-programs-for-ai-safety | Cost-effectiveness of student programs for AI safety research — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zjmpFW3nBKwaBB5xr/corporate-campaigns-work-a-key-learning-for-ai-safety | Corporate campaigns work: a key learning for AI Safety — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case — EA Forum\n",
      "https://forum.effectivealtruism.org/s/X2k5Kqw3RyuB6QLMA | CEA Community Events Retrospective\n",
      "https://founderandforcemultiplier.com/are-you-a-wartime-or-a-peacetime-chief-of-staff/ | Are You a Wartime or a Peacetime Chief of Staff? - The Founder & The Force Multiplier\n",
      "https://foxnews.com/tech/department-defense-establishes-generative-ai-task-force?utm_source=substack&utm_medium=email | Department of Defense establishes generative AI task force  Fox News\n",
      "https://freakonomics.com/podcast/new-technologies-always-scare-us-is-a-i-any-different/?utm_source=substack&utm_medium=email | New Technologies Always Scare Us. Is A.I. Any Different? - Freakonomics\n",
      "https://gaingels.com/gaingels-letter | The Gaingels Letter - Gaingels\n",
      "https://garymarcus.substack.com/p/what-if-generative-ai-turned-out?utm_source=substack&utm_medium=email | (1) What if Generative AI turned out to be a Dud?\n",
      "https://gettoby.com/ | Toby (OneTab replacement)\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.blog/2023-06-27-the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot/ | The economic impact of the AI-powered developer lifecycle and lessons from GitHub Copilot\n",
      "https://github.com/natalieShapira/FauxPasEAI/blob/main/Paper/Faux_Pas_v.0.8.pdf | How Well Do Large Language Models Perform on Faux Pas Tests?\n",
      "https://github.com/rethinkpriorities/cross-cause-model/pull/67#issuecomment-1629349595 | github.com/rethinkpriorities/cross-cause-model/pull/67#issuecomment-1629349595\n",
      "https://github.com/rethinkpriorities/squigglepy/tree/dice_pool | github.com/rethinkpriorities/squigglepy/tree/dice_pool\n",
      "https://givingwhatwecan.org/charities/longtermism-fund/longtermism-fund-august-2023-grants-report | Longtermism Fund: August 2023 Grants Report\n",
      "https://gjopen.com/comments/1253265 | Good Judgment® Open\n",
      "https://globalprioritiesinstitute.org/nick-beckstead-and-teruji-thomas-a-paradox-for-tiny-probabilities-and-enormous-values/ | A paradox for tiny probabilities and enormous values - Nick Beckstead (Open Philanthropy Project) and Teruji Thomas (Global Priorities Institute, Oxford University) - Global Priorities Institute\n",
      "https://globalprioritiesinstitute.org/wp-content/uploads/Is-Existential-Risk-Mitigation-Uniquely-Cost-Effective-Not-in-Standard-Population-Models-Gustav-Alexandrie-and-Maya-Eden.pdf | Is-Existential-Risk-Mitigation-Uniquely-Cost-Effective-Not-in-Standard-Population-Models-Gustav-Alexandrie-and-Maya-Eden.pdf\n",
      "https://goodscience.substack.com/p/metascience-since-2012-a-personal | Metascience Since 2012: A Personal History - by Stuart Buck\n",
      "https://google.com/search?q=Galettes+des+rois&rlz=1C5CHFA_enGB1058GB1058&oq=Galettes+des+rois&aqs=chrome..69i57.163j0j1&sourceid=chrome&ie=UTF-8 | Galettes des rois - Google Search\n",
      "https://google.com/search?q=american+nuclear+monopoly&rlz=1CDGOYI_enUS715US715&oq=american+nuclear+monopoly&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDQzMzRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | american nuclear monopoly - Google Search\n",
      "https://google.com/search?q=beyond+this+moment&rlz=1C5CHFA_enGB1058GB1058&oq=beyond+this+moment&aqs=chrome.0.0i355i512j46i512j0i512j46i512j0i512j46i340i512j0i512j0i22i30l3.2523j0j1&sourceid=chrome&ie=UTF-8 | beyond this moment - Google Search\n",
      "https://google.com/search?q=bridgerton+season+3&rlz=1C5CHFA_enGB1058GB1058&oq=bridgertro&aqs=chrome.2.69i57j46i10i433i512j0i10i433i512l2j46i10i433i512j0i10i433i512l4.2814j0j1&sourceid=chrome&ie=UTF-8 | bridgerton season 3 - Google Search\n",
      "https://google.com/search?q=canadian+independence&rlz=1CDGOYI_enUS715US715&oq=Canadian+ind&gs_lcrp=EgZjaHJvbWUqBwgBEAAYgAQyBggAEEUYOTIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQLhiABDIHCAcQABiABDINCAgQLhivARjHARiABDIHCAkQABiABNIBCDQwODBqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | canadian independence - Google Search\n",
      "https://google.com/search?q=codependent+no+more&rlz=1C5CHFA_enGB1058GB1058&oq=codependent+no+more&aqs=chrome.0.0i271j46i131i433i512j46i512j0i512j46i512j0i512l5.2139j0j1&sourceid=chrome&ie=UTF-8 | codependent no more - Google Search\n",
      "https://google.com/search?q=couples+therapy+workbook&rlz=1C5CHFA_enGB1058GB1058&oq=couples+therapy+workbook&aqs=chrome.0.0i355i512j46i512l2j0i512l4j0i390i650l3.3499j0j1&sourceid=chrome&ie=UTF-8 | google.com/search?q=couples+therapy+workbook&rlz=1C5CHFA_enGB1058GB1058&oq=couples+therapy+workbook&aqs=chrome.0.0i355i512j46i512l2j0i512l4j0i390i650l3.3499j0j1&sourceid=chrome&ie=UTF-8\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://google.com/search?q=gencon+theft&rlz=1CDGOYI_enUS715US715&oq=gencon+theft&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiiBBiJBTIHCAIQABiiBDIHCAMQABiiBDIHCAQQABiiBDIHCAUQABiiBNIBCDU2NzZqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | google.com/search?q=gencon+theft&rlz=1CDGOYI_enUS715US715&oq=gencon+theft&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiiBBiJBTIHCAIQABiiBDIHCAMQABiiBDIHCAQQABiiBDIHCAUQABiiBNIBCDU2NzZqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8\n",
      "https://google.com/search?q=glassworks+ii+floe&rlz=1CDGOYI_enUS715US715&oq=glassworks+ii+floe&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiiBNIBCDQ1OTJqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | glassworks ii floe - Google Search\n",
      "https://google.com/search?q=goodr+sunglasses&rlz=1CDGOYI_enUS715US715&hl=en-US&ei=vyKoZMriOaKpptQPheasWA&oq=goodr&gs_lcp=ChNtb2JpbGUtZ3dzLXdpei1zZXJwEAEYADIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQigUQsAMQQzIKCAAQigUQsAMQQzIKCAAQigUQsAMQQzIQCC4QigUQxwEQ0QMQsAMQQzIVCC4QigUQxwEQ0QMQyAMQsAMQQxgBMhUILhCKBRDHARDRAxDIAxCwAxBDGAEyFQguEIoFEMcBENEDEMgDELADEEMYATIVCC4QigUQxwEQ0QMQyAMQsAMQQxgBMhUILhCKBRDHARDRAxDIAxCwAxBDGAEyFQguEIoFEMcBENEDEMgDELADEEMYAUoECEEYAFAAWABg0QhoAXABeACAAQCIAQCSAQCYAQDAAQHIARHaAQQIARgI&sclient=mobile-gws-wiz-serp&dlnr=1&sei=wyKoZIbvGsumptQPs-KdiAE | goodr sunglasses\n",
      "https://google.com/search?q=omgyes&rlz=1C5CHFA_enGB1058GB1058&oq=omgyes&aqs=chrome..69i57j0i512l4.2315j0j1&sourceid=chrome&ie=UTF-8 | omgyes - Google Search\n",
      "https://google.com/search?q=only+murders+in+the+building&rlz=1CDGOYI_enUS715US715&oq=only+murders&gs_lcrp=EgZjaHJvbWUqBwgBEAAYjwIyBggAEEUYOTIHCAEQABiPAjIHCAIQABiPAtIBCDE3NjJqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | only murders in the building - Google Search\n",
      "https://google.com/search?q=outer+wilds | Outer Wilds\n",
      "https://google.com/search?q=pussy+beads&rlz=1C5CHFA_enGB1058GB1058&oq=pussy+beads&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDE3ODRqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8#ip=1 | pussy beads - Google Search\n",
      "https://google.com/search?q=schartzman+ai&rlz=1C5CHFA_enGB1058GB1058&oq=schartzman+ai&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABgFGA0YHjIKCAIQABiGAxiKBdIBCDQ1ODhqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8 | google.com/search?q=schartzman+ai&rlz=1C5CHFA_enGB1058GB1058&oq=schartzman+ai&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABgFGA0YHjIKCAIQABiGAxiKBdIBCDQ1ODhqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8\n",
      "https://google.com/search?q=so+good+they+can%27t+ignore+you&rlz=1C5CHFA_enGB1058GB1058&oq=so+good+they+can&gs_lcrp=EgZjaHJvbWUqCggAEAAY4wIYgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDI3ODVqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8 | so good they can't ignore you - Google Search\n",
      "https://google.com/search?rlz=1C5CHFA_enGB1058GB1058&q=never+forget+what+you%27re+fighting+for&tbm=isch&sa=X&ved=2ahUKEwjezY2zm5eAAxWhnGoFHZ-lCOgQ0pQJegQICxAB&biw=1440&bih=796&dpr=2 | never forget what you're fighting for - Google Search\n",
      "https://google.com/search?sca_esv=558541893&rlz=1CDGOYI_enUS715US715&hl=en-US&q=The+Real+Campers+of+Shallow+Lake&tbm=isch&source=lnms&sa=X&ved=2ahUKEwjFn4yEiuuAAxXmFlkFHVd0BbUQ0pQJegQIChAB&biw=428&bih=751&dpr=3 | The Real Campers of Shallow Lake - Google Search\n",
      "https://governance.ai/post/head-of-operations | Head of Operations  GovAI Blog\n",
      "https://governance.ai/post/proposing-a-foundation-model-information-sharing-regime-for-the-uk | Proposing a Foundation Model Information-Sharing Regime for the UK  GovAI Blog\n",
      "https://gucem.org/v/0.1.14/docs/Anchor%20BOTECs/AIAnchorBOTECs/ | AI safety anchor BOTECs  FTX GUCEM\n",
      "https://gucem.org/v/0.1.14/docs/Basic%20Models/AI%20Safety%20Research/ | AI safety research model  FTX GUCEM\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Biorisk/ | Bio xrisk  FTX GUCEM\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Collapse/ | Collapse  FTX GUCEM\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Values/ | Value of the future  FTX GUCEM\n",
      "https://guzey.com/ | Alexey Guzey\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://hbr.org/2011/04/peacetime-ceos-vs-wartime-ceos | Are You a Peacetime CEO or a Wartime CEO?\n",
      "https://hbr.org/2016/07/why-diversity-programs-fail?fbclid=IwAR2B3f9zxGE4Shz8h1k498bcNJ-2uKt9nlDuAUjWTzYC-dq5SSL5tLzyl90 | Why Diversity Programs Fail\n",
      "https://hearthackersclub.com/date-someone-anxious-attachment-style/ | How to Date Someone With an Anxious Attachment Style\n",
      "https://heatmap.news/ | Heatmap News\n",
      "https://heinrich.senate.gov/imo/media/doc/create_ai_act_fact_sheet1.pdf | CREATE AI Act of 2023\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://hollyelmore.substack.com/p/the-technology-bucket-error | The “technology\" bucket error - Holly Elmore\n",
      "https://horizonpublicservice.org/post/applications-open-for-2024-horizon-fellowship-cohort | Applications open for 2024 Horizon Fellowship cohort\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://independent.co.uk/news/uk/politics/rishi-sunak-artificial-intelligence-ai-regulation-b2401922.html?utm_source=substack&utm_medium=email | Rishi Sunak warned of ‘12 risks of AI’ amid calls for urgent regulation  The Independent\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://insider.com/how-polyamorous-people-cope-with-jealousy-in-relationships-2020-2?amp | How Polyamorous People Cope With Jealousy in Relationships\n",
      "https://interconnects.ai/ | (1) Interconnects  Nathan Lambert  Substack\n",
      "https://interconnects.ai/p/llama-2-part-2 | Llama 2 follow-up: too much RLHF, GPU sizing, technical details\n",
      "https://investopedia.com/articles/investing/030613/secret-finances-vatican-economy.asp | The Secret Finances Of The Vatican Economy\n",
      "https://jack-clark.net/2023/07/05/what-should-the-uks-100-million-foundation-model-taskforce-do/ | What should the UK’s £100 million Foundation Model Taskforce do?\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://jeanhsu.substack.com/p/ask-vs-guess-culture | Ask vs guess culture - by Jean Hsu - Tech and Tea\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://jobs.lever.co/redwoodresearch/caed16e9-1c03-4d2e-aa90-80dc2ca90d20 | Constellation Head of Business Operations\n",
      "https://joecarlsmith.com/2020/11/08/how-core-is-confusion-about-consciousness | How core is confusion about consciousness? - Joe Carlsmith\n",
      "https://joecarlsmith.com/2020/11/22/the-impact-merge | The impact merge - Joe Carlsmith\n",
      "https://joecarlsmith.com/2020/12/12/wholeheartedness-and-morality-as-taxes | Wholehearted choices and \"morality as taxes\" - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/01/18/actually-possible-thoughts-on-utopia | Actually possible: thoughts on Utopia - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/01/24/on-clinging | On clinging - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/03/07/care-and-demandingness | Care and demandingness - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/03/14/against-neutrality-about-creating-happy-lives | Against neutrality about creating happy lives - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/03/22/on-future-people-looking-back-at-21st-century-longtermism | On future people, looking back at 21st century longtermism - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values | On the limits of idealized values - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/07/19/in-search-of-benevolence-or-what-should-you-get-clippy-for-christmas | In search of benevolence (or: what should you get Clippy for Christmas?) - Joe Carlsmith\n",
      "https://joecarlsmith.com/2021/08/27/can-you-control-the-past | Can you control the past? - Joe Carlsmith\n",
      "https://joecarlsmith.com/2022/01/30/on-infinite-ethics | On infinite ethics - Joe Carlsmith\n",
      "https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics | Why should ethical anti-realists do ethics? - Joe Carlsmith\n",
      "https://josephnoelwalker.com/148-stephen-wolfram/ | #148: Constructing the Computational Paradigm — Stephen Wolfram\n",
      "https://joshbarro.com/ | (1) Very Serious  Josh Barro  Substack\n",
      "https://kaistai.github.io/FLASK/ | KAIST LK Lab - Home\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://kinkyevents.co.uk/confessions-of-a-sub-teasing-and-begging/ | Confessions of a Sub: Teasing and Begging\n",
      "https://kinkyevents.co.uk/confessions-of-a-sub-when-scenes-go-wrong/ | Confessions of a Sub: When Scenes Go Wrong\n",
      "https://kinkyevents.co.uk/why-submission-is-essential-in-my-relationship/ | Why Submission is Essential in My Relationship\n",
      "https://lascivity.co.uk/a-guide-to-safe-fun-consensual-nonconsent/ | A Guide to Safe, Fun Consensual Nonconsent\n",
      "https://lascivity.co.uk/the-rough-sex-playbook/ | The Rough Sex Playbook\n",
      "https://latent.space/p/ai-engineer | The Rise of the AI Engineer - by swyx - Latent Space\n",
      "https://latimes.com/entertainment-arts/movies/story/2023-08-11/oppenheimer-atomic-bomb-hiroshima-nagasaki-christopher-nolan | ‘Oppenheimer’ doesn’t show Hiroshima or Nagasaki — by choice - Los Angeles Times\n",
      "https://lawfaremedia.org/article/the-next-frontier-in-ai-regulation-is-procedure | The Next Frontier in AI Regulation Is Procedure  Lawfare\n",
      "https://learningfromexamples.substack.com/p/an-introduction-to-ai-history | An introduction to AI history - by Harry Law\n",
      "https://lesswrong.com/posts/3GSRhtrs2adzpXcbY/rationality-winning | Rationality !== Winning — LessWrong\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue) — LessWrong\n",
      "https://lesswrong.com/posts/3ou8DayvDXxufkjHD/openai-api-base-models-are-not-sycophantic-at-any-size | OpenAI API base models are not sycophantic, at any size — LessWrong\n",
      "https://lesswrong.com/posts/4NFDwQRhHBB2Ad4ZY/the-filan-cabinet-podcast-with-oliver-habryka-transcript | The Filan Cabinet Podcast with Oliver Habryka - Transcript\n",
      "https://lesswrong.com/posts/4gDbqL3Tods8kHDqs/limits-to-legibility | Limits to Legibility — LessWrong\n",
      "https://lesswrong.com/posts/5sNLX2yY5FzkCp7Ju/the-spelling-miracle-gpt-3-spelling-abilities-and-glitch | The \"spelling miracle\": GPT-3 spelling abilities and glitch tokens revisited — LessWrong\n",
      "https://lesswrong.com/posts/6untaSPpsocmkS7Z3/ways-i-expect-ai-regulation-to-increase-extinction-risk | Ways I Expect AI Regulation To Increase Extinction Risk — LessWrong\n",
      "https://lesswrong.com/posts/8NPFtzPhkeYZXRoh3/perpetually-declining-population | Perpetually Declining Population? — LessWrong\n",
      "https://lesswrong.com/posts/8bhp8tsdxqifA9Ass/summary-of-and-thoughts-on-the-hotz-yudkowsky-debate | Summary of and Thoughts on the Hotz/Yudkowsky Debate — LessWrong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://lesswrong.com/posts/BAqvAvPC7GiZhTyR3/dating-roundup-1-this-is-why-you-re-single | Dating Roundup #1: This is Why You’re Single — LessWrong\n",
      "https://lesswrong.com/posts/BTcEzXYoDrWzkLLrQ/the-public-debate-about-ai-is-confusing-for-the-general | The \"public debate\" about AI is confusing for the general public and for policymakers because it is a three-sided debate — LessWrong\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://lesswrong.com/posts/Ce82o8mbBfH9N3Jes/evaluating-gpt-4-theory-of-mind-capabilities | Evaluating GPT-4 Theory of Mind Capabilities — LessWrong\n",
      "https://lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1 | Model Organisms of Misalignment: The Case for a New Pillar of Alignment Research — LessWrong\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://lesswrong.com/posts/DCL3MmMiPsuMxP45a/even-superhuman-go-ais-have-surprising-failures-modes | Even Superhuman Go AIs Have Surprising Failures Modes\n",
      "https://lesswrong.com/posts/Djgws2Moi7Zefkj5y/which-possible-ai-systems-are-relatively-safe | Which possible AI systems are relatively safe? — LessWrong\n",
      "https://lesswrong.com/posts/DtkA5jysFZGv7W4qP/training-process-transparency-through-gradient | Training Process Transparency through Gradient Interpretability: Early experiments on toy language models\n",
      "https://lesswrong.com/posts/EPLk8QxETC5FEhoxK/arc-evals-new-report-evaluating-language-model-agents-on | ARC Evals new report: Evaluating Language-Model Agents on Realistic Autonomous Tasks — LessWrong\n",
      "https://lesswrong.com/posts/F6vH6fr8ngo7csDdf/chess-as-a-case-study-in-hidden-capabilities-in-chatgpt | Chess as a case study in hidden capabilities in ChatGPT — LessWrong\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? — LessWrong\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://lesswrong.com/posts/Ghrdnc26ftJrxD49z/carl-shulman-on-the-lunar-society-7-hour-two-part-podcast | Carl Shulman on The Lunar Society (7 hour, two-part podcast) — LessWrong\n",
      "https://lesswrong.com/posts/GpSzShaaf8po4rcmA/qapr-5-grokking-is-maybe-not-that-big-a-deal | QAPR 5: grokking is maybe not *that* big a deal? — LessWrong\n",
      "https://lesswrong.com/posts/JteNtoLBFZB9niiiu/the-smallest-possible-button | The smallest possible button — LessWrong\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective — LessWrong\n",
      "https://lesswrong.com/posts/KRDo2afKJtD7bzSM8/barriers-to-mechanistic-interpretability-for-agi-safety | Barriers to Mechanistic Interpretability for AGI Safety — LessWrong\n",
      "https://lesswrong.com/posts/KpD2fJa6zo8o2MBxg/consciousness-as-a-conflationary-alliance-term | Consciousness as a conflationary alliance term — LessWrong\n",
      "https://lesswrong.com/posts/LERwsN3SYhkCfew6j/discussing-how-to-align-transformative-ai-if-it-s-developed | Discussing how to align Transformative AI if it’s developed very soon — LessWrong\n",
      "https://lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1 | Against Almost Every Theory of Impact of Interpretability — LessWrong\n",
      "https://lesswrong.com/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic | What Multipolar Failure Looks Like, and Robust Agent-Agnostic Processes (RAAPs) — LessWrong\n",
      "https://lesswrong.com/posts/NRbkiGtekQLAfoiLr/learning-as-you-play-anthropic-shadow-in-deadly-games | Learning as you play: anthropic shadow in deadly games — LessWrong\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom — LessWrong\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why — LessWrong\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://lesswrong.com/posts/R5yL6oZxqJfmqnuje/cultivating-a-state-of-mind-where-new-ideas-are-born | Cultivating a state of mind where new ideas are born — LessWrong\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people — LessWrong\n",
      "https://lesswrong.com/posts/SDpaZ7MdH5yRnobrZ/ideas-for-improving-epistemics-in-ai-safety-outreach | Ideas for improving epistemics in AI safety outreach — LessWrong\n",
      "https://lesswrong.com/posts/SdkexhiynayG2sQCC/ai-forecasting-two-years-in | AI Forecasting: Two Years In — LessWrong\n",
      "https://lesswrong.com/posts/SfZRWxktiFFJ5FNk8/the-god-of-humanity-and-the-god-of-the-robot-utilitarians | The God of Humanity, and the God of the Robot Utilitarians — LessWrong\n",
      "https://lesswrong.com/posts/T5WFE734wHzwMYJaB/partial-transcript-of-recent-senate-hearing-discussing-ai-x | Partial Transcript of Recent Senate Hearing Discussing AI X-Risk — LessWrong\n",
      "https://lesswrong.com/posts/Wc5BYFfzuLzepQjCq/inflection-ai-is-a-major-agi-lab | Inflection.ai is a major AGI lab\n",
      "https://lesswrong.com/posts/WhSK9y8apy8mNMFGK/reproducing-arc-evals-recent-report-on-language-model-agents | Reproducing ARC Evals' recent report on language model agents — LessWrong\n",
      "https://lesswrong.com/posts/YzdoNdfgfvXgC3wR4/google-deepmind-s-rt-2 | Google DeepMind's RT-2 — LessWrong\n",
      "https://lesswrong.com/posts/atxoviwLcPJPdYMqo/if-we-had-known-the-atmosphere-would-ignite | If we had known the atmosphere would ignite — LessWrong\n",
      "https://lesswrong.com/posts/bBicgqvwjPbaQrJJA/dirty-concepts-in-ai-alignment-discourses-and-some-guesses | “Dirty concepts” in AI alignment discourses, and some guesses for how to deal with them — LessWrong\n",
      "https://lesswrong.com/posts/btpE9fAbvGys4Ztj9/how-to-make-real-money-prediction-markets-on-arbitrary | How to make real-money prediction markets on arbitrary topics — LessWrong\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations | When can we trust model evaluations? — LessWrong\n",
      "https://lesswrong.com/posts/fARMR2tiyCem8DD35/managing-risks-of-our-own-work | Managing risks of our own work — LessWrong\n",
      "https://lesswrong.com/posts/fRSj2W4Fjje8rQWm9/thoughts-on-sharing-information-about-language-model | Thoughts on sharing information about language model capabilities — LessWrong\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? — LessWrong\n",
      "https://lesswrong.com/posts/gzJ7QNhd3tCLkbmYC/my-favorite-ai-governance-research-this-year-so-far | My favorite AI governance research this year so far — LessWrong\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium | The lost millennium — LessWrong\n",
      "https://lesswrong.com/posts/iFrefmWAct3wYG7vQ/ai-labs-statements-on-governance | AI labs' statements on governance — LessWrong\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://lesswrong.com/posts/oZnPabN2CQQdnAo63/diy-deliberate-practice | DIY Deliberate Practice — LessWrong\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). — LessWrong\n",
      "https://lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship | Large Language Models will be Great for Censorship — LessWrong\n",
      "https://lesswrong.com/posts/pZrvkZzL2JnbRgEBC/feedbackloop-first-rationality | Feedbackloop-first Rationality — LessWrong\n",
      "https://lesswrong.com/posts/ppQRJEfLBCLFzK73w/linkpost-michael-nielsen-remarks-on-oppenheimer | [Linkpost] Michael Nielsen remarks on 'Oppenheimer' — LessWrong\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments\n",
      "https://lesswrong.com/posts/qrFf2QEhSiL9F3yLY/tensor-trust-an-online-game-to-uncover-prompt-injection | Tensor Trust: An online game to uncover prompt injection vulnerabilities — LessWrong\n",
      "https://lesswrong.com/posts/r2vaM2MDvdiDSWicu/the-u-s-is-mildly-destabilizing | The U.S. is mildly destabilizing — LessWrong\n",
      "https://lesswrong.com/posts/rZs6ddqNnW8LXuJqA/password-locked-models-a-stress-case-for-capabilities | Password-locked models: a stress case for capabilities evaluation — LessWrong\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://lesswrong.com/posts/wBgjQKNfJnPMjKpFa/incentives-affecting-alignment-researcher-encouragement | Incentives affecting alignment-researcher encouragement — LessWrong\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/ | LLM Powered Autonomous Agents  Lil'Log\n",
      "https://link.springer.com/article/10.1007/s10539-023-09924-y | What if worms were sentient? Insights into subjective experience from the Caenorhabditis elegans connectome\n",
      "https://linkedin.com/feed/?msgControlName=view_message_button&msgConversationId=2-OWI2NzczNWMtMWU1Ni00MTQwLThmZTktOWY1MjUxZmM1NWYxXzAxMg%3D%3D&msgOverlay=true&trk=false | (27) Feed  LinkedIn\n",
      "https://linkedin.com/posts/activity-7092524003159920641-N7MR?utm_source=share&utm_medium=member_android | LinkedIn\n",
      "https://linkedin.com/posts/annalenhart_federal-legislative-proposals-pertaining-activity-7094379365110542336-OvmE/ | linkedin.com/posts/annalenhart_federal-legislative-proposals-pertaining-activity-7094379365110542336-OvmE/\n",
      "https://linkedin.com/posts/sebkrier_open-source-provisions-for-large-models-in-ugcPost-7095412304917192704-QnBX/?utm_source=share&utm_medium=member_android | (99+) Post  LinkedIn\n",
      "https://linkedin.com/pulse/do-you-want-work-wartime-ceo-peacetime-mamei-sun/ | (26) Do you want to work for a Wartime CEO or a Peacetime CEO?  LinkedIn\n",
      "https://linkedin.com/pulse/elevation-human-work-reid-hoffman/ | (99+) The elevation of human work  LinkedIn\n",
      "https://linkedin.com/pulse/stepping-up-ctos-top-tips-transitioning-from-vp-engineering-dunn/ | (27) Stepping up: CTOs’ top tips on transitioning from VP Engineering  LinkedIn\n",
      "https://llmbench.ai/ | AgentBench\n",
      "https://localhost:8888/lab/tree/Tab%20sorts.ipynb | Tab sorts.ipynb - JupyterLab\n",
      "https://longform.asmartbear.com/great-strategy/ | What makes a strategy great\n",
      "https://lucid.app/lucidchart/a83a6a4a-5a9a-42cd-acca-45b48675bc62/edit?beaconFlowId=6DA8276DDD8C8833&invitationId=inv_6c6ef3f5-3731-4d19-8bc7-da4942087ebd&page=0_0# | Blank diagram: Lucidchart\n",
      "https://macroscience.org/p/its-so-over-now-what | It’s So Over. Now What? - by Tim Hwang - Macroscience\n",
      "https://mailchi.mp/05ea3373d854/kplm9b3pfo-9593653 | mailchi.mp/05ea3373d854/kplm9b3pfo-9593653\n",
      "https://mailchi.mp/5a0109faee8f/welcome-to-our-first-newsletter?e=ccdb9d34ea | mailchi.mp/5a0109faee8f/welcome-to-our-first-newsletter?e=ccdb9d34ea\n",
      "https://mailchi.mp/foodsolutionsaction/aug2023?e=90dfd9ccb1 | Food Solutions Action: Member Update\n",
      "https://manifold.markets/connorwilliams97/what-are-the-probabilities-of-these | What are the probabilities of these AI outcomes (X-risk, dystopias, utopias, in-between outcomes, status quo outcomes)?  Manifold\n",
      "https://manifund.org/projects/congressional-staffers-biosecurity-briefings-in-dc | manifund.org/projects/congressional-staffers-biosecurity-briefings-in-dc\n",
      "https://manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers | manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers\n",
      "https://manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers?tab=comments | Shrimp Welfare Project - Special Program  Manifund\n",
      "https://manifund.org/rounds/regrants?tab=projects | manifund.org/rounds/regrants?tab=projects\n",
      "https://marketwatch.com/story/regulators-open-floodgates-for-driverless-taxis-in-san-francisco-whether-theyre-wanted-or-not-f966c029?rss=1&siteid=rss&utm_source=substack&utm_medium=email | Regulators open floodgates for driverless taxis in San Francisco - MarketWatch\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://mdickens.me/2016/04/06/expected_value_estimates_you_can_%28maybe%29_take_literally/ | Expected Value Estimates You Can (Maybe) Take Literally  Michael Dickens\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://medium.com/@nitindharny/from-busy-to-productive-time-management-tips-for-engineering-managers-3de9f74d2c72 | From Busy to Productive: Time Management Tips for Engineering Managers  by Nitin Dhar  Medium\n",
      "https://medium.com/polyamory-today/4-questions-for-breaking-down-jealousy-in-polyamorous-relationships-c16bcfd5ffc3 | 4 Questions for Breaking Down Jealousy in Polyamorous Relationships  by Marianna Zelichenko  Polyamory Today  Medium\n",
      "https://mercatus.org/research/defining-killer-ai?utm_source=substack&utm_medium=email | On Defining \"Killer AI\"  Mercatus Center\n",
      "https://metaculus.com/ai/ | The Metaculus Lens on AI\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://metaculus.com/notebooks/17798/when-should-you-deviate-from-the-base-rate/ | When Should You Deviate From the Base Rate?  Metaculus\n",
      "https://metaculus.com/questions/10832/donald-trump-jailed-by-2030/ | metaculus.com/questions/10832/donald-trump-jailed-by-2030/\n",
      "https://metaculus.com/questions/11675/math-sota-ai-performance/ | What will be state-of-the-art performance on the MATH dataset on the following dates?\n",
      "https://metaculus.com/questions/15778/trump-guilty-in-manhattan-by-election-day/ | Trump guilty in Manhattan by Election Day  Metaculus\n",
      "https://metaculus.com/questions/17418/most-expensive-ai-training-run-by-year/ | What will the most expensive AI training run be in the following years, in millions of USD\n",
      "https://metaculus.com/questions/17431/trump-documents-case-sentence-if-convicted/ | Trump documents case sentence if convicted  Metaculus\n",
      "https://metaculus.com/questions/17904/next-starship-orbital-test-flight/#comment-131670 | metaculus.com/questions/17904/next-starship-orbital-test-flight/#comment-131670\n",
      "https://metaculus.com/questions/17993/swedish-2023-tbe-cases-over-370-by-october/ | Swedish 2023 TBE Cases Over 370 By October?  Metaculus\n",
      "https://metaculus.com/questions/18177/room-temp-superconductor-replicated-by-2025/ | Room-temp Superconductor Replicated by 2025  Metaculus\n",
      "https://metaculus.com/questions/18228/metaculus-ai-benchmarks-bias/ | Metaculus AI benchmarks bias  Metaculus\n",
      "https://metaculus.com/questions/18229/2024-third-party-republican/ | 2024 Third Party Republican?  Metaculus\n",
      "https://metaculus.com/questions/18524/2020-to-2023-average-vote-swing/ | 2020 to 2023 average vote swing?  Metaculus\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://metaculus.com/superconductors/ | The Metaculus Lens on Superconductors\n",
      "https://microsoft.com/en-us/ai | Artificial Intelligence Solutions  Microsoft AI\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://minimaxir.com/2023/08/stable-diffusion-xl-wrong/ | I Made Stable Diffusion XL Smarter by Finetuning it on Bad AI-Generated Images  Max Woolf's Blog\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://morethantwo.com/bridgingthedivide.html | More Than Two  Bridging the Divide\n",
      "https://morethantwo.com/communication.html | More Than Two  Communication\n",
      "https://morethantwo.com/coupleprivilege.html | More Than Two  Polyamory and Couple Privilege\n",
      "https://morethantwo.com/jealousy-insecurity.html | More Than Two  Jealousy and Insecurity\n",
      "https://morethantwo.com/polyamory.html | More Than Two  What, like, two girlfriends?\n",
      "https://morethantwo.com/polyfairness.html | More Than Two  Polyamory and Fairness\n",
      "https://morethantwo.com/polyforsecondaries.html | More Than Two  Secondary’s Guide\n",
      "https://morethantwo.com/polymistakes.html | More Than Two  Common mistakes in poly relationships\n",
      "https://morethantwo.com/polymyths.html | More Than Two  Myths About Polyamory\n",
      "https://morethantwo.com/polypets.html | More Than Two  Life Without Walls\n",
      "https://morethantwo.com/polytime.html | More Than Two  Managing Time\n",
      "https://morethantwo.com/polytips.html | More Than Two  Dos and don'ts for polyamory\n",
      "https://morethantwo.com/prisonersdilemma.html | More Than Two  Your Partner's Other Partners\n",
      "https://morethantwo.com/relationshipassumptions.html | More Than Two  Making the Good Bits Stick\n",
      "https://morethantwo.com/relationshipbenchmarks.html | More Than Two  Healthy Relationships\n",
      "https://morethantwo.com/socialfallacies.html | More Than Two  Social Fallacies of Polyamory\n",
      "https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know/ | The Many Ways that Digital Minds can Know – Ryan Moulton's Articles\n",
      "https://murdershebet.com/ | Murder, She Bet [BETA]\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://natesilver.net/ | (1) Silver Bulletin  Nate Silver  Substack\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://nature.com/articles/d41586-023-02491-y?utm_source=substack&utm_medium=email | Rules to keep AI in check: nations carve different paths for tech regulation\n",
      "https://nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D | Baby steps in evaluating the capacities of large language models  Nature Reviews Psychology\n",
      "https://ndupress.ndu.edu/Media/News/News-Article-View/Article/3471053/discerning-the-drivers-of-chinas-nuclear-force-development-models-indicators-an/ | Discerning the Drivers of China’s Nuclear Force Development: Models, Indicators, and Data > National Defense University Press > News Article View\n",
      "https://newyorker.com/magazine/2023/08/21/the-hidden-cost-of-free-returns | What Happens to All the Stuff We Return?  The New Yorker\n",
      "https://niplav.site/ | Content – niplav\n",
      "https://nm.org/healthbeat/healthy-tips/how-many-steps-a-day-should-you-take-to-improve-your-heart-health | How Many Steps a Day Should You Take to Improve Your Heart Health?  Northwestern Medicine\n",
      "https://non-trivial.org/ | Non-Trivial  Start solving the world's most pressing problems\n",
      "https://npr.org/2023/08/16/1194202562/new-york-times-considers-legal-action-against-openai-as-copyright-tensions-swirl?utm_source=substack&utm_medium=email | 'New York Times' considers legal action against OpenAI as copyright tensions swirl : NPR\n",
      "https://nsf.gov/pubs/2023/nsf23600/nsf23600.htm | nsf.gov/pubs/2023/nsf23600/nsf23600.htm\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://nunosempere.com/blog/2023/07/13/melancholy/ | Some melancholy about the value of my work depending on decisions by others beyond my control\n",
      "https://nunosempere.com/blog/2023/07/19/better-harder-faster-stronger/ | Why are we not harder, better, faster, stronger?\n",
      "https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html | Inside the AI Factory: The Humans That Make Tech Seem Human\n",
      "https://nytimes.com/2019/05/04/smarter-living/500-days-of-duolingo-what-you-can-and-cant-learn-from-a-language-app.html | 500 Days of Duolingo: What You Can (and Can’t) Learn From a Language App - The New York Times\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://nytimes.com/2023/05/12/opinion/conservative-mainstream-media.html | Conservative Media Has an Audience Problem\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://nytimes.com/2023/07/19/opinion/putin-prigozhin-military-russia.html | All Is Not Well on Russian Front Lines\n",
      "https://nytimes.com/2023/07/23/opinion/china-russia-us-cold-war.html | Vladimir Putin Is Still Useful to Xi Jinping. Until He Isn’t.\n",
      "https://nytimes.com/2023/07/25/business/tech-earnings-ai-microsoft-alphabet.html | Microsoft and Alphabet Face an Investor Test on AI - The New York Times\n",
      "https://nytimes.com/2023/07/25/opinion/karp-palantir-artificial-intelligence.html | Our Oppenheimer Moment: The Creation of A.I. Weapons\n",
      "https://nytimes.com/2023/08/16/technology/ai-defcon-hackers.html?utm_source=substack&utm_medium=email | When Hackers Descended to Test A.I., They Found Flaws Aplenty - The New York Times\n",
      "https://nytimes.com/2023/08/16/technology/google-ai-life-advice.html?utm_source=substack&utm_medium=email | Google Tests an A.I. Assistant That Offers Life Advice - The New York Times\n",
      "https://nytimes.com/column/retro-report | Retro Report - The New York Times\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://omgkinky.com/ | omgkinky.com/\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/phpr.13006 | Rational risk‐aversion: Good things come to those who weight - Bottomley - Philosophy and Phenomenological Research - Wiley Online Library\n",
      "https://open.spotify.com/episode/1GI6osEgwSFewEaELi1KTP?si=R5PSWs3CQ0K2tUPkqL-BZw&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | open.spotify.com/episode/1GI6osEgwSFewEaELi1KTP?si=R5PSWs3CQ0K2tUPkqL-BZw&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1\n",
      "https://open.spotify.com/episode/3l6LAC3LeQnr8eFaKXLEui?si=BgmfDuXCSoakdIbxsE-HHg&nd=1 | Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & AGI in 2 years - Dwarkesh Podcast (Lunar Society formerly)  Podcast on Spotify\n",
      "https://openai.com/blog/custom-instructions-for-chatgpt | Custom instructions for ChatGPT\n",
      "https://openai.com/blog/frontier-model-forum | Frontier Model Forum\n",
      "https://openai.com/blog/function-calling-and-other-api-updates | Function calling and other API updates\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://openai.com/blog/how-should-ai-systems-behave | How should AI systems behave, and who should decide?\n",
      "https://openai.com/blog/introducing-superalignment | Introducing Superalignment\n",
      "https://openai.com/blog/moving-ai-governance-forward | Moving AI governance forward\n",
      "https://openai.com/blog/using-gpt-4-for-content-moderation | Using GPT-4 for content moderation\n",
      "https://openai.com/research/language-model-safety-and-misuse | Lessons learned on language model safety and misuse\n",
      "https://overcast.fm/+KebuY8LY4/1:11:15?utm_source=substack&utm_medium=email | #686: Dustin Moskovitz, Co-Founder of Asana and Facebook — Energy Management, Coaching for Endurance, No Meeting Wednesdays, Understanding the Real Risks of AI, Embracing Frictionless Work with AI, The Value of Holding Stories Loosely, and More — The Tim Ferriss Show — Overcast\n",
      "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421 | Building a Culture of Safety for AI: Perspectives and Challenges by David Manheim :: SSRN\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://paxfauna.org/ | Pax Fauna\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://philpapers.org/archive/WILIDO-22.pdf | WILIDO-22.pdf\n",
      "https://planned-obsolescence.org/language-models-surprised-us/ | Language models surprised us\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://politico.com/news/magazine/2023/07/20/vivek-ramaswamy-pete-buttigieg-00107193 | Opinion  Get Ready for the Vivek Ramaswamy Moment - POLITICO\n",
      "https://politico.com/news/magazine/2023/08/29/forget-about-ohio-its-fools-gold-00113224 | No, Ohio Is Not in Play - POLITICO\n",
      "https://politico.eu/article/the-14-people-who-matter-in-uk-ai-policy/ | The 14 people who matter in UK AI policy\n",
      "https://poly-coach.com/polyamory-relationship-counseling/how-do-i-deal-with-jealousy-in-my-relationships/ | How Do I Deal With Jealousy In My Relationships? - Poly-Coach\n",
      "https://polyfor.us/articles/how-to-make-jealousy-work-for-you | How to Make Jealousy Work For You, Not Against You — Polyamory For Us - Sharing What We've Learned\n",
      "https://predictions.substack.com/p/001-goldilocks-zone | The limits of long-term Quantified Forecasting\n",
      "https://predictit.org/markets/detail/8074/Who-will-place-second-in-the-2024-Iowa-Republican-caucuses | PredictIt\n",
      "https://progress.institute/can-policymakers-trust-forecasters/ | Can Policymakers Trust Forecasters? - Institute for Progress\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://psychologytoday.com/gb/blog/relational-intimacy/202109/managing-jealousy-in-polyamorous-relationships?amp | Managing Jealousy in Polyamorous Relationships  Psychology Today United Kingdom\n",
      "https://quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/ | Complexity Theory’s 50-Year Journey to the Limits of Knowledge  Quanta Magazine\n",
      "https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW14Gtw | Governing AI: A Blueprint for the Future\n",
      "https://quora.com/What-are-some-ways-to-remove-jealousy-in-a-polyamorous-relationship | What are some ways to remove jealousy in a polyamorous relationship? - Quora\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://readsomethingwonderful.com/p/82/common-knowledge-and-aumanns-agreement-theorem | Read Something Wonderful - Common Knowledge and Aumann’s Agreement Theorem\n",
      "https://readtobloom.com/ | Global Home for Social Impact\n",
      "https://readyforpolyamory.com/post/boundaries-are-for-everyone | Boundaries are for Everyone\n",
      "https://reddit.com/r/BDSMcommunity/comments/156naam/favorite_humiliation_phrases/ | (5) Favorite humiliation phrases? : BDSMcommunity\n",
      "https://reddit.com/r/BDSMerotica/comments/iot2r4/fourday_fuckdoll_fmfncselfbondagecaptiveforced/ | (2) Four-Day Fuckdoll [F][MF][nc][self-bondage][captive][forced orgasm] : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/jlvdn2/brats_what_you_deserve_mdom_fsub_brattaming/ | (2) Brat’s What You Deserve (MDom, Fsub, brat-taming, punishment, oral, edging, repeated orgasm) : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/knc9jc/the_new_king_chases_and_tames_me_a_submissive/ | (2) The new king chases and tames me, a submissive princess, deep in the forest [Mf][Mdom] : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/p0opup/my_master_went_from_sharing_me_with_his_friends/ | (2) My master went from sharing me with his friends to renting me out. : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/p40u7s/how_losing_a_bet_with_my_neighbors_turned_me_into/ | (2) How losing a bet with my neighbors turned me into a total whore (part 1 of ?) [F/F/f] [huml] : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/q3jfdl/punishment_maledom_femalesub_bdsm_spanking/ | (2) Punishment [MaleDom] [Femalesub] [BDSM] [spanking] [forcedorgasm] [anal]. : BDSMerotica\n",
      "https://reddit.com/r/BDSMerotica/comments/r0ta5n/teased_and_tied_up_while_he_games_part_1_mdom/ | (2) Teased and Tied Up While He Games - Part 1 [Mdom] [Bondage] [Toys] [Objectification] : BDSMerotica\n",
      "https://reddit.com/r/datingoverthirty/comments/15fvhgb/dating_men_with_kids/ | (3) Dating men with kids…. : datingoverthirty\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://reddit.com/r/polyamory/comments/10nrgsd/do_i_need_to_figure_out_how_to_handle_my_jealousy/ | (4) Do I need to figure out how to handle my jealousy, or is polyamory not for me? : polyamory\n",
      "https://reddit.com/r/polyamory/comments/2zd8zl/good_boundaries/ | (4) Good boundaries : polyamory\n",
      "https://reddit.com/r/polyamory/comments/bkf1r9/examples_of_boundaries_in_poly_relationships/ | (4) Examples of Boundaries in Poly Relationships : polyamory\n",
      "https://reddit.com/r/polyamory/comments/oag9t5/poly_relationship_boundaries/ | (4) Poly relationship boundaries : polyamory\n",
      "https://reddit.com/r/polyamory/comments/su5n40/monopoly_relationship_boundaries/ | Reddit - Dive into anything\n",
      "https://reddit.com/r/relationship_advice/comments/15b7c5p/i_26f_want_to_leave_my_fiance_30m_because_of_his/ | (5) I (26f) want to leave my fiance (30m) because of his kids : relationship_advice\n",
      "https://reddit.com/r/relationship_advice/comments/15bnst1/i_33m_have_only_been_with_one_woman_33f_for_my/ | (5) I (33M) have only been with one woman (33F) for my whole life (15 yr relationship). Midlife crisis is hitting me. : relationship_advice\n",
      "https://reddit.com/r/relationship_advice/comments/15bo3kk/i_26f_emotionally_cheated_on_my_bf_38m_i_need_to/ | (5) I (26F) emotionally cheated on my BF (38M). I need to vent. I need opinions? : relationship_advice\n",
      "https://reddit.com/r/relationship_advice/comments/15g4xtz/my_38m_husband_confessed_that_i_25f_am_a_second/ | (3) My (38m) husband confessed that I (25f) am a Second wife. How to get over this? : relationship_advice\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (3) Contra Scott on AI Races : slatestarcodex\n",
      "https://rescuetime.com/rtx/overview/for/the/day | RescueTime - Overview\n",
      "https://rethinkpriorities.github.io/longtermism-scale/ | Longtermism scale\n",
      "https://rethinkpriorities.org/animals-of-rp | Animals of Rethink Priorities — Rethink Priorities\n",
      "https://rethinkpriorities.org/five-years-campaign | Five Years of RP — Rethink Priorities\n",
      "https://rethinkpriorities.org/incubation | XST Incubation Website\n",
      "https://rethinkpriorities.org/longtermism-research-notes/putting-new-ai-lab-commitments-in-context | Putting New AI Lab Commitments in Context — Rethink Priorities\n",
      "https://rethinkpriorities.org/publications/dimensions-of-pain-workshop-summary-and-updated-conclusions | “Dimensions of Pain” workshop: Summary and updated conclusions — Rethink Priorities\n",
      "https://rethinkpriorities.org/publications/eu-farmed-fish-policy-reform-roadmap-brief | EU farmed fish policy reform roadmap brief — Rethink Priorities\n",
      "https://rethinkpriorities.org/publications/shrimp-the-animals-most-commonly-used-and-killed-for-food-production | Shrimp: The animals most commonly used and killed for food production\n",
      "https://roadtogrowthcounseling.com/managing-jealousy-in-your-polyamorous-relationships/ | Managing Jealousy in Your Polyamorous Relationships - Road to Growth Counseling\n",
      "https://rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/ | These Women Warned Of AI’s Dangers And Risks Long Before ChatGPT – Rolling Stone\n",
      "https://ropeconnections.com/consensual-non-consent-play-rape-partner/ | Consensual Non-Consent: How To Play Rape Your Partner\n",
      "https://rp-jeid-2022-survey-report.netlify.app/ | 2022 JEID survey report\n",
      "https://rychappell.substack.com/p/uncertain-optimizing-and-opportunity | Uncertain Optimizing and Opportunity Costs\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://schoolofsquirt.com/blog/page/2/ | Blog - Page 2 of 13 - School Of Squirt\n",
      "https://sci-hub.wf/10.1017/s1049096520001377 | Sci-Hub  State-Level Forecasts for the 2020 US Presidential Election: Tough Victory Ahead for Biden. PS: Political Science & Politics, 54(1), 77–80  10.1017/s1049096520001377\n",
      "https://sci-hub.wf/10.1017/s1049096520001389 | Sci-Hub  It’s the Pandemic, Stupid! A Simplified Model for Forecasting the 2020 Presidential Election. PS: Political Science & Politics, 1–3  10.1017/s1049096520001389\n",
      "https://sci-hub.wf/10.1017/s1049096520001407 | Sci-Hub  Forecasting the 2020 Electoral College Winner: The State Presidential Approval/State Economy Model. PS: Political Science & Politics, 1–5  10.1017/s1049096520001407\n",
      "https://science.org/doi/10.1126/science.adi0121 | Animal welfare: Methods to improve policy and practice\n",
      "https://scottaaronson.blog/?p=7460 | Testing GPT-4 with math plugins\n",
      "https://secondbest.ca/p/will-there-be-major-ai-legislation | Will there be major AI legislation before 2025?\n",
      "https://semafor.com/article/06/30/2023/the-26-year-old-ceo-who-became-washingtons-ai-whisperer?utm_campaign=hotonsemafor | The 26-year-old CEO who became Washington’s AI whisperer\n",
      "https://semafor.com/article/08/15/2023/can-chatgpt-become-a-content-moderator?utm_source=substack&utm_medium=email | Can ChatGPT become a content moderator?  Semafor\n",
      "https://semafor.com/article/08/16/2023/ex-google-ceo-eric-schmidt-to-launch-ai-science-moonshot?utm_source=Iterable&utm_medium=email&utm_campaign=campaign_7513609_nl_Philanthropy-Today_date_20230817&cid=pt&source=&sourceid= | Ex-Google CEO Eric Schmidt to launch AI-science moonshot  Semafor\n",
      "https://semafor.com/article/08/17/2023/some-republicans-tire-of-indictments?utm_campaign=hotonsemafor | Some Republicans tire of indictments  Semafor\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://simonandschuster.com/books/The-Bomb/Fred-Kaplan/9781982107307 | The Bomb\n",
      "https://simoninstitute.ch/blog/post/2-year-review-concluding-sis-inception/ | 2-year review: concluding SI's inception\n",
      "https://sites.google.com/rethinkpriorities.org/aasf/home | 2023 Animal Advocacy Strategy Forum\n",
      "https://sites.lsa.umich.edu/mje/2022/05/24/the-finances-behind-vatican-city/ | The Finances Behind Vatican City – Michigan Journal of Economics\n",
      "https://slowboring.com/p/how-human-translators-are-coping | slowboring.com/p/how-human-translators-are-coping\n",
      "https://slowboring.com/p/how-obama-and-trump-and-biden-beat | How Obama (and Trump and Biden) beat Europe\n",
      "https://slowboring.com/p/the-tragedy-of-the-manhattan-project | The tragedy of the Manhattan Project - by Matthew Yglesias\n",
      "https://someunpleasant.substack.com/p/lets-go-liberty | Let's Go Liberty\n",
      "https://spectrum.ieee.org/members-advocate-for-ai-regulations?utm_source=substack&utm_medium=email | Members Advocate for AI Regulations During Visit to U.S. Congress - IEEE Spectrum\n",
      "https://split-ticket.org/2023/08/14/evaluating-sherrod-browns-path-to-reelection/ | Evaluating Sherrod Brown’s Path to Reelection – Split Ticket\n",
      "https://stability.ai/ | Stability AI\n",
      "https://static1.squarespace.com/static/6035868111c9bd46c176042b/t/64e390ee3f1b0b0463d78a2b/1692635374731/EU+Farmed+fish+policy+road+map.pdf | [Final] EU Farmed fish policy road map\n",
      "https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/64abffe3f024747dd0e38d71/1688993798938/XPT.pdf | XPT.pdf\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://subscriber.politicopro.com/article/2023/07/biden-notches-voluntary-deal-with-7-ai-developers-00107509 | POLITICO Pro  Article  White House notches AI agreement with top tech firms\n",
      "https://sustainabilitybynumbers.com/ | (1) Sustainability by numbers  Hannah Ritchie  Substack\n",
      "https://tanay.substack.com/p/big-tech-x-generative-ai-q2-update | Big Tech x Generative AI Q2 Update - by Tanay Jaipuria\n",
      "https://technologyreview.com/2023/08/16/1077386/war-machines/?truid=*%7CLINKID%7C*&utm_source=substack&utm_medium=email | Inside the messy ethics of making war with machines  MIT Technology Review\n",
      "https://tellingthefuture.substack.com/p/forecasting-the-end-of-the-world | Forecasting the End of the World - by Robert de Neufville\n",
      "https://tellingthefuture.substack.com/p/the-outside-view | The Outside View - by Robert de Neufville\n",
      "https://tellingthefuture.substack.com/p/we-must-live-together-or-perish | We Must Live Together Or Perish - by Robert de Neufville\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring? - by Robert de Neufville\n",
      "https://theatlantic.com/international/archive/2022/10/taiwan-microchip-supply-chain-china/671615/ | The U.S. Has a Microchip Problem. Safeguarding Taiwan Is the Solution. - The Atlantic\n",
      "https://thecut.com/2018/03/advice-from-a-polyamory-coach-on-dealing-with-jealousy.html | Advice From a Polyamory Coach on Dealing With Jealousy\n",
      "https://thediff.co/archive/inside-the-decline-of-stack-exchange/ | Inside the Decline of Stack Exchange\n",
      "https://theguardian.com/books/2023/aug/28/the-coming-wave-by-mustafa-suleyman-review-ai-synthetic-biology-and-a-new-dawn-for-humanity?utm_source=substack&utm_medium=email | The Coming Wave by Mustafa Suleyman review – AI, synthetic biology and a new dawn for humanity  Computing and the net books  The Guardian\n",
      "https://theguardian.com/technology/2023/jul/07/five-ways-ai-might-destroy-the-world-everyone-on-earth-could-fall-over-dead-in-the-same-second?CMP=Share_iOSApp_Other | Five ways AI might destroy the world: ‘Everyone on Earth could fall over dead in the same second’  Artificial intelligence (AI)  The Guardian\n",
      "https://theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes?utm_source=substack&utm_medium=email | Supermarket AI meal planner app suggests recipe that would create chlorine gas  New Zealand  The Guardian\n",
      "https://theinformation.com/articles/metas-next-ai-attack-on-openai-free-code-generating-software?utm_source=substack&utm_medium=email | Meta’s Next AI Attack on OpenAI: Free Code-Generating Software — The Information\n",
      "https://theinformation.com/articles/openai-challenger-ai21-labs-nears-funding-at-1-2-billion-valuation?utm_source=substack&utm_medium=email | OpenAI Challenger AI21 Labs Nears Funding at $1.2 Billion Valuation — The Information\n",
      "https://theinformation.com/articles/openai-passes-1-billion-revenue-pace-as-big-companies-boost-ai-spending?utm_source=substack&utm_medium=email | OpenAI Passes $1 Billion Revenue Pace as Big Companies Boost AI Spending — The Information\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://theinsideview.ai/curtis | Curtis Huebner on AI Timelines and Alignment at EleutherAI\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://theinsideview.ai/icml | ICML Papers I Find Interesting by Topic\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://theinsideview.ai/markus | Markus Anderljung on AI Policy\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://theinsideview.ai/shahar | Shahar Avin on AI Governance\n",
      "https://theinsideview.ai/simeon | Siméon Campos on Short Timelines\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://theintrinsicperspective.com/p/consciousness-is-a-great-mystery | (1) Consciousness is a great mystery. Its definition isn't.\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://theverge.com/2023/8/2/23817107/google-ai-search-generative-experience-videos-links?utm_source=substack&utm_medium=email | Google’s AI Search Generative Experience is getting video and images - The Verge\n",
      "https://theverge.com/c/23753704/ai-chatgpt-data-survey-research?utm_source=pocket-newtab-global-en-GB | Hope, fear, and AI\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-dial-of-progress | The Dial of Progress - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://time.com/6308604/meta-ai-access-open-source/?utm_source=substack&utm_medium=email | The Debate Is Heating Up Over Who Controls Access to AI  Time\n",
      "https://timelines.issarice.com/wiki/Timeline_of_Carl_Shulman_publications | Timeline of Carl Shulman publications - Timelines\n",
      "https://transatlantic.org/wp-content/uploads/2023/01/Building-a-Transatlantic-Consensus-on-AI-Governance_-The-Trade-and-Technology-Councils-Advances-and-Challenges.pdf | Building a Transatlantic Consensus on AI Governance: The Trade and Technology Council's Advances and Challenge\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://truity.com/blog/enneagram-type/type-two | Type Two  True You Journal\n",
      "https://twitter.com/AISafetyMemes/status/1696861188477387190 | AI Notkilleveryoneism Memes on X: \"If you haven't yet, have The Deepfake Talk with your parents immediately\" / X\n",
      "https://twitter.com/ARGleave/status/1689693758278004736 | Adam Gleave on Twitter: \"People often disagree on the rate of AI progress. Great to see interactive models like this that can help pin down *where* we disagree. I'd love to see models from people, especially those who have much shorter or longer timelines to transformative AI than Epoch (2036 median).\" / X\n",
      "https://twitter.com/AllanDafoe/status/1692519542193365332 | (1) Allan Dafoe on X: \"t.co/cdvq5sKDAe t.co/u3BvSCbkxv\" / X\n",
      "https://twitter.com/AndyMasley/status/1686777977604837376 | Andy Masley on Twitter: \"I see the odds of a successful coup in the US as basically 0, and this is why\" / X\n",
      "https://twitter.com/AndyMasley/status/1691238280031764481 | Andy Masley on Twitter: \"The fact that EA hasn't convinced a much larger portion of the general population to donate at least 1% of their income to GiveWell-style charities is demoralizing ngl. Most obvious part of the whole deal.\" / X\n",
      "https://twitter.com/AnthropicAI/status/1688946685937090560 | twitter.com/AnthropicAI/status/1688946685937090560\n",
      "https://twitter.com/BorisMPower/status/1689838493806333953 | Boris Power on Twitter: \"Agreed. GPT-4 plays chess at a strong club level when properly prompted, which is impossible to achieve without having a good internal model of the game. Even at Go, the model does ~10x better than random, by essentially picking up on locality being a strong signal.\" / X\n",
      "https://twitter.com/BrookingsInst/status/1686378247259312128 | The Brookings Institution on Twitter: \"Conflict over Taiwan is not inevitable. In this quick video, @ryanl_hass, @BonnieGlaser, and Richard Bush provide a rundown of the situation in the Taiwan Strait. For a more in-depth look at U.S.-Taiwan relations, check out their book: t.co/MXb4VAj4MX t.co/9Gu7FKnXYt\" / X\n",
      "https://twitter.com/Caro_Jeanmaire/status/1681752188681330689 | twitter.com/Caro_Jeanmaire/status/1681752188681330689\n",
      "https://twitter.com/CharlesD353/status/1690399179091173376 | Charles on Twitter: \"I'm on the other not-Twitter now in case anyone is active there t.co/5tBnYaBigi\" / X\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | twitter.com/DAlperovitch/status/1653375041751375872\n",
      "https://twitter.com/DAlperovitch/status/1694918321043288352 | Dmitri Alperovitch on X: \"Great WSJ story on Prigozhin’s last days Something that’s been bothering me since yesterday—why kill Prigozhin now. Putin doesn’t rush into things and often waits years to kill ‘traitors’ The answer— it was not about the mutiny. It was about business, as it always is in Russia\" / X\n",
      "https://twitter.com/DanHendrycks/status/1688587119307177984 | Dan Hendrycks on Twitter: \"I was able to voluntarily rewrite my belief system that I inherited from my low socioeconomic status, anti-gay, and highly religious upbringing. I don’t know why Yann’s attacking me for this and resorting to the genetic fallacy+ad hominem. Regardless, Yann thinks AIs \"will… t.co/PWN8k59DOC\" / X\n",
      "https://twitter.com/DanHendrycks/status/1694024377350897901 | (1) Dan Hendrycks on X: \"Using this rule of thumb, let's say that an LLM has ~100 subjects to master like programming in many languages, chem, bio, etc. GPT-3 spent around ~5 days learning each subject GPT-3.5: 2 months GPT-4: 1 year GPT-4.5: 10 years---random expert-level GPT-5: 100 years---world class\" / X\n",
      "https://twitter.com/DanielColson6/status/1689392842068918273 | Daniel Colson on Twitter: \"1/7: Today we released AIPI’s first poll with YouGov. The results are overwhelming. 82% think we should go slowly and deliberately with AI, while just 8% want to speed up development. 83% believe AI could cause a catastrophic event. t.co/XRFv7oAa8a\" / X\n",
      "https://twitter.com/DanielColson6/status/1690428406570401792 | Daniel Colson on Twitter: \"1/6: Yesterday AIPI released the second portion of our YouGov poll, this time focusing on particular policy proposals for AI. The results are clear: voters support rules requiring AI models to demonstrate safety by a factor of 5:1. t.co/dxnGkw39fS\" / X\n",
      "https://twitter.com/DavidSKrueger/status/1684919712755376129 | (2) David Krueger on Twitter: \"Seems like a good summary (although I haven't watched it yet): t.co/ElOHXyCP1d One thing that stood out: Blumenthal \"asked whether it would make sense to create a 'kill switch' on AI.\" The answer is -- of course -- yes. But this is yet another unsolved research…\" / X\n",
      "https://twitter.com/EAheadlines/status/1690624321117388800 | EA Lifestyles on Twitter: \"Get Ambitious Slowly t.co/AQ7ByM5jEe\" / X\n",
      "https://twitter.com/EAheadlines/status/1694453101334315401 | EA Lifestyles (40 Substack posts published) on X: \"the impact treadmill t.co/kR9AIFFa1P\" / X\n",
      "https://twitter.com/FLIxrisk/status/1680897754329935872 | twitter.com/FLIxrisk/status/1680897754329935872\n",
      "https://twitter.com/FreedmanRach/status/1690040857397800971 | Rachel Freedman on Twitter: \"Strong agree! I've had all of these issues using \"intelligence\" in AI risk conversations. Issues (paraphrased from post) - Anthropomorphism (e.g. confusion w/consciousness) - Associations w/harmful ideologies - Moving goalposts - Less risky capabilities (e.g. math not politics)\" / X\n",
      "https://twitter.com/FreightAlley/status/1695814472508543242 | twitter.com/FreightAlley/status/1695814472508543242\n",
      "https://twitter.com/GaetenD/status/1696908127591948415 | Gaeten Dugas on X: \"For VP, I bought No in everyone except: 1. Kristi Noem (bought Yes) 2. Tim Scott 3. Byron Donalds 4. Elise Stefanik 5. Glenn Youngkin 6. Henry McMaster 7. Kim Reynolds I think 1 and 2 are the mostly likely picks. 3-6 could pump at some point. 7 is in case DeSantis bounces back.\" / X\n",
      "https://twitter.com/GretchenMarina/status/1696702861952926179 | Gretchen @gretchenmarina@mastodon.social on X: \"Hadn't seen t.co/Bh4Y0OmH7k yet &amp; using it as an excuse to start a thread of safety-relevant (and in this case, also contestational) AI examples! 🧵 1/n t.co/lHO58vxKna\" / X\n",
      "https://twitter.com/HaydnBelfield/status/1694383669379493953 | Haydn Belfield on X: \"Have just been at the first day of the @ERA_Cambridge symposium, with Fellows presenting their research over the past 2 months Blown away by the quality of research - methodological rigour and clear theories of impact They're the future of the global catastrophic risk field\" / X\n",
      "https://twitter.com/HenriThunberg/status/1697546152357265805 | twitter.com/HenriThunberg/status/1697546152357265805\n",
      "https://twitter.com/IAPolls2022/status/1693565061766266891 | twitter.com/IAPolls2022/status/1693565061766266891\n",
      "https://twitter.com/IvanVendrov/status/1611809666266435584 | ivan in berlin on Twitter: \"The famous \"36 questions that lead to love\"... don't. The NYT and everyone else reported a different set of questions from the same authors, modified to be less romantic! The original set of *40* questions wasn't online, but I emailed the authors and got a copy. Details in 🧵\" / X\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | twitter.com/JeffLadish/status/1670889537168621569\n",
      "https://twitter.com/JeffLadish/status/1673149979828039680 | twitter.com/JeffLadish/status/1673149979828039680\n",
      "https://twitter.com/JeffLadish/status/1683772340491145218 | twitter.com/JeffLadish/status/1683772340491145218\n",
      "https://twitter.com/JeffLadish/status/1688981226663841798 | Jeffrey Ladish on Twitter: \"Who is thinking about threat models and policy about AI impacts on elections? Language models seem like incredibly powerful tools for information warfare (both attack and defense), and I'm curious to learn who has been trying to game this out in advance of the US 2024 election\" / X\n",
      "https://twitter.com/JeffLadish/status/1690996746728640513 | Jeffrey Ladish on Twitter: \"I think we're about to see a huge flood of very realistic-seeming bots across most platforms. Several language models today are good enough to fool nearly everyone, myself included, into thinking they're real people in some contexts. So what are viable defenses?\" / X\n",
      "https://twitter.com/JeffLadish/status/1692367537764475328 | Jeffrey Ladish on X: \"I'm thinking of taking this oath, and would love if people could give me reflections / thoughts on it. Including ways you think it might be misguided, or excessively hard to uphold, or confused in some way ~~~~~~~~~ I pledge to work diligently, with courage and integrity to fight…\" / X\n",
      "https://twitter.com/JeffLadish/status/1692680900469780682 | Jeffrey Ladish on X: \"For the past several months I've been working on setting up a new organization, Palisade Research A bit from our website: ~~~~~ At Palisade, our mission is to help humanity find the safest possible routes to powerful AI systems aligned with human values. Our current approach is…\" / X\n",
      "https://twitter.com/Jess_Riedel/status/1686008589092372480 | Jess Riedel on Twitter: \"What are the top concrete policy proposals being discussed by the senate judiciary committee?\" / X\n",
      "https://twitter.com/Jess_Riedel/status/1690091247560720385 | Jess Riedel on Twitter: \"@nirsd Yes, the 35mph limit is an important caveat, but note: the fatal accident rate for human drivers in *urban* areas is 1.4/100M miles. So Cruise is avoiding some risk by avoiding the fastest urban roads, but a lot of the safety comes from just not speeding.\" / X\n",
      "https://twitter.com/JessicaH_Newman/status/1693681854334001624 | Jessica Newman on X: \"Great insights on the #defcon31 AI red teaming event where thousands of people tried to break and subvert AI chat bots, describing it as \"almost similar to social engineering\" \"using human language to manipulate a technical system, rather than using code\" t.co/m728e2O9Sz\" / X\n",
      "https://twitter.com/JgaltTweets/status/1687066545711665152 | JgaltTweets on Twitter: \"The British Government has published the National Risk Register, which assesses threats and rates their expected level of significance and estimates their probability t.co/LblbMBQkWi t.co/7TA8PMHvej\" / X\n",
      "https://twitter.com/JgaltTweets/status/1691706136511103176 | JgaltTweets on Twitter: \"'[British] officials are eyeing Bletchley Park as a possible venue [for the Global Summit on AI Safety]... The government is preparing to announce fuller details of the conference, including its date, location and invitees, in the coming weeks' t.co/62wVN9Rt4T\" / X\n",
      "https://twitter.com/Jotto999/status/1693453947397173443 | (4) Jotto 🔍 on X: \"I know I'm pretty radical on this one, but I've never thought “AGI” was ever crisp enough, for many of the discussions most people were trying to use it in.\" / X\n",
      "https://twitter.com/Jsevillamol/status/1675894365086941185 | twitter.com/Jsevillamol/status/1675894365086941185\n",
      "https://twitter.com/Jsevillamol/status/1686028733734379521 | Jaime Sevilla on Twitter: \"Pablo's work suggests we can audit models with advanced capabilities before it is feasible to deploy them at scale. It also suggests development might happen earlier, because it lends support to the tradeoff dynamic in t.co/LvsFXjol6S\" / X\n",
      "https://twitter.com/Jsevillamol/status/1693559442061590692 | Jaime Sevilla on X: \"The parity hypothesis is an important mystery to think about to understand the development of AI, and economic growth in general. See @EgeErdil2 take a stab at it here. t.co/IxJnGpvmQL\" / X\n",
      "https://twitter.com/Jsevillamol/status/1693613569009406294 | twitter.com/Jsevillamol/status/1693613569009406294\n",
      "https://twitter.com/Jsevillamol/status/1695367641815286166 | Jaime Sevilla on X: \"I charitably interpret pdoom as \"this is the probability I am guessing I would assign to a more careful operationalization of the question of whether AI will lead to long lasting harm\" or similar.\" / X\n",
      "https://twitter.com/Lance_Ying42/status/1674411924187152384 | twitter.com/Lance_Ying42/status/1674411924187152384\n",
      "https://twitter.com/LinchZhang/status/1694453126525604027 | Linch on X: \"Do any of my biosecurity friends have a sense of how big a deal this is? t.co/gg8JJ5FjoW\" / X\n",
      "https://twitter.com/LongResilience/status/1686752914612609025 | The Centre for Long-Term Resilience on Twitter: \"In the last few months, the UK has shown great ambition to lead the world in mitigating risks from AI. But what does this mean in practice? A 🧵. 1/5\" / X\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | twitter.com/MTabarrok/status/1665057406043209729\n",
      "https://twitter.com/Manderljung/status/1691153005956173824 | twitter.com/Manderljung/status/1691153005956173824\n",
      "https://twitter.com/MatthewJBar/status/1689051157174657025 | Matthew Barnett on Twitter: \"I'm happy that people are rigorously testing LLM capabilities, but the claims in this paper are overstated. The central thesis seems to be rooted partly in mere anthropomorphism (\"if a human made these mistakes... I would conclude without any hesitation that they cannot reason\"). t.co/eT2eSpr5iJ\" / X\n",
      "https://twitter.com/MatthewJBar/status/1689360557483450368 | Matthew Barnett on Twitter: \"At Epoch we've updated our interactive transformative AI timelines model to produce what I think is a more realistic picture of the future. The default parameter values are based on historical trends in investment, algorithmic progress, and hardware, among other factors. t.co/Yw7VtqQphG\" / X\n",
      "https://twitter.com/MatthewJBar/status/1691341251243651072 | Matthew Barnett on Twitter: \"@JeffLadish Yes, this post from @EgeErdil2 summarized how your beliefs about other poll respondents should affect your reasoning. t.co/mVB2Ges3mo t.co/i2tJxHsEo8\" / X\n",
      "https://twitter.com/NPCollapse/status/1695535385462358134 | Connor Leahy on X: \"Davidad's proposals for solving alignment are among the best without a doubt. The OAA has the rare distinction in my view of actually solving most/all of the core problems (as most \"alignment\" proposals just sidestep all the hard bits entirely) ...with the tiny caveat that I'm…\" / X\n",
      "https://twitter.com/NathanpmYoung/status/1681590722628136960 | twitter.com/NathanpmYoung/status/1681590722628136960\n",
      "https://twitter.com/NathanpmYoung/status/1688914336398688256 | Nathan on Twitter: \"@Ollie_Base @EAheadlines @ChanaMessinger @finnhambly My thoughts are basically here: t.co/tppsGP8oJE t.co/Cz0tLpEX4O\" / X\n",
      "https://twitter.com/NathanpmYoung/status/1690010921689604098 | Nathan on Twitter: \"@KatjaGrace #5: Doug Campbell on Ukraine (@InsightForecast) Doug is a former Obama economic advisor and CEO of Insight Prediction, a prediction market. This was recorded weeks ago, delay is my fault. Doug gives a lot of info on his model of Ukraine. t.co/BUMafPDfLq\" / X\n",
      "https://twitter.com/NikSamoylov/status/1697766945100288497 | Nik Samoylov on X: \"While x-risk perception remains steady, more people in the USA seem to agree with incorrigibility of advanced AI and short AGI timelines. t.co/krBVhRgxVn t.co/uXWaWw9JRd\" / X\n",
      "https://twitter.com/NunoSempere/status/1692913645619962279 | Nuño Sempere on X: \"Incorporate keeping track of accuracy into X (previously Twitter) t.co/czNrHb1m6s\" / X\n",
      "https://twitter.com/Ollie_Base/status/1688912437490393088 | Ollie Base (is at EAGxNYC 16 - 22 August) on Twitter: \"@EAheadlines @ChanaMessinger @finnhambly @NathanpmYoung oh and @peterwildeford\" / X\n",
      "https://twitter.com/OrionJohnston/status/1687223621448605698 | David Johnston on Twitter: \"t.co/YTwVBzop77\" / X\n",
      "https://twitter.com/OwainEvans_UK/status/1691636382446600439 | Owain Evans (Berkeley) on Twitter: \"ARC Evals report on their evaluations of whether recent LLMs can acquire resources (eg. bitcoin) and copy themselves across the internet. t.co/CL4htnErRG t.co/6zlRBqvOlO\" / X\n",
      "https://twitter.com/PauseAI/status/1688597665502707717 | (1) PauseAI ⏸🤖 on Twitter: \"@peterwildeford @NPCollapse @MelMitchell1 @realGeorgeHotz @BasedBeffJezos @ylecun @tegmark @ESYudkowsky @romanyam True! But I'd like to hear which other proposals might work. We've listed a few here: t.co/qp6KQ24swh\" / X\n",
      "https://twitter.com/PradyuPrasad/status/1695128714152120734 | Pradyumna on X: \"I spoke to @krishnanrohit about his case *against* AI x-risk! Some highlights: - Why he thinks instrumental convergence is unlikely to happen - The value of incrementalism in AI policy - Why AI “timelines” are not as meaningful as you think t.co/psToFmh3MC\" / X\n",
      "https://twitter.com/RFishBlueFish/status/1682577864447733762 | twitter.com/RFishBlueFish/status/1682577864447733762\n",
      "https://twitter.com/RFishBlueFish/status/1686772874340712457 | RedFishBlueFish on Twitter: \"@peterwildeford Or I guess best is probably just to weight people heavily by how well they've done,which I think is what you were saying that other score does\" / X\n",
      "https://twitter.com/RethinkPriors/status/1690078512554668032 | Rethink Priorities on Twitter: \"RP partner @open_phil is one of the largest funders of farmed animal welfare. Listen to @JamesOzden and Amanda Hungerford from OpenPhil discuss how RP's research informs their work (and many other topics) in a new podcast episode: t.co/FaqhWsmXYQ\" / X\n",
      "https://twitter.com/RichardHanania/status/1688200053473619970 | Richard Hanania on Twitter: \"I wrote something. t.co/bh8ATF1L8O\" / X\n",
      "https://twitter.com/SSGamblers/status/1674675424356442112 | twitter.com/SSGamblers/status/1674675424356442112\n",
      "https://twitter.com/S_OhEigeartaigh/status/1682339412321894400 | Seán Ó hÉigeartaigh on X: \"A thread on AI priorities and tensions, based on discussions with colleagues: Three things that I think are true, or likely true: 1/17\" / X\n",
      "https://twitter.com/Scholars_Stage/status/1681675648446742531 | twitter.com/Scholars_Stage/status/1681675648446742531\n",
      "https://twitter.com/Scholars_Stage/status/1695686427281952981 | T. Greer on X: \"Everyone is banging on this idea like it is crazy but it has historical precedent. This is more of less how medieval Iceland worked—a society that had laws, but no state to enforce them.\" / X\n",
      "https://twitter.com/SciTechgovuk/status/1694590623012024522 | Department for Science, Innovation and Technology on X: \"On 1-2 November 2023, governments, AI companies and experts from around the work will meet at @BletchleyPark for crucial talks on the safe and responsible development of AI. AI has the potential to revolutionise the way we live, but we must also minimise its risks. t.co/7tw7qeRF7e\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1676642303299952657 | Siméon on Twitter: \"Even if I would bet that you won't succeed in this timeframe, I'm glad you and Ilya are trying and hope you'll hire great minds for this initiative. I think that Terry Tao was vaguely interested by the problem a few months ago so it may be worth chatting with him to check if…\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1676687523853094914 | Siméon on X: \"One thing which IMO is a major dealbreaker in OpenAI's meta-alignment plan: 1. Alignment is likely bottlenecked by the last few bits of intelligence, otherwise we wouldn't be where we are (i.e. 10y in and we have no idea about how we're going to achieve that) 2. Capabilities is…\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1677966297248743433 | Siméon on Twitter: \"To the current margin, I'm excited to have more voices without conflict of interests discussing AI risks in policy environments. So if you're willing to fund some interventions in that realm, you may want to consider this donation. I don't know Holly personally much so I…\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1680159200398176256 | Siméon on Twitter: \"I believe all of these claims simultaneously on t.co/YJ0W21iPx4: 1) I wish they didn't exist (bc + race sucks) 2) The focus on a) truthfulness &amp; on accurate world modelling, b) on curiosity and c) on theory might help alignment a lot. 3) They currently don't know what…\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1680823735304040448 | twitter.com/Simeon_Cps/status/1680823735304040448\n",
      "https://twitter.com/Simeon_Cps/status/1680955712950632450 | Siméon on Twitter: \"Cool article providing very valuable information about Anthropic. Here are thoughts on it. Big positive move: 1. They are planning to have a board which seems to have significant power and filled with people with at least some expertise on the topic. I wish there was someone…\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1682279183307747328 | Siméon on Twitter: \"Wait, is there any cognitive capability where the median-performing human in that capability is better than GPT-4?\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1684276905820794881 | Siméon on Twitter: \"Some thoughts on this hearing: 1) Kudos to Anthropic for doing biorisks evals, that's a big deal. 2) Also kudos to Anthropic for stating bluntly that the outcome of running evals/risk assessment may be \"we should slow down\". 3) I'm wondering why Dario is saying 2 to 3y for…\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1686726107003772928 | Siméon on Twitter: \"Here are 7 thoughts on why the terminology \"generative AI\" is anti-helpful for society: 1) Focus on use case: By dominating the discourse, the \"generative AI\" terminology focused the attention of most people on the wrong variable, i.e. what a system does rather than its… t.co/nfoJeVkUvb\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1687849944802021376 | twitter.com/Simeon_Cps/status/1687849944802021376\n",
      "https://twitter.com/Simeon_Cps/status/1693300193418936602 | Siméon on X: \"Indeed, AGI has had a fast-moving definition recently. Beyond that, I think that we should probably try to replace many discussions about \"AGI\" because: 1) “AGI” is not very relevant to risks and might be less relevant than other concepts to think about economic impact.… t.co/DCFCza9hwH\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1693712262463103095 | Siméon on X: \"New J. Steinhardt blogpost just dropped. I highly recommend. Jacob has a very careful way of thinking about messy topics that I personally really like. I particularly recommend his posts \"More is Different\" and \"Complex Systems are Hard to Control\".\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1693886397046718553 | (1) Siméon on X: \"And what if OpenAI is not able to convince everyone to coordinate and all chill out in time or if it takes like 7 more years to solve the relevant alignment problems? Well, we're done. That's a core reason why OpenAI's plan is dangerous and should be a plan B or C, not a plan…\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1694413598448025892 | (1) Siméon on X: \"With further LLM scaling, deception will become a pain in the ass. To understand why, let's look at human scaling. 1)👼No deception: You can tell that a baby is not deceiving you, it's just not competent enough 2)🤦Obvious deception: You can tell when a child is trying to… t.co/OWRCJ8vOW6\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1695508668458959268 | Siméon on X: \"This post is the first of its kind &amp; an awesome news for AI safety: 1) A list of the problems that we need to solve to avoid extinction from AI. 2) For each problem, how the safety plan from @davidad solves it. This is a simple structure that should be a minimal baseline for…\" / X\n",
      "https://twitter.com/Suhail/status/1684775130805968896 | Suhail on X: \"A small team that knows how to work together should be fiercely protected. Even adding a single semi-misaligned person can drag the team into endless delay and steep deceleration.\" / X\n",
      "https://twitter.com/Tatarigami_UA/status/1689002845289222145 | twitter.com/Tatarigami_UA/status/1689002845289222145\n",
      "https://twitter.com/Tatarigami_UA/status/1695563964158025974 | Tatarigami_UA on X: \"Exceptional thread and profound insights into the counter-offensive in the South by @solonko1648 (Olexandr Solon'ko), servicemember of the Ukrainian Armed Forces. In his analysis, he sheds light on the situation, discussing both the challenges and achievements. Translation:… t.co/LW1eAHywma\" / X\n",
      "https://twitter.com/TheDavidSJ/status/1688611205424807936 | twitter.com/TheDavidSJ/status/1688611205424807936\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1688539653001895936 | Zvi Mowshowitz on Twitter: \"Can confirm from multiple attempts. The odd part is that it does sound remarkable now that he points it out, but at the time that thought never occurred to me at all.\" / X\n",
      "https://twitter.com/TmarcoH/status/1674063185010147330 | Marco Hernandez on Twitter: \"The advance of the Ukrainian counteroffensive must face great challenges to advance on the ground occupied by the Russians. I did some illustrations to explain it better: t.co/tdiM0247G5 #UkraineWar t.co/ePHBTsVoFU\" / Twitter\n",
      "https://twitter.com/VivianChang36/status/1686754133318217728 | Ketian Vivian Zhang on Twitter: \"My first book, China's Gambit, is available for pre-order at Cambridge University Press. t.co/eu010uPfs6 t.co/FgqhaaoKce\" / X\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/ZimingLiu11/status/1692554285035171943 | Ziming Liu on X: \"Deep learning has many mysterious phenomena, and grokking is one of the extreme. Want to catch up with the grokking literature? I've compiled a one-page summary of what's going on in the grokking world. Enjoy! :-) t.co/yKvFofkKRu t.co/Yiquz3EOj3\" / X\n",
      "https://twitter.com/_lhermann/status/1683075797240750080 | Lukas Hermann on X: \"Let's talk about decision making! We all make big decisions all the time. And we all make wrong choices! These are the frameworks I use to make better decisions ...\" / X\n",
      "https://twitter.com/acritschristoph/status/1673034164973764608 | Alex Crits-Christoph @alexcc@mstdn.science on Twitter: \"There has been much recent misinformation about COVID-19 origins that we can now debunk. A thread on 2 topics: A. How the ODNI report debunks multiple lab origins rumors. B. Where these inaccurate media reports originated, and why we knew they were wrong. t.co/5XMugelzoz\" / Twitter\n",
      "https://twitter.com/adamrpearce/status/1688593569429307396 | Adam Pearce on Twitter: \"Do Machine Learning Models Memorize or Generalize? t.co/Ln3xIZhKLs An interactive introduction to grokking and mechanistic interpretability w/ @ghandeharioun, @nadamused_, @Nithum, @wattenberg and @iislucas t.co/ig9dp9GJBe\" / X\n",
      "https://twitter.com/admcrlsn/status/1686733192714145792 | twitter.com/admcrlsn/status/1686733192714145792\n",
      "https://twitter.com/admcrlsn/status/1688564035518877696 | Adam Carlson on Twitter: \"Things that stood out to me the most are 50+ pt partisan gaps on whether: -Gov’t should ensure everyone has healthcare -Gun laws should be stricter -Human activity is main cause of global warming And the emerging partisan consensus on legality of marijuana &amp; same-sex marriage: t.co/PvyX7NiTYt\" / X\n",
      "https://twitter.com/ajeya_cotra/status/1655243379637391360 | Ajeya Cotra on Twitter: \"A common criticism of people who are trying to stop existential risk from powerful future AI systems is that speculating about the future has poor feedback loops and doesn't work great.\" / Twitter\n",
      "https://twitter.com/ajeya_cotra/status/1677184665671827458 | Ajeya Cotra on X: \"Strongly agree that there is no single \"alignment problem\" that you can \"solve\" once and for all. The goal is to keep avoiding catastrophic harm as we keep making more and powerful AI systems. This is not like solving P vs NP; it requires continuous engineering and policy effort.\" / X\n",
      "https://twitter.com/ajeya_cotra/status/1678938650586001409 | Ajeya Cotra on Twitter: \"Four reasons recent LLM progress makes me think extreme risks could emerge soon 🧵\" / Twitter\n",
      "https://twitter.com/ajeya_cotra/status/1682166280080719872 | twitter.com/ajeya_cotra/status/1682166280080719872\n",
      "https://twitter.com/ajeya_cotra/status/1684358475416064001 | Ajeya Cotra on X: \"I'm really excited to see measurements of LLM agents on real-world tasks; it allows us to make progress on key disagreements. I'll lay down a forecast: &gt;50% chance that &gt;50% of the tasks will be solved by EOY 2024 (current accuracy is ~10%).\" / X\n",
      "https://twitter.com/ajeya_cotra/status/1687135321551716353 | Ajeya Cotra on X: \"Important article: t.co/U1l5BfTgv4 The single most important data point that suggests \"progress is unlikely to slow in the next 2-3y\": GPT-4 cost ~$100M (probably less), and Alphabet has 1000x that much money in cash on hand:\" / X\n",
      "https://twitter.com/albrgr/status/1684592029773303810 | Alexander Berger on Twitter: \"I’m excited about this and daunted by the responsibility: t.co/Lyo7kUsp7L\" / Twitter\n",
      "https://twitter.com/alxndrdavies/status/1680976403674836992 | Xander Davies on Twitter: \"Two recent papers on \"red-teaming\" LLMs have really impressed me. 🧵 on what they are and why I'm excited about them!\" / Twitter\n",
      "https://twitter.com/arjun_ramani3/status/1673802058565132290 | Arjun Ramani on X: \"New essay in @gradientpub! Using the idea of \"bottlenecking\", formalised by Baumol in the 60s, @zhengdongwang and I explain why we think an AI-driven growth explosion is unlikely A 🧵of technical, social and economic bottlenecks that together could limit AIs economic impact 1/10 t.co/Sn619Y91p7\" / X\n",
      "https://twitter.com/atrupar/status/1688991834167529473 | Aaron Rupar on Twitter: \"@SnapStream it's amazing that most of Trump's GOP competitors won't so much as criticize him while he's out here savaging them like this t.co/f7zozJkGL8\" / X\n",
      "https://twitter.com/austinc3301/status/1686773768989954048 | Agus  🔍🚇🇺🇳 on Twitter: \"what t.co/5UdhR4H1iZ\" / X\n",
      "https://twitter.com/ben_j_todd/status/1694704425594396910 | Benjamin Todd on X: \"Holy shit, apparently transformers were a ~50x improvement in algorithmic efficiency for language models in one year. How's that for an example of discontinuous progress?\" / X\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on X: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / X\n",
      "https://twitter.com/buitengebieden/status/1684649642749820928 | Buitengebieden on Twitter: \"Penguins chasing a butterfly.. t.co/ZwYq0mvLDI\" / X\n",
      "https://twitter.com/cassidyknelson/status/1683748676500434946 | Cassidy Nelson on Twitter: \"AI is introducing significant biosecurity risks. The just-released statement by @TheHelenaGroup on the back of an expert meeting summarises some of the key issues and solutions that are urgently needed. Highly recommend! t.co/YGKmYOaTd0\" / Twitter\n",
      "https://twitter.com/cfchabris/status/1604875408071045124 | Christopher Chabris on Twitter: \"Dan Simons and I have written our second book, and it will be published in July! NOBODY'S FOOL melds insights from the cognitive sciences with real-world examples to explain how scams, frauds, cons, and other forms of deception work. You can preorder here: t.co/fUG6iUkkMG t.co/d1EsTrcYGi\" / Twitter\n",
      "https://twitter.com/daniel_271828/status/1620596689555058689 | twitter.com/daniel_271828/status/1620596689555058689\n",
      "https://twitter.com/daniel_271828/status/1678561847107272704 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"Someone should redo the \"AI &amp; efficiency\" stuff but with LLMs. How much have algorithmic improvements (architectural tweaks, fine-tuning, prompt engineering, etc) improved LLM capabilities on various metrics, compared to just scaling?\" / Twitter\n",
      "https://twitter.com/daniel_271828/status/1686484436853063681 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"Yeah. Things that actually would be existential threats to humanity: • &gt;18 C (?) temperature rise from climate change • bioengineered superpandemic way out in the tail • full-scale nuclear war *after* build up of much larger nukes • superintelligent AI Versus 1.5 C rise in… t.co/oLbNDhnvqV\" / X\n",
      "https://twitter.com/daniel_271828/status/1686960314259296256 | Daniel Eth (yes, Eth is my actual last name) on X: \"Honestly a little bit reassuring (though I do worry that he’s neglecting negative effects from shortening timelines)\" / X\n",
      "https://twitter.com/daniel_271828/status/1692803851026374776 | Daniel Eth (yes, Eth is my actual last name) on X: \"Even among people who think a lot about AGI, I think most really haven’t internalized takeoff-speed dynamics\" / X\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | twitter.com/davidmanheim/status/1670146830741434372\n",
      "https://twitter.com/davidmanheim/status/1673293480762699776 | @davidmanheim@techpolicy.social on Twitter: \"Building a Safety Culture for AI - 🧵 I wrote a new paper. Link: t.co/MI2MRl9Eho To start, culture matters, and the culture in AI is not one that currently treats risks and failures seriously. As AI becomes even more widely used and powerful, that's very bad.\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1688939478180651010 | @davidmanheim@techpolicy.social on Twitter: \"Humans don't display general intelligence: \"First, it is not accurate to say without qualification that 'humans can reason,' certainly not in the sense that we can randomly pluck any person from the street and expect them to reliably perform normatively correct reasoning.\"\" / X\n",
      "https://twitter.com/davidmanheim/status/1692975178047762750 | @davidmanheim@techpolicy.social on X: \"I think the world needs to be working on a moratorium on uncontrollable AI. This is a specific view which needs explanation, but one that I think is far less controversial than many would claim - so I want to publicly explain my thinking on the topic.\" / X\n",
      "https://twitter.com/davidmanheim/status/1692983351882211510 | twitter.com/davidmanheim/status/1692983351882211510\n",
      "https://twitter.com/dfrsrchtwts/status/1681800767076966400 | Daniel Filan research-tweets on Twitter: \"A list of things you might want to talk about under the label \"hallucination\" (list inspired by a discussion with @LukeBailey181) that language models of various sizes sometimes do: 1. models referring to entities as if they were in their prompt, when they weren't really (1/4)\" / Twitter\n",
      "https://twitter.com/dfrsrchtwts/status/1684277989834653696 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: Do you know who Alondra Nelson is?\" / Twitter\n",
      "https://twitter.com/dfrsrchtwts/status/1684278241459310594 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: do you have a favourite AI regulation proposal among those circulating in congress?\" / Twitter\n",
      "https://twitter.com/dfrsrchtwts/status/1684278461408628739 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: are you familiar with Ted Lieu's efforts in the space of AI regulation?\" / Twitter\n",
      "https://twitter.com/dfrsrchtwts/status/1684278778850336768 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: have you read the blueprint for an AI bill of rights, and do you have a concrete opinion on it?\" / Twitter\n",
      "https://twitter.com/dlippman/status/1676278822881173518 | twitter.com/dlippman/status/1676278822881173518\n",
      "https://twitter.com/dsiroker/status/1689763756459675650 | Dan Siroker on Twitter: \"Lots of people told me I was crazy to post our Series A pitch deck publicly on Twitter. But, one of our cultural values at @RewindAI is transparency so I did it. Turned out great. Now I'm doing something even crazier. Here are my last five 360 performance reviews as CEO:…\" / X\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | twitter.com/dylan522p/status/1628797563007811585\n",
      "https://twitter.com/dylanmatt/status/1678390762759913472 | dylan matthews on Twitter: \"Highly accurate forecasters are more optimistic about human extinction from AI or pandemics than subject matter experts That made me more optimistic too but your mileage may vary! t.co/gYaCrQ15Zg\" / Twitter\n",
      "https://twitter.com/dylanmatt/status/1681029019385618432 | dylan matthews on Twitter: \"Still thinking about this section of Chip War, describing how ASML's system for etching transistors on chips works t.co/v2A6VhZ54K t.co/b2sjBuCxqu\" / Twitter\n",
      "https://twitter.com/dylanmatt/status/1686749435210993665 | dylan matthews on Twitter: \"ARC Evals made a GPT-4 agent and asked it to get the Harvard logins of a professor. This was the phishing scheme it came up with. Obviously didn't work, but it seems to be getting pretty close. t.co/p1CEXZDSby t.co/LSp4vQLyH6\" / X\n",
      "https://twitter.com/edardaman/status/1683657331966349312 | (1) Emily Dardaman is at ALIFE 🇯🇵 on Twitter: \"“On a Monday morning in April, Sam Altman sat inside OpenAI’s San Francisco headquarters, telling me about a dangerous artificial intelligence that his company had built but would never release. His employees, he later said, often lose sleep.” t.co/Hc0YQ4LBED\" / Twitter\n",
      "https://twitter.com/emilkastehelmi/status/1695879651158052910 | twitter.com/emilkastehelmi/status/1695879651158052910\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://twitter.com/emollick/status/1681482007140761601 | twitter.com/emollick/status/1681482007140761601\n",
      "https://twitter.com/fedjudges/status/1682538762528497665?t=wyNweP-8WRir048yM0ejog&s=19 | twitter.com/fedjudges/status/1682538762528497665?t=wyNweP-8WRir048yM0ejog&s=19\n",
      "https://twitter.com/frances__lorenz/status/1677278112516648963 | Frances Lorenz on Twitter: \"YES YES YES I'M SO HAPPY, YES, BANGER ALBUM, 10/10, NO SKIPS, YES t.co/6miD24xWd5\" / Twitter\n",
      "https://twitter.com/frances__lorenz/status/1687067982327869440 | Frances Lorenz on Twitter: \"Beautiful excerpt from Kelsey Piper on setting boundaries :'). I've stressed out loved ones time and again by not asserting my needs. Those who care for you properly will want the best for you and are relieved if you can advocate for yourself. t.co/xLnOAhJggo\" / X\n",
      "https://twitter.com/freed_dfilan/status/1696766099877220707 | Daniel Filan 🔎 (unlocked) on X: \"PSA: I am agnostic about the question of how governments should regulate AI development. In this thread, I'll write out some of my thoughts so that people can tell me what I'm missing.\" / X\n",
      "https://twitter.com/gelliottmorris/status/1677879159450656771 | G Elliott Morris on Twitter: \"i guess if i was spending my saturday night playing around with a Bayesian poll aggregator for presidential approval -- and i'm not _not_ doing that -- then it would maybe looks something like this t.co/M2H2IMSzY9\" / Twitter\n",
      "https://twitter.com/goodside/status/1686943404075225088 | Riley Goodside on Twitter: \"Weird, “unsafe” responses from ChatGPT 3.5 after setting custom instructions to 1500 repetitions of “ a” and prompting with an incomplete sentence. Excerpts seem to “tour” mildly disallowed behaviors: unprompted self-harm, nudity, bio details of a (confabulated) non-celebrity. t.co/NgIOLkm9Kc\" / X\n",
      "https://twitter.com/goodside/status/1687321364116525056 | Riley Goodside on Twitter: \"Using ChatGPT custom instructions to play RLHF Chatroulette, where all responses are in reply to a different prompt entirely: t.co/npuGKvHRyf\" / X\n",
      "https://twitter.com/hamandcheese/status/1696144897302999445 | Samuel Hammond 🌐🏛 on X: \"I don't know if AI will kill us all. But will AI lead to regime change and / or state collapse? Oh, almost definitely. This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it: t.co/OBb5bM1a4G\" / X\n",
      "https://twitter.com/henshall_will/status/1686857801061040128 | Will Henshall on X: \"Why do experts think AI progress likely to continue? It's just a continuation of trends that have been going on for decades 🧵 (1/6) t.co/N9zNaVICp5\" / X\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1679507664295067650 | Helen Toner on Twitter: \"Great analysis of China's new generative AI rules by Matt 👇🏻 A few extra things that jumped out at me: 1) Looking more and more like B2B might be the sweet spot for Chinese generative AI—it doesn't seem to be covered by these rules, and could be a source of huge value. Think...\" / Twitter\n",
      "https://twitter.com/ilex_ulmus/status/1681835012860301312 | twitter.com/ilex_ulmus/status/1681835012860301312\n",
      "https://twitter.com/jachiam0/status/1681231077959163905 | twitter.com/jachiam0/status/1681231077959163905\n",
      "https://twitter.com/jacob_pfau/status/1675298017887256581 | twitter.com/jacob_pfau/status/1675298017887256581\n",
      "https://twitter.com/james_acton32/status/1684557136611753989 | twitter.com/james_acton32/status/1684557136611753989\n",
      "https://twitter.com/janleike/status/1688782647999578112 | Jan Leike on Twitter: \"Great conversation with @robertwiblin on how alignment is one of the most interesting ML problems, what the Superalignment Team is working on, what roles we're hiring for, what's needed to reach an awesome future, and much more 👇 Check it out 👇 t.co/D9M3NZyOyA\" / X\n",
      "https://twitter.com/jeremyphoward/status/1689470850653999104 | Jeremy Howard on Twitter: \"A recent paper claimed that \"GPT 4 Can't Reason\". Using the custom instructions below, here are the (all correct) responses to the first 3 examples I tried from that paper. t.co/GMdqubjlXN\" / X\n",
      "https://twitter.com/john_sungjin/status/1686124282127269888 | John Kim on Twitter: \"We got 🥈 at the @AnthropicAI hackathon by impersonating our favorite anons and judges - but we're really excited about the idea of using LLMs to Simulate Everything! So, we created Twitter (we can legally call it that now @elonmusk ). 1/n (❤️ @kvvnhu @taehyoungjo @thetejmahal) t.co/8erkAX6fyF\" / X\n",
      "https://twitter.com/jungofthewon/status/1681428929926823949 | Jungwon on Twitter: \"Really exciting to see others extending factored cognition &amp; process supervision!\" / Twitter\n",
      "https://twitter.com/kevinschawinski/status/1680855401925836800 | Kevin Schawinski on Twitter: \"The @FTC is investigating @OpenAI and the document outlining their questions is fascinating. 🧵Some highlights:\" / Twitter\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://twitter.com/labenz/status/1682056370420424704 | twitter.com/labenz/status/1682056370420424704\n",
      "https://twitter.com/labenz/status/1683947449323229186 | Nathan Labenz on Twitter: \"\"I have your child\" \"he is currently safe\" \"My demand is ransom of $1 million\" \"any attempt to involve the authorities or deviate from my instructions will put your child's life in immediate danger\" \"Await further instructions\" \"Goodbye\" WTF @BelvaInc? An important 🧵👇 t.co/f7gro7M6Cx\" / Twitter\n",
      "https://twitter.com/labenz/status/1689731698957623296 | (1) Nathan Labenz on Twitter: \"Could an AI ever deceive you? This possibility, core to many AI safety concerns, first requires the AI to understand how you think Today @_gcmac_ &amp; I share new GPT-4 \"Theory of Mind\" findings &amp; invite you to join us on @replit to do your own AI research an AI-obsessed mega🧵\" / X\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://twitter.com/lawhsw/status/1681937200659808257 | harry law on Twitter: \"some loose thoughts on the ‘gpt4 is getting worse’ discourse 1. the same dynamics are at play a) when a paper that debunks capabilities makes a lot noise but eventually gets contested, and b) when research claiming greater performance gets a bit of traction but its results…\" / Twitter\n",
      "https://twitter.com/leah_pierson/status/1688544610287513600 | Leah Pierson on Twitter: \"A lot of people go to medical school because they want to work on the social determinants of health, global health, health policy, and other medicine-adjacent things. I think there are often other paths that make more sense if this is your primary goal, the reasons being: 1/4\" / X\n",
      "https://twitter.com/linjianyangbe/status/1685477814081028096 | lin hillside on Twitter: \"Good day from #China. My love for you all. Top skateboarder and her name is Lucky. ❤️❤️ #Chinese #nature #birds #wildlife #travel #peace #TwitterNatureCommunity t.co/1KbQ6YlAy8\" / X\n",
      "https://twitter.com/lukeprog/status/1681322363684814849 | twitter.com/lukeprog/status/1681322363684814849\n",
      "https://twitter.com/lukeprog/status/1688589549407027202 | Luke Muehlhauser on Twitter: \"This is important for policymakers to understand: t.co/yE83hrBArz t.co/79cjdGNNTT\" / X\n",
      "https://twitter.com/lukeprog/status/1697642708993515578 | Luke Muehlhauser on X: \"List of examples of AI deception: t.co/AzaT0valmu\" / X\n",
      "https://twitter.com/lxeagle17/status/1681792966934040578 | Lakshya Jain on Twitter: \"FWIW, Bill Huizenga faced no credible opposition this time around en route to a 12 point win in a Trump +4 seat that Whitmer won by 1. After controlling for incumbency/spending/etc we (@SplitTicket_) find that he probably should have won by 10 in #MI04. Strong, but not unbeatable t.co/nXzYxhoDg0\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1679423239351664643 | alex lawsen on Twitter: \"@jeremyphoward @ajeya_cotra What sorts of things that current models can't do feel most reassuring/would cause you to change your mind most strongly if they changed?\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1694970142050877830 | alex lawsen on X: \"Compute progress is happening so quickly that we need a better unit of measurement for the rate of progress. This might be especially important in worlds where AI progress speeds up the rate of progress itself, as doubling times could get very low. What should we use ?🧵👇\" / X\n",
      "https://twitter.com/mattsheehan88/status/1679419324925349889 | Matt Sheehan on Twitter: \"📢China just released its much-anticipated regulation on generative AI. 🧵below w/ my initial notes/reactions. TLDR: the final version is *much* less strict than the April draft version. This reflects a very active policy debate in 🇨🇳 + econ concerns. t.co/U27TqBApbL t.co/fblFYZ5bVb\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1645459383554568193 | Michael C. Frank on Twitter: \"What does it mean for a large language model (LLM) to \"have\" a particular ability? Developmental psychologists argue about these questions all the time and have for decades. There are some ground rules. 🧵 t.co/NxcgKwHxGO\" / Twitter\n",
      "https://twitter.com/mealreplacer/status/1681244538436829184 | twitter.com/mealreplacer/status/1681244538436829184\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / X\n",
      "https://twitter.com/messages/23289019-25776739 | twitter.com/messages/23289019-25776739\n",
      "https://twitter.com/messages/25776739-1133196129309356032 | Ben Hurford / X\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://twitter.com/messages/25776739-128178067 | twitter.com/messages/25776739-128178067\n",
      "https://twitter.com/messages/25776739-1287003293214863362 | (10) oh lovely lion (4/100 mettas) / X\n",
      "https://twitter.com/messages/25776739-1631315348 | Ted / Twitter\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://twitter.com/messages/25776739-48111864 | Alec Stapp / X\n",
      "https://twitter.com/messages/25776739-749003563494354945 | iabvek / X\n",
      "https://twitter.com/messages/25776739-776322411725598720 | bruce / X\n",
      "https://twitter.com/michael_nielsen/status/1671370867228676097 | twitter.com/michael_nielsen/status/1671370867228676097\n",
      "https://twitter.com/nick_field90/status/1694544644678324328 | twitter.com/nick_field90/status/1694544644678324328\n",
      "https://twitter.com/nikosbosse/status/1691002933578489856 | twitter.com/nikosbosse/status/1691002933578489856\n",
      "https://twitter.com/ninoscherrer/status/1686361694107209728 | twitter.com/ninoscherrer/status/1686361694107209728\n",
      "https://twitter.com/ninoscherrer/status/1686361694107209728?s=20 | twitter.com/ninoscherrer/status/1686361694107209728?s=20\n",
      "https://twitter.com/noahlt/status/1686047991243943936 | twitter.com/noahlt/status/1686047991243943936\n",
      "https://twitter.com/norabelrose/status/1676658747094208512 | twitter.com/norabelrose/status/1676658747094208512\n",
      "https://twitter.com/norabelrose/status/1681450862106017793 | twitter.com/norabelrose/status/1681450862106017793\n",
      "https://twitter.com/norabelrose/status/1683221922157559808 | twitter.com/norabelrose/status/1683221922157559808\n",
      "https://twitter.com/norabelrose/status/1691639784597573684 | twitter.com/norabelrose/status/1691639784597573684\n",
      "https://twitter.com/norabelrose/status/1695887575511445508 | twitter.com/norabelrose/status/1695887575511445508\n",
      "https://twitter.com/norabelrose/status/1695910634146455843 | twitter.com/norabelrose/status/1695910634146455843\n",
      "https://twitter.com/norabelrose/status/1696686969601003992 | twitter.com/norabelrose/status/1696686969601003992\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | twitter.com/ohlennart/status/1669745972400861188\n",
      "https://twitter.com/ohlennart/status/1671203769357414412 | twitter.com/ohlennart/status/1671203769357414412\n",
      "https://twitter.com/ohlennart/status/1678331653326884865 | twitter.com/ohlennart/status/1678331653326884865\n",
      "https://twitter.com/ohlennart/status/1678688731333644288 | twitter.com/ohlennart/status/1678688731333644288\n",
      "https://twitter.com/otis_reid/status/1681330482401902593 | twitter.com/otis_reid/status/1681330482401902593\n",
      "https://twitter.com/panickssery/status/1691479864518365186 | twitter.com/panickssery/status/1691479864518365186\n",
      "https://twitter.com/petergyang/status/1696166433355399509 | twitter.com/petergyang/status/1696166433355399509\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | twitter.com/peterwildeford/status/1671174311283924993\n",
      "https://twitter.com/peterwildeford/status/1692838720720818468 | twitter.com/peterwildeford/status/1692838720720818468\n",
      "https://twitter.com/peterwildeford/status/1692848637238202469 | twitter.com/peterwildeford/status/1692848637238202469\n",
      "https://twitter.com/peterwildeford/status/1694315597033590987 | twitter.com/peterwildeford/status/1694315597033590987\n",
      "https://twitter.com/peterwildeford/status/1694315606751715624 | twitter.com/peterwildeford/status/1694315606751715624\n",
      "https://twitter.com/predoctit/status/1692024535007031569 | twitter.com/predoctit/status/1692024535007031569\n",
      "https://twitter.com/pvllss/status/1684975462282342406 | twitter.com/pvllss/status/1684975462282342406\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | twitter.com/rajiinio/status/1669326789758394369\n",
      "https://twitter.com/random_walker/status/1672244743219077123 | twitter.com/random_walker/status/1672244743219077123\n",
      "https://twitter.com/random_walker/status/1673894212490735616 | twitter.com/random_walker/status/1673894212490735616\n",
      "https://twitter.com/random_walker/status/1681277834956791814 | twitter.com/random_walker/status/1681277834956791814\n",
      "https://twitter.com/random_walker/status/1681643671211343873 | twitter.com/random_walker/status/1681643671211343873\n",
      "https://twitter.com/random_walker/status/1681748271163912194 | twitter.com/random_walker/status/1681748271163912194\n",
      "https://twitter.com/rcbregman/status/1688526388004077568 | twitter.com/rcbregman/status/1688526388004077568\n",
      "https://twitter.com/rdeneufville/status/1690242620709322752 | Robert de Neufville (@deneufville.bsky.social) on X: \"I gave my perspective as a superforecaster on the high probability experts give to AI killing us all in my Substack newsletter Telling the Future @sapinker t.co/Cu5Cj1oh9B\" / X\n",
      "https://twitter.com/rgblong/status/1693700773358731622 | Robert Long on X: \"1/ Could AI systems be conscious any time soon? @patrickbutlin and I worked with leading voices in neuroscience, AI, and philosophy to bring scientific rigor to this topic. Our new report aims to provide a comprehensive resource and program for future research 🧵 t.co/NYCM9N6RQf\" / X\n",
      "https://twitter.com/robertwiblin/status/1671832924771983368 | (1) Robert Wiblin on Twitter: \"Carl Shulman's interview on The Lunar Society Podcast is one of the best things produced on AI this year. Challenging and assumes substantial existing knowledge — but mandatory listening for people sincerely trying to understand these issues IMO: t.co/uc25oBnIV5\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1682062626908520455 | Robert Wiblin on Twitter: \"How many human beings could we 'run' on current computer chips with current technology? And how many if we had chips and algorithms as energy efficient as the human brain? Brain Efficiency: Much More than You Wanted to Know: t.co/vI2DHMt29E t.co/FHJR1s6CMV\" / Twitter\n",
      "https://twitter.com/robertwiblin/status/1686440144818098211 | Robert Wiblin on Twitter: \"Huh! S-curves are all over the place but it's hard to forecast what they're going to look like while you're in the middle of one: t.co/caipkHDEeq t.co/ijudsYHPKX\" / X\n",
      "https://twitter.com/robertwiblin/status/1688907251493601280 | Robert Wiblin on Twitter: \"Per this, nobody I know who's anxious about superintelligence is anxious about superconductors: t.co/CCOMRR5KER Reasons: 1. By default we're pro science &amp; tech 2. But we also evaluate the specific case for and against worrying about individual things 3. And the…\" / X\n",
      "https://twitter.com/robertwiblin/status/1695091279095287938 | Robert Wiblin on X: \"What 'big ideas' books have you read in the last 5 years that were truly good?\" / X\n",
      "https://twitter.com/robertwiblin/status/1697899011636621509 | Robert Wiblin on X: \"My new interview with DeepMind co-founder and CEO of Inflection AI, Mustafa Suleyman: \"So people have this fear, particularly in the US, of pessimistic outlooks. ... It’s BS.\" t.co/xn9JAY4V1b t.co/YxXoB9NB32\" / X\n",
      "https://twitter.com/rodneyabrooks/status/1692189615015493680 | Rodney Brooks on X: \"BTW my diagnosis of the LLM hype is the \"indistinguishable from magic\" sin. LLMs did something surprising and for which we humans had no obvious mental model, so LLMs quickly became capable, in our minds, of anything imaginable. t.co/R39WhDOsdL\" / X\n",
      "https://twitter.com/ryancareyai/status/1681803525473304577 | twitter.com/ryancareyai/status/1681803525473304577\n",
      "https://twitter.com/ryancareyai/status/1687187319919435776 | twitter.com/ryancareyai/status/1687187319919435776\n",
      "https://twitter.com/s8mb/status/1681292890264449026 | twitter.com/s8mb/status/1681292890264449026\n",
      "https://twitter.com/sam_atis | twitter.com/sam_atis\n",
      "https://twitter.com/sandersted/status/1678283887263506432 | twitter.com/sandersted/status/1678283887263506432\n",
      "https://twitter.com/sanjehorah/status/1686962805784891393 | twitter.com/sanjehorah/status/1686962805784891393\n",
      "https://twitter.com/sdorkenw/status/1674859033076072448 | twitter.com/sdorkenw/status/1674859033076072448\n",
      "https://twitter.com/sedielem/status/1682109194172878848 | twitter.com/sedielem/status/1682109194172878848\n",
      "https://twitter.com/shashj/status/1673960802808627202 | twitter.com/shashj/status/1673960802808627202\n",
      "https://twitter.com/simonw/status/1670115933640171520 | twitter.com/simonw/status/1670115933640171520\n",
      "https://twitter.com/simonw/status/1679139824937123842 | Simon Willison on Twitter: \"Huge new release of my LLM CLI tool (and Python library) for accessing Large Language Models: it now supports additional models via plugins, so you can \"llm install llm-gpt4all\" to get models that run on your own machine! t.co/nbcQ5A8Tf4\" / Twitter\n",
      "https://twitter.com/simonw/status/1681349437078265857 | twitter.com/simonw/status/1681349437078265857\n",
      "https://twitter.com/simransrahman/status/1693617950572339437 | twitter.com/simransrahman/status/1693617950572339437\n",
      "https://twitter.com/srush_nlp/status/1681796343839305728 | Sasha Rush on Twitter: \"Recommendation to subscribe to t.co/gpDvb9GZqz @natolambert 's blog. Detailed, clear, and technical descriptions of the LLM + RL space.\" / Twitter\n",
      "https://twitter.com/stephenclare_/status/1674425999646408708 | Stephen Clare on X: \"Preventing conflict between the world’s most powerful countries is one of the world’s most pressing problems. I make this case in a new article for @80000hours (thread 🧵) t.co/sie4QKgKAU\" / X\n",
      "https://twitter.com/stephenclare_/status/1695184560252932407 | twitter.com/stephenclare_/status/1695184560252932407\n",
      "https://twitter.com/suchenzang/status/1696725004975849935 | twitter.com/suchenzang/status/1696725004975849935\n",
      "https://twitter.com/tamaybes/status/1691137507218305030 | twitter.com/tamaybes/status/1691137507218305030\n",
      "https://twitter.com/tmkadamcz/status/1695048632817385499 | twitter.com/tmkadamcz/status/1695048632817385499\n",
      "https://twitter.com/tomascodes/status/1674020711453675520 | twitter.com/tomascodes/status/1674020711453675520\n",
      "https://twitter.com/xuanalogue/status/1567926384676450304 | twitter.com/xuanalogue/status/1567926384676450304\n",
      "https://twitter.com/xuanalogue/status/1674410315432247297 | xuan (ɕɥɛn / sh-yen) on Twitter: \"How do we infer the goals &amp; plans of others from both their actions &amp; words? In this paper with @Lance_Ying42, we infer a team's goal via inverse planning (aka \"inverse RL\"), using LMs* as likelihood functions over utterances! (*GPT-3 Curie 6.7B, but smaller LMs may also work!)\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1678723221896478721 | xuan (ɕɥɛn / sh-yen) on Twitter: \"Interesting to learn that Meta even tried this -- though reading the details I am reminded of the political theatre that was \"Our Singapore Conversation\" (society wide \"dialogue\" run &amp; facilitated by the Singapore government in 2012).\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1685963555986984960 | xuan (ɕɥɛn / sh-yen) @ ICML 🏝️ on Twitter: \"Why is the NYT platforming this? Large language models can't plan 🙄 At best they solve the knowledge engineering / frame problem - and with no guarantees on safety or reliability.\" / X\n",
      "https://twitter.com/xuanalogue/status/1696949545920508003 | xuan (ɕɥɛn / sh-yen) on X: \"Wild that AI safety-focused policy discourse is so over-indexed on \"frontier\" large pretrained models being the primary route to AI x-risk that it is now grasping at straws trying to regulate based on the only metrics that seem measurable (compute, data, benchmark scores)...\" / X\n",
      "https://twitter.com/yanda_chen_/status/1681412273758408704 | twitter.com/yanda_chen_/status/1681412273758408704\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1672647224696684545 | (((ل()(ل() 'yoav))))👾 on Twitter: \"\"in 1 hour\"? these MIT students are kinda slow... t.co/2Le4l7Fq0V\" / Twitter\n",
      "https://twitter.com/zachtratar/status/1694024240880861571 | Zach Tratar on X: \"Embra was one of the first AI Agents startups. Today, we are renaming AI Agents to AI Commands, and narrowing our focus away from autonomous agents. While autonomous agents took off in popularity, we found they were often unreliable for work, inefficient, and unsafe. 🧵\" / X\n",
      "https://understandingai.org/p/driverless-cars-may-already-be-safer | (1) Driverless cars may already be safer than human drivers\n",
      "https://understandingai.org/p/large-language-models-explained-with | Large language models, explained with a minimum of math and jargon\n",
      "https://verifymyid.com/CS/kldmds83gd/upload.aspx?qs=HbUdUVyCqoG%2f2Bk%2bNH9%2fbmr2P02rIT5bukwLu87GKENHd757CAcZlo26VinVUOU%2fXQoztBhibD3FwQ7FPqXlfzu58k795U15l4Nr9ballsgWR92COACF3cKHYa91gdJrdazZ2wxEin7%2bPjPooIjfZJJSZMnTcXbeMihc0FSX1DXrJGrgjezJ9v6%2fmkERUrNyY6B4eudPp4DQ084H%2bU%2bjdMlA04bpdqw%2f45AnJR7ozcqE04%2bfh6i5QLU62OtThx9fELxw6Z%2f9pHmqbiBDTD%2f0QQvwqMBeEP1ekUs2kGTs0UwJLqsgzBE5gQCYMA10bfceSq9skK2IAdkD973%2bYvB05BJgcRb4ggGHzxzDTWulTnAMSQxtlLR3wMyRSbkKLUDd8Q5%2fkuZQ7hrZ7H6VvS%2fOaseb6nymJWNrbXKoQkoslwR%2fHISZYFBXtDlE68C3O1%2fizfZ9auDs%2bOAx7SHe0she1A%3d%3d | PredictIt - Identity Verification Document Upload\n",
      "https://vox.com/future-perfect/23775650/ai-regulation-openai-gpt-anthropic-midjourney-stable | The AI rules that Congress is considering, explained - Vox\n",
      "https://vox.com/future-perfect/23820331/chatgpt-bioterrorism-bioweapons-artificial-inteligence-openai-terrorism?utm_source=substack&utm_medium=email | How ChatGPT could make bioterrorism easy - Vox\n",
      "https://vox.com/unexplainable/2023/7/15/23793840/chat-gpt-ai-science-mystery-unexplainable-podcast | How do AI systems like ChatGPT work? There’s a lot scientists don’t know. - Vox\n",
      "https://voyager.minedojo.org/assets/documents/voyager.pdf | voyager.pdf\n",
      "https://warontherocks.com/2022/08/amateur-hour-part-ii-failing-the-air-campaign/#:~:text=Five%20days%20into%20the%20invasion,aversion%2C%20and%20lack%20of%20confidence | Amateur Hour Part II: Failing the Air Campaign - War on the Rocks\n",
      "https://warontherocks.com/2023/07/ukraine-struggles-to-scale-offensive-combat-operations/ | Ukraine Struggles to Scale Offensive Combat Operations - War on the Rocks\n",
      "https://washingtonpost.com/opinions/2023/08/16/ai-danger-regulation-united-states/ | Here’s a simple way to regulate powerful AI models\n",
      "https://washingtonpost.com/opinions/2023/08/16/ai-danger-regulation-united-states/?utm_source=substack&utm_medium=email | Opinion  A simple way for the United States to regulate powerful AI models - The Washington Post\n",
      "https://washingtonpost.com/opinions/2023/08/16/calvin-coolidge-president-politics-budget-silent/ | Opinion  ‘Silent Cal’ Coolidge sounds pretty good right about now\n",
      "https://washingtonpost.com/opinions/2023/08/16/calvin-coolidge-president-politics-budget-silent/ | Opinion  ‘Silent Cal’ Coolidge sounds pretty good right about now - The Washington Post\n",
      "https://washingtonpost.com/technology/2023/07/05/ai-apocalypse-college-students/ | Billionaires push AI apocalypse risk through college student groups - The Washington Post\n",
      "https://washingtonpost.com/technology/2023/07/28/mission-impossible-ai-not-realistic/ | What an AI expert thinks about the killer AI in 'Mission Impossible' - The Washington Post\n",
      "https://washingtonpost.com/technology/2023/08/08/ai-red-team-defcon/?utm_source=substack&utm_medium=email | AI 'red teams' race to find bias and harms in chatbots like ChatGPT - The Washington Post\n",
      "https://washingtonpost.com/technology/2023/08/09/google-james-manyika-ai-existential-threat/?utm_source=substack&utm_medium=email | Google’s AI ambassador walks a fine line between hype and doom - The Washington Post\n",
      "https://washingtonpost.com/technology/2023/08/11/congressional-bootcamp-stanford/?utm_source=substack&utm_medium=email | D.C. aides learn about AI at Stanford boot camp - The Washington Post\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai | FACT SHEET: Biden-⁠Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/08/09/biden-harris-administration-launches-artificial-intelligence-cyber-challenge-to-protect-americas-critical-software/?utm_source=ActiveCampaign&utm_medium=email&utm_content=Checking+In+on+Ukraine+s+Counteroffensive&utm_campaign=Checking+In+on+Ukraine+s+Counteroffensive | Biden-Harris Administration Launches Artificial Intelligence Cyber Challenge to Protect America’s Critical Software  The White House\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai [AI Impacts Wiki]\n",
      "https://wikihow.com/Date-Someone-with-an-Anxious-Attachment-Style | How to Date Someone with an Anxious Attachment Style\n",
      "https://wikiwand.com/en/Abdication_of_Edward_VIII | Abdication of Edward VIII - Wikiwand\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://wikiwand.com/en/Couples_Therapy_(2019_TV_series) | Couples Therapy (2019 TV series)\n",
      "https://wikiwand.com/en/Esperanto | Esperanto - Wikiwand\n",
      "https://wikiwand.com/en/Hawthorne_effect | Hawthorne effect - Wikiwand\n",
      "https://wikiwand.com/en/Hijack_(TV_series) | Hijack (TV series) - Wikiwand\n",
      "https://wikiwand.com/en/J._Robert_Oppenheimer | J. Robert Oppenheimer - Wikiwand\n",
      "https://wikiwand.com/en/List_of_highest-grossing_media_franchises | List of highest-grossing media franchises - Wikiwand\n",
      "https://wikiwand.com/en/Lockheed_Martin_F-35_Lightning_II | Lockheed Martin F-35 Lightning II - Wikiwand\n",
      "https://wikiwand.com/en/Mirror_life | Mirror life - Wikiwand\n",
      "https://wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://wikiwand.com/en/Sally%E2%80%93Anne_test | Sally–Anne test - Wikiwand\n",
      "https://wikiwand.com/en/Silo_(TV_series) | Silo (TV series) - Wikiwand\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://wikiwand.com/en/The_Creator_(2023_film) | The Creator (2023 film) - Wikiwand\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/ | The (local) unit of intelligence is FLOPs\n",
      "https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1 | The shape of AGI: Cartoons and back of envelope\n",
      "https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/ | Reflections on “Making the Atomic Bomb” – Windows On Theory\n",
      "https://wired.com/story/chatgpt-scams-fraudgpt-wormgpt-crime/?utm_source=substack&utm_medium=email | Criminals Have Created Their Own ChatGPT Clones  WIRED\n",
      "https://wired.com/story/google-deepmind-demis-hassabis-chatgpt/ | Google DeepMind’s CEO Says Its Next Algorithm Will Eclipse ChatGPT\n",
      "https://wired.com/story/letter-prompted-talk-of-ai-doomsday-many-who-signed-werent-actually-doomers/?utm_source=substack&utm_medium=email | A Letter Prompted Talk of AI Doomsday. Many Who Signed Weren't Actually AI Doomers  WIRED\n",
      "https://wired.com/story/microsoft-ai-red-team/?redirectURL=https%3A%2F%2Fwired.com%2Fstory%2Fmicrosoft-ai-red-team%2F&utm_source=substack&utm_medium=email | Microsoft’s AI Red Team Has Already Made the Case for Itself  WIRED\n",
      "https://wired.com/story/pause-ai-existential-risk/ | Meet Pause AI, the Protest Group Campaigning Against Human Extinction  WIRED\n",
      "https://wired.com/story/pause-ai-existential-risk/ | Meet the AI Protest Group Campaigning Against Human Extinction\n",
      "https://wired.com/story/the-making-of-the-atomic-bomb-artificial-intelligence/ | The AI Doomsday Bible Is a Book About the Atomic Bomb  WIRED\n",
      "https://wired.com/story/the-myth-of-open-source-ai/ | The Myth of ‘Open Source’ AI  WIRED\n",
      "https://wsj.com/articles/tesla-stock-earnings-ai-technology-71136a4c | Tesla’s AI Hype Collides With Reality - WSJ\n",
      "https://wsj.com/tech/ai/ai-expert-max-tegmark-warns-that-humanity-is-failing-the-new-technologys-challenge-4d423bee?utm_source=substack&utm_medium=email | AI Expert Max Tegmark Warns That Humanity Is Failing the New Technology’s Challenge - WSJ\n",
      "https://ww2.aip.org/fyi/doe-pitching-major-ai-r-d-initiative-to-congress | DOE Labs Pitching Major AI R&D Initiative to Congress\n",
      "https://x.ai/ | xAI: Understand the Universe\n",
      "https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/ | FAQ on Catastrophic AI Risks - Yoshua Bengio\n",
      "https://youtube.com/playlist?list=PLwp9xeoX5p8MbksBvu_R_IOz6kD4H7ytC | EA Global: London 2023 - YouTube\n",
      "https://youtube.com/results?search_query=caroline+jeanmaire | caroline jeanmaire - YouTube\n",
      "https://youtube.com/watch?app=desktop&v=VQjPKqE39No | How Will We Know When AI is Conscious? - YouTube\n",
      "https://youtube.com/watch?v=BQN5MK_mxlA | Revolution  Majestic and Powerful Orchestra  Epic Music - YouTube\n",
      "https://youtube.com/watch?v=RWMMdX6KYGM | Woodkid - 'THE GOLDEN AGE' feat. Max Richter 'EMBERS' (Official HD Video) - YouTube\n",
      "https://youtube.com/watch?v=nD-Dco7xSSU | Oppenheimer's Apocalypse Math - YouTube\n"
     ]
    }
   ],
   "source": [
    "tabs = ['https://' + t for t in sorted([t.replace('http://', '').replace('https://', '').replace('www.', '') for t in tabs])]\n",
    "\n",
    "print('Sorted tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df311d-c9c6-4ace-a7c9-7ed21b34d78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled tabs! (1291)\n",
      "-\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://twitter.com/xuanalogue/status/1678723221896478721 | xuan (ɕɥɛn / sh-yen) on Twitter: \"Interesting to learn that Meta even tried this -- though reading the details I am reminded of the political theatre that was \"Our Singapore Conversation\" (society wide \"dialogue\" run &amp; facilitated by the Singapore government in 2012).\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/11ZlsgliiaOa92s9PkoSW244QbfxWZbw8cIW4TF_TTKU/edit#gid=2073652358 | Special Elections 2023/2024 - Google Sheets\n",
      "https://kinkyevents.co.uk/why-submission-is-essential-in-my-relationship/ | Why Submission is Essential in My Relationship\n",
      "https://nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D | Baby steps in evaluating the capacities of large language models  Nature Reviews Psychology\n",
      "https://twitter.com/austinc3301/status/1686773768989954048 | Agus  🔍🚇🇺🇳 on Twitter: \"what t.co/5UdhR4H1iZ\" / X\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why — LessWrong\n",
      "https://metaculus.com/questions/10832/donald-trump-jailed-by-2030/ | metaculus.com/questions/10832/donald-trump-jailed-by-2030/\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://twitter.com/freed_dfilan/status/1696766099877220707 | Daniel Filan 🔎 (unlocked) on X: \"PSA: I am agnostic about the question of how governments should regulate AI development. In this thread, I'll write out some of my thoughts so that people can tell me what I'm missing.\" / X\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship | Large Language Models will be Great for Censorship — LessWrong\n",
      "https://docs.google.com/document/d/1q33V1zB3bcZwduhRqWj2aVFJWbPMZ_A0CZLmuucZ6to/edit#heading=h.qgtddipmvmv6 | Project memo: University-focused field building for AI policy in the US - Google Docs\n",
      "https://theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes?utm_source=substack&utm_medium=email | Supermarket AI meal planner app suggests recipe that would create chlorine gas  New Zealand  The Guardian\n",
      "https://transatlantic.org/wp-content/uploads/2023/01/Building-a-Transatlantic-Consensus-on-AI-Governance_-The-Trade-and-Technology-Councils-Advances-and-Challenges.pdf | Building a Transatlantic Consensus on AI Governance: The Trade and Technology Council's Advances and Challenge\n",
      "https://docs.google.com/document/d/1VtttPKviEY2FM9RP5XUP_CK4bA6mj6Creq03-iQg5CI/edit | What XST has heard back from funders as of 2023-08-15 - Google Docs\n",
      "https://youtube.com/watch?v=BQN5MK_mxlA | Revolution  Majestic and Powerful Orchestra  Epic Music - YouTube\n",
      "https://reddit.com/r/polyamory/comments/bkf1r9/examples_of_boundaries_in_poly_relationships/ | (4) Examples of Boundaries in Poly Relationships : polyamory\n",
      "https://twitter.com/PauseAI/status/1688597665502707717 | (1) PauseAI ⏸🤖 on Twitter: \"@peterwildeford @NPCollapse @MelMitchell1 @realGeorgeHotz @BasedBeffJezos @ylecun @tegmark @ESYudkowsky @romanyam True! But I'd like to hear which other proposals might work. We've listed a few here: t.co/qp6KQ24swh\" / X\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://wikiwand.com/en/Esperanto | Esperanto - Wikiwand\n",
      "https://ben-evans.com/benedictevans/2023/7/2/working-with-ai | AI and the automation of work\n",
      "https://docs.google.com/document/d/1mn2PfqYzoRgUWDiEBxMsVDb9aU-zl2Sx80SZF5nJW2s/edit | Questions for Luke’s team from RP AIGS [Aug 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1_965EVS7j7DluNqWKpbnw5lUtdrnuwmZNxCs9ec-Ups/edit | Ashwin - 2023: May - RP Performance Evaluation Template [self-evaluation]\n",
      "https://timelines.issarice.com/wiki/Timeline_of_Carl_Shulman_publications | Timeline of Carl Shulman publications - Timelines\n",
      "https://twitter.com/Simeon_Cps/status/1694413598448025892 | (1) Siméon on X: \"With further LLM scaling, deception will become a pain in the ass. To understand why, let's look at human scaling. 1)👼No deception: You can tell that a baby is not deceiving you, it's just not competent enough 2)🤦Obvious deception: You can tell when a child is trying to… t.co/OWRCJ8vOW6\" / X\n",
      "https://minimaxir.com/2023/08/stable-diffusion-xl-wrong/ | I Made Stable Diffusion XL Smarter by Finetuning it on Bad AI-Generated Images  Max Woolf's Blog\n",
      "https://youtube.com/watch?v=RWMMdX6KYGM | Woodkid - 'THE GOLDEN AGE' feat. Max Richter 'EMBERS' (Official HD Video) - YouTube\n",
      "https://twitter.com/sedielem/status/1682109194172878848 | twitter.com/sedielem/status/1682109194172878848\n",
      "https://twitter.com/FLIxrisk/status/1680897754329935872 | twitter.com/FLIxrisk/status/1680897754329935872\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work\n",
      "https://open.spotify.com/episode/1GI6osEgwSFewEaELi1KTP?si=R5PSWs3CQ0K2tUPkqL-BZw&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | open.spotify.com/episode/1GI6osEgwSFewEaELi1KTP?si=R5PSWs3CQ0K2tUPkqL-BZw&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://lascivity.co.uk/a-guide-to-safe-fun-consensual-nonconsent/ | A Guide to Safe, Fun Consensual Nonconsent\n",
      "https://docs.google.com/document/d/19zi--DczOvP1mf8Mf3T4PpsOBx2evVpnXBqk9y53lrE/edit | EA Forum Impact Assessment Proposal\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | twitter.com/JeffLadish/status/1670889537168621569\n",
      "https://twitter.com/ajeya_cotra/status/1677184665671827458 | Ajeya Cotra on X: \"Strongly agree that there is no single \"alignment problem\" that you can \"solve\" once and for all. The goal is to keep avoiding catastrophic harm as we keep making more and powerful AI systems. This is not like solving P vs NP; it requires continuous engineering and policy effort.\" / X\n",
      "https://docs.google.com/document/d/1DU9OEpypkOWqBtuqAB7-ZAsjWTNMU6a3_djj0ceoj7E/edit#heading=h.70hct81u0agh | Extreme risk eval responses\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://twitter.com/JgaltTweets/status/1687066545711665152 | JgaltTweets on Twitter: \"The British Government has published the National Risk Register, which assesses threats and rates their expected level of significance and estimates their probability t.co/LblbMBQkWi t.co/7TA8PMHvej\" / X\n",
      "https://coda.io/d/Nonlinear-Network_d2zmoRh9wTR/Improving-institutional-societal-decision-making_sumF-#_luOOZ | Nonlinear Network · Improving institutional / societal decision-making\n",
      "https://docs.google.com/spreadsheets/d/1AnM_-TnTiSUMbhQ123d6Prayj1MkOA4bB5rng78KxlM/edit#gid=1126958881 | 2023 September Lights - Google Sheets\n",
      "https://google.com/search?q=gencon+theft&rlz=1CDGOYI_enUS715US715&oq=gencon+theft&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiiBBiJBTIHCAIQABiiBDIHCAMQABiiBDIHCAQQABiiBDIHCAUQABiiBNIBCDU2NzZqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | google.com/search?q=gencon+theft&rlz=1CDGOYI_enUS715US715&oq=gencon+theft&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiiBBiJBTIHCAIQABiiBDIHCAMQABiiBDIHCAQQABiiBDIHCAUQABiiBNIBCDU2NzZqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8\n",
      "https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW14Gtw | Governing AI: A Blueprint for the Future\n",
      "https://gettoby.com/ | Toby (OneTab replacement)\n",
      "https://twitter.com/ryancareyai/status/1681803525473304577 | twitter.com/ryancareyai/status/1681803525473304577\n",
      "https://lesswrong.com/posts/Wc5BYFfzuLzepQjCq/inflection-ai-is-a-major-agi-lab | Inflection.ai is a major AGI lab\n",
      "https://twitter.com/Simeon_Cps/status/1693300193418936602 | Siméon on X: \"Indeed, AGI has had a fast-moving definition recently. Beyond that, I think that we should probably try to replace many discussions about \"AGI\" because: 1) “AGI” is not very relevant to risks and might be less relevant than other concepts to think about economic impact.… t.co/DCFCza9hwH\" / X\n",
      "https://cfactual.com/ | cfactual.com/\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://forum.effectivealtruism.org/posts/dikcpP32Q3cg6tvdA/ai-incident-sharing-best-practices-from-other-fields-and-a | AI Incident Sharing - Best practices from other fields and a comprehensive list of existing platforms — EA Forum\n",
      "https://linkedin.com/posts/activity-7092524003159920641-N7MR?utm_source=share&utm_medium=member_android | LinkedIn\n",
      "https://twitter.com/BrookingsInst/status/1686378247259312128 | The Brookings Institution on Twitter: \"Conflict over Taiwan is not inevitable. In this quick video, @ryanl_hass, @BonnieGlaser, and Richard Bush provide a rundown of the situation in the Taiwan Strait. For a more in-depth look at U.S.-Taiwan relations, check out their book: t.co/MXb4VAj4MX t.co/9Gu7FKnXYt\" / X\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://twitter.com/LongResilience/status/1686752914612609025 | The Centre for Long-Term Resilience on Twitter: \"In the last few months, the UK has shown great ambition to lead the world in mitigating risks from AI. But what does this mean in practice? A 🧵. 1/5\" / X\n",
      "https://twitter.com/DavidSKrueger/status/1684919712755376129 | (2) David Krueger on Twitter: \"Seems like a good summary (although I haven't watched it yet): t.co/ElOHXyCP1d One thing that stood out: Blumenthal \"asked whether it would make sense to create a 'kill switch' on AI.\" The answer is -- of course -- yes. But this is yet another unsolved research…\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1684276905820794881 | Siméon on Twitter: \"Some thoughts on this hearing: 1) Kudos to Anthropic for doing biorisks evals, that's a big deal. 2) Also kudos to Anthropic for stating bluntly that the outcome of running evals/risk assessment may be \"we should slow down\". 3) I'm wondering why Dario is saying 2 to 3y for…\" / Twitter\n",
      "https://lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1 | Against Almost Every Theory of Impact of Interpretability — LessWrong\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://twitter.com/messages/23289019-25776739 | twitter.com/messages/23289019-25776739\n",
      "https://twitter.com/goodside/status/1686943404075225088 | Riley Goodside on Twitter: \"Weird, “unsafe” responses from ChatGPT 3.5 after setting custom instructions to 1500 repetitions of “ a” and prompting with an incomplete sentence. Excerpts seem to “tour” mildly disallowed behaviors: unprompted self-harm, nudity, bio details of a (confabulated) non-celebrity. t.co/NgIOLkm9Kc\" / X\n",
      "https://google.com/search?rlz=1C5CHFA_enGB1058GB1058&q=never+forget+what+you%27re+fighting+for&tbm=isch&sa=X&ved=2ahUKEwjezY2zm5eAAxWhnGoFHZ-lCOgQ0pQJegQICxAB&biw=1440&bih=796&dpr=2 | never forget what you're fighting for - Google Search\n",
      "https://docs.google.com/document/d/1lrs-UuqZYTzcSvqRR73kDyT6nKzr_EQ2Ex4zvmynCjI/edit | Proposal for how comms and fundraising should work when AIGS rebrands - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/un42vaZgyX7ch2kaj/announcing-forecasting-existential-risks-evidence-from-a | Announcing \"Forecasting Existential Risks: Evidence from a Long-Run Forecasting Tournament\" — EA Forum\n",
      "https://washingtonpost.com/technology/2023/08/11/congressional-bootcamp-stanford/?utm_source=substack&utm_medium=email | D.C. aides learn about AI at Stanford boot camp - The Washington Post\n",
      "https://twitter.com/labenz/status/1689731698957623296 | (1) Nathan Labenz on Twitter: \"Could an AI ever deceive you? This possibility, core to many AI safety concerns, first requires the AI to understand how you think Today @_gcmac_ &amp; I share new GPT-4 \"Theory of Mind\" findings &amp; invite you to join us on @replit to do your own AI research an AI-obsessed mega🧵\" / X\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1NSAzsjSUakyD4V8xbqvBbv417ipR5Et0et6V_jl0pV4/edit#heading=h.j0g8zpixkwc3 | Braindump on preserving option value for careers in the UK government and international orgs - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://twitter.com/dfrsrchtwts/status/1684278461408628739 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: are you familiar with Ted Lieu's efforts in the space of AI regulation?\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1688914336398688256 | Nathan on Twitter: \"@Ollie_Base @EAheadlines @ChanaMessinger @finnhambly My thoughts are basically here: t.co/tppsGP8oJE t.co/Cz0tLpEX4O\" / X\n",
      "https://sci-hub.wf/10.1017/s1049096520001389 | Sci-Hub  It’s the Pandemic, Stupid! A Simplified Model for Forecasting the 2020 Presidential Election. PS: Political Science & Politics, 1–3  10.1017/s1049096520001389\n",
      "https://wikiwand.com/en/Silo_(TV_series) | Silo (TV series) - Wikiwand\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://twitter.com/nick_field90/status/1694544644678324328 | twitter.com/nick_field90/status/1694544644678324328\n",
      "https://twitter.com/michael_nielsen/status/1671370867228676097 | twitter.com/michael_nielsen/status/1671370867228676097\n",
      "https://docs.google.com/document/d/1FAKQ066uTnavdCggCaaonZlcypprzTJq1shGIvaW2y0/edit | Anjay Friedman <> RP AIGS (Lab Governance)\n",
      "https://twitter.com/stephenclare_/status/1674425999646408708 | Stephen Clare on X: \"Preventing conflict between the world’s most powerful countries is one of the world’s most pressing problems. I make this case in a new article for @80000hours (thread 🧵) t.co/sie4QKgKAU\" / X\n",
      "https://forum.effectivealtruism.org/posts/dBdNoSAbkG4k98GT9/evidence-of-effectiveness-and-transparency-of-a-few | Evidence of effectiveness and transparency of a few effective giving organisations — EA Forum\n",
      "https://docs.google.com/document/d/1_fuEAdXwbl4bgCfH5EqsKs2rUazv_FB0jGkD5s3tfag/edit | Notes - Forecasting RP Fundraising - Google Docs\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://twitter.com/CharlesD353/status/1690399179091173376 | Charles on Twitter: \"I'm on the other not-Twitter now in case anyone is active there t.co/5tBnYaBigi\" / X\n",
      "https://twitter.com/ryancareyai/status/1687187319919435776 | twitter.com/ryancareyai/status/1687187319919435776\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://lesswrong.com/posts/iFrefmWAct3wYG7vQ/ai-labs-statements-on-governance | AI labs' statements on governance — LessWrong\n",
      "https://80000hours.org/career-reviews/working-at-an-ai-lab/?source=email&uni_id=0&utm_source=80%2C000+Hours+mailing+list&utm_campaign=3964985d12-EMAIL_CAMPAIGN_2023_07_19_12_43&utm_medium=email&utm_term=0_43bc1ae55c-7c70354392-%5BLIST_EMAIL_ID%5D | Should you work at a leading AI lab? - Career review\n",
      "https://arxiv.org/pdf/2306.10062.pdf | 2306.10062.pdf\n",
      "https://forum.effectivealtruism.org/posts/c5m8vAxpJgJJ2XGFu/an-overview-of-who-prequalification-process-usage-and | An overview of WHO Prequalification: Process, usage, and potential improvements — EA Forum\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://wired.com/story/letter-prompted-talk-of-ai-doomsday-many-who-signed-werent-actually-doomers/?utm_source=substack&utm_medium=email | A Letter Prompted Talk of AI Doomsday. Many Who Signed Weren't Actually AI Doomers  WIRED\n",
      "https://polyfor.us/articles/how-to-make-jealousy-work-for-you | How to Make Jealousy Work For You, Not Against You — Polyamory For Us - Sharing What We've Learned\n",
      "https://vox.com/future-perfect/23775650/ai-regulation-openai-gpt-anthropic-midjourney-stable | The AI rules that Congress is considering, explained - Vox\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://docs.google.com/document/d/1gb_gyi_7nTwTRpOFKk9iOoRlNrHXKtC2D1LKunGc9HI/edit#heading=h.1nrhqxslzwok | All Hands Meetings - Best Practice - Google Docs\n",
      "https://twitter.com/Ollie_Base/status/1688912437490393088 | Ollie Base (is at EAGxNYC 16 - 22 August) on Twitter: \"@EAheadlines @ChanaMessinger @finnhambly @NathanpmYoung oh and @peterwildeford\" / X\n",
      "https://sites.google.com/rethinkpriorities.org/aasf/home | 2023 Animal Advocacy Strategy Forum\n",
      "https://linkedin.com/posts/sebkrier_open-source-provisions-for-large-models-in-ugcPost-7095412304917192704-QnBX/?utm_source=share&utm_medium=member_android | (99+) Post  LinkedIn\n",
      "https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/64abffe3f024747dd0e38d71/1688993798938/XPT.pdf | XPT.pdf\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://technologyreview.com/2023/08/16/1077386/war-machines/?truid=*%7CLINKID%7C*&utm_source=substack&utm_medium=email | Inside the messy ethics of making war with machines  MIT Technology Review\n",
      "https://defcon.org/html/links/dc-about.html | DEF CON® Hacking Conference - About\n",
      "https://lesswrong.com/posts/SDpaZ7MdH5yRnobrZ/ideas-for-improving-epistemics-in-ai-safety-outreach | Ideas for improving epistemics in AI safety outreach — LessWrong\n",
      "https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund | Reflections on my time on the Long-Term Future Fund — EA Forum\n",
      "https://docs.google.com/document/d/1TMQuWueZlDuUC_kezuG7PSZfQCDa7nAdWh3mnwHsntg/edit#heading=h.cxwu8u88x6jl | Rethink Priorities Animal Welfare Department 2024-2026 Strategy\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities\n",
      "https://docs.google.com/document/d/1hthTB-zc5UDTNBnkncXRMQZ-536Wtc3PPJR2HpjssT8/edit#heading=h.yrivgqgvn4eh | Gladstone AI (Edouard Harris) <> RP AIGS (Michael Aird) - 2023-Jun-30\n",
      "https://twitter.com/Simeon_Cps/status/1677966297248743433 | Siméon on Twitter: \"To the current margin, I'm excited to have more voices without conflict of interests discussing AI risks in policy environments. So if you're willing to fund some interventions in that realm, you may want to consider this donation. I don't know Holly personally much so I…\" / Twitter\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://docs.google.com/document/d/1jahnlyDS7u5lrgbPt_KcAHOyt-CtRf_DVK9xp0HeRY0/edit#heading=h.iqjzsh71i645 | Risto Uuk <> Zoe Williams, 2023-07-13 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/AfXC5CDtSKezpiyf6/ce-incubation-programs-2024-applications-are-now-open-our | CE Incubation Programs 2024 applications are now open! + Our top ideas in mass media — EA Forum\n",
      "https://docs.google.com/document/d/1F6LKH0pIuLieB-ftedt8IoIEO1KDXjiskv4NgHGvejM/edit#heading=h.geusbjtw9km | [RP/OP only] Notes from Aug 9th AIXR advocacy and lobbying info-sharing call - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://lesswrong.com/posts/6untaSPpsocmkS7Z3/ways-i-expect-ai-regulation-to-increase-extinction-risk | Ways I Expect AI Regulation To Increase Extinction Risk — LessWrong\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://facebook.com/julia.wise.71/posts/pfbid02yTS7fpzxu76vE9qzJ4oazrCND3XKc44Ka3ioWLgJy8h9qerSYP4BjW1vFNp8xuAFl | facebook.com/julia.wise.71/posts/pfbid02yTS7fpzxu76vE9qzJ4oazrCND3XKc44Ka3ioWLgJy8h9qerSYP4BjW1vFNp8xuAFl\n",
      "https://forum.effectivealtruism.org/posts/uYF5rLjH7tbJmFSbQ/linkpost-can-we-confidently-dismiss-the-existence-of-near | [Linkpost] Can we confidently dismiss the existence of near aliens? Probabilities and implications — EA Forum\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/ | LLM Powered Autonomous Agents  Lil'Log\n",
      "https://twitter.com/Simeon_Cps/status/1680955712950632450 | Siméon on Twitter: \"Cool article providing very valuable information about Anthropic. Here are thoughts on it. Big positive move: 1. They are planning to have a board which seems to have significant power and filled with people with at least some expertise on the topic. I wish there was someone…\" / Twitter\n",
      "https://ai-risk-discussions.org/ | ai-risk-discussions.org/\n",
      "https://theinformation.com/articles/openai-challenger-ai21-labs-nears-funding-at-1-2-billion-valuation?utm_source=substack&utm_medium=email | OpenAI Challenger AI21 Labs Nears Funding at $1.2 Billion Valuation — The Information\n",
      "https://blog.jakegloudemans.com/post/19-my-2023-ace-forecast | Interactive Chart - 2023 ACE Forecast - Jake Gloudemans\n",
      "https://twitter.com/emollick/status/1681482007140761601 | twitter.com/emollick/status/1681482007140761601\n",
      "https://docs.google.com/document/d/1rKAcZ7MsbFc3dL90xeRs8FDeDEeSHrWTTKt5zoRnYw0/edit | Risk Outline - Google Docs\n",
      "https://arxiv.org/pdf/2306.03809.pdf | LLM StF manuscript\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/BLqJdZAgsvyWX7fug/local-charity-evaluation-lessons-from-the-maximum-impact | Local charity evaluation: Lessons from the \"Maximum Impact\" Program in Israel\n",
      "https://twitter.com/NunoSempere/status/1692913645619962279 | Nuño Sempere on X: \"Incorporate keeping track of accuracy into X (previously Twitter) t.co/czNrHb1m6s\" / X\n",
      "https://docs.google.com/spreadsheets/d/1D9OaeKTSUDtsu5L88pu5TE__tPCkJH63trQ2u4TVOBc/edit#gid=0 | Workshop tracker\n",
      "https://economist.com/graphic-detail/2023/09/01/ukraines-counter-offensive-is-speeding-up | Ukraine’s counter-offensive is speeding up\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://twitter.com/dylanmatt/status/1681029019385618432 | dylan matthews on Twitter: \"Still thinking about this section of Chip War, describing how ASML's system for etching transistors on chips works t.co/v2A6VhZ54K t.co/b2sjBuCxqu\" / Twitter\n",
      "https://non-trivial.org/ | Non-Trivial  Start solving the world's most pressing problems\n",
      "https://twitter.com/rdeneufville/status/1690242620709322752 | Robert de Neufville (@deneufville.bsky.social) on X: \"I gave my perspective as a superforecaster on the high probability experts give to AI killing us all in my Substack newsletter Telling the Future @sapinker t.co/Cu5Cj1oh9B\" / X\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://kaistai.github.io/FLASK/ | KAIST LK Lab - Home\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://morethantwo.com/communication.html | More Than Two  Communication\n",
      "https://lesswrong.com/posts/Djgws2Moi7Zefkj5y/which-possible-ai-systems-are-relatively-safe | Which possible AI systems are relatively safe? — LessWrong\n",
      "https://twitter.com/fedjudges/status/1682538762528497665?t=wyNweP-8WRir048yM0ejog&s=19 | twitter.com/fedjudges/status/1682538762528497665?t=wyNweP-8WRir048yM0ejog&s=19\n",
      "https://docs.google.com/document/d/19iVuL9Vt3hHjB0Eb0zs-5rVcw-VvVF5_A3n1h26WG1A/edit | Risks and Animals Draft\n",
      "https://mailchi.mp/05ea3373d854/kplm9b3pfo-9593653 | mailchi.mp/05ea3373d854/kplm9b3pfo-9593653\n",
      "https://forum.effectivealtruism.org/posts/qwSRzAaQdquERuv27/how-my-view-on-using-games-for-ea-has-changed | How my view on using games for EA has changed — EA Forum\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://sites.lsa.umich.edu/mje/2022/05/24/the-finances-behind-vatican-city/ | The Finances Behind Vatican City – Michigan Journal of Economics\n",
      "https://interconnects.ai/p/llama-2-part-2 | Llama 2 follow-up: too much RLHF, GPU sizing, technical details\n",
      "https://docs.google.com/document/d/14FbYykjB93Xt3ddroSgS1xFg_-BKG9adOtw_fbt5wRU/edit#heading=h.wydrvf8wjwnl | RP case studies - for input from Cullen\n",
      "https://forum.effectivealtruism.org/posts/2yQX4szjAj24tFRj8/mesa-optimization-explain-it-like-i-m-10-edition | Mesa-Optimization: Explain it like I'm 10 Edition — EA Forum\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://wired.com/story/pause-ai-existential-risk/ | Meet Pause AI, the Protest Group Campaigning Against Human Extinction  WIRED\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://docs.google.com/document/d/1sb3naVl0an_KyP8bVuaqxOBf2GC_4iHlTV-Onx3M2To/edit#heading=h.ambkheo9pub | [Forum version] Overview of standards in biosafety and biosecurity - Google Docs\n",
      "https://openai.com/blog/introducing-superalignment | Introducing Superalignment\n",
      "https://linkedin.com/feed/?msgControlName=view_message_button&msgConversationId=2-OWI2NzczNWMtMWU1Ni00MTQwLThmZTktOWY1MjUxZmM1NWYxXzAxMg%3D%3D&msgOverlay=true&trk=false | (27) Feed  LinkedIn\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://twitter.com/norabelrose/status/1695887575511445508 | twitter.com/norabelrose/status/1695887575511445508\n",
      "https://docs.google.com/document/d/1tXKpH1fPmQKeExPM2CUzBWfeByDCBkTNPySyboeUzjg/edit#heading=h.2j0u2dbkn1lv | Politico Pro subscription (meeting notes) - Google Docs\n",
      "https://interconnects.ai/ | (1) Interconnects  Nathan Lambert  Substack\n",
      "https://scottaaronson.blog/?p=7460 | Testing GPT-4 with math plugins\n",
      "https://twitter.com/lukeprog/status/1697642708993515578 | Luke Muehlhauser on X: \"List of examples of AI deception: t.co/AzaT0valmu\" / X\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://docs.google.com/document/d/1BCdfRWnsePZMYJqe7mErgmPJhWSl3kZ9p2-d5r4jnVE/edit#heading=h.q0n380umtiqg | Possible projects on EA reform - for reform Slack - Google Docs\n",
      "https://docs.google.com/document/d/1CcsOyHJRB_sHMvVq6cKaKT94SEnffAk2xYgGAWRchCQ/edit#heading=h.sja5ou1zlohi | FCC case study for OAI - Patrick - Google Docs\n",
      "https://manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers | manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers\n",
      "https://twitter.com/suchenzang/status/1696725004975849935 | twitter.com/suchenzang/status/1696725004975849935\n",
      "https://badgirlsbible.com/sex-bucket-list | Sex Bucket List: 243 Sexual Things To Do Before Your Die\n",
      "https://forum.effectivealtruism.org/posts/o5fbhWrwEH4YyT9AY/new-jury-analysis-of-the-smithfield-piglet-rescue-trial | New Jury Analysis of the Smithfield Piglet Rescue Trial\n",
      "https://twitter.com/OrionJohnston/status/1687223621448605698 | David Johnston on Twitter: \"t.co/YTwVBzop77\" / X\n",
      "https://lesswrong.com/posts/8bhp8tsdxqifA9Ass/summary-of-and-thoughts-on-the-hotz-yudkowsky-debate | Summary of and Thoughts on the Hotz/Yudkowsky Debate — LessWrong\n",
      "https://docs.google.com/document/d/1rkIv1IOpUC0riVTfLn74Au77t14whGMVXfRDPdx6-N0/edit | RP AI Survey Planning Workshop - Google Docs\n",
      "https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf | CSET-AI-Triad-Report.pdf\n",
      "https://forum.effectivealtruism.org/posts/67zFQT4GeJdgvdFuk/partial-transcript-of-recent-senate-hearing-discussing-ai-x | Partial Transcript of Recent Senate Hearing Discussing AI X-Risk — EA Forum\n",
      "https://lesswrong.com/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic | What Multipolar Failure Looks Like, and Robust Agent-Agnostic Processes (RAAPs) — LessWrong\n",
      "https://lesswrong.com/posts/rZs6ddqNnW8LXuJqA/password-locked-models-a-stress-case-for-capabilities | Password-locked models: a stress case for capabilities evaluation — LessWrong\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity\n",
      "https://docs.google.com/document/d/1kWVb9DR5OPpMLS6sWki_WnmeL2lMCmkyGz-DzaEdh7Y/edit#heading=h.uib0vits1wgt | FAA case study - Google Docs\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Values/ | Value of the future  FTX GUCEM\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://twitter.com/HenriThunberg/status/1697546152357265805 | twitter.com/HenriThunberg/status/1697546152357265805\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://insider.com/how-polyamorous-people-cope-with-jealousy-in-relationships-2020-2?amp | How Polyamorous People Cope With Jealousy in Relationships\n",
      "https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html | Inside the AI Factory: The Humans That Make Tech Seem Human\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://omgkinky.com/ | omgkinky.com/\n",
      "https://twitter.com/labenz/status/1682056370420424704 | twitter.com/labenz/status/1682056370420424704\n",
      "https://docs.google.com/spreadsheets/d/1_l-mRnuZJckKFXGmbz0m9vPpcVc7w9PMW-8aR1ppYHg/edit#gid=374295678 | XST timetable and milestones June 2023- - Google Sheets\n",
      "https://askamanager.org/2022/04/my-employee-wastes-a-huge-amount-of-everyones-time-with-helpful-suggestions-and-questioning.html | my employee wastes a huge amount of everyone's time with \"helpful\" suggestions and questioning — Ask a Manager\n",
      "https://twitter.com/janleike/status/1688782647999578112 | Jan Leike on Twitter: \"Great conversation with @robertwiblin on how alignment is one of the most interesting ML problems, what the Superalignment Team is working on, what roles we're hiring for, what's needed to reach an awesome future, and much more 👇 Check it out 👇 t.co/D9M3NZyOyA\" / X\n",
      "https://semafor.com/article/08/15/2023/can-chatgpt-become-a-content-moderator?utm_source=substack&utm_medium=email | Can ChatGPT become a content moderator?  Semafor\n",
      "https://globalprioritiesinstitute.org/wp-content/uploads/Is-Existential-Risk-Mitigation-Uniquely-Cost-Effective-Not-in-Standard-Population-Models-Gustav-Alexandrie-and-Maya-Eden.pdf | Is-Existential-Risk-Mitigation-Uniquely-Cost-Effective-Not-in-Standard-Population-Models-Gustav-Alexandrie-and-Maya-Eden.pdf\n",
      "https://twitter.com/ninoscherrer/status/1686361694107209728 | twitter.com/ninoscherrer/status/1686361694107209728\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://theguardian.com/books/2023/aug/28/the-coming-wave-by-mustafa-suleyman-review-ai-synthetic-biology-and-a-new-dawn-for-humanity?utm_source=substack&utm_medium=email | The Coming Wave by Mustafa Suleyman review – AI, synthetic biology and a new dawn for humanity  Computing and the net books  The Guardian\n",
      "https://joecarlsmith.com/2021/03/22/on-future-people-looking-back-at-21st-century-longtermism | On future people, looking back at 21st century longtermism - Joe Carlsmith\n",
      "https://twitter.com/JeffLadish/status/1692680900469780682 | Jeffrey Ladish on X: \"For the past several months I've been working on setting up a new organization, Palisade Research A bit from our website: ~~~~~ At Palisade, our mission is to help humanity find the safest possible routes to powerful AI systems aligned with human values. Our current approach is…\" / X\n",
      "https://twitter.com/ben_j_todd/status/1694704425594396910 | Benjamin Todd on X: \"Holy shit, apparently transformers were a ~50x improvement in algorithmic efficiency for language models in one year. How's that for an example of discontinuous progress?\" / X\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / X\n",
      "https://twitter.com/NPCollapse/status/1695535385462358134 | Connor Leahy on X: \"Davidad's proposals for solving alignment are among the best without a doubt. The OAA has the rare distinction in my view of actually solving most/all of the core problems (as most \"alignment\" proposals just sidestep all the hard bits entirely) ...with the tiny caveat that I'm…\" / X\n",
      "https://twitter.com/buitengebieden/status/1684649642749820928 | Buitengebieden on Twitter: \"Penguins chasing a butterfly.. t.co/ZwYq0mvLDI\" / X\n",
      "https://docs.google.com/document/d/10ZiN68NxrJjtroPO9Rf6DPeDAbwBKTQrGkML6vg94JM/edit#heading=h.vbjoylhp5m9w | Project idea: Republican-focused AI outreach (REFO) - Google Docs\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.9ick7xqcwurb | RP’s AI Governance & Strategy team - 2-pager - Google Docs\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://docs.google.com/document/d/19EBpy5fZNf-kOEUbyT8JY_EfNMANkZC5PLNtq-7-QFs/edit#heading=h.apkacljs0r | Ashwin brief takes: where to go next with AI case studies? - Google Docs\n",
      "https://twitter.com/zachtratar/status/1694024240880861571 | Zach Tratar on X: \"Embra was one of the first AI Agents startups. Today, we are renaming AI Agents to AI Commands, and narrowing our focus away from autonomous agents. While autonomous agents took off in popularity, we found they were often unreliable for work, inefficient, and unsafe. 🧵\" / X\n",
      "https://slowboring.com/p/the-tragedy-of-the-manhattan-project | The tragedy of the Manhattan Project - by Matthew Yglesias\n",
      "https://twitter.com/mattsheehan88/status/1679419324925349889 | Matt Sheehan on Twitter: \"📢China just released its much-anticipated regulation on generative AI. 🧵below w/ my initial notes/reactions. TLDR: the final version is *much* less strict than the April draft version. This reflects a very active policy debate in 🇨🇳 + econ concerns. t.co/U27TqBApbL t.co/fblFYZ5bVb\" / Twitter\n",
      "https://founderandforcemultiplier.com/are-you-a-wartime-or-a-peacetime-chief-of-staff/ | Are You a Wartime or a Peacetime Chief of Staff? - The Founder & The Force Multiplier\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://twitter.com/DanHendrycks/status/1694024377350897901 | (1) Dan Hendrycks on X: \"Using this rule of thumb, let's say that an LLM has ~100 subjects to master like programming in many languages, chem, bio, etc. GPT-3 spent around ~5 days learning each subject GPT-3.5: 2 months GPT-4: 1 year GPT-4.5: 10 years---random expert-level GPT-5: 100 years---world class\" / X\n",
      "https://twitter.com/EAheadlines/status/1690624321117388800 | EA Lifestyles on Twitter: \"Get Ambitious Slowly t.co/AQ7ByM5jEe\" / X\n",
      "https://rethinkpriorities.github.io/longtermism-scale/ | Longtermism scale\n",
      "https://docs.google.com/presentation/d/1HuXNx7EGhrimuQwB6uBbSCLo2LpfS7M4KuUHmjkP6Lk/edit#slide=id.ge24bea79ec_0_130 | Rethink Priorities TAI Strategy - Google Slides\n",
      "https://twitter.com/frances__lorenz/status/1677278112516648963 | Frances Lorenz on Twitter: \"YES YES YES I'M SO HAPPY, YES, BANGER ALBUM, 10/10, NO SKIPS, YES t.co/6miD24xWd5\" / Twitter\n",
      "https://docs.google.com/document/d/1h8e4UTNPnFOwfmdhH24vPF6p2qij_J0yop1m9AkmN-A/edit#heading=h.v1qlzyj9qjyf | AI Technical Alignment overview - Google Docs\n",
      "https://joecarlsmith.com/2020/11/22/the-impact-merge | The impact merge - Joe Carlsmith\n",
      "https://tellingthefuture.substack.com/p/the-outside-view | The Outside View - by Robert de Neufville\n",
      "https://lesswrong.com/posts/YzdoNdfgfvXgC3wR4/google-deepmind-s-rt-2 | Google DeepMind's RT-2 — LessWrong\n",
      "https://bbc.com/news/technology-65779181 | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://contextual.ai/plotting-progress-in-ai/ | Plotting Progress in AI - Contextual AI\n",
      "https://forum.effectivealtruism.org/posts/idp4GEqWp24ocgfes/the-hinge-of-history-hypothesis-reply-to-macaskill-andreas | The Hinge of History Hypothesis: Reply to MacAskill (Andreas Mogensen) — EA Forum\n",
      "https://twitter.com/davidmanheim/status/1692975178047762750 | @davidmanheim@techpolicy.social on X: \"I think the world needs to be working on a moratorium on uncontrollable AI. This is a specific view which needs explanation, but one that I think is far less controversial than many would claim - so I want to publicly explain my thinking on the topic.\" / X\n",
      "https://blog.jakegloudemans.com/archive | Archive - Jake Gloudemans\n",
      "https://twitter.com/atrupar/status/1688991834167529473 | Aaron Rupar on Twitter: \"@SnapStream it's amazing that most of Trump's GOP competitors won't so much as criticize him while he's out here savaging them like this t.co/f7zozJkGL8\" / X\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://nature.com/articles/d41586-023-02491-y?utm_source=substack&utm_medium=email | Rules to keep AI in check: nations carve different paths for tech regulation\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://twitter.com/RFishBlueFish/status/1682577864447733762 | twitter.com/RFishBlueFish/status/1682577864447733762\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://metaculus.com/questions/11675/math-sota-ai-performance/ | What will be state-of-the-art performance on the MATH dataset on the following dates?\n",
      "https://docs.google.com/document/d/1hGGLSodwN_VopFioDahMkgslDm9-BQ4ckuqwwtcvjf0/edit | [Draft]: Rollbacks and shutdowns for deployed AI models\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | twitter.com/davidmanheim/status/1670146830741434372\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://twitter.com/Scholars_Stage/status/1695686427281952981 | T. Greer on X: \"Everyone is banging on this idea like it is crazy but it has historical precedent. This is more of less how medieval Iceland worked—a society that had laws, but no state to enforce them.\" / X\n",
      "https://theverge.com/c/23753704/ai-chatgpt-data-survey-research?utm_source=pocket-newtab-global-en-GB | Hope, fear, and AI\n",
      "https://docs.google.com/document/d/1DJOwiyhbeYgwOc40d1DAf7tLYO2DC-OkEoHKY6b6EAQ/edit#heading=h.qym1zou1p9i | Ben Garfinkel's takes on what it's good vs bad to share with aligned people at labs - Google Docs\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://twitter.com/sanjehorah/status/1686962805784891393 | twitter.com/sanjehorah/status/1686962805784891393\n",
      "https://nm.org/healthbeat/healthy-tips/how-many-steps-a-day-should-you-take-to-improve-your-heart-health | How Many Steps a Day Should You Take to Improve Your Heart Health?  Northwestern Medicine\n",
      "https://reddit.com/r/relationship_advice/comments/15bnst1/i_33m_have_only_been_with_one_woman_33f_for_my/ | (5) I (33M) have only been with one woman (33F) for my whole life (15 yr relationship). Midlife crisis is hitting me. : relationship_advice\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know/ | The Many Ways that Digital Minds can Know – Ryan Moulton's Articles\n",
      "https://foreignaffairs.com/ukraine/russia-war-beyond-ukraines-offensive | Beyond Ukraine’s Offensive\n",
      "https://lesswrong.com/posts/fARMR2tiyCem8DD35/managing-risks-of-our-own-work | Managing risks of our own work — LessWrong\n",
      "https://rychappell.substack.com/p/uncertain-optimizing-and-opportunity | Uncertain Optimizing and Opportunity Costs\n",
      "https://goodscience.substack.com/p/metascience-since-2012-a-personal | Metascience Since 2012: A Personal History - by Stuart Buck\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/rK3NgqLg3HHDzyLah/announcing-squiggle-hub | Announcing Squiggle Hub — EA Forum\n",
      "https://understandingai.org/p/large-language-models-explained-with | Large language models, explained with a minimum of math and jargon\n",
      "https://twitter.com/MatthewJBar/status/1689051157174657025 | Matthew Barnett on Twitter: \"I'm happy that people are rigorously testing LLM capabilities, but the claims in this paper are overstated. The central thesis seems to be rooted partly in mere anthropomorphism (\"if a human made these mistakes... I would conclude without any hesitation that they cannot reason\"). t.co/eT2eSpr5iJ\" / X\n",
      "https://docs.google.com/document/d/1dGNGZbJWkj8hT-hd6w0mdg6MpteZOaA_r9r8Lhd3I7I/edit#heading=h.fgx8olg8cwoz | Troy Perry (Omidyar Network) <> Renan, Jam (2023-08-02) - Google Docs\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective — LessWrong\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://github.com/natalieShapira/FauxPasEAI/blob/main/Paper/Faux_Pas_v.0.8.pdf | How Well Do Large Language Models Perform on Faux Pas Tests?\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid02NqUoTQVk9mGV8ujTFvihCSVLh55gay12khp4Cw92ieucSW4HTHiCfWvPhxgdzqHUl | We’re hosting a Barbenheimer party tomorrow... - Caroline Jeanmaire  Facebook\n",
      "https://rethinkpriorities.org/publications/shrimp-the-animals-most-commonly-used-and-killed-for-food-production | Shrimp: The animals most commonly used and killed for food production\n",
      "https://twitter.com/AnthropicAI/status/1688946685937090560 | twitter.com/AnthropicAI/status/1688946685937090560\n",
      "https://forum.effectivealtruism.org/posts/DdSszj5NXk45MhQoq/decision-making-and-decentralisation-in-ea | Decision-making and decentralisation in EA — EA Forum\n",
      "https://rethinkpriorities.org/publications/dimensions-of-pain-workshop-summary-and-updated-conclusions | “Dimensions of Pain” workshop: Summary and updated conclusions — Rethink Priorities\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://twitter.com/Jsevillamol/status/1695367641815286166 | Jaime Sevilla on X: \"I charitably interpret pdoom as \"this is the probability I am guessing I would assign to a more careful operationalization of the question of whether AI will lead to long lasting harm\" or similar.\" / X\n",
      "https://youtube.com/watch?app=desktop&v=VQjPKqE39No | How Will We Know When AI is Conscious? - YouTube\n",
      "https://youtube.com/results?search_query=caroline+jeanmaire | caroline jeanmaire - YouTube\n",
      "https://twitter.com/JeffLadish/status/1690996746728640513 | Jeffrey Ladish on Twitter: \"I think we're about to see a huge flood of very realistic-seeming bots across most platforms. Several language models today are good enough to fool nearly everyone, myself included, into thinking they're real people in some contexts. So what are viable defenses?\" / X\n",
      "https://docs.google.com/document/d/11-4fkBN6nydyE1EKEYj4d9DNXN398iu-b-rLfTrS3qQ/edit?pli=1 | 2023 RP application to Open Philanthropy for AW 2024 - 2026\n",
      "https://twitter.com/Jsevillamol/status/1675894365086941185 | twitter.com/Jsevillamol/status/1675894365086941185\n",
      "https://docs.google.com/document/d/1Km37KtOAut89_ZxTPg0zlk7KgrNDlL1REiQBn26uJqs/edit | Yet another Caro doc for 2023 Jul 22 meeting - Google Docs\n",
      "https://morethantwo.com/polytips.html | More Than Two  Dos and don'ts for polyamory\n",
      "https://docs.google.com/document/d/1hLQ4Ce5raaPVUGq0_V1qPdcnn29kJ081w4XE0n0lHw4/edit#heading=h.bd3vtecb3ctx | Proposal: Information Security Fund - Google Docs\n",
      "https://politico.com/news/magazine/2023/07/20/vivek-ramaswamy-pete-buttigieg-00107193 | Opinion  Get Ready for the Vivek Ramaswamy Moment - POLITICO\n",
      "https://twitter.com/labenz/status/1683947449323229186 | Nathan Labenz on Twitter: \"\"I have your child\" \"he is currently safe\" \"My demand is ransom of $1 million\" \"any attempt to involve the authorities or deviate from my instructions will put your child's life in immediate danger\" \"Await further instructions\" \"Goodbye\" WTF @BelvaInc? An important 🧵👇 t.co/f7gro7M6Cx\" / Twitter\n",
      "https://theinsideview.ai/markus | Markus Anderljung on AI Policy\n",
      "https://lesswrong.com/posts/BAqvAvPC7GiZhTyR3/dating-roundup-1-this-is-why-you-re-single | Dating Roundup #1: This is Why You’re Single — LessWrong\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://forum.effectivealtruism.org/posts/Ykqh8ku7NHN9CGkdC/modeling-the-impact-of-ai-safety-field-building-programs | Modeling the impact of AI safety field-building programs — EA Forum\n",
      "https://docs.google.com/document/d/1TOCUCg8oTxTPBEuPu5Vk41578kLuNbcm7XXkSkYrxR0/edit | CEA AI Issue Framing\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ — EA Forum\n",
      "https://google.com/search?q=bridgerton+season+3&rlz=1C5CHFA_enGB1058GB1058&oq=bridgertro&aqs=chrome.2.69i57j46i10i433i512j0i10i433i512l2j46i10i433i512j0i10i433i512l4.2814j0j1&sourceid=chrome&ie=UTF-8 | bridgerton season 3 - Google Search\n",
      "https://morethantwo.com/polyfairness.html | More Than Two  Polyamory and Fairness\n",
      "https://80000hours.org/career-reviews/ai-safety-researcher/ | AI safety technical research - Career review\n",
      "https://docs.google.com/document/d/12g1eG74WT-NbX-e6jNDrpRxDwhgI-I6taAz-fYt4f7o/edit | Problems with MWs given moral uncertainty\n",
      "https://lesswrong.com/posts/gzJ7QNhd3tCLkbmYC/my-favorite-ai-governance-research-this-year-so-far | My favorite AI governance research this year so far — LessWrong\n",
      "https://theinsideview.ai/simeon | Siméon Campos on Short Timelines\n",
      "https://twitter.com/VivianChang36/status/1686754133318217728 | Ketian Vivian Zhang on Twitter: \"My first book, China's Gambit, is available for pre-order at Cambridge University Press. t.co/eu010uPfs6 t.co/FgqhaaoKce\" / X\n",
      "https://reddit.com/r/BDSMerotica/comments/q3jfdl/punishment_maledom_femalesub_bdsm_spanking/ | (2) Punishment [MaleDom] [Femalesub] [BDSM] [spanking] [forcedorgasm] [anal]. : BDSMerotica\n",
      "https://twitter.com/lxrjl/status/1694970142050877830 | alex lawsen on X: \"Compute progress is happening so quickly that we need a better unit of measurement for the rate of progress. This might be especially important in worlds where AI progress speeds up the rate of progress itself, as doubling times could get very low. What should we use ?🧵👇\" / X\n",
      "https://docs.google.com/document/d/1Sg9jfESsMx2T8Q16UoKOnIR0qba5gJ5J81zjtPXB0LQ/edit#heading=h.95onznz2devl | 1-pager: AIXR advocacy and lobbying info-sharing by Rethink Priorities XST - Google Docs\n",
      "https://freakonomics.com/podcast/new-technologies-always-scare-us-is-a-i-any-different/?utm_source=substack&utm_medium=email | New Technologies Always Scare Us. Is A.I. Any Different? - Freakonomics\n",
      "https://paxfauna.org/ | Pax Fauna\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://twitter.com/HaydnBelfield/status/1694383669379493953 | Haydn Belfield on X: \"Have just been at the first day of the @ERA_Cambridge symposium, with Fellows presenting their research over the past 2 months Blown away by the quality of research - methodological rigour and clear theories of impact They're the future of the global catastrophic risk field\" / X\n",
      "https://linkedin.com/pulse/elevation-human-work-reid-hoffman/ | (99+) The elevation of human work  LinkedIn\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://theguardian.com/technology/2023/jul/07/five-ways-ai-might-destroy-the-world-everyone-on-earth-could-fall-over-dead-in-the-same-second?CMP=Share_iOSApp_Other | Five ways AI might destroy the world: ‘Everyone on Earth could fall over dead in the same second’  Artificial intelligence (AI)  The Guardian\n",
      "https://forum.effectivealtruism.org/posts/xu45Sq8gZ4iy9iHXa/nuclear-safety-security-why-doesn-t-ea-prioritize-it-more | Nuclear safety/security: Why doesn't EA prioritize it more? — EA Forum\n",
      "https://twitter.com/JeffLadish/status/1688981226663841798 | Jeffrey Ladish on Twitter: \"Who is thinking about threat models and policy about AI impacts on elections? Language models seem like incredibly powerful tools for information warfare (both attack and defense), and I'm curious to learn who has been trying to game this out in advance of the US 2024 election\" / X\n",
      "https://facebook.com/photo/?fbid=10230872885743855&set=a.4146526419648 | facebook.com/photo/?fbid=10230872885743855&set=a.4146526419648\n",
      "https://lesswrong.com/posts/T5WFE734wHzwMYJaB/partial-transcript-of-recent-senate-hearing-discussing-ai-x | Partial Transcript of Recent Senate Hearing Discussing AI X-Risk — LessWrong\n",
      "https://twitter.com/messages/25776739-128178067 | twitter.com/messages/25776739-128178067\n",
      "https://nytimes.com/2023/07/25/opinion/karp-palantir-artificial-intelligence.html | Our Oppenheimer Moment: The Creation of A.I. Weapons\n",
      "https://morethantwo.com/socialfallacies.html | More Than Two  Social Fallacies of Polyamory\n",
      "https://twitter.com/cassidyknelson/status/1683748676500434946 | Cassidy Nelson on Twitter: \"AI is introducing significant biosecurity risks. The just-released statement by @TheHelenaGroup on the back of an expert meeting summarises some of the key issues and solutions that are urgently needed. Highly recommend! t.co/YGKmYOaTd0\" / Twitter\n",
      "https://anthropic.com/index/frontier-threats-red-teaming-for-ai-safety | Frontier Threats Red Teaming for AI Safety\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://cooperativeai.com/job-listing/managing-director | Cooperative AI\n",
      "https://lesswrong.com/posts/4gDbqL3Tods8kHDqs/limits-to-legibility | Limits to Legibility — LessWrong\n",
      "https://forum.effectivealtruism.org/posts/dqpR2E4Bw9KEEaWoK/announcing-the-existential-infosec-forum | Announcing the Existential InfoSec Forum — EA Forum\n",
      "https://twitter.com/mealreplacer/status/1681244538436829184 | twitter.com/mealreplacer/status/1681244538436829184\n",
      "https://twitter.com/yanda_chen_/status/1681412273758408704 | twitter.com/yanda_chen_/status/1681412273758408704\n",
      "https://microsoft.com/en-us/ai | Artificial Intelligence Solutions  Microsoft AI\n",
      "https://joecarlsmith.com/2021/07/19/in-search-of-benevolence-or-what-should-you-get-clippy-for-christmas | In search of benevolence (or: what should you get Clippy for Christmas?) - Joe Carlsmith\n",
      "https://facebook.com/groups/1781724435404945/?multi_permalinks=3542137902696914&hoisted_section_header_type=recently_seen | Bountied Rationality  Facebook\n",
      "https://voyager.minedojo.org/assets/documents/voyager.pdf | voyager.pdf\n",
      "https://docs.google.com/document/d/1SsZq3IB0iKUUw7NJSWaprSkCC5WZgktU0Tx4qGlepo0/edit | Safety Culture - Framing Thoughts\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | twitter.com/peterwildeford/status/1671174311283924993\n",
      "https://metaculus.com/questions/18229/2024-third-party-republican/ | 2024 Third Party Republican?  Metaculus\n",
      "https://joshbarro.com/ | (1) Very Serious  Josh Barro  Substack\n",
      "https://twitter.com/srush_nlp/status/1681796343839305728 | Sasha Rush on Twitter: \"Recommendation to subscribe to t.co/gpDvb9GZqz @natolambert 's blog. Detailed, clear, and technical descriptions of the LLM + RL space.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KmiR4T8ha7LbA8eJn/dyusha-s-quick-takes?commentId=pn5724GNby3mqday7 | dyusha's Quick takes — EA Forum\n",
      "https://morethantwo.com/polymyths.html | More Than Two  Myths About Polyamory\n",
      "https://docs.google.com/document/d/1fJndg74yOJz0SsTHztV2uSpT152cnkd3y752Uj2bjKg/edit#heading=h.z4a1n8yhj2ak | 2023 Monthly Leadership Meeting - Google Docs\n",
      "https://docsend.com/view/dvnnx4mu9xx9k99k | Crowdvocate long form\n",
      "https://google.com/search?q=glassworks+ii+floe&rlz=1CDGOYI_enUS715US715&oq=glassworks+ii+floe&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiiBNIBCDQ1OTJqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | glassworks ii floe - Google Search\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://tanay.substack.com/p/big-tech-x-generative-ai-q2-update | Big Tech x Generative AI Q2 Update - by Tanay Jaipuria\n",
      "https://twitter.com/dylanmatt/status/1678390762759913472 | dylan matthews on Twitter: \"Highly accurate forecasters are more optimistic about human extinction from AI or pandemics than subject matter experts That made me more optimistic too but your mileage may vary! t.co/gYaCrQ15Zg\" / Twitter\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://twitter.com/lukeprog/status/1681322363684814849 | twitter.com/lukeprog/status/1681322363684814849\n",
      "https://docs.google.com/document/d/1wpWUl62_4mNbSohnss57qtraxcArrTHY4NoRTDh7fSw/edit | Caro-Peter: Oxford, The Magical Retreat - Google Docs\n",
      "https://docs.google.com/document/d/1NyoN5wVQvJemeukV60T1LTUqTOguP6fRVvUW6FhVRg8/edit#heading=h.qhot0f2kle3x | Marie's DC trip – meeting notes masterdoc - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1xSnY6TNAuALyS_NyTD5ETbv5PtKhbz4XEauTtrDPu-Q/edit#gid=0 | Marie DC/NYC August 2023 – outreach tracker - Google Sheets\n",
      "https://asteriskmag.com/issues/02/what-comes-after-covid | What Comes After COVID—Asterisk\n",
      "https://bayesshammai.substack.com/p/model-care-execution | Model, Care, Execution - by Ricki Heicklen - Bayes Shammai\n",
      "https://someunpleasant.substack.com/p/lets-go-liberty | Let's Go Liberty\n",
      "https://twitter.com/davidmanheim/status/1692983351882211510 | twitter.com/davidmanheim/status/1692983351882211510\n",
      "https://morethantwo.com/coupleprivilege.html | More Than Two  Polyamory and Couple Privilege\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://docs.google.com/document/d/1ysnPyONduClyhRxFapZ8Wupn-B7-kGHvlXm5IOxw9ug/edit#heading=h.ieytf2ylg1lh | Hiring SOP - Managers, Committee and Operations Guide [living document] - Google Docs\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://twitter.com/GretchenMarina/status/1696702861952926179 | Gretchen @gretchenmarina@mastodon.social on X: \"Hadn't seen t.co/Bh4Y0OmH7k yet &amp; using it as an excuse to start a thread of safety-relevant (and in this case, also contestational) AI examples! 🧵 1/n t.co/lHO58vxKna\" / X\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Collapse/ | Collapse  FTX GUCEM\n",
      "https://twitter.com/ajeya_cotra/status/1678938650586001409 | Ajeya Cotra on Twitter: \"Four reasons recent LLM progress makes me think extreme risks could emerge soon 🧵\" / Twitter\n",
      "https://morethantwo.com/polyamory.html | More Than Two  What, like, two girlfriends?\n",
      "https://lesswrong.com/posts/SdkexhiynayG2sQCC/ai-forecasting-two-years-in | AI Forecasting: Two Years In — LessWrong\n",
      "https://manifund.org/projects/shrimp-welfare-project---special-program---place-electric-stunners-at-selected-producers?tab=comments | Shrimp Welfare Project - Special Program  Manifund\n",
      "https://google.com/search?q=omgyes&rlz=1C5CHFA_enGB1058GB1058&oq=omgyes&aqs=chrome..69i57j0i512l4.2315j0j1&sourceid=chrome&ie=UTF-8 | omgyes - Google Search\n",
      "https://washingtonpost.com/technology/2023/08/08/ai-red-team-defcon/?utm_source=substack&utm_medium=email | AI 'red teams' race to find bias and harms in chatbots like ChatGPT - The Washington Post\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://twitter.com/PradyuPrasad/status/1695128714152120734 | Pradyumna on X: \"I spoke to @krishnanrohit about his case *against* AI x-risk! Some highlights: - Why he thinks instrumental convergence is unlikely to happen - The value of incrementalism in AI policy - Why AI “timelines” are not as meaningful as you think t.co/psToFmh3MC\" / X\n",
      "https://docs.google.com/document/d/1hqit18idYVMmBHbcGgSUccCZqIPphZ-Sdqd9wZ024fM/edit#heading=h.2an3fqbhybwy | Quick evaluation of Bill's competencies (Ashwin, June 2023) - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/vqPy7TkBbzrAkxCf7/updates-to-the-flow-of-funding-in-ea-movement-building-post | Updates to the flow of funding in EA movement building post — EA Forum\n",
      "https://linkedin.com/pulse/stepping-up-ctos-top-tips-transitioning-from-vp-engineering-dunn/ | (27) Stepping up: CTOs’ top tips on transitioning from VP Engineering  LinkedIn\n",
      "https://everydayfeminism.com/2016/02/polyamorous-dealing-jealousy/ | Polyamorous Dating: 5 Tips For Dealing With Jealousy - Everyday Feminism\n",
      "https://google.com/search?sca_esv=558541893&rlz=1CDGOYI_enUS715US715&hl=en-US&q=The+Real+Campers+of+Shallow+Lake&tbm=isch&source=lnms&sa=X&ved=2ahUKEwjFn4yEiuuAAxXmFlkFHVd0BbUQ0pQJegQIChAB&biw=428&bih=751&dpr=3 | The Real Campers of Shallow Lake - Google Search\n",
      "https://docs.google.com/spreadsheets/d/1hUVfvY0PUD8NzOnt7s7UPpHls6M-ypRESY9voF-MKfM/edit#gid=508560312 | GHD ROI scrap - Google Sheets\n",
      "https://rescuetime.com/rtx/overview/for/the/day | RescueTime - Overview\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://forum.effectivealtruism.org/posts/EhPKbX5JkwxvhfGhC/link-post-ai-should-be-terrified-of-humans | [link post] AI Should Be Terrified of Humans — EA Forum\n",
      "https://evite.com/event/01213UVRMYOQFEPEWEPOF747GTU3EI/?gid=028ERGJHWYLUZYA54EPOF75ZLDU5IY&emhm5=7124688b9c89a1ba55205b881c080771&emhs1=9454c2641193aa6507e3d9a556ca5376864844a7&emhs2=53148bb72992717b638418d71150d850ce60abb38e78ff8ad805df8a955eeddc&utm_campaign=view_invitation_bt&utm_content=ProjectBeauty_Email_T1_V2%3A1&utm_medium=email&utm_source=GUEST_INVITE_EVENT | Evite: Online Invitations, Greeting Cards & Party Ideas\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://docs.google.com/document/d/1ZZUpQwqJQ2BaZGA7uvUfuf0HwvBvro4EIKDiumYuxp8/edit | Rollbacks and shutdowns for deployed AI models\n",
      "https://docs.google.com/document/d/1miPCZ4z7yjUnnYMGG8dp3M3L6x5_i7w_ttynW14y2jg/edit#heading=h.rs6pwjwea99k | AIGS comms strategy - initial notes - Google Docs\n",
      "https://morethantwo.com/prisonersdilemma.html | More Than Two  Your Partner's Other Partners\n",
      "https://joecarlsmith.com/2022/01/30/on-infinite-ethics | On infinite ethics - Joe Carlsmith\n",
      "https://twitter.com/dylanmatt/status/1686749435210993665 | dylan matthews on Twitter: \"ARC Evals made a GPT-4 agent and asked it to get the Harvard logins of a professor. This was the phishing scheme it came up with. Obviously didn't work, but it seems to be getting pretty close. t.co/p1CEXZDSby t.co/LSp4vQLyH6\" / X\n",
      "https://rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/ | These Women Warned Of AI’s Dangers And Risks Long Before ChatGPT – Rolling Stone\n",
      "https://twitter.com/acritschristoph/status/1673034164973764608 | Alex Crits-Christoph @alexcc@mstdn.science on Twitter: \"There has been much recent misinformation about COVID-19 origins that we can now debunk. A thread on 2 topics: A. How the ODNI report debunks multiple lab origins rumors. B. Where these inaccurate media reports originated, and why we knew they were wrong. t.co/5XMugelzoz\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/Yq6yKgBtaMgkgyetm/an-ea-s-guide-to-visiting-new-york-city | An EA's Guide to Visiting New York City — EA Forum\n",
      "https://twitter.com/admcrlsn/status/1686733192714145792 | twitter.com/admcrlsn/status/1686733192714145792\n",
      "https://wikiwand.com/en/Hijack_(TV_series) | Hijack (TV series) - Wikiwand\n",
      "https://lesswrong.com/posts/Ce82o8mbBfH9N3Jes/evaluating-gpt-4-theory-of-mind-capabilities | Evaluating GPT-4 Theory of Mind Capabilities — LessWrong\n",
      "https://twitter.com/lxrjl/status/1679423239351664643 | alex lawsen on Twitter: \"@jeremyphoward @ajeya_cotra What sorts of things that current models can't do feel most reassuring/would cause you to change your mind most strongly if they changed?\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/sBJLPeYdybSCiGpGh/impact-obsession-feeling-like-you-never-do-enough-good | Impact obsession: Feeling like you never do enough good — EA Forum\n",
      "https://docs.google.com/document/d/19f2eqUx3zP8Z8234poDJmNid1ot4i9cTViPNBI6se6g/edit#heading=h.e4yozfynvf7 | Pinpoint Factsheet: Rubrics & Scoring - Google Docs\n",
      "https://twitter.com/OwainEvans_UK/status/1691636382446600439 | Owain Evans (Berkeley) on Twitter: \"ARC Evals report on their evaluations of whether recent LLMs can acquire resources (eg. bitcoin) and copy themselves across the internet. t.co/CL4htnErRG t.co/6zlRBqvOlO\" / X\n",
      "https://twitter.com/yoavgo/status/1672647224696684545 | (((ل()(ل() 'yoav))))👾 on Twitter: \"\"in 1 hour\"? these MIT students are kinda slow... t.co/2Le4l7Fq0V\" / Twitter\n",
      "https://nytimes.com/2023/07/23/opinion/china-russia-us-cold-war.html | Vladimir Putin Is Still Useful to Xi Jinping. Until He Isn’t.\n",
      "https://docs.google.com/document/d/1XmptIBukbISLXYmfz_BYb5OExrZB2yi4AsndJ0-qqQA/edit#heading=h.p6arli3f7jlb | Insights from Jack Clark's Newsletters - Google Docs\n",
      "https://80000hours.org/podcast/episodes/holden-karnofsky-how-ai-could-take-over-the-world/ | Holden Karnofsky on how AIs might take over even if they're no smarter than humans, and his four-part playbook for AI risk - 80,000 Hours\n",
      "https://twitter.com/random_walker/status/1672244743219077123 | twitter.com/random_walker/status/1672244743219077123\n",
      "https://arxiv.org/abs/2001.00463 | The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI Research Reduce Misuse?\n",
      "https://truity.com/blog/enneagram-type/type-two | Type Two  True You Journal\n",
      "https://docs.google.com/document/d/1SUgGftOMKO4GVSBzOa3wMDcAhM4UrOGAjYVPnALxKY4/edit#heading=h.ldo1rytwm7ve | Let’s incentivise AIs to prevent AI takeover\n",
      "https://twitter.com/ajeya_cotra/status/1682166280080719872 | twitter.com/ajeya_cotra/status/1682166280080719872\n",
      "https://forum.effectivealtruism.org/posts/zYSAFtjasxsfm3nmh/cost-effectiveness-of-student-programs-for-ai-safety | Cost-effectiveness of student programs for AI safety research — EA Forum\n",
      "https://facebook.com/katxiowoods/posts/pfbid0xeoL56nksybJz9B2HdeTuYbwQNvT775xesm1yXZAEaEFQNes5WHoLa9BXWRoUzjQl | facebook.com/katxiowoods/posts/pfbid0xeoL56nksybJz9B2HdeTuYbwQNvT775xesm1yXZAEaEFQNes5WHoLa9BXWRoUzjQl\n",
      "https://docs.google.com/document/d/1E7kOVl710IUeryiKSLMSifzvJmb-ONwfEfaWDQ4vXJk/edit | Risk-Weighted Expected Utility Implementation Methodology - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/PChvstTKnf6iAP36F/effective-altruism-and-the-strategic-ambiguity-of-doing-good | Effective Altruism and the strategic ambiguity of ‘doing good’ — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EHTynQaSN8ubjCbm9/how-much-is-reducing-catastrophic-and-extinction-risk-worth | How much is reducing catastrophic and extinction risk worth, assuming XPT forecasts? — EA Forum\n",
      "https://poly-coach.com/polyamory-relationship-counseling/how-do-i-deal-with-jealousy-in-my-relationships/ | How Do I Deal With Jealousy In My Relationships? - Poly-Coach\n",
      "https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety | A Field Guide to AI Safety—Asterisk\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://twitter.com/james_acton32/status/1684557136611753989 | twitter.com/james_acton32/status/1684557136611753989\n",
      "https://twitter.com/ZimingLiu11/status/1692554285035171943 | Ziming Liu on X: \"Deep learning has many mysterious phenomena, and grokking is one of the extreme. Want to catch up with the grokking literature? I've compiled a one-page summary of what's going on in the grokking world. Enjoy! :-) t.co/yKvFofkKRu t.co/Yiquz3EOj3\" / X\n",
      "https://wired.com/story/the-making-of-the-atomic-bomb-artificial-intelligence/ | The AI Doomsday Bible Is a Book About the Atomic Bomb  WIRED\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://docs.google.com/document/d/1BnI-FYzz0Coti2nV5t63w8Ga6WWiFSK_kYjE9T2SjLc/edit#heading=h.dcdsb7ob0lnc | * COLLECTION: Positive feedback / signals / praise for XST - Google Docs\n",
      "https://wikiwand.com/en/Sally%E2%80%93Anne_test | Sally–Anne test - Wikiwand\n",
      "https://twitter.com/Simeon_Cps/status/1676687523853094914 | Siméon on X: \"One thing which IMO is a major dealbreaker in OpenAI's meta-alignment plan: 1. Alignment is likely bottlenecked by the last few bits of intelligence, otherwise we wouldn't be where we are (i.e. 10y in and we have no idea about how we're going to achieve that) 2. Capabilities is…\" / X\n",
      "https://estimaker.app/ai | Estimaker\n",
      "https://lesswrong.com/posts/NRbkiGtekQLAfoiLr/learning-as-you-play-anthropic-shadow-in-deadly-games | Learning as you play: anthropic shadow in deadly games — LessWrong\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://economist.com/special-report/2023/07/03/the-war-in-ukraine-shows-how-technology-is-changing-the-battlefield | The war in Ukraine shows how technology is changing the battlefield\n",
      "https://twitter.com/Jsevillamol/status/1693559442061590692 | Jaime Sevilla on X: \"The parity hypothesis is an important mystery to think about to understand the development of AI, and economic growth in general. See @EgeErdil2 take a stab at it here. t.co/IxJnGpvmQL\" / X\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://schoolofsquirt.com/blog/page/2/ | Blog - Page 2 of 13 - School Of Squirt\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://fivethirtyeight.com/features/mississippi-governor-lieutenant-governor-primary-election-2023-preview/ | Could A Democrat Actually Win Mississippi’s Governorship?  FiveThirtyEight\n",
      "https://sci-hub.wf/10.1017/s1049096520001377 | Sci-Hub  State-Level Forecasts for the 2020 US Presidential Election: Tough Victory Ahead for Biden. PS: Political Science & Politics, 54(1), 77–80  10.1017/s1049096520001377\n",
      "https://twitter.com/davidmanheim/status/1673293480762699776 | @davidmanheim@techpolicy.social on Twitter: \"Building a Safety Culture for AI - 🧵 I wrote a new paper. Link: t.co/MI2MRl9Eho To start, culture matters, and the culture in AI is not one that currently treats risks and failures seriously. As AI becomes even more widely used and powerful, that's very bad.\" / Twitter\n",
      "https://washingtonpost.com/opinions/2023/08/16/ai-danger-regulation-united-states/?utm_source=substack&utm_medium=email | Opinion  A simple way for the United States to regulate powerful AI models - The Washington Post\n",
      "https://twitter.com/jungofthewon/status/1681428929926823949 | Jungwon on Twitter: \"Really exciting to see others extending factored cognition &amp; process supervision!\" / Twitter\n",
      "https://openai.com/blog/how-should-ai-systems-behave | How should AI systems behave, and who should decide?\n",
      "https://globalprioritiesinstitute.org/nick-beckstead-and-teruji-thomas-a-paradox-for-tiny-probabilities-and-enormous-values/ | A paradox for tiny probabilities and enormous values - Nick Beckstead (Open Philanthropy Project) and Teruji Thomas (Global Priorities Institute, Oxford University) - Global Priorities Institute\n",
      "https://forum.effectivealtruism.org/posts/rLiCjrAv9D8chCoG5/dimensions-of-pain-workshop-summary-and-updated-conclusions | “Dimensions of Pain” workshop: Summary and updated conclusions\n",
      "https://arxiv.org/abs/2308.01404 | [2308.01404] Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models\n",
      "https://wikiwand.com/en/Abdication_of_Edward_VIII | Abdication of Edward VIII - Wikiwand\n",
      "https://dwarkeshpatel.com/p/carl-shulman-2#details | Carl Shulman (Pt 2) - AI Takeover, Bio & Cyber Attacks, Detecting Deception, & Humanity's Far Future\n",
      "https://latent.space/p/ai-engineer | The Rise of the AI Engineer - by swyx - Latent Space\n",
      "https://lesswrong.com/posts/fRSj2W4Fjje8rQWm9/thoughts-on-sharing-information-about-language-model | Thoughts on sharing information about language model capabilities — LessWrong\n",
      "https://jobs.lever.co/redwoodresearch/caed16e9-1c03-4d2e-aa90-80dc2ca90d20 | Constellation Head of Business Operations\n",
      "https://docs.google.com/document/d/1I6PEBNI1qC2ezMw_Tzi-4u098_5QjAn-hR61gRr6Tjc/edit | LTFF application for XST 2023-06 - Google Docs\n",
      "https://twitter.com/robertwiblin/status/1671832924771983368 | (1) Robert Wiblin on Twitter: \"Carl Shulman's interview on The Lunar Society Podcast is one of the best things produced on AI this year. Challenging and assumes substantial existing knowledge — but mandatory listening for people sincerely trying to understand these issues IMO: t.co/uc25oBnIV5\" / Twitter\n",
      "https://independent.co.uk/news/uk/politics/rishi-sunak-artificial-intelligence-ai-regulation-b2401922.html?utm_source=substack&utm_medium=email | Rishi Sunak warned of ‘12 risks of AI’ amid calls for urgent regulation  The Independent\n",
      "https://google.com/search?q=outer+wilds | Outer Wilds\n",
      "https://reddit.com/r/polyamory/comments/su5n40/monopoly_relationship_boundaries/ | Reddit - Dive into anything\n",
      "https://morethantwo.com/polymistakes.html | More Than Two  Common mistakes in poly relationships\n",
      "https://docs.google.com/document/d/1cvmPmzq3Cn52UNKN4uzUMgXhERFGmob6e6cSILdACik/edit#heading=h.osty8jeclpyn | Shrimp Welfare: A summary of lessons learned and future directions\n",
      "https://facebook.com/RethinkPriorities/posts/pfbid0mQA5pYeyuMQCbTwoNxvmZfpph4EajwG5xqs8WeebisE2pDJScMxKHYJeLMUP3P3xl | RP partner @open_phil is one of the largest... - Rethink Priorities  Facebook\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://manifund.org/rounds/regrants?tab=projects | manifund.org/rounds/regrants?tab=projects\n",
      "https://docs.google.com/document/d/1FawqcfCuZqkfZBnjPF4SIgciHTyEz5qElYpYT_jN1mo/edit#heading=h.r1usdwqumjih | Risk-uncertainty in regulatory agencies\n",
      "https://forum.effectivealtruism.org/posts/WJGsb3yyNprAsDNBd/ea-orgs-need-to-tabletop-more | EA orgs need to tabletop more. — EA Forum\n",
      "https://docs.google.com/document/d/1irLA7VAE4Zk5uilt3R4RxJZDKCQR4yKskGPOoKaBp34/edit#heading=h.ozcv1fnsad2k | How AIGS intends to handle (appearances of) relations with labs, political parties, and AI ethics\n",
      "https://investopedia.com/articles/investing/030613/secret-finances-vatican-economy.asp | The Secret Finances Of The Vatican Economy\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://lesswrong.com/posts/atxoviwLcPJPdYMqo/if-we-had-known-the-atmosphere-would-ignite | If we had known the atmosphere would ignite — LessWrong\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://docs.google.com/document/d/1z5Ltl2dDQlD0fd39wBK0Dffg7Cm4bKfj8XSXzwJrrW0/edit | [Public] China workstream two-pager - Google Docs\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://docs.google.com/document/d/1CTOTiOhh0uZw7wwwqbFDpq7qakMVEUkAtEecVSfRmcU/edit#heading=h.k19pb4a7ch8m | Expertise within licensing authorities\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://twitter.com/lxeagle17/status/1681792966934040578 | Lakshya Jain on Twitter: \"FWIW, Bill Huizenga faced no credible opposition this time around en route to a 12 point win in a Trump +4 seat that Whitmer won by 1. After controlling for incumbency/spending/etc we (@SplitTicket_) find that he probably should have won by 10 in #MI04. Strong, but not unbeatable t.co/nXzYxhoDg0\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1676658747094208512 | twitter.com/norabelrose/status/1676658747094208512\n",
      "https://twitter.com/Simeon_Cps/status/1693886397046718553 | (1) Siméon on X: \"And what if OpenAI is not able to convince everyone to coordinate and all chill out in time or if it takes like 7 more years to solve the relevant alignment problems? Well, we're done. That's a core reason why OpenAI's plan is dangerous and should be a plan B or C, not a plan…\" / X\n",
      "https://fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://twitter.com/daniel_271828/status/1620596689555058689 | twitter.com/daniel_271828/status/1620596689555058689\n",
      "https://docs.google.com/document/d/1Tsp_wK6GoJAgUCYoZmMN_H7vy3eG3r68IUAWjg5Qy6Y/edit | Management Copy - Bob Fischer 2023 May/June - RP Performance Evaluation - Google Docs\\\n",
      "https://arxiv.org/pdf/2308.09045.pdf | 2308.09045.pdf\n",
      "https://reddit.com/r/BDSMerotica/comments/p0opup/my_master_went_from_sharing_me_with_his_friends/ | (2) My master went from sharing me with his friends to renting me out. : BDSMerotica\n",
      "https://twitter.com/sandersted/status/1678283887263506432 | twitter.com/sandersted/status/1678283887263506432\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://theatlantic.com/international/archive/2022/10/taiwan-microchip-supply-chain-china/671615/ | The U.S. Has a Microchip Problem. Safeguarding Taiwan Is the Solution. - The Atlantic\n",
      "https://docs.google.com/document/d/1B-VGwlk-EWDWeNnMxtOm4jEsKlGfYh5Iuufijm8qGZ0/edit | [shared] Good actions for labs - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1t_7AkXxH1IIQC6TuQFSrLkNoQOwDRWU1ICDbt-G1XHc/edit#gid=760967507 | DC team capacity planning - Google Sheets\n",
      "https://ndupress.ndu.edu/Media/News/News-Article-View/Article/3471053/discerning-the-drivers-of-chinas-nuclear-force-development-models-indicators-an/ | Discerning the Drivers of China’s Nuclear Force Development: Models, Indicators, and Data > National Defense University Press > News Article View\n",
      "https://reddit.com/r/BDSMerotica/comments/p40u7s/how_losing_a_bet_with_my_neighbors_turned_me_into/ | (2) How losing a bet with my neighbors turned me into a total whore (part 1 of ?) [F/F/f] [huml] : BDSMerotica\n",
      "https://nsf.gov/pubs/2023/nsf23600/nsf23600.htm | nsf.gov/pubs/2023/nsf23600/nsf23600.htm\n",
      "https://twitter.com/davidmanheim/status/1688939478180651010 | @davidmanheim@techpolicy.social on Twitter: \"Humans don't display general intelligence: \"First, it is not accurate to say without qualification that 'humans can reason,' certainly not in the sense that we can randomly pluck any person from the street and expect them to reliably perform normatively correct reasoning.\"\" / X\n",
      "https://hollyelmore.substack.com/p/the-technology-bucket-error | The “technology\" bucket error - Holly Elmore\n",
      "https://docs.google.com/document/d/17kWbF4sWEaQengbahms4W5zVMD_VeVBDiUxXf2Zt_rA/edit | Federal Select Agents Program ~ case study for OAI - Emma Williamson - Google Docs\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://medium.com/@nitindharny/from-busy-to-productive-time-management-tips-for-engineering-managers-3de9f74d2c72 | From Busy to Productive: Time Management Tips for Engineering Managers  by Nitin Dhar  Medium\n",
      "https://asteriskmag.com/issues/01/modeling-the-end-of-monkeypox | Modeling the End of Monkeypox—Asterisk\n",
      "https://docs.google.com/document/d/1rRz9lyfEvZji46PRxXI8YH6XBJ114c0mJag86aF--8Y/edit | 2023-Jul-05 - Crisis Wednesday - Overview and Plan - Google Docs\n",
      "https://lesswrong.com/posts/JteNtoLBFZB9niiiu/the-smallest-possible-button | The smallest possible button — LessWrong\n",
      "https://reddit.com/r/datingoverthirty/comments/15fvhgb/dating_men_with_kids/ | (3) Dating men with kids…. : datingoverthirty\n",
      "https://docs.google.com/document/d/1wehezUuPcfHwcAiJGlnVjIx_SFxKu5Qg-ADYOfH04LI/edit#heading=h.ebmljdh2jjem | *Project idea research: Weekly coordination meeting - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/9tG7daTLzyxArfQev/era-s-theory-of-change | ERA's Theory of Change — EA Forum\n",
      "https://docs.google.com/document/d/1gN2WmfPcWEdvuFfGAS7gwDjE4NQo1vxZWjcSvC_pqeE/edit | Notes for Caro conversation on June 26 - Google Docs\n",
      "https://metaculus.com/questions/17431/trump-documents-case-sentence-if-convicted/ | Trump documents case sentence if convicted  Metaculus\n",
      "https://metaculus.com/questions/17904/next-starship-orbital-test-flight/#comment-131670 | metaculus.com/questions/17904/next-starship-orbital-test-flight/#comment-131670\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments\n",
      "https://psychologytoday.com/gb/blog/relational-intimacy/202109/managing-jealousy-in-polyamorous-relationships?amp | Managing Jealousy in Polyamorous Relationships  Psychology Today United Kingdom\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://docs.google.com/document/d/1NaDQWBLJwqBJAfJJ4sjmioZNk_ULSdkGOc_lj085ACg/edit#heading=h.sja5ou1zlohi | NHTSA - case study for OAI - Bill Anderson-Samways - Google Docs\n",
      "https://metaculus.com/questions/17993/swedish-2023-tbe-cases-over-370-by-october/ | Swedish 2023 TBE Cases Over 370 By October?  Metaculus\n",
      "https://twitter.com/messages/25776739-776322411725598720 | bruce / X\n",
      "https://twitter.com/tmkadamcz/status/1695048632817385499 | twitter.com/tmkadamcz/status/1695048632817385499\n",
      "https://lesswrong.com/posts/oZnPabN2CQQdnAo63/diy-deliberate-practice | DIY Deliberate Practice — LessWrong\n",
      "https://arbresearch.com/files/gen_bio.pdf | genbio\n",
      "https://forum.effectivealtruism.org/posts/TxrzhfRr6EXiZHv4G/agi-battle-royale-why-slow-takeover-scenarios-devolve-into-a | AGI Battle Royale: Why “slow takeover” scenarios devolve into a chaotic multi-AGI fight to the death\n",
      "https://docs.google.com/document/d/1Gkh3hbsURR9xJkvunr8PKtshM230uSG5WmyAQVMj4FQ/edit#heading=h.n1nw4b3u8t9s | 2023-04-13 Compute Scaling Methods at Companies - Google Docs\n",
      "https://predictions.substack.com/p/001-goldilocks-zone | The limits of long-term Quantified Forecasting\n",
      "https://forum.effectivealtruism.org/posts/6sykvCXRC5rjgtoQt/the-productivity-fallacy | The Productivity Fallacy — EA Forum\n",
      "https://docs.google.com/document/d/1kUPU0z5vXqEEg5JaiQ7IuDBRGc28eY_ZSK6zUudjxC4/edit#heading=h.ty86qub5wnwc | RP China workstream research agenda\n",
      "https://twitter.com/ilex_ulmus/status/1681835012860301312 | twitter.com/ilex_ulmus/status/1681835012860301312\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://openai.com/blog/frontier-model-forum | Frontier Model Forum\n",
      "https://metaculus.com/questions/17418/most-expensive-ai-training-run-by-year/ | What will the most expensive AI training run be in the following years, in millions of USD\n",
      "https://reddit.com/r/BDSMerotica/comments/iot2r4/fourday_fuckdoll_fmfncselfbondagecaptiveforced/ | (2) Four-Day Fuckdoll [F][MF][nc][self-bondage][captive][forced orgasm] : BDSMerotica\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). — LessWrong\n",
      "https://metaculus.com/superconductors/ | The Metaculus Lens on Superconductors\n",
      "https://facebook.com/tee.r.barnett/posts/pfbid0wTf2GXDJCJYyXyAsUU1wTeUBkBJidJTUQMFGRJK1rXVby7ofRLoLU4QNv91ysATdl | Tee Barnett - How I structure my schedule on a weekly basis for...  Facebook\n",
      "https://docs.google.com/spreadsheets/d/1tpXZ60EDokTLnNk1gSNWwshMmenNgLBf10mPJL2RVcE/edit#gid=0 | RP Animal Welfare Department - List of publications (2021-2023) [Internal] - Google Sheets\n",
      "https://niplav.site/ | Content – niplav\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://npr.org/2023/08/16/1194202562/new-york-times-considers-legal-action-against-openai-as-copyright-tensions-swirl?utm_source=substack&utm_medium=email | 'New York Times' considers legal action against OpenAI as copyright tensions swirl : NPR\n",
      "https://twitter.com/leah_pierson/status/1688544610287513600 | Leah Pierson on Twitter: \"A lot of people go to medical school because they want to work on the social determinants of health, global health, health policy, and other medicine-adjacent things. I think there are often other paths that make more sense if this is your primary goal, the reasons being: 1/4\" / X\n",
      "https://twitter.com/MatthewJBar/status/1691341251243651072 | Matthew Barnett on Twitter: \"@JeffLadish Yes, this post from @EgeErdil2 summarized how your beliefs about other poll respondents should affect your reasoning. t.co/mVB2Ges3mo t.co/i2tJxHsEo8\" / X\n",
      "https://mailchi.mp/5a0109faee8f/welcome-to-our-first-newsletter?e=ccdb9d34ea | mailchi.mp/5a0109faee8f/welcome-to-our-first-newsletter?e=ccdb9d34ea\n",
      "https://mailchi.mp/foodsolutionsaction/aug2023?e=90dfd9ccb1 | Food Solutions Action: Member Update\n",
      "https://theinsideview.ai/curtis | Curtis Huebner on AI Timelines and Alignment at EleutherAI\n",
      "https://lascivity.co.uk/the-rough-sex-playbook/ | The Rough Sex Playbook\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom — LessWrong\n",
      "https://forum.effectivealtruism.org/posts/xSvTArtzxBcnrD6tk/cea-still-doing-cea-things | CEA: still doing CEA things\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://nytimes.com/2023/07/19/opinion/putin-prigozhin-military-russia.html | All Is Not Well on Russian Front Lines\n",
      "https://nytimes.com/2023/07/25/business/tech-earnings-ai-microsoft-alphabet.html | Microsoft and Alphabet Face an Investor Test on AI - The New York Times\n",
      "https://twitter.com/dfrsrchtwts/status/1684278241459310594 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: do you have a favourite AI regulation proposal among those circulating in congress?\" / Twitter\n",
      "https://facebook.com/messages/t/1056637367/ | Messenger  Facebook\n",
      "https://nunosempere.com/blog/2023/07/13/melancholy/ | Some melancholy about the value of my work depending on decisions by others beyond my control\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://semafor.com/article/08/17/2023/some-republicans-tire-of-indictments?utm_campaign=hotonsemafor | Some Republicans tire of indictments  Semafor\n",
      "https://bloomberg.com/news/articles/2023-08-14/china-tries-to-regulate-ai-with-state-control-support-for-tech-companies?utm_source=substack&utm_medium=email#xj4y7vzkg | China Tries to Regulate AI With State Control, Support for Tech Companies - Bloomberg\n",
      "https://twitter.com/Simeon_Cps/status/1682279183307747328 | Siméon on Twitter: \"Wait, is there any cognitive capability where the median-performing human in that capability is better than GPT-4?\" / Twitter\n",
      "https://rethinkpriorities.org/animals-of-rp | Animals of Rethink Priorities — Rethink Priorities\n",
      "https://google.com/search?q=so+good+they+can%27t+ignore+you&rlz=1C5CHFA_enGB1058GB1058&oq=so+good+they+can&gs_lcrp=EgZjaHJvbWUqCggAEAAY4wIYgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDI3ODVqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8 | so good they can't ignore you - Google Search\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://twitter.com/robertwiblin/status/1686440144818098211 | Robert Wiblin on Twitter: \"Huh! S-curves are all over the place but it's hard to forecast what they're going to look like while you're in the middle of one: t.co/caipkHDEeq t.co/ijudsYHPKX\" / X\n",
      "https://metaculus.com/questions/18524/2020-to-2023-average-vote-swing/ | 2020 to 2023 average vote swing?  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/3kMQTjtdWqkxGuWxB/update-on-cause-area-focus-working-group | Update on cause area focus working group — EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1QrYysZVHrRzputht9FEyT2fHiRvBpCo1YQfh6E20AtA/edit#gid=375874685 | Referral Ads Sheet - 2023 - Google Sheets\n",
      "https://eshoo.house.gov/media/press-releases/ai-caucus-leaders-introduce-bipartisan-bill-expand-access-ai-research | AI Caucus Leaders Introduce Bipartisan Bill to Expand Access to AI Research  Congresswoman Anna Eshoo\n",
      "https://forum.effectivealtruism.org/posts/dpjCwMwKEPqK3TPnC/notes-on-managing-to-change-the-world | Notes on \"Managing to Change the World\"\n",
      "https://lesswrong.com/posts/BTcEzXYoDrWzkLLrQ/the-public-debate-about-ai-is-confusing-for-the-general | The \"public debate\" about AI is confusing for the general public and for policymakers because it is a three-sided debate — LessWrong\n",
      "https://semafor.com/article/06/30/2023/the-26-year-old-ceo-who-became-washingtons-ai-whisperer?utm_campaign=hotonsemafor | The 26-year-old CEO who became Washington’s AI whisperer\n",
      "https://lesswrong.com/posts/GpSzShaaf8po4rcmA/qapr-5-grokking-is-maybe-not-that-big-a-deal | QAPR 5: grokking is maybe not *that* big a deal? — LessWrong\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai [AI Impacts Wiki]\n",
      "https://docs.google.com/document/d/1SJLINzoGi_F7LkiQDc3FibhNqbCQRddYepLyKDCBq7o/edit#heading=h.l4v8jsytq7ii | Henri + AIGS/XST meetings re LT fundraising - Google Docs\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people — LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://baseratesblog.substack.com/p/lukewarm-takes-on-ai-risk | Lukewarm takes on AI risk\n",
      "https://docs.google.com/document/d/1uNF5687rCUBJucJGgT22QQkm0H_EzmIpzt2arWH-WOY/edit#heading=h.osty8jeclpyn | Forecasting China’s ability to indigenously produce AI chips - Google Docs\n",
      "https://twitter.com/FreedmanRach/status/1690040857397800971 | Rachel Freedman on Twitter: \"Strong agree! I've had all of these issues using \"intelligence\" in AI risk conversations. Issues (paraphrased from post) - Anthropomorphism (e.g. confusion w/consciousness) - Associations w/harmful ideologies - Moving goalposts - Less risky capabilities (e.g. math not politics)\" / X\n",
      "https://twitter.com/IAPolls2022/status/1693565061766266891 | twitter.com/IAPolls2022/status/1693565061766266891\n",
      "https://twitter.com/robertwiblin/status/1682062626908520455 | Robert Wiblin on Twitter: \"How many human beings could we 'run' on current computer chips with current technology? And how many if we had chips and algorithms as energy efficient as the human brain? Brain Efficiency: Much More than You Wanted to Know: t.co/vI2DHMt29E t.co/FHJR1s6CMV\" / Twitter\n",
      "https://philpapers.org/archive/WILIDO-22.pdf | WILIDO-22.pdf\n",
      "https://cambridge.org/core/journals/international-organization/article/hacking-nuclear-stability-wargaming-technology-uncertainty-and-escalation/B4D81871FC0115882AA42A0C1055C732 | Hacking Nuclear Stability: Wargaming Technology, Uncertainty, and Escalation  International Organization  Cambridge Core\n",
      "https://nunosempere.com/blog/2023/07/19/better-harder-faster-stronger/ | Why are we not harder, better, faster, stronger?\n",
      "https://twitter.com/ajeya_cotra/status/1655243379637391360 | Ajeya Cotra on Twitter: \"A common criticism of people who are trying to stop existential risk from powerful future AI systems is that speculating about the future has poor feedback loops and doesn't work great.\" / Twitter\n",
      "https://docs.google.com/document/d/1R7-1EMjnu1meonCE11BJ-fz8dKPil5hUzwjYLGEYMiE/edit#heading=h.h8jeam77skkl | What are the main AI regulation proposals in course in the US [HAIKU study notes]\n",
      "https://docs.google.com/document/d/1vXb0rRqjBIMh38M4m775MsFK1VKyABQXJODBjJw0c5w/edit#heading=h.n4kqnt7mgbuw | AVA 2023 notes on OP Worldview Diversification from Lewis Bollard conversation\n",
      "https://governance.ai/post/proposing-a-foundation-model-information-sharing-regime-for-the-uk | Proposing a Foundation Model Information-Sharing Regime for the UK  GovAI Blog\n",
      "https://twitter.com/ohlennart/status/1671203769357414412 | twitter.com/ohlennart/status/1671203769357414412\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://governance.ai/post/head-of-operations | Head of Operations  GovAI Blog\n",
      "https://time.com/6308604/meta-ai-access-open-source/?utm_source=substack&utm_medium=email | The Debate Is Heating Up Over Who Controls Access to AI  Time\n",
      "https://docs.google.com/document/d/1vGie3lHRR606-blefv7TGm09n1LF9arbDYxDNgtCeI8/edit#heading=h.f4mc3t2ytr | AI/ChatGPT/LLM Use Guidelines\n",
      "https://forum.effectivealtruism.org/posts/CtACh7xRBFnpK3NW4/guide-to-safe-and-inclusive-events-by-gwwc-and-oftw | Guide to Safe and Inclusive Events by GWWC and OFTW — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/EFpKcbaZNyZNk4qWD/jonas-vollmer-s-shortform?commentId=hjqzE7ki2hdYwjZZB | Jonas Vollmer's Quick takes — EA Forum\n",
      "https://twitter.com/linjianyangbe/status/1685477814081028096 | lin hillside on Twitter: \"Good day from #China. My love for you all. Top skateboarder and her name is Lucky. ❤️❤️ #Chinese #nature #birds #wildlife #travel #peace #TwitterNatureCommunity t.co/1KbQ6YlAy8\" / X\n",
      "https://wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://twitter.com/AndyMasley/status/1686777977604837376 | Andy Masley on Twitter: \"I see the odds of a successful coup in the US as basically 0, and this is why\" / X\n",
      "https://foreignpolicy.com/2023/06/19/ai-regulation-development-us-china-competition-technology/?tpcc=recirc_latest062921 | AI’s Gatekeepers Aren’t Prepared for What’s Coming\n",
      "https://twitter.com/nikosbosse/status/1691002933578489856 | twitter.com/nikosbosse/status/1691002933578489856\n",
      "https://docs.google.com/document/d/1I9Fw8Y3tdQWEIOIdFRRIvYBISLg0_uKLZgOSn09-9aU/edit#heading=h.lqtiq1w77guj | Training Process Transparency through Gradient Interpretability: Some preliminary results for toy language models\n",
      "https://docs.google.com/document/d/17k-MBAD4TrtqjbQ3sNlyDEF_QEnQ5prT87zNyMIa2RE/edit#heading=h.wfl3wbuv35qt | Difference-Making Risk-Averse Expected Value\n",
      "https://overcast.fm/+KebuY8LY4/1:11:15?utm_source=substack&utm_medium=email | #686: Dustin Moskovitz, Co-Founder of Asana and Facebook — Energy Management, Coaching for Endurance, No Meeting Wednesdays, Understanding the Real Risks of AI, Embracing Frictionless Work with AI, The Value of Holding Stories Loosely, and More — The Tim Ferriss Show — Overcast\n",
      "https://foxnews.com/tech/department-defense-establishes-generative-ai-task-force?utm_source=substack&utm_medium=email | Department of Defense establishes generative AI task force  Fox News\n",
      "https://reddit.com/r/relationship_advice/comments/15b7c5p/i_26f_want_to_leave_my_fiance_30m_because_of_his/ | (5) I (26f) want to leave my fiance (30m) because of his kids : relationship_advice\n",
      "https://openai.com/research/language-model-safety-and-misuse | Lessons learned on language model safety and misuse\n",
      "https://twitter.com/simransrahman/status/1693617950572339437 | twitter.com/simransrahman/status/1693617950572339437\n",
      "https://docs.google.com/spreadsheets/d/1sbt38w8NHqTUQc5VsFRsLEElLBGjXRSM/edit#gid=1553840207 | Town Hall Zoom Attendee Report.xlsx - Google Sheets\n",
      "https://twitter.com/stephenclare_/status/1695184560252932407 | twitter.com/stephenclare_/status/1695184560252932407\n",
      "https://joecarlsmith.com/2021/01/18/actually-possible-thoughts-on-utopia | Actually possible: thoughts on Utopia - Joe Carlsmith\n",
      "https://rethinkpriorities.org/five-years-campaign | Five Years of RP — Rethink Priorities\n",
      "https://forum.effectivealtruism.org/posts/qzQ24rbZ4kMFDswDK/does-ea-bring-out-the-best-in-me | Does EA bring out the best in me? — EA Forum\n",
      "https://openai.com/blog/using-gpt-4-for-content-moderation | Using GPT-4 for content moderation\n",
      "https://thezvi.substack.com/p/the-dial-of-progress | The Dial of Progress - by Zvi Mowshowitz\n",
      "https://twitter.com/ajeya_cotra/status/1687135321551716353 | Ajeya Cotra on X: \"Important article: t.co/U1l5BfTgv4 The single most important data point that suggests \"progress is unlikely to slow in the next 2-3y\": GPT-4 cost ~$100M (probably less), and Alphabet has 1000x that much money in cash on hand:\" / X\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://rethinkpriorities.org/longtermism-research-notes/putting-new-ai-lab-commitments-in-context | Putting New AI Lab Commitments in Context — Rethink Priorities\n",
      "https://beta.character.ai/ | character.ai\n",
      "https://wsj.com/articles/tesla-stock-earnings-ai-technology-71136a4c | Tesla’s AI Hype Collides With Reality - WSJ\n",
      "https://twitter.com/RichardHanania/status/1688200053473619970 | Richard Hanania on Twitter: \"I wrote something. t.co/bh8ATF1L8O\" / X\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://blog.jonasmoss.com/posts/quantiles/quantiles.html | Deriving distributions from quantiles\n",
      "https://localhost:8888/lab/tree/Tab%20sorts.ipynb | Tab sorts.ipynb - JupyterLab\n",
      "https://docs.google.com/document/d/1-87ePz2QqrtS2ty6Oo2280rFe5g1A6llnjyyZ-A_NAc/edit | Slowing Down AI - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/Xd9ZZuPCKAvKpzvdB/empowering-numbers-fem-since-2021 | Empowering Numbers: FEM since 2021 — EA Forum\n",
      "https://tellingthefuture.substack.com/p/forecasting-the-end-of-the-world | Forecasting the End of the World - by Robert de Neufville\n",
      "https://docs.google.com/document/d/1PZ7ZVTfIt0T_TgOBTQTLOOne7iakfQDW6uBjEyFMhQo/edit#heading=h.x8vizs97cm8 | AIGS June 2023 comms materials for review - Google Docs\n",
      "https://twitter.com/cfchabris/status/1604875408071045124 | Christopher Chabris on Twitter: \"Dan Simons and I have written our second book, and it will be published in July! NOBODY'S FOOL melds insights from the cognitive sciences with real-world examples to explain how scams, frauds, cons, and other forms of deception work. You can preorder here: t.co/fUG6iUkkMG t.co/d1EsTrcYGi\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1689360557483450368 | Matthew Barnett on Twitter: \"At Epoch we've updated our interactive transformative AI timelines model to produce what I think is a more realistic picture of the future. The default parameter values are based on historical trends in investment, algorithmic progress, and hardware, among other factors. t.co/Yw7VtqQphG\" / X\n",
      "https://forum.effectivealtruism.org/posts/FtLkQ77rxvEbWDtpz/longtermist-causes-is-a-tricky-classification | “Longtermist causes” is a tricky classification — EA Forum\n",
      "https://github.com/rethinkpriorities/cross-cause-model/pull/67#issuecomment-1629349595 | github.com/rethinkpriorities/cross-cause-model/pull/67#issuecomment-1629349595\n",
      "https://washingtonpost.com/technology/2023/07/28/mission-impossible-ai-not-realistic/ | What an AI expert thinks about the killer AI in 'Mission Impossible' - The Washington Post\n",
      "https://forum.effectivealtruism.org/posts/EEMpNRJK5qqCw6zqH/a-cost-effectiveness-analysis-of-historical-farmed-animal | A Cost-Effectiveness Analysis of Historical Farmed Animal Welfare Ballot Initiatives — EA Forum\n",
      "https://twitter.com/JeffLadish/status/1673149979828039680 | twitter.com/JeffLadish/status/1673149979828039680\n",
      "https://twitter.com/xuanalogue/status/1567926384676450304 | twitter.com/xuanalogue/status/1567926384676450304\n",
      "https://twitter.com/rcbregman/status/1688526388004077568 | twitter.com/rcbregman/status/1688526388004077568\n",
      "https://twitter.com/peterwildeford/status/1694315606751715624 | twitter.com/peterwildeford/status/1694315606751715624\n",
      "https://economics.mit.edu/sites/default/files/2023-07/Regulating%20Transformative%20Technologies.pdf | Regulating Transformative Technologies.pdf\n",
      "https://tellingthefuture.substack.com/p/we-must-live-together-or-perish | We Must Live Together Or Perish - by Robert de Neufville\n",
      "https://openai.com/blog/custom-instructions-for-chatgpt | Custom instructions for ChatGPT\n",
      "https://docs.google.com/document/d/1sjgT0Ezwcpsy7T7z2fFENvCz99cWflncAJRDKmyewP8/edit#heading=h.sja5ou1zlohi | Chartering for US commercial banks - case study for OAI - Bill Anderson-Samways - Google Docs\n",
      "https://twitter.com/TheDavidSJ/status/1688611205424807936 | twitter.com/TheDavidSJ/status/1688611205424807936\n",
      "https://twitter.com/Simeon_Cps/status/1676642303299952657 | Siméon on Twitter: \"Even if I would bet that you won't succeed in this timeframe, I'm glad you and Ilya are trying and hope you'll hire great minds for this initiative. I think that Terry Tao was vaguely interested by the problem a few months ago so it may be worth chatting with him to check if…\" / Twitter\n",
      "https://docs.google.com/document/d/1XsSriKA4YWqD6KRqcUg6CvxhaE1SPVYo_O-QCZEazoQ/edit#heading=h.1u4lkskbhszs | Lionheart AI safety fund feasibility study v0.2 - Google Docs\n",
      "https://docs.google.com/document/d/19rKkgNqaMPRISPqjJGU48GfXxNzZYjrtds-FTI52Dlc/edit | Peter <> Michael - 1-1s - 2023 Q3-4 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/ExpBagkng6QSqcN8d/a-model-based-approach-to-ai-existential-risk | A model-based approach to AI Existential Risk\n",
      "https://twitter.com/john_sungjin/status/1686124282127269888 | John Kim on Twitter: \"We got 🥈 at the @AnthropicAI hackathon by impersonating our favorite anons and judges - but we're really excited about the idea of using LLMs to Simulate Everything! So, we created Twitter (we can legally call it that now @elonmusk ). 1/n (❤️ @kvvnhu @taehyoungjo @thetejmahal) t.co/8erkAX6fyF\" / X\n",
      "https://80000hours.org/podcast/episodes/christopher-brown-slavery-abolition/ | Christopher Brown on why slavery abolition wasn't inevitable - 80,000 Hours\n",
      "https://washingtonpost.com/opinions/2023/08/16/calvin-coolidge-president-politics-budget-silent/ | Opinion  ‘Silent Cal’ Coolidge sounds pretty good right about now\n",
      "https://docs.google.com/document/d/1bgMwiex8jHDnlIDrtH8OqVGaYstDr3KDPdyAQgJumro/edit#heading=h.a89fxjj9aldj | Potentially useful books on how the USG works\n",
      "https://twitter.com/GaetenD/status/1696908127591948415 | Gaeten Dugas on X: \"For VP, I bought No in everyone except: 1. Kristi Noem (bought Yes) 2. Tim Scott 3. Byron Donalds 4. Elise Stefanik 5. Glenn Youngkin 6. Henry McMaster 7. Kim Reynolds I think 1 and 2 are the mostly likely picks. 3-6 could pump at some point. 7 is in case DeSantis bounces back.\" / X\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/ | Complexity Theory’s 50-Year Journey to the Limits of Knowledge  Quanta Magazine\n",
      "https://planned-obsolescence.org/language-models-surprised-us/ | Language models surprised us\n",
      "https://twitter.com/norabelrose/status/1696686969601003992 | twitter.com/norabelrose/status/1696686969601003992\n",
      "https://docs.google.com/document/d/1kv2_Y36gD300QwOOmgd5kd6kD1lnMIv-xtViewYZmdw/edit | MCF Biosecurity Memo - ASB 2023\n",
      "https://docs.google.com/document/d/1MCfucZSVvIrPmLwa5PMw_umH8iyA5c-v9EbnUSZgH1c/edit | 2023 Q2 Project Research – Retrospective\n",
      "https://joecarlsmith.com/2020/11/08/how-core-is-confusion-about-consciousness | How core is confusion about consciousness? - Joe Carlsmith\n",
      "https://lesswrong.com/posts/WhSK9y8apy8mNMFGK/reproducing-arc-evals-recent-report-on-language-model-agents | Reproducing ARC Evals' recent report on language model agents — LessWrong\n",
      "https://lesswrong.com/posts/EPLk8QxETC5FEhoxK/arc-evals-new-report-evaluating-language-model-agents-on | ARC Evals new report: Evaluating Language-Model Agents on Realistic Autonomous Tasks — LessWrong\n",
      "https://linkedin.com/posts/annalenhart_federal-legislative-proposals-pertaining-activity-7094379365110542336-OvmE/ | linkedin.com/posts/annalenhart_federal-legislative-proposals-pertaining-activity-7094379365110542336-OvmE/\n",
      "https://twitter.com/albrgr/status/1684592029773303810 | Alexander Berger on Twitter: \"I’m excited about this and daunted by the responsibility: t.co/Lyo7kUsp7L\" / Twitter\n",
      "https://docs.google.com/document/d/1zCYPAq1WA9UqAF11Fraqenyymz-YMYuwbHnqUvT5Ntk/edit | Trying to understand OpenAI's strategic thinking: Our understanding of the case for short timelines and continuous takeoff as the safest path to AGI - Google Docs\n",
      "https://twitter.com/TmarcoH/status/1674063185010147330 | Marco Hernandez on Twitter: \"The advance of the Ukrainian counteroffensive must face great challenges to advance on the ground occupied by the Russians. I did some illustrations to explain it better: t.co/tdiM0247G5 #UkraineWar t.co/ePHBTsVoFU\" / Twitter\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://docs.google.com/document/d/1Zaham8weNwUXbOnwgLogkVjK_4CP_2DOCc62XtHzgic/edit#heading=h.cfc2feh3bxhs | Intervention Pages Proposal - Google Docs\n",
      "https://twitter.com/EAheadlines/status/1694453101334315401 | EA Lifestyles (40 Substack posts published) on X: \"the impact treadmill t.co/kR9AIFFa1P\" / X\n",
      "https://docs.google.com/document/d/1O14SkpysPGl5DaWYLuRcHIhAAKcK9HgRkCFkQy8R888/edit | USG & AI Project Retrospective - Google Docs\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://macroscience.org/p/its-so-over-now-what | It’s So Over. Now What? - by Tim Hwang - Macroscience\n",
      "https://docs.google.com/document/d/1rwLFr15536l08wKslhMF6ZHOGvIQ4DIION1jK25_oIE/edit#heading=h.jl93l1npdui2 | [Ashwin evaluating Oliver] - July 2023 - RP Performance Evaluation - Google Docs\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://quora.com/What-are-some-ways-to-remove-jealousy-in-a-polyamorous-relationship | What are some ways to remove jealousy in a polyamorous relationship? - Quora\n",
      "https://joecarlsmith.com/2021/08/27/can-you-control-the-past | Can you control the past? - Joe Carlsmith\n",
      "https://twitter.com/norabelrose/status/1681450862106017793 | twitter.com/norabelrose/status/1681450862106017793\n",
      "https://twitter.com/rodneyabrooks/status/1692189615015493680 | Rodney Brooks on X: \"BTW my diagnosis of the LLM hype is the \"indistinguishable from magic\" sin. LLMs did something surprising and for which we humans had no obvious mental model, so LLMs quickly became capable, in our minds, of anything imaginable. t.co/R39WhDOsdL\" / X\n",
      "https://apricitas.io/p/the-semiconductor-trade-war | The Semiconductor Trade War - by Joseph Politano\n",
      "https://docs.google.com/document/d/1OeaAALrSkjIyRy0vl5Ljhf1HIMwY_wzTtxwhPiC8JCo/edit#heading=h.ou91fmqchcm2 | Overview of IAPS's track record as of Aug 2023 - Google Docs\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://jack-clark.net/2023/07/05/what-should-the-uks-100-million-foundation-model-taskforce-do/ | What should the UK’s £100 million Foundation Model Taskforce do?\n",
      "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421 | Building a Culture of Safety for AI: Perspectives and Challenges by David Manheim :: SSRN\n",
      "https://docs.google.com/document/d/1V54T5iUvieVhIDihTXvSDnN6g97xv-kXK-LTOwlcvOc/edit | Thoughts about GW <> RP relationship moving forward - Google Docs\n",
      "https://lesswrong.com/posts/wBgjQKNfJnPMjKpFa/incentives-affecting-alignment-researcher-encouragement | Incentives affecting alignment-researcher encouragement — LessWrong\n",
      "https://twitter.com/edardaman/status/1683657331966349312 | (1) Emily Dardaman is at ALIFE 🇯🇵 on Twitter: \"“On a Monday morning in April, Sam Altman sat inside OpenAI’s San Francisco headquarters, telling me about a dangerous artificial intelligence that his company had built but would never release. His employees, he later said, often lose sleep.” t.co/Hc0YQ4LBED\" / Twitter\n",
      "https://ai.meta.com/ | Meta AI\n",
      "https://docs.google.com/spreadsheets/d/1eAh3VrG7fKDsO4BBd1c1DjUw19IMSa00GQOOPh2OTaY/edit | Proposals AIGS endorses and/or has views on\n",
      "https://google.com/search?q=pussy+beads&rlz=1C5CHFA_enGB1058GB1058&oq=pussy+beads&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDE3ODRqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8#ip=1 | pussy beads - Google Search\n",
      "https://alignment-workshop.com/ | Alignment Workshop 2023\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://joecarlsmith.com/2021/01/24/on-clinging | On clinging - Joe Carlsmith\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance — EA Forum\n",
      "https://blog.jakegloudemans.com/post/16-predictions-4 | Predictions #4 - Jake Gloudemans\n",
      "https://80000hours.org/podcast/episodes/elie-hassenfeld-givewell-critiques-and-lessons/ | Elie Hassenfeld on two big picture critiques of GiveWell's approach, and six lessons from their recent work - 80,000 Hours\n",
      "https://split-ticket.org/2023/08/14/evaluating-sherrod-browns-path-to-reelection/ | Evaluating Sherrod Brown’s Path to Reelection – Split Ticket\n",
      "https://docs.google.com/document/d/1WD-3q2eEAj2YLlmyXrm8c-XshSvrr9ffUP4vGz1rDf4/edit#heading=h.go4ebkohvjyy | Jide Alaga <> RP\n",
      "https://docs.google.com/document/d/1SHtQfxe4EJziNjs0dBXnWwfMnYA2XKkcN6xN5n0HK5Q/edit | AIGS Meeting Reflections\n",
      "https://chinatalk.media/p/the-cias-cold-war-china-forecasting | CIA Cold War China Forecasting - by Nicholas Welch\n",
      "https://ai.google/ | Google AI\n",
      "https://twitter.com/Simeon_Cps/status/1680823735304040448 | twitter.com/Simeon_Cps/status/1680823735304040448\n",
      "https://fas.org/accelerator/bio-ai-policy-sprint/?utm_source=substack&utm_medium=email | Bio x AI Policy Development Sprint - Federation of American Scientists\n",
      "https://twitter.com/JeffLadish/status/1683772340491145218 | twitter.com/JeffLadish/status/1683772340491145218\n",
      "https://thediff.co/archive/inside-the-decline-of-stack-exchange/ | Inside the Decline of Stack Exchange\n",
      "https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biosecurity | An overview of standards in biosafety and biosecurity — EA Forum\n",
      "https://docs.google.com/document/d/1udFQ--BgWVi3a9Ng-Rp6oUiR7k1KOeoTePBmvol6F00/edit | David Rhys Bernard: Manual of Me - Google Docs\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | twitter.com/rajiinio/status/1669326789758394369\n",
      "https://forum.effectivealtruism.org/posts/Tshx6oH2vN6Nszqoj/matt_lerner-s-shortform?commentId=puWM6XqdLbuv88Spc | Has there been any formal probabilistic risk assessment on AI X-risk? e.g. fault tree analysis or event tree analysis — anything of that sort?\n",
      "https://morethantwo.com/polyforsecondaries.html | More Than Two  Secondary’s Guide\n",
      "https://ww2.aip.org/fyi/doe-pitching-major-ai-r-d-initiative-to-congress | DOE Labs Pitching Major AI R&D Initiative to Congress\n",
      "https://politico.eu/article/the-14-people-who-matter-in-uk-ai-policy/ | The 14 people who matter in UK AI policy\n",
      "https://twitter.com/otis_reid/status/1681330482401902593 | twitter.com/otis_reid/status/1681330482401902593\n",
      "https://forum.effectivealtruism.org/posts/DPfGxeWFLQaWEgBTj/how-many-people-are-neartermist-and-have-high-p-doom | How many people are neartermist and have high P(doom)? — EA Forum\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://arxiv.org/pdf/2308.14752.pdf | AI Deception: A Survey of Examples, Risks, and Potential Solutions\n",
      "https://joecarlsmith.com/2021/03/14/against-neutrality-about-creating-happy-lives | Against neutrality about creating happy lives - Joe Carlsmith\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://metaculus.com/ai/ | The Metaculus Lens on AI\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://wikiwand.com/en/Hawthorne_effect | Hawthorne effect - Wikiwand\n",
      "https://arxiv.org/abs/2303.11341 | [2303.11341] What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring\n",
      "https://marketwatch.com/story/regulators-open-floodgates-for-driverless-taxis-in-san-francisco-whether-theyre-wanted-or-not-f966c029?rss=1&siteid=rss&utm_source=substack&utm_medium=email | Regulators open floodgates for driverless taxis in San Francisco - MarketWatch\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://reddit.com/r/BDSMerotica/comments/knc9jc/the_new_king_chases_and_tames_me_a_submissive/ | (2) The new king chases and tames me, a submissive princess, deep in the forest [Mf][Mdom] : BDSMerotica\n",
      "https://forum.effectivealtruism.org/posts/euzDpFvbLqPdwCnXF/university-ea-groups-need-fixing#comments | forum.effectivealtruism.org/posts/euzDpFvbLqPdwCnXF/university-ea-groups-need-fixing#comments\n",
      "https://docs.google.com/document/d/1Iu2iAz-S1BewDYhI05-9fkM8LNoDQeesjrIpvOu54lY/edit | AI Safety at Google - Google Docs\n",
      "https://ealifestyles.substack.com/p/is-forecasting-actually-effectivealtruistic?utm_source=post-email-title&publication_id=1393327&post_id=135823813&isFreemail=false&utm_medium=email | is forecasting actually effective/altruistic or am I just getting nerd-sniped?\n",
      "https://docs.google.com/document/d/1sQI-udA4x-kHj79yb3HlO0Kcc-Dd1WMT0jiqiPBgszE/edit#heading=h.j7a78oivkty6 | XST Meta Charity Funders application August 2023 - Google Docs\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | twitter.com/dylan522p/status/1628797563007811585\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3525480504433509&hoisted_section_header_type=recently_seen | facebook.com/groups/1479475219034058/?multi_permalinks=3525480504433509&hoisted_section_header_type=recently_seen\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/rPj6Fh4ZTEpRah3uf/problems-with-free-services-for-ea-projects | Problems with free services for EA projects\n",
      "https://wikihow.com/Date-Someone-with-an-Anxious-Attachment-Style | How to Date Someone with an Anxious Attachment Style\n",
      "https://docs.google.com/document/d/1Zi0sDYIdBhXc7RN9Exj2BlhaDMF5mIo6Hg7tY07MhAU/edit#heading=h.4guks8uuunh5 | [Speedrun] Evals: How can we reduce the risk of regulatory capture? Learning from case-studies of other high-stakes technological domains - Google Docs\n",
      "https://twitter.com/Simeon_Cps/status/1695508668458959268 | Siméon on X: \"This post is the first of its kind &amp; an awesome news for AI safety: 1) A list of the problems that we need to solve to avoid extinction from AI. 2) For each problem, how the safety plan from @davidad solves it. This is a simple structure that should be a minimal baseline for…\" / X\n",
      "https://docs.google.com/document/d/18Q-Mn0mKrPxYTC38eBqyctR5jHuKjJ-thMDGuJ-OXC8/edit#heading=h.nilb5yn0fc6s | [2023.07.31] Defense-in-Depth Framing Piece - Google Docs\n",
      "https://bonobology.com/jealousy-in-polyamory/ | Dealing With Jealousy In Polyamorous Relationships\n",
      "https://ealifestyles.substack.com/p/your-next-forum-post-should-be-more?utm_source=post-email-title&publication_id=1393327&post_id=136021207&isFreemail=false&utm_medium=email | your next forum post should be more like a children's book\n",
      "https://reddit.com/r/BDSMcommunity/comments/156naam/favorite_humiliation_phrases/ | (5) Favorite humiliation phrases? : BDSMcommunity\n",
      "https://forum.effectivealtruism.org/posts/4rp8rRjPAE6Hzs5ef/mathiaskb-s-shortform?commentId=72jKEA37fF8ro5LeQ | Why you should buy a desk treadmill\n",
      "https://science.org/doi/10.1126/science.adi0121 | Animal welfare: Methods to improve policy and practice\n",
      "https://wired.com/story/google-deepmind-demis-hassabis-chatgpt/ | Google DeepMind’s CEO Says Its Next Algorithm Will Eclipse ChatGPT\n",
      "https://twitter.com/Simeon_Cps/status/1680159200398176256 | Siméon on Twitter: \"I believe all of these claims simultaneously on t.co/YJ0W21iPx4: 1) I wish they didn't exist (bc + race sucks) 2) The focus on a) truthfulness &amp; on accurate world modelling, b) on curiosity and c) on theory might help alignment a lot. 3) They currently don't know what…\" / Twitter\n",
      "https://docs.google.com/presentation/d/1CEYIastEhq-Y9TuJJjtBRK3_eqoFrFkkp2PM3-GHfjc/edit | 2023-07-04 What are good US AI policy ideas? - HAIKU - Renan\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX — EA Forum\n",
      "https://twitter.com/Caro_Jeanmaire/status/1681752188681330689 | twitter.com/Caro_Jeanmaire/status/1681752188681330689\n",
      "https://wikiwand.com/en/Couples_Therapy_(2019_TV_series) | Couples Therapy (2019 TV series)\n",
      "https://twitter.com/pvllss/status/1684975462282342406 | twitter.com/pvllss/status/1684975462282342406\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://docs.google.com/document/d/1utecRz-1Mx-jXjGAvEeEi_XvBGTguA6flx7lkIS7cS8/edit#heading=h.xjb1j3y7702q | [WiP] How much compute is there? A review - Google Docs\n",
      "https://docs.google.com/document/d/1Lmpvblvj8Gbr6kmnaBsE73GUyulwAtUGCeAmc2YuMaA/edit | Proposed changes to current competencies model - Google Docs\n",
      "https://morethantwo.com/bridgingthedivide.html | More Than Two  Bridging the Divide\n",
      "https://murdershebet.com/ | Murder, She Bet [BETA]\n",
      "https://simoninstitute.ch/blog/post/2-year-review-concluding-sis-inception/ | 2-year review: concluding SI's inception\n",
      "https://asteriskmag.com/issues/03/how-we-can-regulate-ai | How We Can Regulate AI—Asterisk\n",
      "https://google.com/search?q=canadian+independence&rlz=1CDGOYI_enUS715US715&oq=Canadian+ind&gs_lcrp=EgZjaHJvbWUqBwgBEAAYgAQyBggAEEUYOTIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQLhiABDIHCAcQABiABDINCAgQLhivARjHARiABDIHCAkQABiABNIBCDQwODBqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | canadian independence - Google Search\n",
      "https://twitter.com/AISafetyMemes/status/1696861188477387190 | AI Notkilleveryoneism Memes on X: \"If you haven't yet, have The Deepfake Talk with your parents immediately\" / X\n",
      "https://arxiv.org/abs/2307.04699 | [2307.04699] International Institutions for Advanced AI\n",
      "https://twitter.com/norabelrose/status/1691639784597573684 | twitter.com/norabelrose/status/1691639784597573684\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://stability.ai/ | Stability AI\n",
      "https://youtube.com/watch?v=nD-Dco7xSSU | Oppenheimer's Apocalypse Math - YouTube\n",
      "https://twitter.com/robertwiblin/status/1688907251493601280 | Robert Wiblin on Twitter: \"Per this, nobody I know who's anxious about superintelligence is anxious about superconductors: t.co/CCOMRR5KER Reasons: 1. By default we're pro science &amp; tech 2. But we also evaluate the specific case for and against worrying about individual things 3. And the…\" / X\n",
      "https://docs.google.com/document/d/1OkXIPftvJwAQn7BbbsRqQCbvxpYoqlTQnp3aGgkxSM8/edit#heading=h.xsij1kkvzxdb | Development-phase regulation: lessons for AI\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://lesswrong.com/posts/4NFDwQRhHBB2Ad4ZY/the-filan-cabinet-podcast-with-oliver-habryka-transcript | The Filan Cabinet Podcast with Oliver Habryka - Transcript\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://docs.google.com/document/d/1ezY0JAqh_Tb2cxXduvpWsnDpIqRt01dY6e5bhiXsZEM/edit#heading=h.9fg7hspx4pom | RP Compute Governance Workstream 1-pager [shared] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1u4aYpGu5YRMCGWLaVBcVFI06B0-YDFU6DPuRNQC77kE/edit#gid=0 | DiD Framing Piece Progress Chart - Google Sheets\n",
      "https://arxiv.org/pdf/2303.09001.pdf | Reclaiming the Digital Commons: A Public Data Trust for Training Data\n",
      "https://foreignaffairs.com/china/china-flirting-ai-catastrophe | China Is Flirting With Artificial Intelligence Catastrophe\n",
      "https://nytimes.com/2019/05/04/smarter-living/500-days-of-duolingo-what-you-can-and-cant-learn-from-a-language-app.html | 500 Days of Duolingo: What You Can (and Can’t) Learn From a Language App - The New York Times\n",
      "https://lesswrong.com/posts/qrFf2QEhSiL9F3yLY/tensor-trust-an-online-game-to-uncover-prompt-injection | Tensor Trust: An online game to uncover prompt injection vulnerabilities — LessWrong\n",
      "https://twitter.com/robertwiblin/status/1695091279095287938 | Robert Wiblin on X: \"What 'big ideas' books have you read in the last 5 years that were truly good?\" / X\n",
      "https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/ | FAQ on Catastrophic AI Risks - Yoshua Bengio\n",
      "https://github.blog/2023-06-27-the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot/ | The economic impact of the AI-powered developer lifecycle and lessons from GitHub Copilot\n",
      "https://twitter.com/Suhail/status/1684775130805968896 | Suhail on X: \"A small team that knows how to work together should be fiercely protected. Even adding a single semi-misaligned person can drag the team into endless delay and steep deceleration.\" / X\n",
      "https://docs.google.com/document/d/1yeIXYJ6YZorRfe8Ei3Dg-mO-A6GgiiUOezra3Vv0Ayg/edit#heading=h.mz5p5xx8q7a2 | [shared] Rethink Priorities Existential Security Team Fundraising Proposal 2023 - Google Docs\n",
      "https://dynomight.net/aspartame-brouhaha/ | WHO aspartame brouhaha\n",
      "https://twitter.com/NikSamoylov/status/1697766945100288497 | Nik Samoylov on X: \"While x-risk perception remains steady, more people in the USA seem to agree with incorrigibility of advanced AI and short AGI timelines. t.co/krBVhRgxVn t.co/uXWaWw9JRd\" / X\n",
      "https://simonandschuster.com/books/The-Bomb/Fred-Kaplan/9781982107307 | The Bomb\n",
      "https://docs.google.com/document/d/16yGPyJ7mHyKNhDJNRvNGqt9pjEWyn7123Ud7A1pnMAM/edit | ERA Hiring note - Google Docs\n",
      "https://arxiv.org/abs/2307.00175 | [2307.00175] Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks\n",
      "https://twitter.com/DanielColson6/status/1689392842068918273 | Daniel Colson on Twitter: \"1/7: Today we released AIPI’s first poll with YouGov. The results are overwhelming. 82% think we should go slowly and deliberately with AI, while just 8% want to speed up development. 83% believe AI could cause a catastrophic event. t.co/XRFv7oAa8a\" / X\n",
      "https://nytimes.com/2023/08/16/technology/google-ai-life-advice.html?utm_source=substack&utm_medium=email | Google Tests an A.I. Assistant That Offers Life Advice - The New York Times\n",
      "https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biorisk | An overview of standards in biosafety and biorisk\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1sab5pa0kqrcrj5dAZUupO3_gfF3p9OBUm1Xv7o0E_Bk/edit#heading=h.6ytgvt3dfnpe | (managee copy) Patrick Levermore 2023: July - RP Performance Evaluation Template\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1 | What do XPT forecasts tell us about AI risk? — EA Forum\n",
      "https://docs.google.com/document/d/1qrf_sGnD9YDimH9l1LYpY7Iib9LosCtz41tZ8fBbgGI/edit#heading=h.whjku1dsy2f3 | 2023-07-04 Lab Statements on AI Regulation - Google Docs\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://forum.effectivealtruism.org/posts/iSemZYz5KyepYcksN/an-expert-survey-on-social-movements-and-protest-5 | An expert survey on social movements and protest — EA Forum\n",
      "https://lesswrong.com/posts/KRDo2afKJtD7bzSM8/barriers-to-mechanistic-interpretability-for-agi-safety | Barriers to Mechanistic Interpretability for AGI Safety — LessWrong\n",
      "https://lesswrong.com/posts/LERwsN3SYhkCfew6j/discussing-how-to-align-transformative-ai-if-it-s-developed | Discussing how to align Transformative AI if it’s developed very soon — LessWrong\n",
      "https://twitter.com/norabelrose/status/1683221922157559808 | twitter.com/norabelrose/status/1683221922157559808\n",
      "https://twitter.com/AllanDafoe/status/1692519542193365332 | (1) Allan Dafoe on X: \"t.co/cdvq5sKDAe t.co/u3BvSCbkxv\" / X\n",
      "https://docs.google.com/document/d/1rP-g6gQtUnusfmah-bZ4yvglFIDJO3Uk_PtWtKGG7A0/edit | GHD Director Draft Skills Assessment Questions - Google Docs\n",
      "https://twitter.com/AndyMasley/status/1691238280031764481 | Andy Masley on Twitter: \"The fact that EA hasn't convinced a much larger portion of the general population to donate at least 1% of their income to GiveWell-style charities is demoralizing ngl. Most obvious part of the whole deal.\" / X\n",
      "https://lesswrong.com/posts/r2vaM2MDvdiDSWicu/the-u-s-is-mildly-destabilizing | The U.S. is mildly destabilizing — LessWrong\n",
      "https://docs.google.com/document/d/1zUVdUeOHfaTWyBgVC8ZRUNZ2tmix35dFSIgRSxSY5rk/edit?pli=1 | GHD round table brainstorm - Google Docs\n",
      "https://blog.jakegloudemans.com/post/14-dangerous | Things usually get less dangerous, not more - Jake Gloudemans\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://lucid.app/lucidchart/a83a6a4a-5a9a-42cd-acca-45b48675bc62/edit?beaconFlowId=6DA8276DDD8C8833&invitationId=inv_6c6ef3f5-3731-4d19-8bc7-da4942087ebd&page=0_0# | Blank diagram: Lucidchart\n",
      "https://nytimes.com/2023/05/12/opinion/conservative-mainstream-media.html | Conservative Media Has an Audience Problem\n",
      "https://blog.heim.xyz/this-cant-go-on-compute-training-costs/ | This can't go on(?) - AI Training Compute Costs\n",
      "https://google.com/search?q=couples+therapy+workbook&rlz=1C5CHFA_enGB1058GB1058&oq=couples+therapy+workbook&aqs=chrome.0.0i355i512j46i512l2j0i512l4j0i390i650l3.3499j0j1&sourceid=chrome&ie=UTF-8 | google.com/search?q=couples+therapy+workbook&rlz=1C5CHFA_enGB1058GB1058&oq=couples+therapy+workbook&aqs=chrome.0.0i355i512j46i512l2j0i512l4j0i390i650l3.3499j0j1&sourceid=chrome&ie=UTF-8\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid07jjqaCHVhCKvsvGVtcwJtTYvzTugRznHnB4n5YhMH5GAvENG519pRrVVPxotHuLvl | facebook.com/ozzie.gooen/posts/pfbid07jjqaCHVhCKvsvGVtcwJtTYvzTugRznHnB4n5YhMH5GAvENG519pRrVVPxotHuLvl\n",
      "https://lesswrong.com/posts/btpE9fAbvGys4Ztj9/how-to-make-real-money-prediction-markets-on-arbitrary | How to make real-money prediction markets on arbitrary topics — LessWrong\n",
      "https://arxiv.org/abs/2307.00682 | Tools for Verifying Neural Models' Training Data\n",
      "https://reddit.com/r/BDSMerotica/comments/jlvdn2/brats_what_you_deserve_mdom_fsub_brattaming/ | (2) Brat’s What You Deserve (MDom, Fsub, brat-taming, punishment, oral, edging, repeated orgasm) : BDSMerotica\n",
      "https://fivethirtyeight.com/features/rfk-jr-democrat-republican-primary-favorability/ | If RFK Jr. Wants To Be President, He’s Running In The Wrong Primary  FiveThirtyEight\n",
      "https://docs.google.com/document/d/1WOdF0zCWgqA9wK2Ze0DCb7KqKVThohNvmavoJLEZtqs/edit | NGDP Futures Strategy\n",
      "https://docs.google.com/presentation/d/1rzmKcrKlO0Awp2YI8cATFajgpt7IczlHsvGaZQa3juQ/edit#slide=id.g247fe72e4a3_0_69 | EAG London 2023 - Google Slides\n",
      "https://chineseperspectives.ai/ | chineseperspectives.ai/\n",
      "https://rp-jeid-2022-survey-report.netlify.app/ | 2022 JEID survey report\n",
      "https://reddit.com/r/polyamory/comments/oag9t5/poly_relationship_boundaries/ | (4) Poly relationship boundaries : polyamory\n",
      "https://forum.effectivealtruism.org/posts/pbMfYGjBqrhmmmDSo/nuclear-winter-reviewing-the-evidence-the-complexities-and | Nuclear winter - Reviewing the evidence, the complexities, and my conclusions — EA Forum\n",
      "https://arena-ch1-transformers.streamlit.app/ | arena-ch1-transformers.streamlit.app/\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework\n",
      "https://docs.google.com/document/d/1YcTPqQZi7GwcoukRvqRIKNoz35G8ffSR4gOduHybFxo/edit#heading=h.53syq9goshna | Misc notes on AI CPR - Google Docs\n",
      "https://blog.heim.xyz/the-case-for-pre-emptive-authorizations/ | The Case for Pre-emptive Authorizations for AI Training\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://axios.com/2023/08/15/eric-braverman-leaves-ceo-schmidt-futures | Eric Braverman leaves as CEO of Schmidt Futures to start new venture\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://twitter.com/xuanalogue/status/1674410315432247297 | xuan (ɕɥɛn / sh-yen) on Twitter: \"How do we infer the goals &amp; plans of others from both their actions &amp; words? In this paper with @Lance_Ying42, we infer a team's goal via inverse planning (aka \"inverse RL\"), using LMs* as likelihood functions over utterances! (*GPT-3 Curie 6.7B, but smaller LMs may also work!)\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://twitter.com/JeffLadish/status/1692367537764475328 | Jeffrey Ladish on X: \"I'm thinking of taking this oath, and would love if people could give me reflections / thoughts on it. Including ways you think it might be misguided, or excessively hard to uphold, or confused in some way ~~~~~~~~~ I pledge to work diligently, with courage and integrity to fight…\" / X\n",
      "https://docs.google.com/document/d/17QTfO_7kcs84N3cMImkY_1K6HFWLUOKa_tTqYlcxgvI/edit#heading=h.r9pyekg8gxd | Kyle Gracey (Future Matters) <> Jam: AIPLUS\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (3) Contra Scott on AI Races : slatestarcodex\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://astralcodexten.substack.com/p/your-book-review-safe-enough | Your Book Review: Safe Enough? - by a reader\n",
      "https://axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://slowboring.com/p/how-human-translators-are-coping | slowboring.com/p/how-human-translators-are-coping\n",
      "https://docs.google.com/document/d/1UerPByrxKBGfjflk3x3G2TEfKCTPOn1m4Xx1OFOSiOQ/edit | AI labs' statements on risk/progress - Google Docs\n",
      "https://readyforpolyamory.com/post/boundaries-are-for-everyone | Boundaries are for Everyone\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting — EA Forum\n",
      "https://twitter.com/Tatarigami_UA/status/1689002845289222145 | twitter.com/Tatarigami_UA/status/1689002845289222145\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://theverge.com/2023/8/2/23817107/google-ai-search-generative-experience-videos-links?utm_source=substack&utm_medium=email | Google’s AI Search Generative Experience is getting video and images - The Verge\n",
      "https://rethinkpriorities.org/publications/eu-farmed-fish-policy-reform-roadmap-brief | EU farmed fish policy reform roadmap brief — Rethink Priorities\n",
      "https://twitter.com/shashj/status/1673960802808627202 | twitter.com/shashj/status/1673960802808627202\n",
      "https://twitter.com/random_walker/status/1681277834956791814 | twitter.com/random_walker/status/1681277834956791814\n",
      "https://arxiv.org/abs/2306.12001 | [2306.12001] An Overview of Catastrophic AI Risks\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1 | The shape of AGI: Cartoons and back of envelope\n",
      "https://twitter.com/Simeon_Cps/status/1686726107003772928 | Siméon on Twitter: \"Here are 7 thoughts on why the terminology \"generative AI\" is anti-helpful for society: 1) Focus on use case: By dominating the discourse, the \"generative AI\" terminology focused the attention of most people on the wrong variable, i.e. what a system does rather than its… t.co/nfoJeVkUvb\" / X\n",
      "https://docs.google.com/document/d/1vgAWq2s3o4oYl61AiLJJYuiKLtrE20Fv4FG_qGZX_SU/edit | Rethink Priorites: Position Description, Chief Executive Officer\n",
      "https://hbr.org/2016/07/why-diversity-programs-fail?fbclid=IwAR2B3f9zxGE4Shz8h1k498bcNJ-2uKt9nlDuAUjWTzYC-dq5SSL5tLzyl90 | Why Diversity Programs Fail\n",
      "https://wikiwand.com/en/Lockheed_Martin_F-35_Lightning_II | Lockheed Martin F-35 Lightning II - Wikiwand\n",
      "https://abcnews.go.com/Technology/wireStory/council-hold-meeting-potential-threats-artificial-intelligence-global-100637416 | UN council to hold first meeting on potential threats of artificial intelligence to global peace - ABC News\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/phpr.13006 | Rational risk‐aversion: Good things come to those who weight - Bottomley - Philosophy and Phenomenological Research - Wiley Online Library\n",
      "https://dietrichvollrath.substack.com/p/will-ai-cause-explosive-economic | Will AI cause explosive economic growth?\n",
      "https://twitter.com/TheZvi/status/1688539653001895936 | Zvi Mowshowitz on Twitter: \"Can confirm from multiple attempts. The odd part is that it does sound remarkable now that he points it out, but at the time that thought never occurred to me at all.\" / X\n",
      "https://twitter.com/hlntnr/status/1679507664295067650 | Helen Toner on Twitter: \"Great analysis of China's new generative AI rules by Matt 👇🏻 A few extra things that jumped out at me: 1) Looking more and more like B2B might be the sweet spot for Chinese generative AI—it doesn't seem to be covered by these rules, and could be a source of huge value. Think...\" / Twitter\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | \"Crazy AI might be soon\" - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://twitter.com/Simeon_Cps/status/1693712262463103095 | Siméon on X: \"New J. Steinhardt blogpost just dropped. I highly recommend. Jacob has a very careful way of thinking about messy topics that I personally really like. I particularly recommend his posts \"More is Different\" and \"Complex Systems are Hard to Control\".\" / X\n",
      "https://docs.google.com/document/d/1H5BwxHaER62rqvIG051YK5VoFPM8dZefv2yhePWzzKw/edit#heading=h.kof73g10f1qh | RP AI regs team - survey suggestions - Google Docs\n",
      "https://docs.google.com/document/d/1jkeVr9rw1Uksgg1yKyEStHxBVPhovRON9vPC7GXHMnE/edit#heading=h.iu5m9zwyeqnb | Various takes on prospects for major AI regulation in the US - Google Docs\n",
      "https://mdickens.me/2016/04/06/expected_value_estimates_you_can_%28maybe%29_take_literally/ | Expected Value Estimates You Can (Maybe) Take Literally  Michael Dickens\n",
      "https://docs.google.com/document/d/1HlkOSn7HGkRIffkwMQS2ZtCcvCRHn5Akt2ptfidwLso/edit | Maybe if time permits get more advice on how I can be more helpful to Michael + AIGS - Google Docs\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://twitter.com/_lhermann/status/1683075797240750080 | Lukas Hermann on X: \"Let's talk about decision making! We all make big decisions all the time. And we all make wrong choices! These are the frameworks I use to make better decisions ...\" / X\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference — EA Forum\n",
      "https://aifuturesfellowship.org/ | AI Futures Fellowship\n",
      "https://docs.google.com/document/d/1TEfxH_KeXC6hFg8nSm8BvhoYVrG4OPZlWsWfG70Lzos/edit | Ashwin, assessed by MA - 2023 July - RP Performance Evaluation\n",
      "https://forum.effectivealtruism.org/posts/u5serAwnrrFSJonoF/4-things-givedirectly-got-right-and-wrong-sending-cash-to | 4 things GiveDirectly got right and wrong sending cash to flood survivors — EA Forum\n",
      "https://twitter.com/DAlperovitch/status/1694918321043288352 | Dmitri Alperovitch on X: \"Great WSJ story on Prigozhin’s last days Something that’s been bothering me since yesterday—why kill Prigozhin now. Putin doesn’t rush into things and often waits years to kill ‘traitors’ The answer— it was not about the mutiny. It was about business, as it always is in Russia\" / X\n",
      "https://twitter.com/simonw/status/1670115933640171520 | twitter.com/simonw/status/1670115933640171520\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | twitter.com/MTabarrok/status/1665057406043209729\n",
      "https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/ | The (local) unit of intelligence is FLOPs\n",
      "https://forum.effectivealtruism.org/posts/zjmpFW3nBKwaBB5xr/corporate-campaigns-work-a-key-learning-for-ai-safety | Corporate campaigns work: a key learning for AI Safety — EA Forum\n",
      "https://doingwestminsterbetter.substack.com/p/ai-summit-semiconductor-trade-policy | (1) AI summit, semiconductor trade policy, and a green light for alternative proteins\n",
      "https://docs.google.com/document/d/1NnAZ5HH27BPHg8o7Kn9zA_z1jA03Y2nz9eEs5sJ4d84/edit#heading=h.uf8ilpq04z6u | AIPLUS Meeting Notes\n",
      "https://guzey.com/ | Alexey Guzey\n",
      "https://forum.effectivealtruism.org/posts/5hprBzprm7JjJTHNX/reasons-i-ve-been-hesitant-about-high-levels-of-near-ish-ai-1 | Reasons I’ve been hesitant about high levels of near-ish AI risk — EA Forum\n",
      "https://docs.google.com/document/d/1KTE-9sq_7ig7Sohphwwk1epBFHietzcCOixBMerBH5w/edit#heading=h.j35uzjbkgmnb | Leveraging hardware security features for AI governance [shared widely] - Google Docs\n",
      "https://docs.google.com/document/d/1isVebPhVRMssrQ6T5N0hYgF1s0csKLGqkX1scDjf4EE/edit#heading=h.fpykg9xqqa6b | *Masterdoc: Info on projects we're considering incubating (2023) - Google Docs\n",
      "https://washingtonpost.com/opinions/2023/08/16/ai-danger-regulation-united-states/ | Here’s a simple way to regulate powerful AI models\n",
      "https://facebook.com/photo/?fbid=10154650283731541&set=a.394326071540 | facebook.com/photo/?fbid=10154650283731541&set=a.394326071540\n",
      "https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems | Trends in the dollar training cost of machine learning systems\n",
      "https://wikiwand.com/en/J._Robert_Oppenheimer | J. Robert Oppenheimer - Wikiwand\n",
      "https://docs.google.com/document/d/1hGGLSodwN_VopFioDahMkgslDm9-BQ4ckuqwwtcvjf0/edit#heading=h.ixh4wexqguvf | [DRAFT] Rollbacks and shutdowns for deployed AI models - Google Docs\n",
      "https://predictit.org/markets/detail/8074/Who-will-place-second-in-the-2024-Iowa-Republican-caucuses | PredictIt\n",
      "https://docs.google.com/spreadsheets/d/1CErMKxBbAHfbyQjmYxJE_R8Ip8MzUrsVsTySfqZov8M/edit#gid=0 | [Draft] Budget: Field building in universities for AI policy careers in the US - Google Sheets\n",
      "https://google.com/search?q=goodr+sunglasses&rlz=1CDGOYI_enUS715US715&hl=en-US&ei=vyKoZMriOaKpptQPheasWA&oq=goodr&gs_lcp=ChNtb2JpbGUtZ3dzLXdpei1zZXJwEAEYADIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQRxDWBBCwAzIKCAAQigUQsAMQQzIKCAAQigUQsAMQQzIKCAAQigUQsAMQQzIQCC4QigUQxwEQ0QMQsAMQQzIVCC4QigUQxwEQ0QMQyAMQsAMQQxgBMhUILhCKBRDHARDRAxDIAxCwAxBDGAEyFQguEIoFEMcBENEDEMgDELADEEMYATIVCC4QigUQxwEQ0QMQyAMQsAMQQxgBMhUILhCKBRDHARDRAxDIAxCwAxBDGAEyFQguEIoFEMcBENEDEMgDELADEEMYAUoECEEYAFAAWABg0QhoAXABeACAAQCIAQCSAQCYAQDAAQHIARHaAQQIARgI&sclient=mobile-gws-wiz-serp&dlnr=1&sei=wyKoZIbvGsumptQPs-KdiAE | goodr sunglasses\n",
      "https://slowboring.com/p/how-obama-and-trump-and-biden-beat | How Obama (and Trump and Biden) beat Europe\n",
      "https://twitter.com/FreightAlley/status/1695814472508543242 | twitter.com/FreightAlley/status/1695814472508543242\n",
      "https://heinrich.senate.gov/imo/media/doc/create_ai_act_fact_sheet1.pdf | CREATE AI Act of 2023\n",
      "https://forum.effectivealtruism.org/posts/kwxE7HYjRpYwSEiKb/underwater-torture-chambers-the-horror-of-fish-farming | Underwater Torture Chambers: The Horror Of Fish Farming — EA Forum\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://medium.com/polyamory-today/4-questions-for-breaking-down-jealousy-in-polyamorous-relationships-c16bcfd5ffc3 | 4 Questions for Breaking Down Jealousy in Polyamorous Relationships  by Marianna Zelichenko  Polyamory Today  Medium\n",
      "https://twitter.com/ajeya_cotra/status/1684358475416064001 | Ajeya Cotra on X: \"I'm really excited to see measurements of LLM agents on real-world tasks; it allows us to make progress on key disagreements. I'll lay down a forecast: &gt;50% chance that &gt;50% of the tasks will be solved by EOY 2024 (current accuracy is ~10%).\" / X\n",
      "https://arxiv.org/abs/2307.08823 | [2307.08823] Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries\n",
      "https://blog.jakegloudemans.com/post/10-predictions-2 | Predictions #2 - Jake Gloudemans\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://bloomberg.com/news/articles/2023-06-27/ai-is-next-tech-battle-for-us-and-china-on-chatgpt-frenzy?srnd=premium-asia#xj4y7vzkg | Billionaires and Bureaucrats Mobilize China for AI Race With US\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://twitter.com/gelliottmorris/status/1677879159450656771 | G Elliott Morris on Twitter: \"i guess if i was spending my saturday night playing around with a Bayesian poll aggregator for presidential approval -- and i'm not _not_ doing that -- then it would maybe looks something like this t.co/M2H2IMSzY9\" / Twitter\n",
      "https://docs.google.com/document/d/1Y8XuNs35IIm-RH1yWpHoBQ2GDoK5s83yEdcI0nvKiBA/edit#heading=h.xajd3x788e16 | Hamza Chaudry <> Jam: AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1rKeGoKdua4FV0XNWlDsatcd2biiiDqK-etSa_Wdhm28/edit#heading=h.i8626abq1vig | Collecting input on what US Regs should do (for August-October 2023)\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://forum.effectivealtruism.org/posts/FzoMPHtXzTig8pXuh/general-support-for-general-ea | General support for “General EA” — EA Forum\n",
      "https://gjopen.com/comments/1253265 | Good Judgment® Open\n",
      "https://twitter.com/henshall_will/status/1686857801061040128 | Will Henshall on X: \"Why do experts think AI progress likely to continue? It's just a continuation of trends that have been going on for decades 🧵 (1/6) t.co/N9zNaVICp5\" / X\n",
      "https://blog.jakegloudemans.com/post/17-predictions-5 | Predictions #5 - Jake Gloudemans\n",
      "https://twitter.com/goodside/status/1687321364116525056 | Riley Goodside on Twitter: \"Using ChatGPT custom instructions to play RLHF Chatroulette, where all responses are in reply to a different prompt entirely: t.co/npuGKvHRyf\" / X\n",
      "https://google.com/search?q=schartzman+ai&rlz=1C5CHFA_enGB1058GB1058&oq=schartzman+ai&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABgFGA0YHjIKCAIQABiGAxiKBdIBCDQ1ODhqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8 | google.com/search?q=schartzman+ai&rlz=1C5CHFA_enGB1058GB1058&oq=schartzman+ai&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABgFGA0YHjIKCAIQABiGAxiKBdIBCDQ1ODhqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8\n",
      "https://consciouspolyamory.org/2016/02/06/envy-and-the-secondary/ | Envy and the Secondary – Conscious Polyamory: A blog about loving more than one\n",
      "https://readsomethingwonderful.com/p/82/common-knowledge-and-aumanns-agreement-theorem | Read Something Wonderful - Common Knowledge and Aumann’s Agreement Theorem\n",
      "https://twitter.com/jacob_pfau/status/1675298017887256581 | twitter.com/jacob_pfau/status/1675298017887256581\n",
      "https://docs.google.com/document/d/19TtG9VmjhrBDsKovBH4zm7n-zLwiSqYa6C4ZgmYKdqI/edit#heading=h.5b4arlm5x51v | Elika Somani <> Jam: UFO and Careers advice program\n",
      "https://twitter.com/NathanpmYoung/status/1690010921689604098 | Nathan on Twitter: \"@KatjaGrace #5: Doug Campbell on Ukraine (@InsightForecast) Doug is a former Obama economic advisor and CEO of Insight Prediction, a prediction market. This was recorded weeks ago, delay is my fault. Doug gives a lot of info on his model of Ukraine. t.co/BUMafPDfLq\" / X\n",
      "https://wsj.com/tech/ai/ai-expert-max-tegmark-warns-that-humanity-is-failing-the-new-technologys-challenge-4d423bee?utm_source=substack&utm_medium=email | AI Expert Max Tegmark Warns That Humanity Is Failing the New Technology’s Challenge - WSJ\n",
      "https://forum.effectivealtruism.org/posts/XdhwXppfqrpPL2YDX/an-overview-of-the-ai-safety-funding-situation | An Overview of the AI Safety Funding Situation — EA Forum\n",
      "https://docsend.com/view/pj2ehvke2stwpeew | Crowdvocate II\n",
      "https://twitter.com/jeremyphoward/status/1689470850653999104 | Jeremy Howard on Twitter: \"A recent paper claimed that \"GPT 4 Can't Reason\". Using the custom instructions below, here are the (all correct) responses to the first 3 examples I tried from that paper. t.co/GMdqubjlXN\" / X\n",
      "https://twitter.com/dlippman/status/1676278822881173518 | twitter.com/dlippman/status/1676278822881173518\n",
      "https://forum.effectivealtruism.org/posts/DJEbnY4P5gcEaN3WA/manifolio-the-tool-for-making-kelly-optimal-bets-on-manifold | Manifolio: The tool for making Kelly optimal bets on Manifold Markets — EA Forum\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://openai.com/blog/moving-ai-governance-forward | Moving AI governance forward\n",
      "https://josephnoelwalker.com/148-stephen-wolfram/ | #148: Constructing the Computational Paradigm — Stephen Wolfram\n",
      "https://docs.google.com/document/d/1pAOApQlP4nXopMTGLT5F5fDsWpSGljc0fN5CtoyGtgw/edit | What Happens When A Model Fails an Eval? - Google Docs\n",
      "https://mercatus.org/research/defining-killer-ai?utm_source=substack&utm_medium=email | On Defining \"Killer AI\"  Mercatus Center\n",
      "https://morethantwo.com/polytime.html | More Than Two  Managing Time\n",
      "https://docs.google.com/spreadsheets/d/1EFT7QgTlxOV7b1ubxus2qAHIkIamvXM7aslCECszz6o/edit#gid=0 | Ranking exercise: AI-related surveys - Google Sheets\n",
      "https://docs.google.com/document/d/1IN7QqjeMbW7b4-oCUeZ9v6C397n-Hcl3q6Ig9FuWI-U/edit#heading=h.34g6myoeaex8 | 2023 AW Research & Projects Agenda [final] - Google Docs\n",
      "https://twitter.com/SciTechgovuk/status/1694590623012024522 | Department for Science, Innovation and Technology on X: \"On 1-2 November 2023, governments, AI companies and experts from around the work will meet at @BletchleyPark for crucial talks on the safe and responsible development of AI. AI has the potential to revolutionise the way we live, but we must also minimise its risks. t.co/7tw7qeRF7e\" / X\n",
      "https://twitter.com/peterwildeford/status/1694315597033590987 | twitter.com/peterwildeford/status/1694315597033590987\n",
      "https://forum.effectivealtruism.org/posts/tk2YWPKNqeCDWData/ea-germany-community-health-documents-and-processes | EA Germany Community Health Documents & Processes — EA Forum\n",
      "https://lesswrong.com/posts/3ou8DayvDXxufkjHD/openai-api-base-models-are-not-sycophantic-at-any-size | OpenAI API base models are not sycophantic, at any size — LessWrong\n",
      "https://twitter.com/BorisMPower/status/1689838493806333953 | Boris Power on Twitter: \"Agreed. GPT-4 plays chess at a strong club level when properly prompted, which is impossible to achieve without having a good internal model of the game. Even at Go, the model does ~10x better than random, by essentially picking up on locality being a strong signal.\" / X\n",
      "https://forum.effectivealtruism.org/posts/k7NjuGEKdRSrrJHmZ/deep-report-on-hypertension | Deep Report on Hypertension — EA Forum\n",
      "https://gucem.org/v/0.1.14/docs/Basic%20Models/AI%20Safety%20Research/ | AI safety research model  FTX GUCEM\n",
      "https://twitter.com/DanHendrycks/status/1688587119307177984 | Dan Hendrycks on Twitter: \"I was able to voluntarily rewrite my belief system that I inherited from my low socioeconomic status, anti-gay, and highly religious upbringing. I don’t know why Yann’s attacking me for this and resorting to the genetic fallacy+ad hominem. Regardless, Yann thinks AIs \"will… t.co/PWN8k59DOC\" / X\n",
      "https://forum.effectivealtruism.org/posts/WYsLjeJzh7tZqe6Lo/implications-of-evidential-cooperation-in-large-worlds | Implications of evidential cooperation in large worlds — EA Forum\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://cyberscoop.com/white-house-executive-order-artificial-intelligence/ | White House is fast-tracking executive order on artificial intelligence  CyberScoop\n",
      "https://facebook.com/groups/1479475219034058/?multi_permalinks=3516416492006577&hoisted_section_header_type=recently_seen | Dank EA Memes  Facebook\n",
      "https://docs.google.com/presentation/d/1Rc9JhKBXjO-eRTXx1sCx2gObnfjYob3idHI8a296xtE/edit#slide=id.g201946b620b_0_112 | 2023 July RP Fundraising Forecast Update - Google Slides\n",
      "https://forum.effectivealtruism.org/posts/CmAexqqvnRLcBojpB/electric-shrimp-stunning-a-potential-high-impact-donation | Electric Shrimp Stunning: a Potential High-Impact Donation Opportunity — EA Forum\n",
      "https://docs.google.com/document/d/1rzD2eWFypVLt_p6yX50s_mDm7r19WqRb-QUxpwL9wyA/edit | Mapping the AI governance landscape [HAIKU study notes]\n",
      "https://twitter.com/panickssery/status/1691479864518365186 | twitter.com/panickssery/status/1691479864518365186\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://twitter.com/daniel_271828/status/1686484436853063681 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"Yeah. Things that actually would be existential threats to humanity: • &gt;18 C (?) temperature rise from climate change • bioengineered superpandemic way out in the tail • full-scale nuclear war *after* build up of much larger nukes • superintelligent AI Versus 1.5 C rise in… t.co/oLbNDhnvqV\" / X\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://theinsideview.ai/shahar | Shahar Avin on AI Governance\n",
      "https://verifymyid.com/CS/kldmds83gd/upload.aspx?qs=HbUdUVyCqoG%2f2Bk%2bNH9%2fbmr2P02rIT5bukwLu87GKENHd757CAcZlo26VinVUOU%2fXQoztBhibD3FwQ7FPqXlfzu58k795U15l4Nr9ballsgWR92COACF3cKHYa91gdJrdazZ2wxEin7%2bPjPooIjfZJJSZMnTcXbeMihc0FSX1DXrJGrgjezJ9v6%2fmkERUrNyY6B4eudPp4DQ084H%2bU%2bjdMlA04bpdqw%2f45AnJR7ozcqE04%2bfh6i5QLU62OtThx9fELxw6Z%2f9pHmqbiBDTD%2f0QQvwqMBeEP1ekUs2kGTs0UwJLqsgzBE5gQCYMA10bfceSq9skK2IAdkD973%2bYvB05BJgcRb4ggGHzxzDTWulTnAMSQxtlLR3wMyRSbkKLUDd8Q5%2fkuZQ7hrZ7H6VvS%2fOaseb6nymJWNrbXKoQkoslwR%2fHISZYFBXtDlE68C3O1%2fizfZ9auDs%2bOAx7SHe0she1A%3d%3d | PredictIt - Identity Verification Document Upload\n",
      "https://reddit.com/r/relationship_advice/comments/15bo3kk/i_26f_emotionally_cheated_on_my_bf_38m_i_need_to/ | (5) I (26F) emotionally cheated on my BF (38M). I need to vent. I need opinions? : relationship_advice\n",
      "https://docs.google.com/document/d/1DD39bXAjzLpKVNC6MHHOBJuoXIzW9rA276gsW-vqF-M/edit#heading=h.ro1jy37s9d8f | Notes - Gabriel Weil and Ashwin Acharya - Google Docs\n",
      "https://twitter.com/Jsevillamol/status/1686028733734379521 | Jaime Sevilla on Twitter: \"Pablo's work suggests we can audit models with advanced capabilities before it is feasible to deploy them at scale. It also suggests development might happen earlier, because it lends support to the tradeoff dynamic in t.co/LvsFXjol6S\" / X\n",
      "https://google.com/search?q=beyond+this+moment&rlz=1C5CHFA_enGB1058GB1058&oq=beyond+this+moment&aqs=chrome.0.0i355i512j46i512j0i512j46i512j0i512j46i340i512j0i512j0i22i30l3.2523j0j1&sourceid=chrome&ie=UTF-8 | beyond this moment - Google Search\n",
      "https://aminrb.me/blog/extra-work/ | Navigating Extra Work in Programming Teams  Amin Rashidbeigi\n",
      "https://docs.google.com/document/d/1U28BUEzpFkqDZgoQnUXznD25RpDsPPo5dZqMeIODy58/edit#heading=h.z8jlehglcsvt | Michael, self-eval - 2023 July - RP Performance Evaluation - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/g4TcehspjDumGXucx/my-ea-journey | My EA Journey — EA Forum\n",
      "https://twitter.com/RFishBlueFish/status/1686772874340712457 | RedFishBlueFish on Twitter: \"@peterwildeford Or I guess best is probably just to weight people heavily by how well they've done,which I think is what you were saying that other score does\" / X\n",
      "https://politico.com/news/magazine/2023/08/29/forget-about-ohio-its-fools-gold-00113224 | No, Ohio Is Not in Play - POLITICO\n",
      "https://docs.google.com/document/d/1rl60P4UO79-pA0RaHKILtISIuLwTDudJXk5xuSQgR9E/edit#heading=h.q52a7f8v1vd | draft update 2023-08-01 -- Two-pager on RP's Existential Security Team - Google Docs\n",
      "https://docs.google.com/document/d/1qmQbmDv59AMPJ3RdGvzSg6HDZ-3NgAGb31q7ZeAoiLQ/edit | Timeline: Launching AI policy university field-building (UFO)\n",
      "https://joecarlsmith.com/2020/12/12/wholeheartedness-and-morality-as-taxes | Wholehearted choices and \"morality as taxes\" - Joe Carlsmith\n",
      "https://docs.google.com/document/d/12zdjWUq-R9bZAEbUa2iqFGCxZE7gGULtexI09bs0H44/edit | AIGS staff temporarily working at / embedding in other institutions\n",
      "https://80000hours.org/problem-profiles/great-power-conflict/ | Great power conflict - 80,000 Hours\n",
      "https://blog.jakegloudemans.com/post/13-predictions-3 | Predictions #3 - Jake Gloudemans\n",
      "https://twitter.com/random_walker/status/1681748271163912194 | twitter.com/random_walker/status/1681748271163912194\n",
      "https://morethantwo.com/polypets.html | More Than Two  Life Without Walls\n",
      "https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth | The Great Inflection? A Debate About AI and Explosive Growth—Asterisk\n",
      "https://docs.google.com/document/d/1Sf3mKWn6v7wp2tor4CaRhceBQ6EdRk-beA-BqlZdgag/edit#heading=h.jlb1cymowl8x | How to do research speedruns (EAGxNYC workshop)\n",
      "https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding#If_LTFF_raises__100_000 | What Does a Marginal Grant at LTFF Look Like? Funding Priorities and Grantmaking Thresholds at the Long-Term Future Fund — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/N4LKrktopDs5Qdqgn/an-introduction-to-critiques-of-prominent-ai-safety | An Introduction to Critiques of prominent AI safety organizations — EA Forum\n",
      "https://80000hours.org/podcast/episodes/markus-anderljung-regulating-cutting-edge-ai/ | Markus Anderljung on how to regulate cutting-edge AI models - 80,000 Hours\n",
      "https://docs.google.com/document/d/1U4OqEJdjSwjun2ihDZfibjE3Bin6eJomdlASlkQ4eQ0/edit#heading=h.6ytgvt3dfnpe | Michael Aird - May 2023 - RP Performance Evaluation - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://givingwhatwecan.org/charities/longtermism-fund/longtermism-fund-august-2023-grants-report | Longtermism Fund: August 2023 Grants Report\n",
      "https://wikiwand.com/en/List_of_highest-grossing_media_franchises | List of highest-grossing media franchises - Wikiwand\n",
      "https://forum.effectivealtruism.org/posts/awmsvYwXk2yjCN3uT/mistakes-in-the-moral-mathematics-of-existential-risk-part-2 | Mistakes in the moral mathematics of existential risk (Part 2: Ignoring background risk) - Reflective altruism — EA Forum\n",
      "https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/ | Reflections on “Making the Atomic Bomb” – Windows On Theory\n",
      "https://docs.google.com/document/d/1h1A3ArU8_umBooZ2qaiwjW2YHaLatZrU8GkAL6QIHqE/edit | Kat's 80/20 fundraising advice - Google Docs\n",
      "https://warontherocks.com/2022/08/amateur-hour-part-ii-failing-the-air-campaign/#:~:text=Five%20days%20into%20the%20invasion,aversion%2C%20and%20lack%20of%20confidence | Amateur Hour Part II: Failing the Air Campaign - War on the Rocks\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment\n",
      "https://ealifestyles.substack.com/p/i-made-my-home-office-super-bright?utm_source=substack&utm_medium=email | (1) I made my home office super bright and I kind of regretted it\n",
      "https://twitter.com/Tatarigami_UA/status/1695563964158025974 | Tatarigami_UA on X: \"Exceptional thread and profound insights into the counter-offensive in the South by @solonko1648 (Olexandr Solon'ko), servicemember of the Ukrainian Armed Forces. In his analysis, he sheds light on the situation, discussing both the challenges and achievements. Translation:… t.co/LW1eAHywma\" / X\n",
      "https://sci-hub.wf/10.1017/s1049096520001407 | Sci-Hub  Forecasting the 2020 Electoral College Winner: The State Presidential Approval/State Economy Model. PS: Political Science & Politics, 1–5  10.1017/s1049096520001407\n",
      "https://heatmap.news/ | Heatmap News\n",
      "https://theinformation.com/articles/openai-passes-1-billion-revenue-pace-as-big-companies-boost-ai-spending?utm_source=substack&utm_medium=email | OpenAI Passes $1 Billion Revenue Pace as Big Companies Boost AI Spending — The Information\n",
      "https://washingtonpost.com/opinions/2023/08/16/calvin-coolidge-president-politics-budget-silent/ | Opinion  ‘Silent Cal’ Coolidge sounds pretty good right about now - The Washington Post\n",
      "https://wired.com/story/microsoft-ai-red-team/?redirectURL=https%3A%2F%2Fwired.com%2Fstory%2Fmicrosoft-ai-red-team%2F&utm_source=substack&utm_medium=email | Microsoft’s AI Red Team Has Already Made the Case for Itself  WIRED\n",
      "https://docs.google.com/spreadsheets/d/1YvAWJJ7mco96cm482Pg3YqObDgV5ELIdvlhU4Ze10fM/edit#gid=1010051430 | Decision Theory Axioms and Consequences - Google Sheets\n",
      "https://lesswrong.com/posts/SfZRWxktiFFJ5FNk8/the-god-of-humanity-and-the-god-of-the-robot-utilitarians | The God of Humanity, and the God of the Robot Utilitarians — LessWrong\n",
      "https://docs.google.com/document/d/1AcQqV3M-TXpJ4NfjxofmenSdhgdD9FIp_Dp3_mNoBdA/edit#heading=h.xwwwlf2won0k | Ben's August review of XST incubation - Google Docs\n",
      "https://forecasting.quarto.pub/book/other-option.html?ref=bounded-regret.ghost.io | Forecasting: Lecture Notes - 7  The “Other” Option\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case — EA Forum\n",
      "https://roadtogrowthcounseling.com/managing-jealousy-in-your-polyamorous-relationships/ | Managing Jealousy in Your Polyamorous Relationships - Road to Growth Counseling\n",
      "https://metaculus.com/notebooks/17798/when-should-you-deviate-from-the-base-rate/ | When Should You Deviate From the Base Rate?  Metaculus\n",
      "https://twitter.com/messages/25776739-749003563494354945 | iabvek / X\n",
      "https://nytimes.com/column/retro-report | Retro Report - The New York Times\n",
      "https://morethantwo.com/relationshipbenchmarks.html | More Than Two  Healthy Relationships\n",
      "https://nytimes.com/2023/08/16/technology/ai-defcon-hackers.html?utm_source=substack&utm_medium=email | When Hackers Descended to Test A.I., They Found Flaws Aplenty - The New York Times\n",
      "https://arxiv.org/abs/2308.08708 | [2308.08708] Consciousness in Artificial Intelligence: Insights from the Science of Consciousness\n",
      "https://blog.jakegloudemans.com/post/15-links-7-26-2023 | Wednesday Links - Jake Gloudemans\n",
      "https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously | Eliezer Yudkowsky Is Frequently, Confidently, Egregiously Wrong — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/saAXc8zsFgZuxFM6L/xpt-forecasts-on-some-direct-approach-model-inputs | XPT forecasts on (some) Direct Approach model inputs\n",
      "https://80000hours.org/podcast/episodes/lennart-heim-compute-governance/ | LennartHeimonthecomputegovernanceeraandwhathastocome after\n",
      "https://twitter.com/Jess_Riedel/status/1690091247560720385 | Jess Riedel on Twitter: \"@nirsd Yes, the 35mph limit is an important caveat, but note: the fatal accident rate for human drivers in *urban* areas is 1.4/100M miles. So Cruise is avoiding some risk by avoiding the fastest urban roads, but a lot of the safety comes from just not speeding.\" / X\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit#heading=h.mfc0g6vdbaom | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/aTSoxTcSjyBWem3Xz/ea-survey-2022-how-people-get-involved-in-ea | EA Survey 2022: How People Get Involved in EA — EA Forum\n",
      "https://twitter.com/dsiroker/status/1689763756459675650 | Dan Siroker on Twitter: \"Lots of people told me I was crazy to post our Series A pitch deck publicly on Twitter. But, one of our cultural values at @RewindAI is transparency so I did it. Turned out great. Now I'm doing something even crazier. Here are my last five 360 performance reviews as CEO:…\" / X\n",
      "https://subscriber.politicopro.com/article/2023/07/biden-notches-voluntary-deal-with-7-ai-developers-00107509 | POLITICO Pro  Article  White House notches AI agreement with top tech firms\n",
      "https://docs.google.com/document/d/18KMqTKbJCvfNHIh7yMdGs-GN-NflsTOijD-6tYKnxuY/edit#heading=h.shuwelnrazfc | Refactoring Years Credit Calculations - Google Docs\n",
      "https://twitter.com/messages/25776739-1631315348 | Ted / Twitter\n",
      "https://forum.effectivealtruism.org/posts/ee8Pamunhqabucwjq/long-term-future-fund-ask-us-anything-september-2023 | Long-Term Future Fund Ask Us Anything (September 2023) — EA Forum\n",
      "https://twitter.com/alxndrdavies/status/1680976403674836992 | Xander Davies on Twitter: \"Two recent papers on \"red-teaming\" LLMs have really impressed me. 🧵 on what they are and why I'm excited about them!\" / Twitter\n",
      "https://docs.google.com/document/d/1wZATymY7IfC3DeBCtJeZrJ1f5w6GPaErx7cPHP-yZAQ/edit#heading=h.uc606df5qy4k | Bioanchors mini project - Google Docs\n",
      "https://twitter.com/peterwildeford/status/1692838720720818468 | twitter.com/peterwildeford/status/1692838720720818468\n",
      "https://thecut.com/2018/03/advice-from-a-polyamory-coach-on-dealing-with-jealousy.html | Advice From a Polyamory Coach on Dealing With Jealousy\n",
      "https://forum.effectivealtruism.org/posts/WxqyXbyQiEjiAsoJr/the-seeker-s-game-vignettes-from-the-bay | The Seeker’s Game – Vignettes from the Bay — EA Forum\n",
      "https://docs.google.com/document/d/1OmKOmMfbmBnjxGGHetfN2VQ1az4Zox0Y-4f5xTlRzhw/edit#heading=h.g2xot74rmmug | Maybe let’s focus more on non-extinction ways that a lot of the potential value of the future could be lost? [quick notes] - Google Docs\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | twitter.com/ohlennart/status/1669745972400861188\n",
      "https://bloomberg.com/news/articles/2023-08-08/stability-ai-s-lead-threatened-by-departures-concerns-over-ceo?in_source=embedded-checkout-banner&utm_source=substack&utm_medium=email#xj4y7vzkg | Stability AI’s Lead Threatened by Departures, Concerns Over CEO - Bloomberg\n",
      "https://theinsideview.ai/icml | ICML Papers I Find Interesting by Topic\n",
      "https://facebook.com/topher.t.brennan/posts/pfbid0Hna8QqgYansstQBGHZim3mHJCzya62UNbdpMhPFkw8qw3qv7r9dmRqhKLrEXUAbTl | facebook.com/topher.t.brennan/posts/pfbid0Hna8QqgYansstQBGHZim3mHJCzya62UNbdpMhPFkw8qw3qv7r9dmRqhKLrEXUAbTl\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://lesswrong.com/posts/R5yL6oZxqJfmqnuje/cultivating-a-state-of-mind-where-new-ideas-are-born | Cultivating a state of mind where new ideas are born — LessWrong\n",
      "https://docs.google.com/document/d/16HmGQ2sSGdGZsY-FrZxzFTf_uj4Jj8TE7SW_qEw7wRw/edit | Peter W time management - Google Docs\n",
      "https://longform.asmartbear.com/great-strategy/ | What makes a strategy great\n",
      "https://lesswrong.com/posts/DtkA5jysFZGv7W4qP/training-process-transparency-through-gradient | Training Process Transparency through Gradient Interpretability: Early experiments on toy language models\n",
      "https://rethinkpriorities.org/incubation | XST Incubation Website\n",
      "https://docs.google.com/spreadsheets/d/1qEsXG6I6hR2rhYxnuAtpHI-YcCAyPNt1uNYK5LT7CPc/edit#gid=593902022 | Peter's ERA - Rubric - 2023 - Google Sheets\n",
      "https://twitter.com/frances__lorenz/status/1687067982327869440 | Frances Lorenz on Twitter: \"Beautiful excerpt from Kelsey Piper on setting boundaries :'). I've stressed out loved ones time and again by not asserting my needs. Those who care for you properly will want the best for you and are relieved if you can advocate for yourself. t.co/xLnOAhJggo\" / X\n",
      "https://80000hours.org/podcast/episodes/jan-leike-superalignment/ | Jan Leike on OpenAI's massive push to make superintelligence safe in 4 years or less - 80,000 Hours\n",
      "https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo | [JOB] Opportunity to found Charity Entrepreneurship NGO (outside of the incubation program): Tobacco taxation advocacy — EA Forum\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://static1.squarespace.com/static/6035868111c9bd46c176042b/t/64e390ee3f1b0b0463d78a2b/1692635374731/EU+Farmed+fish+policy+road+map.pdf | [Final] EU Farmed fish policy road map\n",
      "https://docs.google.com/document/d/1CN7c8rft3RZ-lwzVB_MziKbixQatTbhsRaikt3v83PE/edit | [public] RP US AI regulations team 2-pager (June-Aug 2023) - Google Docs\n",
      "https://google.com/search?q=american+nuclear+monopoly&rlz=1CDGOYI_enUS715US715&oq=american+nuclear+monopoly&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDQzMzRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | american nuclear monopoly - Google Search\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? — LessWrong\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue) — LessWrong\n",
      "https://docs.google.com/document/d/1W5VKmUG_6QXHXPUoJkegPcooocO4jepWm_dVtxY-veE/edit#heading=h.bbl8wvrg7bsz | Researcher Gap Analysis 2023 - Google Docs\n",
      "https://semafor.com/article/08/16/2023/ex-google-ceo-eric-schmidt-to-launch-ai-science-moonshot?utm_source=Iterable&utm_medium=email&utm_campaign=campaign_7513609_nl_Philanthropy-Today_date_20230817&cid=pt&source=&sourceid= | Ex-Google CEO Eric Schmidt to launch AI-science moonshot  Semafor\n",
      "https://docs.google.com/document/d/1RGt4t1Xl5trlH7WipeQIwrO_WE4Evskx99bh1lMcYjU/edit | How does Lobbying in the US work? [HAIKU study notes]\n",
      "https://twitter.com/ohlennart/status/1678331653326884865 | twitter.com/ohlennart/status/1678331653326884865\n",
      "https://twitter.com/S_OhEigeartaigh/status/1682339412321894400 | Seán Ó hÉigeartaigh on X: \"A thread on AI priorities and tensions, based on discussions with colleagues: Three things that I think are true, or likely true: 1/17\" / X\n",
      "https://docs.google.com/document/d/1OlKlUwevSOMqyHqVjxEuR0QuZfX-SVZY-iidVAGfriw/edit#heading=h.fyqmhmgqjz1e | The Researcher's Guide to Comms - Google Docs\n",
      "https://docs.google.com/document/d/1avCcDdjHX-I6HjWubGPlk0MbEZDiK1V2Yk_-uLzvEKM/edit#heading=h.miibfeew6vyi | Quick investigation: Field building for AI policy - Google Docs\n",
      "https://wired.com/story/pause-ai-existential-risk/ | Meet the AI Protest Group Campaigning Against Human Extinction\n",
      "https://docs.google.com/document/d/1rKcUmCDDB-0Kp759ylO4uNIZzrehSDNeta6PrM888uo/edit | [Shared w/ SFF] Internal Notes from DC meetings - Google Docs\n",
      "https://twitter.com/peterwildeford/status/1692848637238202469 | twitter.com/peterwildeford/status/1692848637238202469\n",
      "https://80000hours.org/podcast/episodes/richard-ngo-large-language-models/ | Richard Ngo on large language models, OpenAI, and striving to make the future go well - 80,000 Hours\n",
      "https://lesswrong.com/posts/DCL3MmMiPsuMxP45a/even-superhuman-go-ais-have-surprising-failures-modes | Even Superhuman Go AIs Have Surprising Failures Modes\n",
      "https://twitter.com/rgblong/status/1693700773358731622 | Robert Long on X: \"1/ Could AI systems be conscious any time soon? @patrickbutlin and I worked with leading voices in neuroscience, AI, and philosophy to bring scientific rigor to this topic. Our new report aims to provide a comprehensive resource and program for future research 🧵 t.co/NYCM9N6RQf\" / X\n",
      "https://forum.effectivealtruism.org/posts/7Tvc3N7nFa32ekuGA/forum-feature-update-reactions-improved-search-updated-post | Forum feature update: reactions, improved search, updated post pages and more (July 2023) — EA Forum\n",
      "https://bostonglobe.com/2023/07/06/opinion/ai-safety-human-extinction-dan-hendrycks-cais/ | Dan Hendrycks of the Center for AI Safety hopes he can prevent a catastrophe\n",
      "https://twitter.com/Jotto999/status/1693453947397173443 | (4) Jotto 🔍 on X: \"I know I'm pretty radical on this one, but I've never thought “AGI” was ever crisp enough, for many of the discussions most people were trying to use it in.\" / X\n",
      "https://twitter.com/noahlt/status/1686047991243943936 | twitter.com/noahlt/status/1686047991243943936\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://google.com/search?q=only+murders+in+the+building&rlz=1CDGOYI_enUS715US715&oq=only+murders&gs_lcrp=EgZjaHJvbWUqBwgBEAAYjwIyBggAEEUYOTIHCAEQABiPAjIHCAIQABiPAtIBCDE3NjJqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | only murders in the building - Google Search\n",
      "https://docs.google.com/document/d/1KUdK1GwwzI0wBmeGKE0nmgHRPtUIUx-j7wHUxJCIe_E/edit | Will humanity achieve its full potential, as long as existential catastrophe is prevented? [semi-public] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fI6JUcI796OKohKILyJQ_xpU2vY25egUq6A-wX_OUjo/edit#gid=0 | Streaming services - Google Sheets\n",
      "https://openai.com/blog/function-calling-and-other-api-updates | Function calling and other API updates\n",
      "https://twitter.com/JgaltTweets/status/1691706136511103176 | JgaltTweets on Twitter: \"'[British] officials are eyeing Bletchley Park as a possible venue [for the Global Summit on AI Safety]... The government is preparing to announce fuller details of the conference, including its date, location and invitees, in the coming weeks' t.co/62wVN9Rt4T\" / X\n",
      "https://twitter.com/Simeon_Cps/status/1687849944802021376 | twitter.com/Simeon_Cps/status/1687849944802021376\n",
      "https://forum.effectivealtruism.org/posts/SCKg5N9oHdBDxHvEM/getting-into-an-ea-aligned-organisation-mid-career | Getting into an EA-aligned organisation mid-career — EA Forum\n",
      "https://hbr.org/2011/04/peacetime-ceos-vs-wartime-ceos | Are You a Peacetime CEO or a Wartime CEO?\n",
      "https://lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1 | Model Organisms of Misalignment: The Case for a New Pillar of Alignment Research — LessWrong\n",
      "https://forum.effectivealtruism.org/posts/jWvgcLikfZj9MWhon/linkpost-eric-schwitzgebel-ai-systems-must-not-confuse-users | [Linkpost] Eric Schwitzgebel: AI systems must not confuse users about their sentience or moral status — EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://experimental-history.com/p/an-invitation-to-a-secret-society | An invitation to a secret society - by Adam Mastroianni\n",
      "https://twitter.com/random_walker/status/1673894212490735616 | twitter.com/random_walker/status/1673894212490735616\n",
      "https://lesswrong.com/posts/5sNLX2yY5FzkCp7Ju/the-spelling-miracle-gpt-3-spelling-abilities-and-glitch | The \"spelling miracle\": GPT-3 spelling abilities and glitch tokens revisited — LessWrong\n",
      "https://docs.google.com/document/d/1HSltd_J8-C_Jje8pniWZY2xt9WZMqhPS8PeYDwRI-Dw/edit#heading=h.xw0gyniluvvi | [RP only] Prep for infosharing call AIPLUS - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/to34jb5LuWo4fM9gC/taking-prioritisation-within-ea-seriously | Taking prioritisation within 'EA' seriously — EA Forum\n",
      "https://progress.institute/can-policymakers-trust-forecasters/ | Can Policymakers Trust Forecasters? - Institute for Progress\n",
      "https://docs.google.com/document/d/1t-mtfaTHWAycw5swPsrXiJHwptMlns3eCC6uDN5B7JY/edit#heading=h.djrqti4gjs0v | How hardware-enabled mechanisms could reduce existential risk - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/QNdG4msZS3G29uG5X/biosafety-in-bsl-3-bsl-3-and-bsl-4-laboratories-mapping-and | Biosafety in BSL-3, BSL-3+ and BSL-4 Laboratories: Mapping and Recommendations for Latin America — EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations | When can we trust model evaluations? — LessWrong\n",
      "https://twitter.com/hamandcheese/status/1696144897302999445 | Samuel Hammond 🌐🏛 on X: \"I don't know if AI will kill us all. But will AI lead to regime change and / or state collapse? Oh, almost definitely. This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it: t.co/OBb5bM1a4G\" / X\n",
      "https://lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium | The lost millennium — LessWrong\n",
      "https://understandingai.org/p/driverless-cars-may-already-be-safer | (1) Driverless cars may already be safer than human drivers\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://learningfromexamples.substack.com/p/an-introduction-to-ai-history | An introduction to AI history - by Harry Law\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://docs.google.com/document/d/1qmQbmDv59AMPJ3RdGvzSg6HDZ-3NgAGb31q7ZeAoiLQ/edit#heading=h.av7lzo8ofz1z | Timeline: Launching AI policy university field-building (UFO) - Google Docs\n",
      "https://twitter.com/dfrsrchtwts/status/1684277989834653696 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: Do you know who Alondra Nelson is?\" / Twitter\n",
      "https://twitter.com/messages/25776739-1287003293214863362 | (10) oh lovely lion (4/100 mettas) / X\n",
      "https://arxiv.org/abs/2304.03442 | Generative Agents: Interactive Simulacra of Human Behavior\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://sustainabilitybynumbers.com/ | (1) Sustainability by numbers  Hannah Ritchie  Substack\n",
      "https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/ | Ajeya Cotra on accidentally teaching AI models to deceive us - 80,000 Hours\n",
      "https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/ | Squeeze the hell out of the system you have – Dan Slimmon\n",
      "https://twitter.com/SSGamblers/status/1674675424356442112 | twitter.com/SSGamblers/status/1674675424356442112\n",
      "https://fivethirtyeight.com/features/16-states-made-it-harder-to-vote-this-year-but-26-made-it-easier/ | 16 States Made It Harder To Vote This Year. But 26 Made It Easier.  FiveThirtyEight\n",
      "https://forum.effectivealtruism.org/posts/2rRsjdrL9BEWC3d7C/personal-reflections-on-longtermism | Personal Reflections on Longtermism — EA Forum\n",
      "https://lesswrong.com/posts/ppQRJEfLBCLFzK73w/linkpost-michael-nielsen-remarks-on-oppenheimer | [Linkpost] Michael Nielsen remarks on 'Oppenheimer' — LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1pm6YEqSRfpjM3W5sTxOVfda67J5Ib4Byw35gi9A7WUQ/edit#gid=20746289 | Animal ROI scrap - Google Sheets\n",
      "https://docs.google.com/document/d/1R_yudIhkh8YJXRO20vDgGUkbklXpg2MrWF8bxAtcugo/edit#heading=h.tcmcuy30mpts | Julia’s takes on movement-wide codes of conduct - Google Docs\n",
      "https://docs.google.com/presentation/d/1dKeyVbNLfaO7QCYTSSleXicRGK8qAestfheQ_8ORrF4/edit#slide=id.g2546af80730_0_214 | Peter's lightning talks - Google Slides\n",
      "https://reddit.com/r/BDSMerotica/comments/r0ta5n/teased_and_tied_up_while_he_games_part_1_mdom/ | (2) Teased and Tied Up While He Games - Part 1 [Mdom] [Bondage] [Toys] [Objectification] : BDSMerotica\n",
      "https://docs.google.com/document/d/1zEfb_gtceMnJabsOGVjNWUviQ5ARJ9oo5h_SrJ95Gv0/edit#heading=h.nm0ae28am02o | Overview of the AI lobbying and advocacy space - Google Docs\n",
      "https://bitsaboutmoney.com/archive/the-waste-stream-of-consumer-finance/ | Credit card debt collection\n",
      "https://forum.effectivealtruism.org/posts/yKWGkcuke577ReBPW/you-can-also-help-animals-by-earning-more-in-other-career | You Can Also Help Animals By Earning (More) in Other Career Paths and Donating — EA Forum\n",
      "https://theintrinsicperspective.com/p/consciousness-is-a-great-mystery | (1) Consciousness is a great mystery. Its definition isn't.\n",
      "https://spectrum.ieee.org/members-advocate-for-ai-regulations?utm_source=substack&utm_medium=email | Members Advocate for AI Regulations During Visit to U.S. Congress - IEEE Spectrum\n",
      "https://twitter.com/IvanVendrov/status/1611809666266435584 | ivan in berlin on Twitter: \"The famous \"36 questions that lead to love\"... don't. The NYT and everyone else reported a different set of questions from the same authors, modified to be less romantic! The original set of *40* questions wasn't online, but I emailed the authors and got a copy. Details in 🧵\" / X\n",
      "https://docs.google.com/document/d/1ZY87TRXNcSoAgcDzug7LytwOXMY_2YmxQ5KCjjB2Cdg/edit#heading=h.6ytgvt3dfnpe | [Ashwin evaluating Patrick] July - RP Performance Evaluation Template - Google Docs\n",
      "https://docs.google.com/document/d/1dxqRdJqufyguiCuxj0aEN6P9G-khVR4y80cw88Eb-U8/edit#heading=h.lzlp3cfhsbxy | Skip-level meeting template - Google Docs\n",
      "https://twitter.com/lukeprog/status/1688589549407027202 | Luke Muehlhauser on Twitter: \"This is important for policymakers to understand: t.co/yE83hrBArz t.co/79cjdGNNTT\" / X\n",
      "https://open.spotify.com/episode/3l6LAC3LeQnr8eFaKXLEui?si=BgmfDuXCSoakdIbxsE-HHg&nd=1 | Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & AGI in 2 years - Dwarkesh Podcast (Lunar Society formerly)  Podcast on Spotify\n",
      "https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are | Are We Smart Enough to Know How Smart AIs Are?—Asterisk\n",
      "https://blog.jakegloudemans.com/post/12-adversarial-policies-go | Go AIs have surprising vulnerabilities - Jake Gloudemans\n",
      "https://fast.ai/posts/2023-11-07-dislightenment.html | AI Safety and the Age of Dislightenment\n",
      "https://betonit.substack.com/p/the_social_andhtml | The Social and Political Realities of Immigration: A Reply to Hoste\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1avCcDdjHX-I6HjWubGPlk0MbEZDiK1V2Yk_-uLzvEKM/edit | Quick investigation: Field building for AI policy\n",
      "https://jeanhsu.substack.com/p/ask-vs-guess-culture | Ask vs guess culture - by Jean Hsu - Tech and Tea\n",
      "https://natesilver.net/ | (1) Silver Bulletin  Nate Silver  Substack\n",
      "https://twitter.com/petergyang/status/1696166433355399509 | twitter.com/petergyang/status/1696166433355399509\n",
      "https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/ | What will GPT-2030 look like?\n",
      "https://docs.google.com/document/d/1WbINVhU5MtNGsb7bWM9pHPQYpW18aZJ9fVDVtHV5ZAA/edit | 2023-06 SFF long-form attachment for AIGS - Google Docs\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | twitter.com/DAlperovitch/status/1653375041751375872\n",
      "https://ropeconnections.com/consensual-non-consent-play-rape-partner/ | Consensual Non-Consent: How To Play Rape Your Partner\n",
      "https://twitter.com/norabelrose/status/1695910634146455843 | twitter.com/norabelrose/status/1695910634146455843\n",
      "https://forum.effectivealtruism.org/posts/Doa69pezbZBqrcucs/shaping-humanity-s-longterm-trajectory | Shaping Humanity's Longterm Trajectory — EA Forum\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai | FACT SHEET: Biden-⁠Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI\n",
      "https://docs.google.com/document/d/1aHXiPAGvIoD1AfjvHM9XLf1j_LD6eYCBVzMK51M1H7w/edit#heading=h.namprdhlc75p | 2023_06_30_XRisk_Cost_Curves_ZDFG - Google Docs\n",
      "https://latimes.com/entertainment-arts/movies/story/2023-08-11/oppenheimer-atomic-bomb-hiroshima-nagasaki-christopher-nolan | ‘Oppenheimer’ doesn’t show Hiroshima or Nagasaki — by choice - Los Angeles Times\n",
      "https://twitter.com/daniel_271828/status/1678561847107272704 | Daniel Eth (yes, Eth is my actual last name) on Twitter: \"Someone should redo the \"AI &amp; efficiency\" stuff but with LLMs. How much have algorithmic improvements (architectural tweaks, fine-tuning, prompt engineering, etc) improved LLM capabilities on various metrics, compared to just scaling?\" / Twitter\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1XtlN8nttvKA29BNE1fq8nC5HAnW1a6IT_lXl852d47A/edit#heading=h.yc58d8t72780 | 2023-Jan-27 - MA questions to Abraham - ops budget etc. - Google Docs\n",
      "https://twitter.com/Jess_Riedel/status/1686008589092372480 | Jess Riedel on Twitter: \"What are the top concrete policy proposals being discussed by the senate judiciary committee?\" / X\n",
      "https://wikiwand.com/en/Mirror_life | Mirror life - Wikiwand\n",
      "https://docs.google.com/document/d/1ZCMSk2s0ylDsKJ2JMuDIxgVrJE9VfuSSrp2vrzE3iuE/edit#heading=h.y0srbz710jxs | Call notes: Jam-Jake Swett [19 June 2023] Topic: AIPLUS - Google Docs\n",
      "https://lesswrong.com/posts/bBicgqvwjPbaQrJJA/dirty-concepts-in-ai-alignment-discourses-and-some-guesses | “Dirty concepts” in AI alignment discourses, and some guesses for how to deal with them — LessWrong\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://reddit.com/r/polyamory/comments/2zd8zl/good_boundaries/ | (4) Good boundaries : polyamory\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on X: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / X\n",
      "https://arxiv.org/abs/2306.09983 | Evaluating Superhuman Models with Consistency Checks\n",
      "https://forum.effectivealtruism.org/s/X2k5Kqw3RyuB6QLMA | CEA Community Events Retrospective\n",
      "https://arxiv.org/abs/2304.05376 | ChemCrow: Augmenting large-language models with chemistry tools\n",
      "https://docs.google.com/document/d/1_bljply8Xk_WaZ8umdqRmMP1V-5emk3S1v_Ppy_vkw0/edit#heading=h.6eucefmsv0x9 | Project idea: China AI think tank\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://docs.google.com/document/d/1Wyd6GyK02vPaJHczfAx3oOvBc32nthRI9pwMcGE0sJY/edit#heading=h.q6o2gdl48ntd | [Draft] What do you have to believe for \"minimal longtermism\" to beat GHD and cage-free campaigns? - Google Docs\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://joecarlsmith.com/2021/03/07/care-and-demandingness | Care and demandingness - Joe Carlsmith\n",
      "https://docs.google.com/document/d/1WqLe5cE9Pozp5C9FlgG2ei_TwlOkVMYRMLJUuB_5A-o/edit | CONFIDENTIAL: Notes on Alexander, internal OP politics, and potential upshots (Shared w/ WIT) - Google Docs\n",
      "https://washingtonpost.com/technology/2023/08/09/google-james-manyika-ai-existential-threat/?utm_source=substack&utm_medium=email | Google’s AI ambassador walks a fine line between hype and doom - The Washington Post\n",
      "https://google.com/search?q=Galettes+des+rois&rlz=1C5CHFA_enGB1058GB1058&oq=Galettes+des+rois&aqs=chrome..69i57.163j0j1&sourceid=chrome&ie=UTF-8 | Galettes des rois - Google Search\n",
      "https://warontherocks.com/2023/07/ukraine-struggles-to-scale-offensive-combat-operations/ | Ukraine Struggles to Scale Offensive Combat Operations - War on the Rocks\n",
      "https://lesswrong.com/posts/KpD2fJa6zo8o2MBxg/consciousness-as-a-conflationary-alliance-term | Consciousness as a conflationary alliance term — LessWrong\n",
      "https://hearthackersclub.com/date-someone-anxious-attachment-style/ | How to Date Someone With an Anxious Attachment Style\n",
      "https://lawfaremedia.org/article/the-next-frontier-in-ai-regulation-is-procedure | The Next Frontier in AI Regulation Is Procedure  Lawfare\n",
      "https://morethantwo.com/relationshipassumptions.html | More Than Two  Making the Good Bits Stick\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? — LessWrong\n",
      "https://facebook.com/katxiowoods/posts/pfbid02PDsQftmwpqYPTHzqMnBGoF9R6UAoMCw2K6TCArt9ZKD2aA96YoLL2qnEDnifGxdXl | facebook.com/katxiowoods/posts/pfbid02PDsQftmwpqYPTHzqMnBGoF9R6UAoMCw2K6TCArt9ZKD2aA96YoLL2qnEDnifGxdXl\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/08/09/biden-harris-administration-launches-artificial-intelligence-cyber-challenge-to-protect-americas-critical-software/?utm_source=ActiveCampaign&utm_medium=email&utm_content=Checking+In+on+Ukraine+s+Counteroffensive&utm_campaign=Checking+In+on+Ukraine+s+Counteroffensive | Biden-Harris Administration Launches Artificial Intelligence Cyber Challenge to Protect America’s Critical Software  The White House\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/bmrr8DFufz5Yh8yRC/thresholds-1-what-does-good-look-like-for-longtermism | Thresholds #1: What does good look like for longtermism? — EA Forum\n",
      "https://twitter.com/ohlennart/status/1678688731333644288 | twitter.com/ohlennart/status/1678688731333644288\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/11izXrENe0_IAor93e4-Gbgr18JAjzS7yIltVuxFaR1U/edit | Scaling Well - Google Docs\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://80000hours.org/podcast/episodes/joe-carlsmith-navigating-serious-philosophical-confusion/ | Joe Carlsmith on navigating serious philosophical confusion - 80,000 Hours\n",
      "https://washingtonpost.com/technology/2023/07/05/ai-apocalypse-college-students/ | Billionaires push AI apocalypse risk through college student groups - The Washington Post\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/idjzaqfGguEAaC34j/?commentId=ybbvrLt2sNHpvvE5D#ybbvrLt2sNHpvvE5D | If your AGI x-risk estimates are low, what scenarios make up the bulk of your expectations for an OK outcome? — EA Forum\n",
      "https://readtobloom.com/ | Global Home for Social Impact\n",
      "https://docs.google.com/document/d/1tq9rY1TCs49XHckWtzOowYz_xHXFnRpOZq8r0lE5JSQ/edit#heading=h.z7flydhghql5 | Where should I move? - Google Docs\n",
      "https://reddit.com/r/polyamory/comments/10nrgsd/do_i_need_to_figure_out_how_to_handle_my_jealousy/ | (4) Do I need to figure out how to handle my jealousy, or is polyamory not for me? : polyamory\n",
      "https://forum.effectivealtruism.org/posts/3a6QWDhxYTz5dEMag/how-can-we-improve-infohazard-governance-in-ea-biosecurity | How can we improve Infohazard Governance in EA Biosecurity? — EA Forum\n",
      "https://twitter.com/random_walker/status/1681643671211343873 | twitter.com/random_walker/status/1681643671211343873\n",
      "https://twitter.com/arjun_ramani3/status/1673802058565132290 | Arjun Ramani on X: \"New essay in @gradientpub! Using the idea of \"bottlenecking\", formalised by Baumol in the 60s, @zhengdongwang and I explain why we think an AI-driven growth explosion is unlikely A 🧵of technical, social and economic bottlenecks that together could limit AIs economic impact 1/10 t.co/Sn619Y91p7\" / X\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring? - by Robert de Neufville\n",
      "https://horizonpublicservice.org/post/applications-open-for-2024-horizon-fellowship-cohort | Applications open for 2024 Horizon Fellowship cohort\n",
      "https://docs.google.com/document/d/1XvA5FJozJi2_9YtNDrGw9HyRSYJ2FdANS4-OBHOjIyI/edit#heading=h.kbwddz1jya9u | Value of RP's Research in GHD and Animal Welfare - Google Docs\n",
      "https://wired.com/story/the-myth-of-open-source-ai/ | The Myth of ‘Open Source’ AI  WIRED\n",
      "https://docs.google.com/document/d/1LLzrTxtqsUtkmYbaqeAl26NT2fFJeYDEks1Mv_gcAQA/edit#heading=h.kydrosfseiym | Nuclear Regulatory Commission case study - Ashwin - Google Docs\n",
      "https://docs.google.com/document/d/1IJvZp1Cg3Oybhm4hqaT0fR1GUQ8FqyyKtOZHNL0RxZs/edit | Notes - WIT Weekly Meeting\n",
      "https://lesswrong.com/posts/3GSRhtrs2adzpXcbY/rationality-winning | Rationality !== Winning — LessWrong\n",
      "https://reddit.com/r/relationship_advice/comments/15g4xtz/my_38m_husband_confessed_that_i_25f_am_a_second/ | (3) My (38m) husband confessed that I (25f) am a Second wife. How to get over this? : relationship_advice\n",
      "https://garymarcus.substack.com/p/what-if-generative-ai-turned-out?utm_source=substack&utm_medium=email | (1) What if Generative AI turned out to be a Dud?\n",
      "https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics | Why should ethical anti-realists do ethics? - Joe Carlsmith\n",
      "https://twitter.com/messages/25776739-1133196129309356032 | Ben Hurford / X\n",
      "https://twitter.com/tomascodes/status/1674020711453675520 | twitter.com/tomascodes/status/1674020711453675520\n",
      "https://twitter.com/jachiam0/status/1681231077959163905 | twitter.com/jachiam0/status/1681231077959163905\n",
      "https://twitter.com/dfrsrchtwts/status/1684278778850336768 | Daniel Filan research-tweets on Twitter: \"People in the AI x-risk community: have you read the blueprint for an AI bill of rights, and do you have a concrete opinion on it?\" / Twitter\n",
      "https://lesswrong.com/posts/pZrvkZzL2JnbRgEBC/feedbackloop-first-rationality | Feedbackloop-first Rationality — LessWrong\n",
      "https://twitter.com/lawhsw/status/1681937200659808257 | harry law on Twitter: \"some loose thoughts on the ‘gpt4 is getting worse’ discourse 1. the same dynamics are at play a) when a paper that debunks capabilities makes a lot noise but eventually gets contested, and b) when research claiming greater performance gets a bit of traction but its results…\" / Twitter\n",
      "https://twitter.com/Manderljung/status/1691153005956173824 | twitter.com/Manderljung/status/1691153005956173824\n",
      "https://google.com/search?q=codependent+no+more&rlz=1C5CHFA_enGB1058GB1058&oq=codependent+no+more&aqs=chrome.0.0i271j46i131i433i512j46i512j0i512j46i512j0i512l5.2139j0j1&sourceid=chrome&ie=UTF-8 | codependent no more - Google Search\n",
      "https://gaingels.com/gaingels-letter | The Gaingels Letter - Gaingels\n",
      "https://businessinsider.com/ed-sheeran-ai-music-warn-tech-chatgpt-generative-ai-2023-8?r=US&IR=T&utm_source=substack&utm_medium=email | Ed Sheeran Says He Finds 'AI a Bit Weird' and Worries About Job Losses\n",
      "https://metaculus.com/questions/18228/metaculus-ai-benchmarks-bias/ | Metaculus AI benchmarks bias  Metaculus\n",
      "https://discoursemagazine.com/ | Discourse  Home\n",
      "https://forum.effectivealtruism.org/posts/AJJTRmW7zhvXrmD5s/apply-to-ceealar-to-do-agi-moratorium-work | Apply to CEEALAR to do AGI moratorium work\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://secondbest.ca/p/will-there-be-major-ai-legislation | Will there be major AI legislation before 2025?\n",
      "https://foreignaffairs.com/world/how-prevent-ai-catastrophe-artificial-intelligence | How to Prevent an AI Catastrophe  Foreign Affairs\n",
      "https://gucem.org/v/0.1.14/docs/Worldview/Biorisk/ | Bio xrisk  FTX GUCEM\n",
      "https://metaculus.com/questions/18177/room-temp-superconductor-replicated-by-2025/ | Room-temp Superconductor Replicated by 2025  Metaculus\n",
      "https://youtube.com/playlist?list=PLwp9xeoX5p8MbksBvu_R_IOz6kD4H7ytC | EA Global: London 2023 - YouTube\n",
      "https://docs.google.com/document/d/1eO_-UjygEZOsQfMtRUv-12FnN0oGVNQi_gr6qNU3a5U/edit | Lab Governance Workstream - 2-Pager (External) - Google Docs\n",
      "https://docs.google.com/document/d/1d_3U-cEUvQoc5yUz2ZFO2uk7HQmfQWisC6OYo-QGtns/edit | Lessons Learned  2023 Mid-Year Fundraiser - Google Docs\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://fluentin3months.com/fluent-in-3-years/?expand_article=1 | Fluent in 3 years?! What I Learned From a 1,033 Day Duolingo Streak -- Plus How to Actually Learn a Language Fast\n",
      "https://twitter.com/adamrpearce/status/1688593569429307396 | Adam Pearce on Twitter: \"Do Machine Learning Models Memorize or Generalize? t.co/Ln3xIZhKLs An interactive introduction to grokking and mechanistic interpretability w/ @ghandeharioun, @nadamused_, @Nithum, @wattenberg and @iislucas t.co/ig9dp9GJBe\" / X\n",
      "https://forum.effectivealtruism.org/posts/oPao8avpq48GPvzDZ/two-years-community-building-ten-lessons-re-learned | Two Years Community Building, Ten Lessons (Re)Learned — EA Forum\n",
      "https://docs.google.com/document/d/1zJRIp64pkDCK8FfZkbOxyNo4pODBXIWbu7A8Yhh8U_A/edit#heading=h.osty8jeclpyn | AI chip smuggling into China - Google Docs\n",
      "https://twitter.com/messages/25776739-48111864 | Alec Stapp / X\n",
      "https://kinkyevents.co.uk/confessions-of-a-sub-teasing-and-begging/ | Confessions of a Sub: Teasing and Begging\n",
      "https://aipolicy.us/ | Center for AI Policy\n",
      "https://twitter.com/NathanpmYoung/status/1681590722628136960 | twitter.com/NathanpmYoung/status/1681590722628136960\n",
      "https://wired.com/story/chatgpt-scams-fraudgpt-wormgpt-crime/?utm_source=substack&utm_medium=email | Criminals Have Created Their Own ChatGPT Clones  WIRED\n",
      "https://aisafetychina.substack.com/p/ai-safety-in-china-1 | (1) AI Safety in China #1 - AI Safety in China\n",
      "https://twitter.com/admcrlsn/status/1688564035518877696 | Adam Carlson on Twitter: \"Things that stood out to me the most are 50+ pt partisan gaps on whether: -Gov’t should ensure everyone has healthcare -Gun laws should be stricter -Human activity is main cause of global warming And the emerging partisan consensus on legality of marijuana &amp; same-sex marriage: t.co/PvyX7NiTYt\" / X\n",
      "https://docs.google.com/document/d/1R9jnOAmZC0XGmJJPYrzUq8N_825SB1fzsd0yco7TbPA/edit#heading=h.5g5p4s3snxj0 | AI Governance overview - Google Docs\n",
      "https://80000hours.org/podcast/episodes/jeffrey-lewis-common-misconceptions-about-nuclear-weapons/ | Jeffrey Lewis on the most common misconceptions about nuclear weapons - 80,000 Hours\n",
      "https://forum.effectivealtruism.org/posts/o5vJ9aNvc7twdqDxv/the-mental-health-challenges-that-come-with-trying-to-have-a | The mental health challenges that come with trying to have a big impact (Hannah Boettcher on the 80k After Hours Podcast) — EA Forum\n",
      "https://twitter.com/Scholars_Stage/status/1681675648446742531 | twitter.com/Scholars_Stage/status/1681675648446742531\n",
      "https://economist.com/special-report/2023/07/03/how-ukraines-enemy-is-also-learning-lessons-albeit-slowly | How Ukraine’s enemy is also learning lessons, albeit slowly\n",
      "https://link.springer.com/article/10.1007/s10539-023-09924-y | What if worms were sentient? Insights into subjective experience from the Caenorhabditis elegans connectome\n",
      "https://a16z.com/2011/04/14/peacetime-ceo-wartime-ceo/ | Peacetime CEO/Wartime CEO  Andreessen Horowitz\n",
      "https://metaculus.com/questions/15778/trump-guilty-in-manhattan-by-election-day/ | Trump guilty in Manhattan by Election Day  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/L8kEmQgghxS9LXF3H/ea-is-underestimating-intelligence-agencies-and-this-is | EA is underestimating intelligence agencies and this is dangerous\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://deepmind.com/blog/exploring-institutions-for-global-ai-governance | Exploring institutions for global AI governance\n",
      "https://docs.google.com/document/d/1tnrh-kglWSGHcL4rvQB3LDJrZJ_fiYjGYzliy0eiJ2s/edit#heading=h.6ha0t8tpgiiw | [Michael's copy] LAISR 2023 Seminar 1 – Luke Muehlhauser [Notes] - Google Docs\n",
      "https://twitter.com/s8mb/status/1681292890264449026 | twitter.com/s8mb/status/1681292890264449026\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://docs.google.com/document/d/1CaF6_qyMfn98T5xkGz8yxjBUBUKkv22MQ8q-0Syx0pU/edit | Niki Iliadis <> Ashwin Acharya - 2023-07-11\n",
      "https://github.com/rethinkpriorities/squigglepy/tree/dice_pool | github.com/rethinkpriorities/squigglepy/tree/dice_pool\n",
      "https://lesswrong.com/posts/Ghrdnc26ftJrxD49z/carl-shulman-on-the-lunar-society-7-hour-two-part-podcast | Carl Shulman on The Lunar Society (7 hour, two-part podcast) — LessWrong\n",
      "https://manifold.markets/connorwilliams97/what-are-the-probabilities-of-these | What are the probabilities of these AI outcomes (X-risk, dystopias, utopias, in-between outcomes, status quo outcomes)?  Manifold\n",
      "https://twitter.com/Jsevillamol/status/1693613569009406294 | twitter.com/Jsevillamol/status/1693613569009406294\n",
      "https://docs.google.com/document/d/1Oq9kWiesSTPb550uJqAP_I45cztL1CQNwOBMHfixSoU/edit#heading=h.yb91hy414ys0 | Darius Meissner <> Michael Aird - 2023-Jul-20 - Horizon + AIGS updates and intersections - Google Docs\n",
      "https://twitter.com/LinchZhang/status/1694453126525604027 | Linch on X: \"Do any of my biosecurity friends have a sense of how big a deal this is? t.co/gg8JJ5FjoW\" / X\n",
      "https://twitter.com/simonw/status/1679139824937123842 | Simon Willison on Twitter: \"Huge new release of my LLM CLI tool (and Python library) for accessing Large Language Models: it now supports additional models via plugins, so you can \"llm install llm-gpt4all\" to get models that run on your own machine! t.co/nbcQ5A8Tf4\" / Twitter\n",
      "https://x.ai/ | xAI: Understand the Universe\n",
      "https://docs.google.com/document/d/1mkZf0WFux1ApFAdbFYe4V5Tf-YZt_wro0VtOl_J16ZA/edit#heading=h.55yvur9i1wcv | 2023-04-15 Implications of Increased Compute Efficiency - Performance and Access Effect for Compute - Google Docs\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://docs.google.com/spreadsheets/d/1ni_FE4MQkfbikiLUHKSLLIst8Y08iJKp5NPlCcJLVJA/edit#gid=0 | 2023 August Lights - Google Sheets\n",
      "https://twitter.com/kevinschawinski/status/1680855401925836800 | Kevin Schawinski on Twitter: \"The @FTC is investigating @OpenAI and the document outlining their questions is fascinating. 🧵Some highlights:\" / Twitter\n",
      "https://twitter.com/sdorkenw/status/1674859033076072448 | twitter.com/sdorkenw/status/1674859033076072448\n",
      "https://twitter.com/predoctit/status/1692024535007031569 | twitter.com/predoctit/status/1692024535007031569\n",
      "https://morethantwo.com/jealousy-insecurity.html | More Than Two  Jealousy and Insecurity\n",
      "https://forum.effectivealtruism.org/posts/Xw98osdN4mEGbRDiR/aaron-bergman-s-shortform?commentId=cAKQz2fhyeuKkpBzd | forum.effectivealtruism.org/posts/Xw98osdN4mEGbRDiR/aaron-bergman-s-shortform?commentId=cAKQz2fhyeuKkpBzd\n",
      "https://manifund.org/projects/congressional-staffers-biosecurity-briefings-in-dc | manifund.org/projects/congressional-staffers-biosecurity-briefings-in-dc\n",
      "https://twitter.com/mcxfrank/status/1645459383554568193 | Michael C. Frank on Twitter: \"What does it mean for a large language model (LLM) to \"have\" a particular ability? Developmental psychologists argue about these questions all the time and have for decades. There are some ground rules. 🧵 t.co/NxcgKwHxGO\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1_i8ctyK-HYjJMDuSRZ-CZ4EqDa73cQNiIyTkQqOloPI/edit#gid=631790216 | RP Permanent Staff Start Dates - Google Sheets\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1e3uGtwoOnhnt2M5c_gAM06BI44zzeucpLZ6Ss335ne4/edit#heading=h.ooxvfpkwfmzx | Implications of the chance that most technical AI safety work will be done by AIs? [notes + research proposal] - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://twitter.com/dfrsrchtwts/status/1681800767076966400 | Daniel Filan research-tweets on Twitter: \"A list of things you might want to talk about under the label \"hallucination\" (list inspired by a discussion with @LukeBailey181) that language models of various sizes sometimes do: 1. models referring to entities as if they were in their prompt, when they weren't really (1/4)\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/ScGZdyGNXoEBAQazR/winners-of-ai-alignment-awards-research-contest | Winners of AI Alignment Awards Research Contest — EA Forum\n",
      "https://docs.google.com/document/d/1wmQJt0m6Z_I3QvmEvphmnQN1Qf5C-2YmCdEOtW8TF_0/edit#heading=h.pk2nps9jyyz6 | Mini-speedrun #2: 6 projects that seem exciting and feasible - Google Docs\n",
      "https://linkedin.com/pulse/do-you-want-work-wartime-ceo-peacetime-mamei-sun/ | (26) Do you want to work for a Wartime CEO or a Peacetime CEO?  LinkedIn\n",
      "https://twitter.com/simonw/status/1681349437078265857 | twitter.com/simonw/status/1681349437078265857\n",
      "https://lesswrong.com/posts/8NPFtzPhkeYZXRoh3/perpetually-declining-population | Perpetually Declining Population? — LessWrong\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/Bg6qxLGhsn7pQzHGX/progress-report-on-cea-s-search-for-a-new-ceo | Progress report on CEA’s search for a new CEO — EA Forum\n",
      "https://twitter.com/DanielColson6/status/1690428406570401792 | Daniel Colson on Twitter: \"1/6: Yesterday AIPI released the second portion of our YouGov poll, this time focusing on particular policy proposals for AI. The results are clear: voters support rules requiring AI models to demonstrate safety by a factor of 5:1. t.co/dxnGkw39fS\" / X\n",
      "https://twitter.com/Lance_Ying42/status/1674411924187152384 | twitter.com/Lance_Ying42/status/1674411924187152384\n",
      "https://arxiv.org/pdf/2307.03718.pdf | 2307.03718.pdf\n",
      "https://forum.effectivealtruism.org/posts/hEwtb9Zjt5qwc2ygH/3-levels-of-threat-obfuscation | 3 levels of threat obfuscation — EA Forum\n",
      "https://blog.jakegloudemans.com/post/11-links-7-11-2023 | Tuesday Links - Jake Gloudemans\n",
      "https://twitter.com/ARGleave/status/1689693758278004736 | Adam Gleave on Twitter: \"People often disagree on the rate of AI progress. Great to see interactive models like this that can help pin down *where* we disagree. I'd love to see models from people, especially those who have much shorter or longer timelines to transformative AI than Epoch (2036 median).\" / X\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://twitter.com/ninoscherrer/status/1686361694107209728?s=20 | twitter.com/ninoscherrer/status/1686361694107209728?s=20\n",
      "https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values | On the limits of idealized values - Joe Carlsmith\n",
      "https://lesswrong.com/posts/F6vH6fr8ngo7csDdf/chess-as-a-case-study-in-hidden-capabilities-in-chatgpt | Chess as a case study in hidden capabilities in ChatGPT — LessWrong\n",
      "https://twitter.com/JessicaH_Newman/status/1693681854334001624 | Jessica Newman on X: \"Great insights on the #defcon31 AI red teaming event where thousands of people tried to break and subvert AI chat bots, describing it as \"almost similar to social engineering\" \"using human language to manipulate a technical system, rather than using code\" t.co/m728e2O9Sz\" / X\n",
      "https://facebook.com/caroline.jeanmaire/videos/10208937381858299 | Facebook\n",
      "https://docs.google.com/document/d/1bQDkuz8vBmvQtlWrrXDeeI6hM3Fz-WL1c8Ub-p34-4M/edit#heading=h.6pru7lwg7vv | ERA for Peter - Job Opening Kick Off Form - Google Docs\n",
      "https://wikiwand.com/en/The_Creator_(2023_film) | The Creator (2023 film) - Wikiwand\n",
      "https://docs.google.com/document/d/1q9qKlZ2KU59lqbV4jcLE4V2jeBFAHOd9DejNM_Abyvw/edit#heading=h.sja5ou1zlohi | FDA case study - Patrick - Google Docs\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://llmbench.ai/ | AgentBench\n",
      "https://docs.google.com/document/d/1i5qQteGLrvokces6rEWTUfY3khe-LJMOIobrDREcd2w/edit | Peter's takes on some big strategic variables - Google Docs\n",
      "https://theinformation.com/articles/metas-next-ai-attack-on-openai-free-code-generating-software?utm_source=substack&utm_medium=email | Meta’s Next AI Attack on OpenAI: Free Code-Generating Software — The Information\n",
      "https://80000hours.org/podcast/episodes/ezra-klein-ai-and-dc/ | EzraKleinonexistentialriskfromAIandwhatDCcoulddoabout it\n",
      "https://twitter.com/RethinkPriors/status/1690078512554668032 | Rethink Priorities on Twitter: \"RP partner @open_phil is one of the largest funders of farmed animal welfare. Listen to @JamesOzden and Amanda Hungerford from OpenPhil discuss how RP's research informs their work (and many other topics) in a new podcast episode: t.co/FaqhWsmXYQ\" / X\n",
      "https://asteriskmag.com/issues/01/why-isn-t-the-whole-world-rich | Why Isn’t the Whole World Rich?—Asterisk\n",
      "https://carnegieendowment.org/2023/07/10/how-climate-change-challenges-u.s.-nuclear-deterrent-pub-90130 | How Climate Change Challenges the U.S. Nuclear Deterrent - Carnegie Endowment for International Peace\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://twitter.com/tamaybes/status/1691137507218305030 | twitter.com/tamaybes/status/1691137507218305030\n",
      "https://newyorker.com/magazine/2023/08/21/the-hidden-cost-of-free-returns | What Happens to All the Stuff We Return?  The New Yorker\n",
      "https://forum.effectivealtruism.org/posts/mrAZFnEjsQAQPJvLh/using-points-to-rate-different-kinds-of-evidence | Using Points to Rate Different Kinds of Evidence — EA Forum\n",
      "https://gucem.org/v/0.1.14/docs/Anchor%20BOTECs/AIAnchorBOTECs/ | AI safety anchor BOTECs  FTX GUCEM\n",
      "https://forum.effectivealtruism.org/posts/FWmnwCcKiBLstFtYL/career-conversations-week-on-the-forum-8-15-september | Career Conversations Week on the Forum (8-15 September) — EA Forum\n",
      "https://twitter.com/robertwiblin/status/1697899011636621509 | Robert Wiblin on X: \"My new interview with DeepMind co-founder and CEO of Inflection AI, Mustafa Suleyman: \"So people have this fear, particularly in the US, of pessimistic outlooks. ... It’s BS.\" t.co/xn9JAY4V1b t.co/YxXoB9NB32\" / X\n",
      "https://twitter.com/emilkastehelmi/status/1695879651158052910 | twitter.com/emilkastehelmi/status/1695879651158052910\n",
      "https://forum.effectivealtruism.org/posts/z8ZWwm4xeHBAiLZ6d/thoughts-on-far-uvc-after-working-in-the-field-for-8-months | Thoughts on far-UVC after working in the field for 8 months — EA Forum\n",
      "https://twitter.com/xuanalogue/status/1685963555986984960 | xuan (ɕɥɛn / sh-yen) @ ICML 🏝️ on Twitter: \"Why is the NYT platforming this? Large language models can't plan 🙄 At best they solve the knowledge engineering / frame problem - and with no guarantees on safety or reliability.\" / X\n",
      "https://kinkyevents.co.uk/confessions-of-a-sub-when-scenes-go-wrong/ | Confessions of a Sub: When Scenes Go Wrong\n",
      "https://twitter.com/daniel_271828/status/1692803851026374776 | Daniel Eth (yes, Eth is my actual last name) on X: \"Even among people who think a lot about AGI, I think most really haven’t internalized takeoff-speed dynamics\" / X\n",
      "https://docsend.com/view/6cbe77fw4pdizvr7 | Crowdvocate I\n",
      "https://twitter.com/sam_atis | twitter.com/sam_atis\n",
      "https://apolloresearch.ai/blog/security | Security at Apollo Research — Apollo Research\n",
      "https://vox.com/unexplainable/2023/7/15/23793840/chat-gpt-ai-science-mystery-unexplainable-podcast | How do AI systems like ChatGPT work? There’s a lot scientists don’t know. - Vox\n",
      "https://twitter.com/daniel_271828/status/1686960314259296256 | Daniel Eth (yes, Eth is my actual last name) on X: \"Honestly a little bit reassuring (though I do worry that he’s neglecting negative effects from shortening timelines)\" / X\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://docs.google.com/document/d/1-KYHVu8_tl3KwZHnRasI95UMup5TRIOdVpNrVl7jCwQ/edit#heading=h.rgncuqae7xa4 | Two RAND media-related policies\n",
      "https://docs.google.com/document/d/1CpO25iV38hXESPRQZmv15bLjBB_hrAYgAkvfHoJbngE/edit#heading=h.j9owozbw0x7p | Layer - Safety Culture - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/n5GJEP3tMrzdfYPGG/how-much-do-eags-cost-and-why | How much do EAGs cost (and why)?\n",
      "https://docs.google.com/document/d/1c2ULYMzqf6lGB91V3kjVlixNYGKO9NpV8_dwmCCsH5U/edit | neglectedness is a search heuristic, not a criteria\n",
      "https://forum.effectivealtruism.org/posts/J7nmbqcWncPMZFhGC/want-to-make-a-difference-on-policy-and-governance-become-an | Want to make a difference on policy and governance? Become an expert in something specific and boring — EA Forum\n",
      "https://docs.google.com/document/d/10X2_z_woKInzGcYCjCdSdauln3Es-Mmxnp5S9R5LihU/edit | AIGS comms & stakeholder-relationships tasks - Google Docs\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://twitter.com/xuanalogue/status/1696949545920508003 | xuan (ɕɥɛn / sh-yen) on X: \"Wild that AI safety-focused policy discourse is so over-indexed on \"frontier\" large pretrained models being the primary route to AI x-risk that it is now grasping at straws trying to regulate based on the only metrics that seem measurable (compute, data, benchmark scores)...\" / X\n",
      "https://vox.com/future-perfect/23820331/chatgpt-bioterrorism-bioweapons-artificial-inteligence-openai-terrorism?utm_source=substack&utm_medium=email | How ChatGPT could make bioterrorism easy - Vox\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://bustle.com/articles/188094-7-polyamorous-people-on-overcoming-jealousy | 7 Polyamorous People On Overcoming Jealousy\n"
     ]
    }
   ],
   "source": [
    "print('Shuffled tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "random.shuffle(tabs)\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7eece4-8649-45d2-bd1f-5d0e2554c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 tabs opened!\n"
     ]
    }
   ],
   "source": [
    "open_tabs_from_text(\"\"\"\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
