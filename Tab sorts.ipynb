{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs(tabs, page=1, per_page=10):\n",
    "    page_start = (page - 1) * per_page\n",
    "    total_pages = int(np.ceil(len(tabs) / per_page))\n",
    "    if page > total_pages:\n",
    "        raise ValueError('Cannot open page {}, only have {} pages'.format(page, total_pages))\n",
    "    page_end = page * per_page\n",
    "    if page_end > len(tabs):\n",
    "        page_end = len(tabs)\n",
    "    paged_tabs = tabs[page_start:page_end]\n",
    "    print('Opening page {}/{} (tabs {}-{} of {})'.format(page, total_pages, page_start, page_end, len(tabs)))\n",
    "    \n",
    "    for tab in paged_tabs:\n",
    "        open_tab(tab)\n",
    "\n",
    "        \n",
    "def open_random_n_tabs(tabs, n=5):\n",
    "    tabs = random.sample(tabs, len(tabs))\n",
    "    open_tabs(tabs, page=1, per_page=n)\n",
    "    return tabs[5:]\n",
    "\n",
    "        \n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748\n",
      "745\n",
      "733\n",
      "726\n",
      "725\n"
     ]
    }
   ],
   "source": [
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Messages ## (10 tabs)\n",
      "\n",
      "https://twitter.com/messages/25776739-1068417927903436800 | Brendan Finan / Twitter\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/messages/25776739-103418485 | Twitter\n",
      "https://app.swapcard.com/messages/channel/a0cdf139-86f6-44f2-845c-7823690f77c5?chatUserId=VXNlcl8xMzQzNzI3OA%3D%3D | https://app.swapcard.com/messages\n",
      "https://mail.google.com/mail/u/1/#search/taiga/FMfcgzGsmrCCwpgZPzzTHhZMJTwFQrJJ | TAIGA - May Highlights - peter@rethinkpriorities.org - Rethink Priorities Mail\n",
      "https://twitter.com/messages/25776739-1133196129309356032 | Ben Hurford / Twitter\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://mail.google.com/mail/u/1/#inbox/FMfcgzGsmWvfprTRZBTdxvRkgLQQHfMW | Status is red for USG & advanced AI - Rethink Priorities - peter@rethinkpriorities.org - Rethink Priorities Mail\n",
      "https://twitter.com/messages/25776739-1551581042259132418 | john stuart chill / Twitter\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower())], label='Messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c2b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Facebook ## (10 tabs)\n",
      "\n",
      "https://www.facebook.com/photo/?fbid=259678536582311&set=a.202281482322017 | Facebook\n",
      "https://www.facebook.com/tee.r.barnett/posts/pfbid061so1GHv1QsdDxnwtCYjVXVtTBTpLbuPZMvbTN3osbdLtkEXVC9haexd5HTSTL2Cl | Tee Barnett - I've accidentally transfigured my consumption of...  Facebook\n",
      "https://www.facebook.com/eurleif/posts/pfbid02gKMS3PvRowzd6vAf8qfGpugMtyUUbmbydLtZi92kvpv28QETQfceiNKXhNJnb2Qfl | Leif K-Brooks - It occurred to me that I've never really done a...  Facebook\n",
      "https://www.facebook.com/jonathan.erhardt.5/posts/pfbid02BnGSgCgLwB2fohbZqXabFqCkbwWfRGLEuFFb2QA6ZFiXHFyeiuXwNuPnxtWCaeMVl | https://www.facebook.com/jonathan.erhardt.5/posts/pfbid02BnGSgCgLwB2fohbZqXabFqCkbwWfRGLEuFFb2QA6ZFiXHFyeiuXwNuPnxtWCaeMVl\n",
      "https://www.facebook.com/baxter.bullock/posts/pfbid0zoMiWbTj5V4sK4V2YvFRgCwYMnTnJ834hLtyNJQh3LN5j5STQ1z6ZWSuuJeheWCQl | Baxter Bullock - There has been a lot going on in my life - new...  Facebook\n",
      "https://www.facebook.com/yudkowsky/posts/pfbid0KkfKmLvmtKNnPATgwi2bDWNZDrVqXYsth8gticx72Dk3XdiRdBcYYYpRfz3kGRjBl | The problem with making decision theory... - Eliezer Yudkowsky  Facebook\n",
      "https://www.facebook.com/linchuan.zhang/posts/pfbid02rdPWaumb5VkptCiz7yG8tgjPqco4PvQ26d48uy9HpQevS7SeQictVrM9oB8Thwqhl | Linchuan Zhang - https://scholars-stage.org/yale-and-the-education-...  Facebook\n",
      "https://www.facebook.com/jsnorris/posts/pfbid0hWUY8Cmv7DHN1VeiXSCS2TrxeopEv9BDScP3aH77P8tXkhStaNPK5JCF23PwN3Tcl | James Norris - 6 minutes for Eliezer Yudkowsky to summarize 20+...  Facebook\n",
      "https://www.facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://www.facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie on boards\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if 'facebook.com' in t.lower() and 'messages' not in t.lower()], label='Facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d6e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Twitter ## (186 tabs)\n",
      "\n",
      "https://twitter.com/ohwizenedtortle/status/1653253209958543360 | oh restful lion on Twitter: \"You see a dating app profile mentioning Taylor Swift like in the images in the next tweet. This makes you more or less interested in dating them? (If absolutely no change, remember they could have written something else, so you probs should update A BIT)\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1659916922123694080 | https://twitter.com/SpacedOutMatt/status/1659916922123694080\n",
      "https://twitter.com/edardaman | https://twitter.com/edardaman\n",
      "https://twitter.com/JasonGMatheny/status/1662075820523896832 | Jason Matheny on Twitter: \"Thank you to the philanthropic supporters who've helped us reach this milestone. Your gifts are fueling @RANDCorporation research on the biggest problems facing humanity: tech governance, climate change, countering autocracy, reducing inequity, and more. https://t.co/Jo48dZPaiX\" / Twitter\n",
      "https://twitter.com/RFishBlueFish/status/1659342200914812928 | RedFishBlueFish on Twitter: \"@NathanpmYoung @peterwildeford This is great and really captures the anti-probability intuition that I have. My probabilities vary greatly with my mood (even though they shouldn‚Äôt)\" / Twitter\n",
      "https://twitter.com/Jess_Riedel/status/1663592047700496385 | Jess Riedel on Twitter: \"\"Whether you have heard of the Extropians or not, they have influenced you...This is an annotated tour through the primary sources\" https://t.co/YGBNCO0Pzv https://t.co/CgIJtakNiK\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1655663054544310272 | Daniel Eth on Twitter: \"NOTE: the account @danieI_eth (with a capital \"i\" instead of a lowercase \"L\" for the last name) is impersonating me. Please go and report them! https://t.co/p6c8xZwqCy\" / Twitter\n",
      "https://twitter.com/lxeagle17/status/1659265370170228736 | Lakshya Jain on Twitter: \"Twenty years ago, both parties came up with conflicting theories on how they were entering a new age of dominance. Neither of them panned out, so now everyone is determined to ignore *any* signs of danger for either party because things always work themselves out automatically.\" / Twitter\n",
      "https://twitter.com/KofmanMichael/status/1654572418705289225 | Michael Kofman on Twitter: \"I think that tracks, but depends on what happens with mobilization later this year. Either way Russian offensive potential appears exhausted for some time. Gerasimov‚Äôs winter offensive expended resources and achieved close to nothing.\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1662823346390683648 | https://twitter.com/NathanpmYoung/status/1662823346390683648\n",
      "https://twitter.com/arankomatsuzaki/status/1662991826431639553 | https://twitter.com/arankomatsuzaki/status/1662991826431639553\n",
      "https://twitter.com/LinchZhang/status/1663698230067232768 | Linch on Twitter: \"I think some ppl have the model of \"experts of risk of a new technology\" as composing a \"technical engineering section\" where the people who produce the technology are experts, and \"political section\" where politicians or political scientists are the experts. This seems wrong.\" / Twitter\n",
      "https://twitter.com/StanfordHAI/status/1662164342853206045 | Stanford HAI on Twitter: \"How might companies' use of AI change the way they pay their workers? A recent study from @stanford and @mit provides insights: https://t.co/78c20l0Vrq\" / Twitter\n",
      "https://twitter.com/DefMon3/status/1659954245238681601 | https://twitter.com/DefMon3/status/1659954245238681601\n",
      "https://twitter.com/xuanalogue/status/1664436618436964356 | xuan (…ï…•…õn / sh-yen) on Twitter: \"Really neat paper which finds that: - Human gameplay is well-modeled by planning as heuristic search - Human response times are predicted by n. iterations of a planning alg. - Better players have higher estimated search depth - But *not* higher heuristic quality, interestingly!\" / Twitter\n",
      "https://twitter.com/RethinkPriors/status/1659004160040226820 | https://twitter.com/RethinkPriors/status/1659004160040226820\n",
      "https://twitter.com/tepelmacher/status/1655751424964464641 | Elliot Teperman on Twitter: \"Farmed Animal Funders is hiring an Executive Director! üéâüêîüê∑üêüüéâ Super exciting and important role in the farm animal protection ecosystem helping donors fight factory farming! Please share with your network and anyone that might be interested. https://t.co/UY7KIqcljA\" / Twitter\n",
      "https://twitter.com/DeepMind/status/1656351454221697042 | Google DeepMind on Twitter: \"PaLM-2 is a next generation large language model with improved coding, multilingual and reasoning capabilities. It will power over 25 new @Google products and features, bringing the latest in advanced AI to benefit people. Here‚Äôs how it‚Äôs being deployed already. ‚¨áÔ∏è #GoogleIO\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1660709054950285318 | https://twitter.com/JeffLadish/status/1660709054950285318\n",
      "https://twitter.com/MatthewJBar/status/1661229163544723456 | https://twitter.com/MatthewJBar/status/1661229163544723456\n",
      "https://twitter.com/AIBetsPredictit/status/1659013011963518978 | https://twitter.com/AIBetsPredictit/status/1659013011963518978\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. https://t.co/uxjtyYAEFo\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1660971688220147715 | Nathan is at EAG üîç (say hi üëã) on Twitter: \"I don't really claim to be a good ally or whatever but I think that EA smuggles a lot in under the guise of \"correct thought\" Endless hedging verbal ticks, soft neoliberalism, sci-fi, huel, puns. These aren't effective altruism they are founder effects. Lets have other vibes.\" / Twitter\n",
      "https://twitter.com/HaydnBelfield/status/1664939007946440704 | Haydn Belfield on Twitter: \"Nice overview of AI risks &amp; solutions from @rhysblakely &amp; @whippletom I argue frontier systems (bigger &amp; more powerful than any yet developed) should be regulated ‚Äúlike risky bio or nuclear experiments with licences, pre-approval &amp; 3rdparty evaluations‚Äù https://t.co/APKHwSuMoB\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1654457947819311104 | Sim√©on on Twitter: \"I think that comments like \"Don't make proposal X for AGI safety because it's not feasible/people will never accept to do it\" is currently a strategy people should be very wary of. 1) Currently, public opinion &amp; policy discussions are moving extremely fast so it's hard to be‚Ä¶\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1663908761973473280 | https://twitter.com/JgaltTweets/status/1663908761973473280\n",
      "https://twitter.com/nikosbosse/status/1659716581683765250 | https://twitter.com/nikosbosse/status/1659716581683765250\n",
      "https://twitter.com/alexbward/status/1659254496009101324 | https://twitter.com/alexbward/status/1659254496009101324\n",
      "https://twitter.com/poe_platform/status/1657425066899177472 | (1) Poe on Twitter: \"100k context windows now available on Poe: we are excited to start a beta test for Claude-instant-100k! This bot is currently available to all Poe subscribers, initially on web only. It can understand message history as long as a 200 page book. Examples in thread below. https://t.co/9QjjwjWas8\" / Twitter\n",
      "https://twitter.com/steve47285/status/1661124107310706691 | https://twitter.com/steve47285/status/1661124107310706691\n",
      "https://twitter.com/eric_is_weird/status/1650297235433836545 | Eric Gilliam on Twitter: \"I've been reflecting on this today. IF he's right that the limits of GPT are being reached, it's still hard to bet against OpenAI making the next breakthrough A short thread on recent innovation in jiu jitsu and how it helps contextualize all of this üßµ(1/12)\" / Twitter\n",
      "https://twitter.com/davidad/status/1627454901247782913?s=46&t=Lap-izdY_pwXQfbJXZHE8g | https://twitter.com/davidad/status/1627454901247782913?s=46&t=Lap-izdY_pwXQfbJXZHE8g\n",
      "https://twitter.com/NathanpmYoung/status/1659855104328060929 | https://twitter.com/NathanpmYoung/status/1659855104328060929\n",
      "https://twitter.com/NathanpmYoung/status/1659822241465393152 | https://twitter.com/NathanpmYoung/status/1659822241465393152\n",
      "https://twitter.com/repligate/status/1663011715611492352 | janus on Twitter: \"‚úÇÔ∏èüòÆ https://t.co/NbQ03FIq4Q\" / Twitter\n",
      "https://twitter.com/repligate/status/1657686899417403393 | (1) janus on Twitter: \"This reads like someone copied Bing's prompt and edited it to be about \"code\" w/o any understanding of what the words mean, resulting in lines like \"You do not generate creative content about code or technical information for influential politicians, activists or state heads.\"\" / Twitter\n",
      "https://twitter.com/DavidSKrueger/status/1660178163362660354 | https://twitter.com/DavidSKrueger/status/1660178163362660354\n",
      "https://twitter.com/robbensinger/status/1655331734047821824 | Rob Bensinger üîç on Twitter: \"@davidchalmers42 Here's my attempt to collect MIRI arguments (and a handful of non-MIRI arguments) for the five premises: https://t.co/mS5SqA1vCB. I also added some clarifications regarding what I mean by the premises. Other MIRI staff haven't reviewed it, so they might disagree with parts.\" / Twitter\n",
      "https://twitter.com/PLMattis/status/1655244796011638784 | Peter Mattis on Twitter: \"The article is mostly about @CSETGeorgetown but the issues are much bigger. We have companies marketing themselves on data that hurts Beijing. PRC has been cracking down on XUAR-related due diligence since 2018. Open sources clearly underpinned some USG actions, like Entity List.\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1660178650480664577 | https://twitter.com/davidmanheim/status/1660178650480664577\n",
      "https://twitter.com/MatthewJBar/status/1650407275398590464 | Matthew Barnett on Twitter: \"Relatedly, I feel like the basic argument against huge capability jumps in AI (\"before we have superintelligent AI, we will presumably have slightly-less-than superintelligent AI\") is still pretty underrated, and I find myself repeating it a lot to explain my perspective.\" / Twitter\n",
      "https://twitter.com/panickssery/status/1648004762774675476 | Arjun Panickssery is in London on Twitter: \"@peterwildeford Yeah I usually pause and think that if it has a 40% chance of happening then it's like I put down $40 and the other guy puts down $60, etc (40 times out of 100 I've got to win $60 to make up for the $40 I lose 60 times) Note it's (1-p)/p not the reverse if you're putting down $1\" / Twitter\n",
      "https://twitter.com/boazbaraktcs/status/1652059204134248448 | (1) Boaz Barak on Twitter: \"1/5 In our post https://t.co/Lbxyc9e942, Aaronson and I discuss potential scenarios for AI. In particular we say that for \"super-intelligence\" type scenarios, AI will need to break out of the current \"sheer data&amp;compute scale\" paradigm. Given Moore's law, why is this the case?\" / Twitter\n",
      "https://twitter.com/CecilYongo/status/1661795188208009223 | Cecil Yongo on Twitter: \"Big privilege to listen to the most cited comp scientist alive today, Geoff Hinton. A very straightforward and dark (depending on how you see it I guess) üòÇ message: Super-intelligence is coming and we‚Äôre probably screwed. Some more highlights:- https://t.co/3kmdQtNMgU\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1659731083636686848 | https://twitter.com/JgaltTweets/status/1659731083636686848\n",
      "https://twitter.com/JosephPolitano/status/1663942643859050498 | https://twitter.com/JosephPolitano/status/1663942643859050498\n",
      "https://twitter.com/stokel/status/1663551277417267203 | (1) Chris Stokel-Walker ~ @stokel@infosec.exchange on Twitter: \"So, this statement... There seem to be three broad groups of signatories: 1) The existential threat worriers (who genuinely believe AI could become sentient and kill us). They may be right! But they've been saying this a while https://t.co/10cYwF7EmJ\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1650250076667932673 | Nora Belrose on Twitter: \"Either @petemandik's meta-illusionism about consciousness is true (the illusion is illusory), or Luke Roelofs' panpsychism is true (rocks are conscious), there is no in between\" / Twitter\n",
      "https://twitter.com/PatientPersists/status/1654489679096344578 | Siebe. on Twitter: \"@peterwildeford Btw random share, but I've been reading \"How Democracies Die\" by Steven Levitsky and it's really good. Also lots of stuff invoicing Supreme Courts\" / Twitter\n",
      "https://twitter.com/gdb/status/1652369023609470976 | (1) Greg Brockman on Twitter: \"ChatGPT for life improvement: https://t.co/RwOIRaK9hG\" / Twitter\n",
      "https://twitter.com/shouldhaveanima/status/1662204009904750592 | why you should have an animal on Twitter: \"This video is so cute i can watch it forever https://t.co/NsY6KYMq9l\" / Twitter\n",
      "https://twitter.com/Willyintheworld/status/1530629463129456640 | https://twitter.com/Willyintheworld/status/1530629463129456640\n",
      "https://twitter.com/HaydnBelfield/status/1657000119814725633 | Haydn Belfield on Twitter: \"Fascinating read on chip subsidies. https://t.co/9wN7XlhQwM https://t.co/2RQrwOKHjC\" / Twitter\n",
      "https://twitter.com/i/communities/1492420299450724353 | https://twitter.com/i/communities/1492420299450724353\n",
      "https://twitter.com/AnthropicAI/status/1656700154190389248 | Anthropic on Twitter: \"Introducing 100K Context Windows! We‚Äôve expanded Claude‚Äôs context window to 100,000 tokens of text, corresponding to around 75K words. Submit hundreds of pages of materials for Claude to digest and analyze. Conversations with Claude can go on for hours or days. https://t.co/4WLEp7ou7U\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1556301242460143620 | (2) David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"I've been thinking about how people change the world for the better for quite a while. Turns out it's hard, and the world is complex, but more critically, most people aren't trying. And if they care about the world, and want it to be better, that's a shame. (1/25)\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1665033975696326657 | alex lawsen on Twitter: \"Quick thoughts on what recently increased attention on AI x-risk means for people who want to try to prevent it, as usual for this account this is my thoughts not an official 80k line. I'm even on holiday this week!\" / Twitter\n",
      "https://twitter.com/railboss/status/1653539437266055174 | A #1, Emperor of the North Pole on Twitter: \"@peterwildeford @hradzka I‚Äôm sure he does well with people who are unfamiliar with his history of insane conspiracy theories.\" / Twitter\n",
      "https://twitter.com/Kirsten3531/status/1662948844735176705 | (2) Kirsten on Twitter: \"Best use case I've found for chatgpt so far: I listed a bunch of foods I like and it made me a meal plan that actually looks delicious (don't worry I'm not actually going to eat this few calories, I just wanted to save room for dessert!) https://t.co/76i2pPNNJr\" / Twitter\n",
      "https://twitter.com/KofmanMichael/status/1659592846972788737 | https://twitter.com/KofmanMichael/status/1659592846972788737\n",
      "https://twitter.com/calebwatney/status/1661030085858656257 | Caleb Watney on Twitter: \"@moskov @davidmanheim Boosting range/coverage are technical problems we can make progress on. But fundamentally, mass-deployed far-UVC is one of the few things I can imagine actually making humanity safe from engineered pandemics.\" / Twitter\n",
      "https://twitter.com/AlecStapp/status/1652783849338724352 | Alec Stapp on Twitter: \"More than 15,000 people have participated in human challenge trials over the last 40 years and not one person has died (or even been permanently impaired). We should have done human challenge trials for COVID but alas‚Ä¶ https://t.co/bwyWCPdIoQ\" / Twitter\n",
      "https://twitter.com/ryancbriggs/status/1652314484948496385 | Ryan Briggs on Twitter: \"@peterwildeford If you like subjective expert rater methods, then V-DEM is good. See also https://t.co/yaHqzoNRt2\" / Twitter\n",
      "https://twitter.com/grhmc/status/1659889031876943872 | https://twitter.com/grhmc/status/1659889031876943872\n",
      "https://twitter.com/spencemo_c/status/1647790750535667713 | Spencerüôèüîçüìöü•ïüö≤üßò‚Äç‚ôÇÔ∏èüöêüåê on Twitter: \"@peterwildeford For now. What odds would you set for party Id #s to stay within ~15% of total (eg 35% total, d/r 25-45) in 1/2/3/5 years\" / Twitter\n",
      "https://twitter.com/iabvek/status/1654992086457012224 | iabvek on Twitter: \"@peterwildeford @JgaltTweets @metaculus lets book it, also interested in betting more than $400 at these odds if you or others are interested\" / Twitter\n",
      "https://twitter.com/birchlse/status/1659883804662591490 | https://twitter.com/birchlse/status/1659883804662591490\n",
      "https://twitter.com/Scholars_Stage/status/1661765278672248835 | T. Greer on Twitter: \"This ad strengthens the impression that Trump will beat him\" / Twitter\n",
      "https://twitter.com/noahdgoodman/status/1658547328444428293 | https://twitter.com/noahdgoodman/status/1658547328444428293\n",
      "https://twitter.com/StephenLCasper/status/1656179296086691843 | Stephen Casper on Twitter: \"Thread: [1/4] I'm underwhelmed by OpenAI's work on \"automating interpretability\". I don't think it's a very big step forward for interpretability or safety. I think they're trying to hype this up to be much more than it is.\" / Twitter\n",
      "https://twitter.com/anthrupad/status/1655421669660405762 | wÃ∏ÕÇÕÇÕïaÃ∑ÕêÕîÃótÃ¥ÕóÃôeÃµÃîÃïÃ¨rÃ¥ÃìÃäÃ∞mÃµÕÉÃΩÕôÕñaÃµÃìÕíÃóÃ¢rÃ∏ÃΩÃ≤kÃ∑ÕùÃÅÕîÃß on Twitter: \"Rob Bensinger argues that its likely that 'STEM-level AGI' (AGI which can reason about all the hard sciences) results in human extinction. He breaks it into a series of 5 claims (in the img) If you doubt the confidence of the conclusion, which claim(s) do you disagree with? https://t.co/GLS86dKJ1U\" / Twitter\n",
      "https://twitter.com/mealreplacer/status/1659843658529603584 | https://twitter.com/mealreplacer/status/1659843658529603584\n",
      "https://twitter.com/arnavg_/status/1662189000667590656 | Arnav Gudibande on Twitter: \"A recent trend is to fine-tune open-source LMs on ChatGPT outputs (e.g., Alpaca, Self-Instruct, Vicuna), with the aim of broadly imitating the model. In our new paper, we critically analyze this approach. https://t.co/nyOWEdGnvV üëá[1/N] https://t.co/dQ7l78kQzt\" / Twitter\n",
      "https://twitter.com/bridget_e_l | https://twitter.com/bridget_e_l\n",
      "https://twitter.com/JgaltTweets/status/1658903600075030528 | https://twitter.com/JgaltTweets/status/1658903600075030528\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won‚Äôt)üßµ https://t.co/23ErIoRIsk\" / Twitter\n",
      "https://twitter.com/labenz/status/1655092874768179200 | https://twitter.com/labenz/status/1655092874768179200\n",
      "https://twitter.com/MatthewJBar/status/1657596044186906624 | (1) Matthew Barnett on Twitter: \"There are many predictions you can make that will be misinterpreted as trending wrong even if you end up being right. So, to the extent you want prestige from forecasting, you should optimize both for being right and for saying things that people will think are trending right.\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1665209063419047936 | Sim√©on (in DC) on Twitter: \"One (complicated) reason why it's likely that humans are not the upper bound of intelligence is that there's often a robustness/optimization trade-off and human architecture is leaning a lot towards robustness. Ex: If you accept to lose in robustness of your supply chains, you‚Ä¶\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1654974738706444290 | JgaltTweets on Twitter: \"'The situation in the area of the Zaporozhye NPP \"is becoming increasingly unpredictable and potentially dangerous,\" the Director General said. \"I‚Äôm extremely concerned about the very real nuclear safety and security risks facing the plant,\" he noted.'\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1662814788580175872 | JgaltTweets on Twitter: \"In late March 2022, before PaLM and DALL-E 2 in April and Gato in May, the median on Metaculus for a 'weakly general' AI was 2043, 21 years away. By the start of June it was 2030. Now it's May 2026, three years from now. https://t.co/276E2LZK12\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1660222896369991683 | https://twitter.com/JeffLadish/status/1660222896369991683\n",
      "https://twitter.com/Simeon_Cps/status/1655287351403266049 | (1) Sim√©on on Twitter: \"Comparing the current version of DeepMind with the current version of OpenAI and Anthropic to assess how safety oriented the latter will be when they'll build AGI is a bit misleading. While DeepMind is in its AGI-org state, OpenAI is in a compute-dependent state and Anthropic‚Ä¶ https://t.co/sYN1NEh6qF\" / Twitter\n",
      "https://twitter.com/tamaybes/status/1651297219822116867 | Tamay Besiroglu on Twitter: \"Can we use scaling laws to estimate what is required to reach 'human level' on some arbitrary task? Our (speculative) framework suggests yes. We show that scaling laws provide insight into the *horizons* over which outputs are indistinguishable from human-generated outputs. https://t.co/eRfHGiVohZ\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1656744272861753346 | Sim√©on on Twitter: \"More seriously, I've sadly recently updated increasingly towards Nate Soares &amp; Yudkowsky for a few reasons. 1) Looking at how other industries (aviation, nuclear, biosafety) with security mindsets &amp; deep safety cultures failed to get to 0 accidents despite immense efforts poured‚Ä¶\" / Twitter\n",
      "https://twitter.com/ohlennart/status/1658893267570655232 | https://twitter.com/ohlennart/status/1658893267570655232\n",
      "https://twitter.com/JustaNormalDino/status/1659440758041067521 | https://twitter.com/JustaNormalDino/status/1659440758041067521\n",
      "https://twitter.com/ebriakou/status/1659259174293741571 | https://twitter.com/ebriakou/status/1659259174293741571\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://twitter.com/TaliaRinger/status/1661824840435638345 | Talia Ringer on Twitter: \"If you're curious how I can have such strong opinions about thinking it does not make sense to even discuss \"AGI\" while also being super into mechanistic interpretability work and thinking it is incredibly important, this podcast does a pretty good job\" / Twitter\n",
      "https://twitter.com/frances__lorenz/status/1656642985038151681 | Frances Lorenz on Twitter: \"hey cuties, really sad to have to take this public, but @mealreplacer recently sent me this violent tiktok (https://t.co/BH8OC3JWHH), anyways I think I might have to bully him off this platform\" / Twitter\n",
      "https://twitter.com/moskov/status/1661019398919057408 | Dustin Moskovitz on Twitter: \"Almost everyone replying to my thread yesterday can‚Äôt even imagine this. Objections to my premise are are all about improved scenarios around lockdowns and reactive vaccines, when I meant preventative measures we‚Äôre not even bothering to fund.\" / Twitter\n",
      "https://twitter.com/repligate/status/1653657915201290242 | janus on Twitter: \"highly specific demon https://t.co/TTyJcgfX4r\" / Twitter\n",
      "https://twitter.com/gelliottmorris/status/1660037899994251266 | https://twitter.com/gelliottmorris/status/1660037899994251266\n",
      "https://twitter.com/CharlesD353/status/1664392860441927682 | Charles on Twitter: \"I feel pretty strongly that one should not put a sub 0.01% probability on anything that isn't a quite well understood phenomenon (e.g. p(win lottery)) or something that clearly violates physical laws IMO.\" / Twitter\n",
      "https://twitter.com/_MedGold/status/1632775869545447430 | ·¥ç·¥á·¥Ö …¢·¥è ü·¥Ö üêí on Twitter: \"Not every girl was born to be a sex slave. Emily Ratajkowski is. Gio Scotti is not. She‚Äôs meant to greeted with a kiss on the forehead, a light smack on the ass, and be surprised with vacations &amp; handbags. Total QT wife material, u must know difference. https://t.co/v22OQNixgu\" / Twitter\n",
      "https://twitter.com/MarkHertling/status/1664307395516825600 | MarkHertling on Twitter: \"When @bianca_nobilo pulls out her whiteboard, it‚Äôs a good idea to listen to get a 2 minute explainer. Put her and @katieporteroc together &amp; it would be magical.\" / Twitter\n",
      "https://twitter.com/lisperati/status/1654479672846221313 | Conrad Barski on Twitter: \"@JgaltTweets @peterwildeford where's the head with the little spot of tussled hair? oh there it is\" / Twitter\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok üèóÔ∏èüöÄ on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row https://t.co/Tq3raRQHJf\" / Twitter\n",
      "https://twitter.com/daniel_271828/status/1620596689555058689 | https://twitter.com/daniel_271828/status/1620596689555058689\n",
      "https://twitter.com/MDubrawski/status/1654477167869214721 | Micha≈Ç Dubrawski - Standing with üá∫üá¶ on Twitter: \"I thought that it might be worth adding a list of questions suggested for a forecast's post-mortem analysis to this old thread. This is based on @TLiptay initial three questions mentioned above. https://t.co/3MLPwcW7Vu\" / Twitter\n",
      "https://twitter.com/AISafetyMemes/status/1664981210076938241 | AI Notkilleveryoneism Memes on Twitter: \"Guys, there‚Äôs finally an AI x-risk documentary, and it‚Äôs a *masterpiece* THIS is the video to send to curious friends. Let‚Äôs blow this thing up. Don't Look Up - The Documentary: The Case For AI as an Existential Threat https://t.co/tjKTgeP5KD\" / Twitter\n",
      "https://twitter.com/moreisdifferent/status/1654639966670970880 | Dan Elton on Twitter: \"PSA: apply to the SERI-MATS AI Safety summer research program. Deadline is May 7th. https://t.co/xtslNfjxNS\" / Twitter\n",
      "https://twitter.com/metaculus/status/1659603759377399809 | https://twitter.com/metaculus/status/1659603759377399809\n",
      "https://twitter.com/arankomatsuzaki/status/1660815714985603072 | Aran Komatsuzaki on Twitter: \"RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text Generates a paragraph at each timestep and updates its language-based long-short term memory stored on the hard drive and the prompt, respectively. repo: https://t.co/VxP6hWJqJO abs: https://t.co/DbP8TXhnYA https://t.co/0uBQGiaX7M\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1660362928334450688 | https://twitter.com/RichardMCNgo/status/1660362928334450688\n",
      "https://twitter.com/janleike/status/1655982055736643585 | Jan Leike on Twitter: \"Really exciting new work on automated interpretability: We ask GPT-4 to explain firing patterns for individual neurons in LLMs and score those explanations. https://t.co/Fmu8IAb7Hy\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1652720550349873154 | xuan (…ï…•…õn / sh-yen) on Twitter: \"@peterwildeford I think if you have one widget / coin, the probability P(t) it will have turned on by time `t` is just the CDF of the geometric distribution at `t`, i.e. the total probability of the coin having come up heads in `t` or less flips: P(t) = CDF(Geometric, t, p) = 1-(1-p)^t\" / Twitter\n",
      "https://twitter.com/repligate/status/1653641639171170304 | janus on Twitter: \"a curious bing https://t.co/bDQKqiYC5D\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1658813589858181121 | https://twitter.com/xuanalogue/status/1658813589858181121\n",
      "https://twitter.com/xuanalogue/status/1652874311605137408 | xuan (…ï…•…õn / sh-yen) on Twitter: \"Bizarre to me that so many LLM benchmarks were using top-1 accuracy as a metric rather than the Brier score or similar -- apparently once you switch to the latter (and other continuous and/or linear metrics), many \"emergent\" behaviors go away!\" / Twitter\n",
      "https://twitter.com/HaydnBelfield/status/1663678184720662538 | Haydn Belfield on Twitter: \"I don't think this is a credible response to this Statement, for the simple reason that the vast majority of signatories (250+ by my count) are university professors, with no incentive to 'distract from business models' or hype up companies' products https://t.co/YFuEM6a4WH\" / Twitter\n",
      "https://twitter.com/financialjuice/status/1663903257255616520 | https://twitter.com/financialjuice/status/1663903257255616520\n",
      "https://twitter.com/salonium/status/1663123391178592258 | Saloni on Twitter: \"New post by me @OurWorldInData! How do researchers study the prevalence of mental illnesses worldwide? What are the limitations with these estimates? Thread. https://t.co/U3TasgO6xy https://t.co/GT4TD3QXAX\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1659117926404747266 | https://twitter.com/NathanpmYoung/status/1659117926404747266\n",
      "https://twitter.com/JgaltTweets/status/1652060385346834432 | https://twitter.com/JgaltTweets/status/1652060385346834432\n",
      "https://twitter.com/Jsevillamol/status/1664034651046813696 | Jaime Sevilla on Twitter: \"Presenting a new Epoch double feature! Today we release an interactive model of AI timelines and an opinion piece by researcher @MatthewJBar explaining our approach to modeling the future of AI. üßµ https://t.co/NzToTPNuU5\" / Twitter\n",
      "https://twitter.com/emollick/status/1652394722843848706 | Ethan Mollick on Twitter: \"Overrated &amp; underrated forms of GPT compared to online hype Overrated: AutoGPT (awesome future possibilities, doesn‚Äôt work well yet), ChatGPT plugins (ditto), ChatGPT with web (currently struggles) Underrated: Bing Creative Mode (GPT-4 &amp; internet), ChatGPT with code interpreter\" / Twitter\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) https://t.co/pkFdPqgAzb\" / Twitter\n",
      "https://twitter.com/adversariel/status/1650313930802368512 | Ariel on Twitter: \"There‚Äôs a lot of fearmongering about LLMs being capable of finding 0day There are three highly complex roadblocks that need to be overcome for this to be a real concern: statefulness, hallucination, and contamination https://t.co/ZZq4OPrglb\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/jachiam0/status/1591494093766787076 | Joshua Achiam on Twitter: \"üßµ to clarify my views on AGI, timelines, and x-risk. TL;DR: My AGI timelines are short-ish (within two decades with things getting weird soon) and I think x-risk is real, but I think probabilities of doom by AGI instrumentally opting to kill us are greatly exaggerated. 1/\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1660973340633227264 | Nathan is at EAG üîç (say hi üëã) on Twitter: \"My relationship learnings doc (very nsfw/honest) Don't read unless you want that. https://t.co/7RNCsnQLmY\" / Twitter\n",
      "https://twitter.com/ModeledBehavior/status/1645444418848129025 | Adam Ozimek on Twitter: \"Read the reddit thread on Ozempic improving people's impulse control broadly https://t.co/spB8QDDLQl And here is a review of evidence in favor https://t.co/h6iWgKl56b Now consider: what are the downstream implications of a society with greater impulse control?\" / Twitter\n",
      "https://twitter.com/SocDoneLeft/status/1636573328583409664 | SDL on Twitter: \"@samaneller215 @peterwildeford @jonatanpallesen @jeffrsebo @RethinkPriors @remindmetweets RELEASE THE ü¶êSHRIMPü¶ê üóÉFILESüóÉ WHAT DOES BIG CRUSTACEAN HAVE TO HIDE?!\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1654319722668883970 | https://twitter.com/JeffLadish/status/1654319722668883970\n",
      "https://twitter.com/kristjanmoore/status/1663860424100413440 | https://twitter.com/kristjanmoore/status/1663860424100413440\n",
      "https://twitter.com/jkcarlsmith/status/1655720268156010498 | Joe Carlsmith on Twitter: \"How worried about AI risk will we feel in the future, when we can see advanced machine intelligence up close? We should worry accordingly now. I wrote an essay about this: https://t.co/cJoVCh8Pus https://t.co/pn46hN2Lzr\" / Twitter\n",
      "https://twitter.com/roeldobbe/status/1664945763380613120 | Roel Dobbe (he/they) @roeldobbe@akademienl.social on Twitter: \"OpenAI‚Äô push to make ChatGPT available as plug-in to whatever you want will lead to numerous new safety hazards and emergent harms. 1/3 https://t.co/Wlz3qRob6o\" / Twitter\n",
      "https://twitter.com/catherineols/status/1653175701275811843 | Catherine Olsson on Twitter: \"In college I stopped eating meat, on the spot, when a friend asked why I hadn't yet. Social checks on our ethics can be so influential. I often think about when I would quit Anthropic or leave AI entirely. I encourage others to. I can already tell this move will influence me.\" / Twitter\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | A good Œ±lpha-Minus ‚ò∫Ô∏è on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://twitter.com/Jotto999/status/1664424657108316161 | Jotto üîç on Twitter: \"This seems ridiculously low, unless the timeframe is \"before 2024\" or \"before any new fabs start production\" or something like that. What about when nearby stars are colonized by AI descendants, and humans aren't a credible political threat? Why would it still be only 0.001%?\" / Twitter\n",
      "https://twitter.com/TetraspaceWest/status/1659283551831879698 | tetraspace is at EAG londonüíé on Twitter: \"I've noticed two slightly-conflated arguments about why you want safety guarantees in AGI. Named by replacing \"AGI\" with a different thing: \"If you're not sure that a gun isn't loaded, then it's loaded\" \"If you're not sure that your cryptography is secure, then it's insecure\"\" / Twitter\n",
      "https://twitter.com/TetraspaceWest/status/1658822554168045569 | tetraspace üíé on Twitter: \"it‚Äôs simple. any datacenter that hosts an LLM that can be prompt engineered into giving medical advice is a ‚Äúmedical device‚Äù and therefore falls under the remit of the FDA\" / Twitter\n",
      "https://twitter.com/gelliottmorris/status/1660322653851336704 | https://twitter.com/gelliottmorris/status/1660322653851336704\n",
      "https://twitter.com/jachiam0 | Joshua Achiam (@jachiam0) / Twitter\n",
      "https://twitter.com/Jsevillamol/status/1664673402387415040 | Jaime Sevilla on Twitter: \"The Riesgos Catastr√≥ficos Globales team has published a survey of concrete AI risks! They have talked to experts and reviewed the literature to summarize the concrete ways that present and future AI systems may cause harm. üßµ https://t.co/jjZI97kofB\" / Twitter\n",
      "https://twitter.com/jeffclune/status/1664618665160085505 | Jeff Clune on Twitter: \"Introducing Thought Cloning: AI agents learn to *think* &amp; act like humans by imitating the thoughts &amp; actions of humans thinking out loud while acting, enhancing performance, efficiency, generalization, AI Safety &amp; Interpretability. Led by @shengranhu https://t.co/a2hmGZ4t3f 1/5 https://t.co/h9PBgDHrMA\" / Twitter\n",
      "https://twitter.com/arankomatsuzaki/status/1661895861670952966 | Aran Komatsuzaki on Twitter: \"Voyager: An Open-Ended Embodied Agent with Large Language Models Presents the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. proj:‚Ä¶ https://t.co/l915Is82lz\" / Twitter\n",
      "https://twitter.com/emollick/status/1659310930952347651 | Ethan Mollick on Twitter: \"Me: ChatGPT with Code Interpreter, visualize a four dimensional shape in a way I can understand, use an animated GIF. Don't use a tesseract. AI: Sure, here is a 4D hypersphere, divided into 3D \"slices\" like an MRI of a body is 2D slices (Its neat explanation in next tweet 1/2) https://t.co/h0O6oltxT7\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1656595723155292162 | (2) Nathan üîç (DM me ideas of things to predict) on Twitter: \"üéâü§ñüìà New Nathan Post üìàü§ñüéâ AI Risk/Reward Probability Model All models are wrong, but some are useful. I'm wrong, but how? I will bet on or retract any number in the following thread. https://t.co/m27djOXPAy\" / Twitter\n",
      "https://twitter.com/simonw/status/1661460336334241794 | https://twitter.com/simonw/status/1661460336334241794\n",
      "https://twitter.com/milesaturpin/status/1656010877269602304 | (7) Miles Turpin on Twitter: \"‚ö°Ô∏èNew paper!‚ö°Ô∏è It‚Äôs tempting to interpret chain-of-thought explanations as the LLM's process for solving a task. In this new work, we show that CoT explanations can systematically misrepresent the true reason for model predictions. https://t.co/ecPRDTin8h üßµ https://t.co/9zp5evMoaA\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1653247793061044226 | (1) Jeffrey Ladish on Twitter: \"Hugging Chat, a ChatGPT-clone based on a LLaMA-based model, was just launched. I've been using it and while it's a little rough around the edges, it feels similar to ChatGPT in terms of capabilities Only 5 months passed between the launch of ChatGPT and HuggingChat\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | S√©b Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here‚Äôs a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. üèõ https://t.co/1Grjv93laf\" / Twitter\n",
      "https://twitter.com/arankomatsuzaki/status/1663379403424911362 | Aran Komatsuzaki on Twitter: \"Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory - Surpasses previous methods, achieving +47.5% in success rate on the \"ObtainDiamond\" task, - First to procure all items in the Minecraft‚Ä¶ https://t.co/lH0RQY1VoT\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Tweet / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1660583080015347712 | https://twitter.com/Simeon_Cps/status/1660583080015347712\n",
      "https://twitter.com/JGraabak/status/1659462285365059585 | Jakob Graabak on Twitter: \"*Longer runways*. Once things have fully settled down after the FTX fallout, I hope we all can agree that, as a norm, established projects should always have 1-2 years of runway\" / Twitter\n",
      "https://twitter.com/labenz/status/1662207274365128704 | Nathan Labenz on Twitter: \"Is LLM context window hyperinflation the best or the worst kind of hyperinflation? I've studied ALiBi positional encodings and played with the 100K models to try &amp; answer: does this advance portend substantially more dangerous forms of AI? My answer: No, but long-term maybe yes\" / Twitter\n",
      "https://twitter.com/emollick/status/1651439624693207040 | https://twitter.com/emollick/status/1651439624693207040\n",
      "https://twitter.com/DrRadchenko/status/1656585919049129986 | Sergey Radchenko on Twitter: \"So to reflect a bit on Snyder's NYT oped: https://t.co/CZ2aCix1k0. The key argument is that nuclear powers have lost wars. The examples include US wars in Vietnam, Afghanistan, and Iraq, the Soviet war in Afghanistan, the French in Algeria and the collapse of the British Empire.\" / Twitter\n",
      "https://twitter.com/AndyMasley/status/1658875333242679297 | https://twitter.com/AndyMasley/status/1658875333242679297\n",
      "https://twitter.com/emollick/status/1660135548084690944 | https://twitter.com/emollick/status/1660135548084690944\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This ü§Ø is a very big ü§Ø I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" https://t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1648707119271628803 | Nathan üîç (DM me ideas of things to predict) on Twitter: \"The Asshole Filter Incentives that benefit assholes over personally kind people. Leading to you only interacting with assholes. https://t.co/ao5qGVTVjJ\" / Twitter\n",
      "https://twitter.com/OrionJohnston/status/1659515115392364545 | David Johnston on Twitter: \"@peterwildeford I've been leaning into the vagueness and unspecifiability lately with \"the probability that an ideal (but physically plausible) reasoner would assign\" I'm never actually going to resolve it either way, and this version avoids the temptation to replicate popular biases\" / Twitter\n",
      "https://twitter.com/ArmsControlWonk/status/1658857929322242048 | https://twitter.com/ArmsControlWonk/status/1658857929322242048\n",
      "https://twitter.com/daniel_eth/status/1660108792384880641 | https://twitter.com/daniel_eth/status/1660108792384880641\n",
      "https://twitter.com/russellwald/status/1658852120563712000 | Russell Wald on Twitter: \"Two hearings on AI in the Senate in the same day are great! But one was sensational the other was substantive. What the fed gov does with its own AI policy has ripple effects across the AI landscape. https://t.co/Ib1soMKsPI\" / Twitter\n",
      "https://twitter.com/yayalexisgay/status/1658491983256494083 | Alexis Gay on Twitter: \"brought to you by @async_com... when the meeting could have been a voice note https://t.co/UdSozMB0gl\" / Twitter\n",
      "https://twitter.com/_akhaliq/status/1659076009772171264 | https://twitter.com/_akhaliq/status/1659076009772171264\n",
      "https://twitter.com/GaetenD/status/1659913988321210371 | https://twitter.com/GaetenD/status/1659913988321210371\n",
      "https://twitter.com/MassDara/status/1655205051999178752 | Dara Massicot on Twitter: \"Prigozhin's publicity campaign yields results: Wagner to get weapons/ammo, and Surovikin is named as Wagner-MOD liaison. I can only speculate on the level of Kremlin intervention here. Shoigu and Gerasimov still retain the means to play their long game &amp; isolate their rivals.\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload‚Äîe.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://twitter.com/goodside/status/1661907164250750979 | Riley Goodside on Twitter: \"Really enjoying this paper. A deep case study in what LLMs actually learn and how their mimicry differs from faithful simulation. If you‚Äôve used LLMs for coding you‚Äôve seen how the loops aren‚Äôt really run. This is what they do instead.\" / Twitter\n",
      "https://twitter.com/StephenLCasper/status/1660718320348176385 | Stephen Casper on Twitter: \"üßµWe have a new example of how fast the AI proliferation pipeline is. Less than 6 months after ChatGPT was announced, BLOOMChat is an open-source 176B parameter copycat that achieved a win-rate of 45.25% against GPT-4 in a human preference study. https://t.co/SVj1R5x75j\" / Twitter\n",
      "https://twitter.com/goodside/status/1665004834733404160 | Riley Goodside on Twitter: \"My four rules for tweeting prompts: 1) Omit no text. 2) Cherry-pick honestly. 3) Restrict line width. 4) No empty tweets. A thread.\" / Twitter\n",
      "https://twitter.com/stanislavfort/status/1659676932353433601 | https://twitter.com/stanislavfort/status/1659676932353433601\n",
      "https://twitter.com/jachiam0/status/1662558656695775233 | Joshua Achiam on Twitter: \"Might keep this thread going with links as they happen. https://t.co/HJ2dn535IH\" / Twitter\n",
      "https://twitter.com/S_OhEigeartaigh/status/1659477159134601219 | Se√°n √ì h√âigeartaigh on Twitter: \"In-depth and well-written article in inews by Stuart Ritchie on reasons for concern about existential risk from AI. Really feels like these concerns are firmly entering the mainstream.\" / Twitter\n",
      "https://twitter.com/AmandaAskell/status/1660332621950517248 | https://twitter.com/AmandaAskell/status/1660332621950517248\n",
      "https://twitter.com/tshevl/status/1660286010041696257 | https://twitter.com/tshevl/status/1660286010041696257\n",
      "https://twitter.com/ESYudkowsky/status/1658616828741160960 | Eliezer Yudkowsky on Twitter: \"Fools often misrepresent me as saying that superintelligence can do anything because magic. To clearly show this false, here's a concrete list of stuff I expect superintelligence can or can't do: - FTL (faster than light) travel: DEFINITE NO - Find some hack for going &gt;50 OOM‚Ä¶\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1660025510691471360 | https://twitter.com/daniel_eth/status/1660025510691471360\n",
      "https://twitter.com/Elliot__Davies/status/1654478733057613824 | Elliot Davies on Twitter: \"@peterwildeford The analogy to Stable Diffusion (which cost like 1000x less to train than Dalle 2) seems totally fair to me, what is it missing? Phrased differently, what's not to be spooked about assuming above statement is true?\" / Twitter\n",
      "https://twitter.com/emollick/status/1654301934591827972 | (1) Ethan Mollick on Twitter: \"Bing is getting a bunch of new capabilities, but now is sort of weird and doesn't know what it is capable of doing It appears that it may be able to write and run code like ChatGPT's Code Interpreter, but keeps forgetting how to show graphs while believing it can send me emails https://t.co/1XN3ikQRsV\" / Twitter\n",
      "https://twitter.com/lmsysorg/status/1661818390783352833 | lmsys.org on Twitter: \"‚öîÔ∏èChatbot Arena Leaderboard Update! Exciting to welcome new entrants: - Google PaLM 2 - Claude-instant-v1 - MosaicML MPT-7B The competition is heating upüî• Check out our analysis for all the surprising results at https://t.co/v9NOY3k9ql Remember, your vote shapes the arena.‚Ä¶ https://t.co/NklFP9d3wt\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1654079782177341443 | S√©b Krier on Twitter: \"White House announces an independent commitment from leading AI labs like Anthropic, Google, Hugging Face, Microsoft, NVIDIA, OpenAI, and Stability AI, to participate in a public evaluation of AI systems on an evaluation platform developed by Scale AI. https://t.co/6JjDrLFRlb\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1653052405133754368 | Daniel Paleka on Twitter: \"What happened last month in AI/ML safety research (1/8):\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1653323207582023687 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"New post on why people seem confused about why AI systems are safe or unsafe. Systems that cannot be unsafe cannot be safe. https://t.co/3JCcnH1E3Q\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Eth on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1630881124858880000 | https://twitter.com/JeffLadish/status/1630881124858880000\n",
      "https://twitter.com/davidmanheim/status/1543625010451021827 | https://twitter.com/davidmanheim/status/1543625010451021827\n",
      "https://twitter.com/labenz/status/1654853321876815872 | https://twitter.com/labenz/status/1654853321876815872\n"
     ]
    }
   ],
   "source": [
    "twitter_tabs = sorted([t for t in tabs if 'twitter.com' in t.lower() and 'messages' not in t.lower()])\n",
    "print_tabs(twitter_tabs, label='Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8d623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(twitter_tabs, page=1, per_page=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4635d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google Docs ## (168 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit#heading=h.tnew02vlmfya | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1tMcC_b18ZDowxIhrSqsHfg4S2X02JF2ui3W4P62d6Lg/edit#heading=h.livlmiwiaubo | Report on Data Centers - TAIGA Version 2023-04-20 - Google Docs\n",
      "https://docs.google.com/document/d/1JJ2VnvEdiDjorrRsNTcPGaMPVVz3APoD7C31zwY7yKw/edit#heading=h.osty8jeclpyn | Rethink Priorities‚Äô Climate Research Strategy\n",
      "https://docs.google.com/document/d/1X4V1y6uKJCcecbRUsYdmcKc_DK2LsEUjWeAXPI3PXr0/edit#heading=h.ze7bbpcr5m3f | How workstreams within AIGS might work [notes; work-in-progress] - Google Docs\n",
      "https://docs.google.com/document/d/1Hq5IoWUwfxSC_xLJ4EFHmL8ZnFmMm1GVMvgTft7S7Q8/edit#heading=h.nr49y8jkbne5 | Ben‚Äôs rough thoughts on GLT part of 2023 LT department retreat - Google Docs\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit# | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1s4zVmg6c6l0Dv6lZOMlTeuJGKDyCFK8iOitzTGA8rgI/edit#heading=h.cn0nfi8o81o1 | Herding Alpacas\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1ZkO0L37_sWDMJ32hl9hV0HpOqNDQvQsxHDyk4bLSU28/edit#heading=h.gcqpcr8adw7o | RP <> GovAI 23-May-2023 - Overview of our respective work - Google Docs\n",
      "https://docs.google.com/document/d/15FIf6-pvc0Nc2ItFWz5Qk19F-Dg1MPRilB21cXWDjHU/edit#heading=h.drzlnsxrz21q | How can SP be involved in founder support?\n",
      "https://docs.google.com/document/d/1x3OjJQffC-TOPGMTBXGKFJ7kX_u7BT7z1CX3SuuMX94/edit#heading=h.e09t5a8o01r2 | Longtermism / existential risk / existential security framing - Google Docs\n",
      "https://docs.google.com/document/d/1zOXtV5cwXiDllJQmzSFzeADz3c8jPrCBiN8Nb75nlyM/edit#heading=h.yts3d84e5c30 | Project Hub: Defense in Depth (EAG London) - Google Docs\n",
      "https://docs.google.com/document/d/1v9Afif1o_thEamTTUm1BL0yiY1cqIvt0VNR3EIVMnjQ/edit# | [shared with LT] Proposal: Switch AIGS's primary branding to something new and distinct from RP [notes for AIGS Leads discussion] - Google Docs\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1lxE7-F7L9_i-mKBq5T3yGvKd8LxaqtI2om_9N6Codrc/edit#gid=0 | GHD Prospects List - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1AfG6ne_RLz90ZIEvTy0CAIwtZaHXkv8x2oPo0hg6t5M/edit?userstoinvite=kieran@rethinkpriorities.org#gid=0 | XST Fundraising Plan 2023 [sheet] - Google Sheets\n",
      "https://docs.google.com/document/d/1m_-XgZgBs0LZHplodgBbGcpiGtNWalPxPBjGOwF6rig/edit#heading=h.bq6kltrig94a | Macrocalendar - Google Docs\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://docs.google.com/document/d/1x4gYr4q1C5hofjLItBMrq_WebtlGSggPGECp48N1KrU/edit | AI movie forecast operationalization - Google Docs\n",
      "https://docs.google.com/document/d/1ZYfKFjzOeFiaK86U0np0W2XcpjUIdjJ51Vq7hxntht8/edit#heading=h.6pw5bytuj5u7 | (Forum copy) RP Campus Awareness Survey - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1kX4RVoWGicYug0Dr0Rt5sLfobHbjMLABlcY-dsTOMqg/edit# | Cascading conditional probabilities show transformative AGI by 2043 is <1% likely\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1SS8XmzHIaS_q7AcPNxKLbHK2kOa3PyPkXMS1Az1cQaM/edit#heading=h.nb2tkwr1m161 | Trading off compute in training and inference\n",
      "https://docs.google.com/document/d/14giRxnDwnCOMI_HTIHnbwU66XiX51XHYxO8aQfMUXc0/edit#heading=h.ilkan3e0drym | Jared Brown <> Michael Aird - 2023-Apr-13 - US AI policy, lobbying, Global Shield - Google Docs\n",
      "https://docs.google.com/document/d/1LNyJApFsLrxVe9Z_LuiOIge-K0rTab2o0Bhtb3Vn-fY/edit#heading=h.zee6ngwoj6jg | RP <> Chatham House May 17, 2023 - Google Docs\n",
      "https://docs.google.com/presentation/d/1iuYIHlHvsnvOUoRX__BCc5J2A0cSieJlENSAyT_uFg8/edit#slide=id.ge44d99aa4e_0_0 | Survey OKRs presentation - Google Slides\n",
      "https://docs.google.com/document/d/14dDtyEAh7ealQGfVG8xBaWxcQcyT5sdCNTEDj9blTo8/edit | WIT Possible Projects Apr 2023\n",
      "https://docs.google.com/presentation/d/19d8DDka9xErkDEHqEhFz152AjOjFLs4tIbZB9vNuBmY/edit#slide=id.ge44d99aa4e_0_0 | WIT OKRs for April 2023 All Staff Meeting - Google Slides\n",
      "https://docs.google.com/presentation/d/1KW7ZkuCdXAC8FEfC6r3w15QQQTn4jUyjFSX24WzCte8/edit#slide=id.g232fae25e24_0_7 | 2023 AW Department OKRs - Google Slides\n",
      "https://docs.google.com/document/d/1UOUK8hMxDD0WlM6jEbjI9dWyC73yulOEtoU2MWYaooA/edit#heading=h.tufvzyw73c4q | Updates on AIGS team strategy etc. [April 2023; DRAFT] - Google Docs\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit#heading=h.y3b6zbr0v5zz | Proposal: Switch AIGS's primary branding to something new and distinct from RP [notes for AIGS Leads discussion] - Google Docs\n",
      "https://docs.google.com/document/d/1qiQDQKSUDTvyurVzWT-Vn6RmJ24a4Emol8pGO1-ZIb0/edit | Untitled document - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers\n",
      "https://docs.google.com/document/d/1gyU2yGPUPEyHhj3kvvKSDh1-TFetU4q7p2wcV-KI6is/edit#heading=h.zee6ngwoj6jg | RP <> 80k May 18, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro\n",
      "https://docs.google.com/presentation/d/1dal9XJTgni7TfqMw2OylVwsMWrfz_FaYjPOdcoVl10o/edit#slide=id.g232c77bbbb5_0_5 | Copy of Org-Wide OKRs Presentation - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/1P8mkLmPOrTNnVH4lOOoPebtlHIp1Pi3lg8bA8NUqaTo/edit#gid=0 | GHW asks - Google Sheets\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit#heading=h.pqlvjrmba57q | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://docs.google.com/document/d/1mcRMh43ciXvtFiZnd9c5GIyNU1IW-KrXTy9-VjO49bY/edit# | [EAG London 2033] XST's tentative top 10 projects - Google Docs\n",
      "https://docs.google.com/document/d/1EZ1TgTnJ6zt_-JuhboXJwEDZ7r4R2D8WnOzLE7DphUg/edit | What would it look like to regulate AI like bio and nuclear? - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit#gid=107848425 | Survey team time allocations - Google Sheets\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://docs.google.com/document/d/1rdsErwdQxdOPtOU3bCaWFTMmTMxNWqmNXJgzAl0y3TE/edit | EIP grant recommendations [shared] - Google Docs\n",
      "https://docs.google.com/document/d/12A4_adulGL1NPE7Xd08hUfe3spLFKfcRwXyD28FRt5o/edit | RP Copy of How I think about TAI deployment scenario analysis - Google Docs\n",
      "https://docs.google.com/document/d/14T_RBzlfBTn4IOdxqG0fh6ilmGOxqGWtyKQZPEiHbqc/edit#heading=h.e6lo2rv2yae9 | XSOC - Google Docs\n",
      "https://docs.google.com/document/d/1KpePoyEai4ZUiCxq8jVpL5EP0JogHkGwj-ZdRe-IDeM/edit#heading=h.ik0d9km8mxzo | My tentative model of P(doom by 2070) - Google Docs\n",
      "https://docs.google.com/document/d/1RMjcOgNwZWvBzfu5oB_llwAThk15QpGTLxy_eLBwVLE/edit | WIT Sequence #1 - Google Docs\n",
      "https://docs.google.com/document/d/1-YmmnXkzaQA2AydAUPKVGHFbjDLCe2qck09IpmNBqcM/edit#heading=h.osty8jeclpyn | Rethink Priorities ‚Äî Insect Farming and Welfare Strategy - Google Docs\n",
      "https://docs.google.com/document/d/1zOXtV5cwXiDllJQmzSFzeADz3c8jPrCBiN8Nb75nlyM/edit | Project Hub: Defense in Depth\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=1888482782 | PTO Report Effective Jan 1, 2023 - Managers - Google Sheets\n",
      "https://docs.google.com/document/d/1X9nKas72w_MRIte7sdeBsNSl_rek-j1kk8r18zRQrEw/edit | Funding application: Condor Camp 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1YlgCHFINkfIFJ3vWaUgGC3Gv3ZmbTfj6l0PL-CTQ_TA/edit#heading=h.52ldutosr4la | Analysis - EAA Survey Results - Google Docs\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit#heading=h.u6dhzn2rpi5b | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search\n",
      "https://docs.google.com/document/d/16r-PIQCIZSKGgahwJUK0kuTjVY2vLoIQGcsEeuJDfZc/edit | LT Retreat May 2023 - Lab Governance Workstream - Google Docs\n",
      "https://docs.google.com/document/d/1VYgp37pHoGX0rx5ze6p6I9RiWBx2oT4xKMtYq_TMCmg/edit | 5 Year Retrospective Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/1vouv73_c8L05fHDh8x3A_HSBukclMbIb4JE7O2UdFLY/edit#heading=h.x1uc7lfftp0 | AIGS 2023 OKRs [as of April 2023] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/1ZQBY3Cutw1gX-GLZvMVpLa_aLkNtwLCATifABNWxUw4/edit#heading=h.3a213phaz2nq | Conversation notes template: [non-RP full name] <> [RP full name] - YYYY-MM-DD - [topics] - Google Docs\n",
      "https://docs.google.com/document/d/1wYFyLk148hYK0OxOtNPfNu9l9XIjOPr3bNwzs6A4XpE/edit# | Copy of [Michael Aird, Feb 2023, manager-assessment] RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1gke0Inp30cktPIGoQxKP0W_Qk5dwKVqua2gJ1pzbbk4/edit | RSVP Form: Rethink Priorities Brunch  Monday 22nd May (Responses) - Google Sheets\n",
      "https://docs.google.com/document/d/1szG_6iGL1V2a_89AepyGs7lxg-UO1rp4TPGBL_MNSRg/edit#heading=h.z1m60iksdy8y | AI Message Testing Proposal - Google Docs\n",
      "https://docs.google.com/document/d/15XU5QDOSJw5DimExN-bvXggqYwg-h_x116Z2Yuwz0i0/edit | D1 1500: Strat I - Strategic Context and High-Level Goals\n",
      "https://docs.google.com/document/d/18mSdRCL0l0ApuOYU6oiC7ImzLjFbuetehqTLkw6PP-o/edit#heading=h.qvx51emxxmz4 | Splitting up EA\n",
      "https://docs.google.com/document/d/1tHguGS8oKjaeG_eRpyTCLD-bfPWDV-fS7jGAqE7jmUI/edit | Caleb's thoughts on RP Potential Project Directions + thoughts on LT incubation - Google Docs\n",
      "https://docs.google.com/document/d/1vRHTl_fYJa7a-3SK2MxYw215eZ9bH5DgkzAvAYMaoLU/edit#heading=h.xc4zt432pfyz | Corporate / Lab Governance Team - 1-Pager - Google Docs\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It\n",
      "https://docs.google.com/spreadsheets/d/1TKdLTOeDfBjXUoUAJdPh40Z13bmYf5hvuTUTJH0m41c/edit#gid=2031513321 | [confidential] Staff Overallocation - Google Sheets\n",
      "https://docs.google.com/document/d/16aEouFa8470SCYgTNEWEqhJQQw-daaMx4Q2LLf-8W5E/edit#heading=h.6ytgvt3dfnpe | Zoe Williams - May 2023 - RP Performance Evaluation Template - Google Docs\n",
      "https://docs.google.com/document/d/1usMVjv7hMx22K-eu71o1bcfj-7JH_l-aXbfYb6NHSoM/edit | Threat Model for Existential Risks from AI - Google Docs\n",
      "https://docs.google.com/document/d/16eUus559s_YsBMHCr4PgzZohx-CMYCLWRXOqApRgSbw/edit#heading=h.cxf5v1ex5u4o | EAG London 2023 Takeaways (Jam) - Google Docs\n",
      "https://docs.google.com/document/d/1U1wrLukImWK74SHDPQs2ZoxmMP0CdCidIyXk6Z0vafM/edit#heading=h.wf2ojxu3u6z1 | Some updates to RP's branding position with regard to the EA and the EA Community - Google Docs\n",
      "https://docs.google.com/document/d/1fLL5BZf8VdhdEQ9uNDne6mp8sNTmgUJSOJ8LQxaZVFI/edit#heading=h.ahaokbxu01um | How bad/good would shorter AI timelines be? Why? [writeup idea + notes + reading list]\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://docs.google.com/document/d/1AdeJ7p3emmpzL_TV6tF0Y6bmmKOXQOBZu0Z3noWlAaY/edit#heading=h.ldebapglg1l1 | May 2023 LT Retreat and Coworking Participants' Guide\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Sleepwalking into Survival\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.q52a7f8v1vd | Two-pager on RP's AI Governance & Strategy team - Google Docs\n",
      "https://docs.google.com/document/d/1gd6qQx-SP6rfAVQE5rzfPH0zXYOOHXBa13JSUd2zROQ/edit | Daniel's Randomly Generated Future: Hardware Accelerates\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1HnK-FdiI03P4qmBtgi6grQAexE31Fh9HL8YtkrgslXs/edit#heading=h.9o8tvlxyo2vp | [WIP] Updates on Condor + updates to my model of longtermist talent search in Brazil - Google Docs\n",
      "https://docs.google.com/document/d/1R-H-1old8f9NwsyKNK4d8vEur8350Ju9dDrKIz1dx2o/edit#heading=h.pkj0s0mloy5v | Rough notes on \"crunch time\": definitions, related concepts, prior work\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/18sXLBNMsLwKXGqFVXESHNBDdK-z7SIu2BH_EYrSw7sY/edit | Project Description [Current] 03/28/23\n",
      "https://docs.google.com/document/d/1Xp43r9fNweDd-e40SUwr_eOkXONQ3vFV5xGXCyaW2n0/edit#heading=h.jrcbnm1fd14j | AIGS Subteams Structure - Detailed Feedback - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes\n",
      "https://docs.google.com/spreadsheets/d/1TlWcxy-fuzXd93DEJ_sj8R6Ikm4HJMZd92sXULbnZvM/edit#gid=0 | [very confidential] Staff Risk - Google Sheets\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period\n",
      "https://docs.google.com/document/d/14ou5ob0SPa52boGDrPYZ4Oj_Gje0dCJOV_8l7mftK9o/edit#heading=h.htupmo9y9du4 | EAG London 2023 - Renan Notes - Google Docs\n",
      "https://docs.google.com/document/d/1WSyIfis0vc5pEBI8RpWp7o0tnTHJAS5OeTWgY_H2xdM/edit#heading=h.ors7j470u62z | AI: Thinking Out Loud (WIP) - Google Docs\n",
      "https://docs.google.com/document/d/1uDG6vIINHYu29M6m8md3JiN38TBZ45rvU7VSP5dQr_A/edit#heading=h.pdhqhnskdwfb | [Draft] A defense of high-probability doom predictions\n",
      "https://docs.google.com/presentation/d/1iYnnK3TwNBugTCeeRVyL8MJhSb92ZTUNO-7y5Iwyyvs/edit#slide=id.g232b11b7cba_0_5 | GLT OKRs 2023 -- RP All Staff Meeting 2023-04-20 - Google Slides\n",
      "https://docs.google.com/document/d/1b4Wck2eE8gDMsZQlDPWiUje3souy2dyfBHn7n4ZzmsY/edit | [For GovAI] Our top AI governance projects - Google Docs\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://docs.google.com/document/d/11OQkFGkKmIKs3L8q23-aMuPvNcQpX6HxxMvNSkJiP7o/edit | AIGS Compute Gov - Job Opening Kick Off Form - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1lbazshEDUNzT-5gBYqfrmC9hvKRIxSbXroHywxPctw4/edit | [shared] Slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/1CpO25iV38hXESPRQZmv15bLjBB_hrAYgAkvfHoJbngE/edit#heading=h.j9owozbw0x7p | Layer - Safety Culture - Google Docs\n",
      "https://docs.google.com/presentation/d/1jLK9tjEH7Mxqx1fz0IPDzKJvcoLJJVo4jpZuZ42j-rA/edit#slide=id.g213a7bae0d5_0_0 | GHD OKRs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://docs.google.com/document/d/1sMH8fibfO602ZsttAjjxq4bBld5xn5UwuIraIInwTzs/edit#heading=h.z1512e3souac | (Forum copy) Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://docs.google.com/document/d/18aOKioNfnAfYgEX439P2Cq9Ocv_C1I6Jkjxkgowslus/edit#heading=h.6ytgvt3dfnpe | 2023: May - RP Performance Evaluation for Ben Snodin - Self Eval - Google Docs\n",
      "https://docs.google.com/document/d/1zsKIgyLjBitm2V-fmJaEPODf8lCYDLOrCuXfewO1HhU/edit#heading=h.wcbf4hgpncir | Biosecurity 5pger - Google Docs\n",
      "https://docs.google.com/document/d/1uNF5687rCUBJucJGgT22QQkm0H_EzmIpzt2arWH-WOY/edit#heading=h.osty8jeclpyn | Forecasting China‚Äôs ability to indigenously produce AI chips\n",
      "https://docs.google.com/document/d/1fbEOkpK1ieUze--zbtgUjIOGImX1kYYGUNJXzpHyYmQ/edit | Examining pathways through which narrow AI systems might increase the likelihood of nuclear war\n",
      "https://docs.google.com/document/d/14ApHvL04itCT2eK6vipKUuG7pXqu0wysyaQ1ERZKUM4/edit#heading=h.1jko4iyren03 | Thinking about AIGS org - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on the US natsec community‚Äôs relationship to AI\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1DYrtSDO6m05GhXFAEkDZn8QNkyPAFwRBkQOlY3x22ns/edit#heading=h.h5pv6sr57sib | RP AI Public Attitudes Surveys - Google Docs\n",
      "https://docs.google.com/document/d/10pSj7Jb68sPO0bQyw7cMswsMtx1A7tOGPxy3JbrLC8I/edit#heading=h.6rnrfpst2h9p | Thoughts on founder support preparation - Google Docs\n",
      "https://docs.google.com/document/d/1sZ7N2pOjFaluiZ6roUx90IH2t1rvVX9AjHbfK5qeEoM/edit | Notes EAG neartermist - Google Docs\n",
      "https://drive.google.com/drive/u/1/folders/1Ql6jcg3xnkDD8f5qh9hNM7t4HRv6_XQN | Uncertainty Workshop 3 (April 19, 2023) - Employee Resources - Google Drive\n",
      "https://docs.google.com/document/d/1QpW-WvW9zzSwWvg3GvzF5BMbGRm5uv_kU9pebIApZI8/edit# | XST Fundraising Emails 2023 - Google Docs\n",
      "https://docs.google.com/document/u/2/d/1fOCLx9srgcK3-oEKteAu-vTMAyXDEDPGyuIW4tcY6IA/edit | 2023 Altruistic Policy Telecon Agenda\n",
      "https://docs.google.com/document/d/1WEl6K9qmd9_6kuVw6UyRroFsxXbfFIYd_hTpZbrZlZs/edit# | Pivotal act: Definition, examples, & reading list\n",
      "https://docs.google.com/document/d/12oQImZrUFiEgJzyG_1xGrulyEYL7UFckJJMKPDVnr9Y/edit | Forecasting Twitter list\n",
      "https://docs.google.com/document/d/1gJImzAEBg7idY5FrwGisK6BYo2NLW1WYcGPrs1I2ESY/edit | AIGS rebranding working group - meeting notes - Google Docs\n",
      "https://docs.google.com/document/d/1kTYCNSt61wTZVLQavlGd3UHHXeyKNSxLQM_UPfyPnKM/edit# | Weekly team call (\"AI concerned\" team) - Google Docs\n",
      "https://docs.google.com/document/d/1-NRtsVxqE4LnL_gYn0wDRbfH2RvoDthzp-j_9mUazOI/edit#heading=h.3fjkh1axp1du | Three proposed strategies for AGI endgames\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/document/d/1QFTYRSJPyQoKfO_bFrsxG861xebXbX3XzvBEEaT7Z1U/edit#heading=h.mj6mty720ju | [V.3] What is going to matter if an AI crash project emerges?\n",
      "https://docs.google.com/document/d/1FMJZ9wjxooB-7HD7K7c-kEasF1qYuXMfq4wPrFioq_Q/edit#heading=h.mdmelsvomij2 | Info on how GovAI does hiring (Georg Arndt <> Michael Aird notes, 2023-May-15) - Google Docs\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://docs.google.com/document/d/1OmKOmMfbmBnjxGGHetfN2VQ1az4Zox0Y-4f5xTlRzhw/edit#heading=h.g2xot74rmmug | Maybe let‚Äôs focus more on non-extinction ways that a lot of the potential value of the future could be lost? [quick notes]\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1h-oWerawF0jTZ0kAp7ORSBPPlg1h_F34FEFGjMvkiPM/edit#heading=h.osty8jeclpyn | RP Climate Research Strategy (public-facing) - Google Docs\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit | Community building in a world where people actually listen to us\n",
      "https://docs.google.com/document/d/1wJCLEHAR34joF-cIGxAwCMQm8-D-mlP6LPBoMboFdHk/edit | A survey of concrete risks derived from Artificial Intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1xMyAJe1jUrt_NbQtXQm4thXvoj-rvOyJdAyPifZO3kw/edit#heading=h.zee6ngwoj6jg | RP <> Ada Lovelace Institute May 18, 2023 - Google Docs\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay, detect, defend\n",
      "https://docs.google.com/document/d/1fqSeu0YL223ngmSCvkuhsJ5zCKBOEzxhyfSEkUPfUq8/edit# | AI threat model reading list [crappy first attempt]\n",
      "https://docs.google.com/document/d/1VSypWxtDRjP5bPsmmvIcvbvHg7RE7o3XZVI3P5ltMdk/edit#heading=h.8ei4qtw0vfk0 | Josh Jacobson: Jam 1-1 about x-risk entrepreneurship (25 April 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1kpdCPU2I0NLWPRwQ4qPSUZcZDobnyR9UY-iSOSBQRm4/edit#heading=h.natf23qmy2fx | Scaling laws literature review - Google Docs\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1TaopVXaa79awP2RmWtAnyLulzw0e2f_1nyJtnON5kI8/edit#heading=h.nxinzza3nrt7 | [shared] Review and Future Plans: Condor Camp 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1zxQGQfDeD7uTnUoJ2_L47jKWvSoancgtEsH4Zd6NAt4/edit#heading=h.ow22kk7tct5w | XST retreat 2023 ‚Äì Schedule and Discussion notes - Google Docs\n",
      "https://docs.google.com/document/d/1z3YrMwEcdNGt2X2GoFNIVhbcBZxzsBFiSz4_q6vJXO8/edit#heading=h.n3opm8r5uhlr | Center for Long Term Priorities Update: April 2023 (shared) - Google Docs\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit#heading=h.u5ylt23gllew | [outdated] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit#heading=h.mak2h8fgpqe9 | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1_l-mRnuZJckKFXGmbz0m9vPpcVc7w9PMW-8aR1ppYHg/edit#gid=0 | XST June+July timetable, June 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1jtX74U03k3_tzvqAc0sTJaYpwx3OI72qrRPXz9r6DGE/edit#heading=h.1lhw3y6kfeo8 | Jam‚Äôs proposal for founder search and support - Google Docs\n",
      "https://docs.google.com/document/d/1r0TPCpivFX3sHbcDdRc2ZC85tiocnFZyii2woVVacMs/edit#heading=h.c6m59byd7k3s | AI Reading Notes - Google Docs\n",
      "https://docs.google.com/document/d/1KJx_GhV3A8c2leu4hisMDO7sciY49p8BygQAfbJ1mXw/edit#heading=h.tjvfcbqz2mvz | Founder search leads list - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1LyQKNesRensq3BjLWgzcdJ3wJBjl0n98fAQ7g7HRbYk/edit#heading=h.koq63kgkerx2 | Prioritarianism and Resource Allocation - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/19DnT7ACpkiiNe9oGnceXYYW2vztuZPW5FkhXXqzJCQc/edit#gid=0 | RP LT work in progress (WiP) sessions: Sign-up sheet [internal + GovAI] - Google Sheets\n",
      "https://docs.google.com/document/d/1NfyHOxI7AW0apsyrkW9Eqv_LSLLR9_vlmVmSa7QlxZA/edit#heading=h.ohimieuzefxf | Info on AI lab boards - Google Docs\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit#heading=h.wsiggdpisp4j | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/1FeRGXrKaJb2nh3lBiyJeRvnIc1-ki2qayhQ8jLT8dJI/edit#heading=h.ebauujwlzvti | EAS 2022 Demographics - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1FROfNCchRS8nYmPSkwsBF6V5ncQTaeMvjbB_5tkkde8/edit#gid=1708690655 | Program Service Revenue Tracking - Overall - Google Sheets\n",
      "https://drive.google.com/file/d/12Pj4o8ainEbBE8hUliQ_P0yTzMIhG6Pe/view | Hurwit Memo re RP Organizational Health 5-11-23.pdf - Google Drive\n",
      "https://docs.google.com/document/d/1SbGV0Nc-Nh6WYkTNQ7QUxnbi9kRw0XsMwSqmBk0U0eM/edit | [Private] EAIF Vision and Scope - Google Docs\n",
      "https://docs.google.com/document/d/1P5iIXobV9Ail-xSFI182xIt427HlWENMEsjQMyJIM0Q/edit# | May/June notes on Caro - Google Docs\n",
      "https://docs.google.com/document/d/1lu_anb7XT9WZPsy8tNvt0U0Q_nbNl4SeCMc18OndOws/edit | WAW theory of change (Neil, Peter, Sagar) - Google Docs\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit# | Info on recent/upcoming AI policy happenings, from May 2023 coordination call\n",
      "https://docs.google.com/document/d/1vomm7q1BERofa1w5kH9_vu_MuekikihkZlYkBYFmE24/edit#heading=h.vf1mp2zaq0zs | Notes on improving coordination in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1KCIK1su59h7VEfRqxV1rAtR0flcoxisVEr90cpYeia0/edit | Max Dalton <> Ben (potential advisor) 2023-05-09 - Google Docs\n",
      "https://docs.google.com/document/d/1lIigtRkpUTCZpijZWRZ2yy85xve6WSOfUikVtnfX1Ck/edit | Draft post: Seeking (Paid) Case Studies on Standards - Google Docs\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://docs.google.com/document/d/1NkIRgUBqIJHc3LL9PghZwebiCqpG6ZlXGEm7NO13knY/edit#heading=h.16s07xk8ys17 | High-level comparative speedruns: Proposed structure - Google Docs\n"
     ]
    }
   ],
   "source": [
    "doc_tabs = sorted([t for t in tabs if ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower())])\n",
    "print_tabs(doc_tabs, label='Google Docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(doc_tabs, page=1, per_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479f45a0-d63f-474d-aa76-2ddab5a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = copy(doc_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e71249-4e0e-47aa-9fcd-69b9219f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = open_random_n_tabs(doc_tabs_, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6311fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google search ## (10 tabs)\n",
      "\n",
      "https://www.google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://www.google.com/search?q=is+it+common+for+a+woman+to+have+twenty+sexual+partners&rlz=1CDGOYI_enUS715US715&oq=is+it+common+for+a+woman+to+have+twenty+sexual+partners&aqs=chrome..69i57.15480j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | is it common for a woman to have twenty sexual partners - Google Search\n",
      "https://www.google.com/search?q=norwegian+sovereign+wealth+fund&rlz=1CDGOYI_enUS715US715&oq=norwegian+sover&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDMzODFqMGo0qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | norwegian sovereign wealth fund - Google Search\n",
      "https://mail.google.com/mail/u/1/#search/taiga/FMfcgzGsmrCCwpgZPzzTHhZMJTwFQrJJ | TAIGA - May Highlights - peter@rethinkpriorities.org - Rethink Priorities Mail\n",
      "https://www.google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://www.google.com/search?q=neal+caffrey+prison+escape&rlz=1CDGOYI_enUS715US715&oq=neil+caffrey+pris&gs_lcrp=EgZjaHJvbWUqCAgBEAAYFhgeMgYIABBFGDkyCAgBEAAYFhge0gEJMTEyNjVqMGo0qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | neal caffrey prison escape - Google Search\n",
      "https://www.google.com/search?q=cognitive+emulations+conjecture&rlz=1C5CHFA_enGB1058GB1058&oq=cognitive+emulations+conjecture&aqs=chrome..69i57j0i546l5j69i60.1717j0j1&sourceid=chrome&ie=UTF-8 | cognitive emulations conjecture - Google Search\n",
      "https://www.google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://www.google.com/search?q=father%27s+day&rlz=1CDGOYI_enUS715US715&oq=father%27s+day&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTINCAEQABiDARixAxiABDINCAIQABiDARixAxiABDINCAMQABiDARixAxiABDINCAQQABiDARixAxiABDINCAUQABiDARixAxiABDIHCAYQABiABDINCAcQABiDARixAxiABDINCAgQABiDARixAxiABDINCAkQABiDARixAxiKBdIBCDExOTRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | father's day - Google Search\n",
      "https://www.google.com/search?q=a+grief+observed&rlz=1C5CHFA_enUS925US925&oq=A+Grief+Observed&aqs=chrome.0.0i355i433i512j46i340i433i512l2j0i512l4j46i512j0i512l2.2909j0j1&sourceid=chrome&ie=UTF-8 | a grief observed - Google Search\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('google.com' in t.lower() and 'search' in t.lower() and\n",
    "                                   not ('docs.google' in t.lower() or 'sheets.google' in t.lower()))]),\n",
    "           label='Google search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b9762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EAFo/LW ## (108 tabs)\n",
      "\n",
      "https://www.lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/pR35WbLmruKdiMn2r/continuous-doesn-t-mean-slow | Continuous doesn‚Äôt mean slow - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‚ÄòDissolving‚Äô AI Risk ‚Äì Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/icdd4FCKuwqyAuYBm/eli-s-review-of-is-power-seeking-ai-an-existential-risk | Eli's review of \"Is power-seeking AI an existential risk?\"\n",
      "https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://forum.effectivealtruism.org/posts/edceBA7h7sB53aAWT/an-overview-of-the-who-essential-medicines-list-procedures | An overview of the WHO Essential Medicines List: procedures, usage, and potential improvements - EA Forum\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/oLk5QEY2y2fL9ifoE/blog-update-reflective-altruism | Blog update: Reflective altruism\n",
      "https://www.lesswrong.com/posts/ejxwraMP5ye7Bgmpm/things-i-learned-by-spending-five-thousand-hours-in-non-ea | Things I Learned by Spending Five Thousand Hours In Non-EA Charities - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/vC6v2iTafkydBvnz7/agi-ruin-scenarios-are-likely-and-disjunctive | AGI ruin scenarios are likely (and disjunctive)\n",
      "https://forum.effectivealtruism.org/posts/CAC8zn292C9T5aopw/community-health-and-special-projects-updates-and-contacting-1 | Community Health & Special Projects: Updates and Contacting Us - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/LZxXjkZDzvdEDFpxz/apply-now-first-ever-eagxnyc-this-august | Apply Now: First-Ever EAGxNYC This August\n",
      "https://forum.effectivealtruism.org/posts/G2vPqkCZkJusKGLtK/introducing-animal-policy-international | Introducing Animal Policy International - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Dq69kvjKyxQzKNRH7/seeking-expertise-to-improve-ea-organizations | Seeking expertise to improve EA organizations - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/eaLwfhXbw2kNxA4es/bridging-ea-s-gender-gap-input-from-60-people | Bridging EA's Gender Gap: Input From 60 People - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nTALzRAWxRnrxvoep/implications-of-the-whitehouse-meeting-with-ai-ceos-for-ai | Implications of the Whitehouse meeting with AI CEOs for AI superintelligence risk - a first-step towards evals? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case\n",
      "https://forum.effectivealtruism.org/posts/LgscQde9vQW4xLrjC/on-child-wasting-mega-charities-and-measurability-bias | On Child Wasting, Mega-Charities, and Measurability Bias - EA Forum\n",
      "https://www.lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/ckokr9uhr2Cu3h5En/tips-for-people-considering-starting-new-incubators | Tips for people considering starting new incubators - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/HuLCFBEbekZ6AE7LP/linkpost-survey-evidence-on-the-number-of-vegans-in-the-uk | Linkpost: Survey evidence on the number of vegans in the UK - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky‚Äôs ‚ÄòMost Important Century‚Äô - EA Forum\n",
      "https://www.lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://www.lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/2TdXocyDF9PxWewwY/should-the-ea-community-be-cause-first-or-member-first | Should the EA community be cause-first or member-first? - EA Forum\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference\n",
      "https://forum.effectivealtruism.org/posts/cJc3f4HmFqCZsgGJe/don-t-interpret-prediction-market-prices-as-probabilities | Don't Interpret Prediction Market Prices as Probabilities - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/bB2CSnFS6mEcNmPgD/the-costs-of-caution | The costs of caution - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gSGhrCXdntxLrMAmJ/ai-strategy-career-pipeline | AI strategy career pipeline - EA Forum\n",
      "https://www.lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get | How bad could a war get? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/8YXFaM9yHbhiJTPqp/agi-rising-why-we-are-in-a-new-era-of-acute-risk-and | AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence\n",
      "https://forum.effectivealtruism.org/posts/JZEgmumeamzBAAprt/how-come-there-isn-t-that-much-focus-in-ea-on-research-into | How come there isn't that much focus in EA on research into whether / when AI's are likely to be sentient? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/AJDgnPXqZ48eSCjEQ/ea-survey-2022-demographics?commentId=sR5GhwEvcHHfWpRTK#sR5GhwEvcHHfWpRTK | EA Survey 2022: Demographics - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/7hMgK4hciBhXmBRnW/do-you-think-decreasing-the-consumption-of-animals-is-good | Do you think decreasing the consumption of animals is good/bad? Think again? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/vWRP8g8pqN9np4Aow/what-are-work-practices-that-you-ve-adopted-that-you-now | What are work practices that you‚Äôve adopted that you now think are underrated? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/cPkfCviK5cAsevTdM/the-charity-entrepreneurship-top-ideas-new-charity | The Charity Entrepreneurship top ideas new charity prediction market - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/3KAuAS2shyDwnjzNa/predictable-updating-about-ai-risk | Predictable updating about AI risk\n",
      "https://forum.effectivealtruism.org/posts/myp9Y9qJnpEEWhJF9/linch-s-shortform?commentId=ymhXwLRhjAh2qEHeA | Linch's Shortform - EA Forum\n",
      "https://www.lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI\n",
      "https://forum.effectivealtruism.org/posts/5oTr4ExwpvhjrSgFi/things-i-learned-by-spending-five-thousand-hours-in-non-ea | Things I Learned by Spending Five Thousand Hours In Non-EA Charities - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DAD4777WJqFe9jZZM/a-flaw-in-a-simple-version-of-worldview-diversification | A flaw in a simple version of worldview diversification - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DZEkYatZeMSbGBAjk/why-are-we-so-complacent-about-ai-hell-1 | Why aren‚Äôt more of us working to prevent AI hell? - EA Forum\n",
      "https://www.lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson‚Äôs latest AI risk position statement - LessWrong\n",
      "https://www.lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/8Z2uFCkrg2dCnadA4/kfc-supplier-sued-for-cruelty | KFC Supplier Sued for Cruelty\n",
      "https://www.lesswrong.com/posts/3nDR23ksSQJ98WNDm/developmental-stages-of-gpts | Developmental Stages of GPTs - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/dpjCwMwKEPqK3TPnC/notes-on-managing-to-change-the-world | Notes on \"Managing to Change the World\" - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/3KuCzHJHCz99sf3ZB/beyond-cost-effectiveness-insights-for-effective-altruism | Beyond Cost-Effectiveness: Insights for Effective Altruism from Health Economics - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/7mSqokBNuHu3rzy4L/retrospective-on-recent-activity-of-riesgos-catastroficos | Retrospective on recent activity of Riesgos Catastr√≥ficos Globales - EA Forum\n",
      "https://www.lesswrong.com/posts/sTe78dNJDGywu9Dz6/solving-the-mechanistic-interpretability-challenges-eis-vii | Solving the Mechanistic Interpretability challenges: EIS VII Challenge 1 - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/gt6fPgRdEHJSLGd3N/thoughts-on-the-openai-alignment-plan-will-ai-research | Thoughts on the OpenAI alignment plan: will AI research assistants be net-positive for AI existential risk?\n",
      "https://forum.effectivealtruism.org/posts/idjzaqfGguEAaC34j/if-your-agi-x-risk-estimates-are-low-what-scenarios-make-up | If your AGI x-risk estimates are low, what scenarios make up the bulk of your expectations for an OK outcome? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/5Lytcvj7GCSysBtSD/my-impact-assessment-of-giving-what-we-can | My impact assessment of Giving What We Can - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/eK8sEq7Djxp3NqxLQ/tyler-cowen-s-challenge-to-develop-an-actual-mathematical | Tyler Cowen's challenge to develop an 'actual mathematical model' for AI X-Risk - EA Forum\n",
      "https://www.lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/nh8dx6JJt3Ga3BRdp/gwwc-reporting-attrition-visualization#comments | GWWC Reporting Attrition Visualization - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L5EuQ3araz7iESjEA/ea-in-africa-is-lowkey-thriving | EA in Africa is lowkey thriving - EA Forum\n",
      "https://www.lesswrong.com/posts/PdooAsNFiohmyburK | AI Takeover Scenario with Scaled LLMs - LessWrong\n",
      "https://www.lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts).\n",
      "https://www.lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://www.lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people\n",
      "https://www.lesswrong.com/posts/agv26XfXfKfKiKwDm/the-crux-list | The Crux List - LessWrong\n",
      "https://www.lesswrong.com/posts/FG6icLPKizEaWHex5/announcing-apollo-research#comments | Announcing Apollo Research - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/eYQ4A3Wft7rbdZahG/announcing-the-confido-app-bringing-forecasting-to-everyone | Announcing the Confido app: bringing forecasting to everyone - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Cre2YC3hd5DeYLqDH/link-post-new-york-times-white-house-unveils-initiatives-to | [Link Post: New York Times] White House Unveils Initiatives to Reduce Risks of A.I.\n",
      "https://www.lesswrong.com/posts/AZHHEPYWvTovvtikz/human-level-diplomacy-was-my-fire-alarm | Human-level Diplomacy was my fire alarm\n",
      "https://forum.effectivealtruism.org/posts/MSkxRv8hviGvGgasD/ai-risk-reward-thinking-in-public | AI risk/reward: Thinking in public - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/8xNSiwj5gjoDTRquQ/announcing-the-publication-of-animal-liberation-now | Announcing the Publication of Animal Liberation Now - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/T7PC22Yc9heFL5Ay4/iqisa-a-library-for-handling-forecasting-datasets | Iqisa: A Library For Handling Forecasting Datasets - EA Forum\n",
      "https://www.lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://www.lesswrong.com/posts/JcgtKunqmELefxksx/killing-socrates | Killing Socrates - LessWrong\n",
      "https://www.lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://www.lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/cP7gkDFxgJqHDGdfJ/ea-and-longtermism-not-a-crux-for-saving-the-world | EA and Longtermism: not a crux for saving the world - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MDkYSuCzFbEgGgtAd/ai-doom-and-david-hume-a-defence-of-empiricism-in-ai-safety | AI Doom and David Hume: A Defence of Empiricism in AI Safety - EA Forum\n",
      "https://www.lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://www.lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/EPhDMkovGquHtFq3h/an-experiment-eliciting-relative-estimates-for-open | An experiment eliciting relative estimates for Open Philanthropy‚Äôs 2018 AI safety grants\n",
      "https://www.lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://forum.effectivealtruism.org/posts/yMptv5msFnnfESCqm/how-i-solved-my-problems-with-low-energy-or-burnout | How I solved my problems with low energy (or: burnout)\n",
      "https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://www.lesswrong.com/posts/ydeaHqDPJ5REJWvat/a-one-question-turing-test-for-gpt-3&sa=D&source=docs&ust=1682467697191709&usg=AOvVaw0LPkn3Xf3wpX5jicctHQBL | Blocked by Cold Turkey\n",
      "https://forum.effectivealtruism.org/posts/6Mi2LqLRjSkQNdLbH/orthogonal-a-new-agent-foundations-alignment-organization | Orthogonal: A new agent foundations alignment organization - EA Forum\n",
      "https://www.lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://www.lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://www.lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results | \"Existential risk from AI\" survey results\n",
      "https://www.lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://forum.effectivealtruism.org/posts/4p8RpK2fYKFmEcA9w/optic-forecasting-comp-pilot-postmortem | OPTIC [Forecasting Comp] ‚Äî Pilot Postmortem - EA Forum\n",
      "https://www.lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://forum.effectivealtruism.org/posts/7CdtdieiijWXWhiZB/what-s-going-on-with-crunch-time | What‚Äôs going on with ‚Äòcrunch time‚Äô? - EA Forum\n",
      "https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023 | The Learning-Theoretic Agenda: Status 2023 - LessWrong\n",
      "https://www.lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/DW4FyzRTfBfNDWm6J/some-cruxes-on-impactful-alternatives-to-ai-policy-work | Some cruxes on impactful alternatives to AI policy work - EA Forum\n",
      "https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n"
     ]
    }
   ],
   "source": [
    "ea_fo_tabs = sorted([t for t in tabs if ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower())])\n",
    "print_tabs(ea_fo_tabs, label='EAFo/LW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffa8f80-4aa6-4afe-8c6a-59194d69895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(ea_fo_tabs, page=1, per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ae2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metaculus etc. ## (27 tabs)\n",
      "\n",
      "https://manifold.markets/leagues | Manifold Markets\n",
      "https://twitter.com/metaculus/status/1659603759377399809 | https://twitter.com/metaculus/status/1659603759377399809\n",
      "https://www.metaculus.com/questions/16592/open-source-gpt-4-before-2027/ | Open Source GPT 4 before 2027?  Metaculus\n",
      "https://www.metaculus.com/questions/11919/ua-strikes-ru-proper-wus-rockets-by-723/ | Ukraine Hits Russia w/US Rocket  Metaculus\n",
      "https://www.metaculus.com/questions/7216/ai-sputnik-moment-by-2050/ | AI Sputnik moment by 2050  Metaculus\n",
      "https://www.metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://twitter.com/iabvek/status/1654992086457012224 | iabvek on Twitter: \"@peterwildeford @JgaltTweets @metaculus lets book it, also interested in betting more than $400 at these odds if you or others are interested\" / Twitter\n",
      "https://www.metaculus.com/questions/16014/ai-unauthorized-access-before-2033/ | AI Unauthorized Access Before 2033?  Metaculus\n",
      "https://manifold.markets/group/ce-2023-top-ideas | https://manifold.markets/group/ce-2023-top-ideas\n",
      "https://www.metaculus.com/questions/12326/student-debt-cancellation-blocked-by-2024/ | Student debt cancellation blocked by 2024?  Metaculus\n",
      "https://www.metaculus.com/questions/17241/alberta-election-2023-winner/ | Alberta election 2023 winner  Metaculus\n",
      "https://www.metaculus.com/questions/14337/geopolitical-risk-index-for-2023/ | https://www.metaculus.com/questions/14337/geopolitical-risk-index-for-2023/\n",
      "https://twitter.com/AIBetsPredictit/status/1659013011963518978 | https://twitter.com/AIBetsPredictit/status/1659013011963518978\n",
      "https://www.metaculus.com/questions/17114/limjaroenrat-confirmed-as-prime-minister/ | Limjaroenrat confirmed as Prime Minister?  Metaculus\n",
      "https://twitter.com/JgaltTweets/status/1662814788580175872 | JgaltTweets on Twitter: \"In late March 2022, before PaLM and DALL-E 2 in April and Gato in May, the median on Metaculus for a 'weakly general' AI was 2043, 21 years away. By the start of June it was 2030. Now it's May 2026, three years from now. https://t.co/276E2LZK12\" / Twitter\n",
      "https://www.metaculus.com/questions/9062/time-from-weak-agi-to-superintelligence/ | Time From (weak) AGI to Superintelligence  Metaculus\n",
      "https://www.metaculus.com/questions/16726/human-level-intelligence-before-2030/ | Human-level intelligence before 2030?  Metaculus\n",
      "https://www.metaculus.com/questions/17090/russia-damages-patriot-air-defense-system/ | Russia damages Patriot air defense system?  Metaculus\n",
      "https://quorumapp.com/?sid=91&question=2979 | Quorum\n",
      "https://www.metaculus.com/notebooks/17050/ai-pathways-report/ | AI Pathways Report  Metaculus\n",
      "https://manifold.markets/DanMan314/will-gpt5-be-at-least-a-tiny-bit-st | Will GPT-5 be at least a tiny bit strategic at the \"Numbers Game\"?  Manifold Markets\n",
      "https://www.metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://www.metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://manifold.markets/BionicD0LPH1N/how-many-state-of-ai-report-2021-pr-d02d0781fc90 | How many State of AI Report 2022 predictions will be judged true by their authors in the 2023 report?  Manifold Markets\n",
      "https://www.metaculus.com/questions/1394/will-ai-progress-surprise-us/ | Will AI progress surprise Metaculus  Metaculus\n",
      "https://manifold.markets/JamesDillard/will-ai-wipe-out-humanity-before-th#ykO1FXmONiOxj5ZnPJoB | Will AI wipe out humanity before the year 2100  Manifold Markets\n",
      "https://www.metaculus.com/notebooks/16616/the-global-push-to-return-to-the-moon-predicting-the-lunar-landings-and-trends-of-the-2020s/ | The Global Push to Return to the Moon: Predicting the Lunar Landings and Trends of the 2020s\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('metaculus' in t.lower() or 'manifold' in t.lower() or 'quorum' in t.lower() or 'predictit' in t.lower())]), label='Metaculus etc.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72bdaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Wikipedia ## (3 tabs)\n",
      "\n",
      "https://www.wikiwand.com/en/Hygge | Hygge - Wikiwand\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://www.wikiwand.com/en/Russo-Ukrainian_War | Russo-Ukrainian War - Wikiwand\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('wikipedia' in t.lower() or 'wikiwand' in t.lower())]), label='Wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reddit ## (7 tabs)\n",
      "\n",
      "https://www.reddit.com/r/BDSMerotica/comments/58p3w8/slave_emporium_pet_training/ | (4) Slave Emporium: Pet Training : BDSMerotica\n",
      "https://twitter.com/ModeledBehavior/status/1645444418848129025 | Adam Ozimek on Twitter: \"Read the reddit thread on Ozempic improving people's impulse control broadly https://t.co/spB8QDDLQl And here is a review of evidence in favor https://t.co/h6iWgKl56b Now consider: what are the downstream implications of a society with greater impulse control?\" / Twitter\n",
      "https://www.reddit.com/r/BDSMerotica/comments/57u41y/the_slave_emporium_check_comments_for_a_surprise/ | Reddit - Dive into anything\n",
      "https://www.reddit.com/r/BDSMcommunity/ | https://www.reddit.com/r/BDSMcommunity/\n",
      "https://www.reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://www.reddit.com/user/slavegirl123/ | (4) Reddit - Dive into anything\n",
      "https://www.reddit.com/r/BDSMerotica/comments/zbl0s0/the_new_york_academy_for_the_education_of_women/ | (4) The New York Academy for the Education of Women - Ch. 1 (slavery, non-consensual) TW: noncon : BDSMerotica\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'reddit' in t.lower()]), label='Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedf293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## localhost ## (2 tabs)\n",
      "\n",
      "https://guarded-everglades-89687.herokuapp.com/?aggregator=-Custom | Upcoming Links\n",
      "http://localhost:8890/lab/tree/(4B)%20XRisk%20Model.ipynb | (4B) XRisk M‚Ä¶ - JupyterLab\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()]), label='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677f610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Chores ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instacart' in t.lower()]), label='Chores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fce865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Amazon ## (1 tabs)\n",
      "\n",
      "https://www.amazon.com/Fifty-Shades-Grey-Dakota-Johnson/dp/B00TJYYKD6?crid=14T5J5DN5APHC&keywords=fifty%2Bshades%2Bof%2Bgrey&sprefix=147&ref_=sr_1_2&workflowType=Commerce-TVOD&qid=1682303978&sr=8-2 | Amazon.com: Fifty Shades of Grey : Dakota Johnson, Jamie Dornan, Jennifer Ehle, Eloise Mumford, Victor Rasuk, Luke Grimes, Marcia Gay Harden, Kelly Marcel, Sam Taylor-Johnson, Michael De Luca, E L James, Dana Brunetti: Prime Video\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'amazon.com' in t.lower()]), label='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d46af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Morning Dispatch ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'morning' in t.lower() and 'dispatch' in t.lower()]), label='Morning Dispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "108d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GitHub ## (6 tabs)\n",
      "\n",
      "https://github.com/heroku/homebrew-brew/issues/23 | No native support for heroku-node on MacBook M1 ¬∑ Issue #23 ¬∑ heroku/homebrew-brew\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://github.com/laurakduffy/risk_ambiguity_model/blob/main/econ_models.ipynb | risk_ambiguity_model/econ_models.ipynb at main ¬∑ laurakduffy/risk_ambiguity_model\n",
      "https://github.com/microsoft/guidance | microsoft/guidance: A guidance language for controlling large language models.\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'github.com' in t.lower()]), label='GitHub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d911bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube ## (9 tabs)\n",
      "\n",
      "https://www.youtube.com/watch?v=yHnwk2sATdI | Ep 4 - When will AGI arrive? - Ryan Kupyn (Data Scientist & Forecasting Researcher @ Amazon AWS) - YouTube\n",
      "https://www.youtube.com/watch?v=MoN9ql6Yymw&list=RDtsmPCi7NKrg&index=4 | David Kushner - Daylight (Official Music Video) - YouTube\n",
      "https://www.youtube.com/watch?v=NPstXhM0gUI | DALS S04 - Une rumba avec Aliz√©e et Gr√©goire Lyonnet sur ''Pas toi'' (Tal) - YouTube\n",
      "https://www.youtube.com/watch?app=desktop&v=NXNCu6ekccw | Maud et Nicolas 2017 Comp√©tition Rock Avanc√© - YouTube\n",
      "https://www.youtube.com/watch?app=desktop&v=2SQOXbh-2vU | DALS S04 - Un jive avec Aliz√©e et Gr√©goire Lyonnet sur ''Crazy in love'' (Beyonc√©) - YouTube\n",
      "https://www.youtube.com/watch?v=axRgsdL6NO0 | DALS S04 - Un charleston avec Aliz√©e et Gr√©goire Lyonnet sur ''Bang Bang'' (Will I Am) - YouTube\n",
      "https://www.youtube.com/watch?v=FjMqY8hHK7Y | Artificial Intelligence Career Stories  EA Student Summit 2020 - YouTube\n",
      "https://www.youtube.com/watch?v=glVWseHBtaw | https://www.youtube.com/watch?v=glVWseHBtaw\n",
      "https://www.youtube.com/watch?v=6An7bj2Kmc0 | DALS S04 - Une rumba avec Aliz√©e, Gr√©goire Lyonnet et Candice sur ''Une femme avec une femme'' - YouTube\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'yout' in t.lower()]), label='YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2649c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instagram ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instagram.com' in t.lower()]), label='Instagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab0e02f2-e275-486f-98d3-37d3218dc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asana ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'app.asana.com' in t.lower()]), label='Asana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc70c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Other ## (179 tabs)\n",
      "\n",
      "https://siderea.dreamwidth.org/1237182.html | siderea  [psych/anthro/soc, Patreon] Class (American)\n",
      "https://www.cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://80000hours.org/podcast/episodes/elie-hassenfeld-givewell-critiques-and-lessons/ | Elie Hassenfeld on two big picture critiques of GiveWell's approach, and six lessons from their recent work - 80,000 Hours\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://www.americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/tcCxPLBrEXdxN5HCQ | Shah and Yudkowsky on alignment failures\n",
      "https://80000hours.org/2023/05/how-80000-hours-has-changed-some-of-our-advice-after-the-collapse-of-ftx/ | How 80,000 Hours has changed some of our advice after the collapse of FTX - 80,000 Hours\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/cCrpbZ4qTCEYXbzje | Ngo and Yudkowsky on scientific reasoning and pivotal acts\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/sCCdCLPN9E3YvdZhj | Shulman and Yudkowsky on AI progress\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/?source=email&uni_id=0&utm_source=80%2C000+Hours+mailing+list&utm_campaign=ea94351288-EMAIL_CAMPAIGN_2023_05_11_05_03&utm_medium=email&utm_term=0_43bc1ae55c-4e772af3ad-%5BLIST_EMAIL_ID%5D | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://www.governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://www.nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://www.nbcnews.com/meet-the-press/meetthepressblog/biden-launches-first-tv-ad-re-election-campaign-rcna81512 | Biden launches first TV ad of re-election campaign\n",
      "https://www.alignmentforum.org/s/FN5Gj4JM6Xr7F4vts/p/3DFBbPFZyscrAiTKS | My Overview of the AI Alignment Landscape: Threat Models\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://www.alignmentforum.org/posts/GQat3Nrd9CStHyGaq/response-to-katja-grace-s-ai-x-risk-counterarguments | Response to Katja Grace's AI x-risk counterarguments\n",
      "https://superuser.com/questions/1647798/what-is-the-correct-homebrew-installation-command-for-an-m1-mac-mini-and-big-sur | bash - What is the correct Homebrew Installation command for an M1 Mac mini and Big Sur? - Super User\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://every.to/no-small-plans/a-founder-s-guide-to-expanding-your-comfort-zone | When You Plateau, So Does Your Company - No Small Plans - Every\n",
      "https://www.bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware | Chatting Our Way Into Creating a Polymorphic Malware\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/7MCqRnZzvszsxgtJi | Christiano, Cotra, and Yudkowsky on AI progress\n",
      "https://micahflee.com/2023/04/capturing-the-flag-with-gpt-4/?utm_source=substack&utm_medium=email | Capturing the Flag with GPT-4\n",
      "https://clarifyingconsequences.substack.com/p/half-baked-ideas-defining-and-measuring | Change my mind: we should define and measure the effectiveness of advanced AI\n",
      "https://companiesmarketcap.com/most-profitable-companies/ | Companies ranked by earnings - CompaniesMarketCap.com\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI‚Äôs Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://www.cold-takes.com/what-ai-companies-can-do-today-to-help-with-the-most-important-century/ | What AI companies can do today to help with the most important century\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://nostalgebraist.tumblr.com/post/705192637617127424/gpt-4-prediction-it-wont-be-very-useful | trees are harlequins, words are harlequins ‚Äî gpt-4 prediction: it won't be very useful\n",
      "https://www.new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://grandcanyon.com/planning/grand-canyon-vacation-planning-your-biggest-challenge/ | Grand Canyon Vacation Planning: Your Biggest Challenge\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://catalist.us/whathappened2022/ | What Happened in 2022  Catalist\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | Carer - playlist by caroleslie  Spotify\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://arxiv.org/ftp/arxiv/papers/2206/2206.09360.pdf | 2206.09360.pdf\n",
      "https://fas.org/publication/strengthening-policy-by-bringing-evidence-to-life/ | Strengthening Policy by Bringing Evidence to Life - Federation of American Scientists\n",
      "https://noahpinion.substack.com/p/2023-is-when-the-empires-strike-back | 2023 is when the empires strike back - by Noah Smith\n",
      "https://theinsideview.ai/roblong | https://theinsideview.ai/roblong\n",
      "https://queue.acm.org/detail.cfm?id=3595878 | DevEx: What Actually Drives Productivity - ACM Queue\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8o | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk ‚Äì musings and rough drafts\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://arxiv.org/abs/2210.00720 | [2210.00720] Complexity-Based Prompting for Multi-Step Reasoning\n",
      "https://blog.beeminder.com/pomopoker/ | Pomodoro Poker  Beeminder Blog\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds ‚Äì The sideways view\n",
      "https://medium.com/@miles_24227/scoring-humanitys-progress-on-ai-governance-5a5131cb84c7 | Scoring Humanity‚Äôs Progress on AI Governance  by Miles B  May, 2023  Medium\n",
      "https://www.whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://ealifestyles.substack.com/p/i-dont-want-to-talk-about-ai?sd=pf | I don't want to talk about ai - EA Lifestyles\n",
      "https://www.slowboring.com/p/doing-the-math-on-deficit-reduction | Doing the math on deficit reduction - by Matthew Yglesias\n",
      "https://www.onemedical.com/blog/healthy-living/6-common-allergy-myths-you-should-stop-believing/?utm_source=eloqua&utm_medium=email&utm_campaign=2023_Q2_PAGM_US_Apr27_OMInsider | 6 Common Allergy Myths You Should Stop Believing  One Medical\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://aiobjectives.org/ | https://aiobjectives.org/\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI ‚Äì AI Impacts\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://gwern.net/fiction/clippy | It Looks Like You‚Äôre Trying To Take Over The World\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://www.foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power‚Äôs Staying Power\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://arxiv.org/pdf/2202.09292.pdf | 2202.09292.pdf\n",
      "https://www.ft.com/content/5e38eec5-8caa-41d1-b4fd-b0ac5e8ca58a | Washington isn‚Äôt listening to business on China any more  Financial Times\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://archive.is/R6V7V | Henry Kissinger explains how to avoid world war three\n",
      "https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf | FLI_Policymaking_In_The_Pause.pdf\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/gf9hhmSvpZfyfS34B | Ngo's view on alignment difficulty\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://acesounderglass.com/2023/05/13/lessons-learned-from-offering-in-office-nutritional-testing/ | Lessons learned from offering in-office nutritional testing ‚Äì Aceso Under Glass\n",
      "https://mattbruenig.com/2023/03/05/equality-and-equity/ | Equality and Equity ‚Äì Matt Bruenig Dot Com\n",
      "https://www.semianalysis.com/p/google-we-have-no-moat-and-neither | Google \"We Have No Moat, And Neither Does OpenAI\"\n",
      "https://stefanfschubert.com/blog/2023/4/30/how-it-feels-vs-what-it-does-across-domains | How it feels vs. what it does, across domains ‚Äî Stefan Schubert\n",
      "https://danluu.com/wat/ | Normalization of deviance\n",
      "https://www.slowboring.com/p/the-climate-lefts-plans-for-the-next | The climate left's plans for the next two years are bad\n",
      "https://thezvi.substack.com/p/to-predict-what-happens-ask-what | To Predict What Happens, Ask What Happens\n",
      "https://worksinprogress.co/ | https://worksinprogress.co/\n",
      "https://www.amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://www.nytimes.com/interactive/2023/04/21/science/parrots-video-chat-facetime.html | Can Parrots Talk Over Video Chat? Experiment Shows How They Adapt and Connect - The New York Times\n",
      "https://rethinkpriorities.pinpointhq.com/admin/talent-pipeline/registered-candidates | Talent Pipeline  Rethink Priorities Careers\n",
      "https://arxiv.org/pdf/2304.03442.pdf | Generative Agents: Interactive Simulacra of Human Behavior\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/vwLxd6hhFvPbvKmBH | https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/vwLxd6hhFvPbvKmBH\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://rychappell.substack.com/p/review-of-the-good-it-promises-the | Review of The Good It Promises, the Harm It Does\n",
      "https://rethinkpriorities.org/publications/spongy-moth-outbreaks | Drawing attention to invasive Lymantria dispar dispar spongy moth outbreaks as an important, neglected issue in wild animal welfare\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://www.sambowman.co/p/democracy-is-the-solution-to-vetocracy | Democracy is the solution to vetocracy - by Sam Bowman\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://fivethirtyeight.com/features/who-gave-up-more-in-the-debt-ceiling-negotiations-biden-or-republicans/ | Who Gave Up More In The Debt Ceiling Negotiations: Biden Or Republicans?  FiveThirtyEight\n",
      "https://www.cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://theinsideview.ai/david | https://theinsideview.ai/david\n",
      "https://www.bloomberg.com/news/articles/2023-05-02/alphabet-microsoft-other-firms-to-attend-white-house-meeting-on-ai-safeguards?leadSource=uverify%2520wall | Alphabet, Microsoft Among Tech Firms to Attend AI Meeting at White House - Bloomberg\n",
      "https://blog.beeminder.com/tocks/ | Tocks  Beeminder Blog\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://epochai.org/blog/power-laws-in-speedrunning-and-machine-learning | Power laws in Speedrunning and Machine Learning\n",
      "https://public.opendatasoft.com/explore/dataset/times-person-of-the-year/table/?sort=year | Time's Person of the Year, 1927-Present ‚Äî Opendatasoft\n",
      "https://www.samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won‚Äôt take it over by playing ‚Äú3-dimensional chess‚Äù. ‚Äì Windows On Theory\n",
      "https://mastodon.social/@danluu/109579156612202841 | https://mastodon.social/@danluu/109579156612202841\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? ¬∑ Gwern.net\n",
      "https://www.wsj.com/articles/microsoft-bets-that-fusion-power-is-closer-than-many-think-cb1b09dc?fbclid=IwAR38ZC0X15uAOn5ZMWC_WVO5tN6omCmbMHmRj9_zNMsBHbdcg2Eo4OgKaIs | Microsoft Bets That Fusion Power Is Closer Than Many Think - WSJ\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/hwxj4gieR7FWNwYfa | Ngo and Yudkowsky on AI capability gains\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://www.planned-obsolescence.org/is-it-time-for-a-pause/ | Is it time for a pause?\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/nPauymrHwpoNr6ipx | Conversation on technology forecasting and gradualism\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "## Shuffled all tabs ## (1046 tabs) | \n",
      "https://www.warner.senate.gov/public/index.cfm/pressreleases?ID=4DED779E-9804-4948-A031-BA4C7EE76C20 | Warner Calls on AI Companies to Prioritize Security and Prevent Malicious Misuse - Press Releases - Mark R. Warner\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://bdsmtrainingacademy.com/the-seduction-of-abduction-play/ | The Seduction of Abduction Play\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/fS7Zdj2e2xMqE6qja | More Christiano, Cotra, and Yudkowsky on AI progress\n",
      "https://theinsideview.ai/alex | https://theinsideview.ai/alex\n",
      "https://www.campaignforaisafety.org/ | Campaign for AI Safety\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.maximumprogress.org/extropia-archaeology | Extropian Archaeology ‚Äî Maximum Progress\n",
      "https://arxiv.org/abs/2305.20010 | Human or Not? A Gamified Approach to the Turing Test\n",
      "https://soundcloud.com/dnonkong/blue | Stream Blue by Duncan Thum  Listen online for free on SoundCloud\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 ‚Äì Rodney Brooks\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://www.safe.ai/statement-on-ai-risk | Statement on AI Risk  CAIS\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/oKYWbXioKaANATxKY | Soares, Tallinn, and Yudkowsky discuss AGI cognition\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech‚Ä¶  by Elizabeth Ayer  Medium\n",
      "https://medium.com/cto-as-a-service/5-things-founders-investors-and-recruiters-should-know-about-the-cto-role-a65d7bb66264 | 5 Things Founders, Investors and Recruiters Should Know about the CTO role  by Marc van Neerven  CTO-as-a-Service  Medium\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://theinsideview.ai/ethan2 | https://theinsideview.ai/ethan2\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://maximumprogress.substack.com/p/grading-extropian-predictions | Grading Extropian Predictions - by Maxwell Tabarrok\n",
      "https://www.scmp.com/tech/tech-war/article/3219623/chinese-leader-xi-jinping-urges-country-seize-opportunities-artificial-intelligence-modernise | Chinese leader Xi Jinping urges country to seize opportunities in artificial intelligence to modernise industry  South China Morning Post\n",
      "https://soundcloud.com/dnonkong/sets/restoration | Stream Duncan Thum  Listen to Restoration playlist online for free on SoundCloud\n",
      "https://jobs.ashbyhq.com/openphilanthropy/e3a4e593-f8cd-4ae3-ab51-4f710222b9cc | Research Analyst / Junior Research Analyst - Biosecurity & Pandemic Preparedness @ Open Philanthropy\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer\n",
      "https://www.bbc.com/worklife/article/20201026-why-healthy-neurotics-can-thrive-in-stressful-times | Why ‚Äòhealthy neurotics‚Äô can thrive in stressful times - BBC Worklife\n",
      "https://haggstrom.blogspot.com/2023/04/are-large-language-models-intelligent.html | H√§ggstr√∂m h√§vdar: Are large language models intelligent? Are humans?\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The ‚Äúpercentogram‚Äù‚Äîa histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "http://www.kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://jack-clark.net/2023/04/03/import-ai-323-ai-researcher-warns-about-ai-bloomberggpt-and-an-open-source-flamingo/ | Import AI 323: AI researcher warns about AI; BloombergGPT; and an open source Flamingo  Import AI\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://theinsideview.ai/irina | https://theinsideview.ai/irina\n",
      "https://www.drorpoleg.com/thinking-fast-and-slopes/ | Thinking Fast and Slopes\n",
      "https://blog.aiimpacts.org/p/a-tai-which-kills-all-humans-might | A TAI which kills all humans might also doom itself\n",
      "https://www.alignmentforum.org/posts/qYzqDtoQaZ3eDDyxa/distinguishing-ai-takeover-scenarios | Distinguishing AI takeover scenarios\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans‚Äô Rights and Safety\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety ‚Äì Windows On Theory\n",
      "https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://cdixon.org/2009/09/19/climbing-the-wrong-hill | cdixon  Climbing the wrong hill\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://www.mynectar.com/ | Allergy Treatment & Alternative to Allergy Shots  Nectar\n",
      "https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance | How your data is used to improve model performance  OpenAI Help Center\n",
      "https://www.legalpriorities.org/blog/2023/lpp-annual-report-2022/ | Annual report 2022 ‚Äì Legal Priorities Project ‚Äì Legal Priorities Blog\n",
      "https://time.com/6283609/artificial-intelligence-race-existential-threat/ | Moving Too Fast on AI Could Be Terrible for Humanity  Time\n",
      "https://arxiv.org/abs/2305.16960 | Training Socially Aligned Language Models in Simulated Human Society\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/NbGmfxbaABPsspib7 | Christiano and Yudkowsky on AI predictions and human intelligence\n",
      "https://www.brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST‚Äôs AI Risk Management Framework plants a flag in the AI debate\n",
      "https://direct-approach-feedback.web.app/blog/direct-approach-interactive-model | Direct Approach Interactive Model\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n"
     ]
    }
   ],
   "source": [
    "tabs_ = [t for t in tabs if (not ('google.com' in t.lower() and 'search' in t.lower() and not ('docs.google' in t.lower() or 'sheets.google' in t.lower())) and\n",
    "                             not ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower()) and\n",
    "                             not 'facebook.com' in t.lower() and\n",
    "                             not 'twitter.com' in t.lower() and\n",
    "                             not ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower()) and\n",
    "                             not ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower() or 'quorum' in t.lower()) and\n",
    "                             not ('wikipedia' in t.lower() or 'wikiwand' in t.lower()) and\n",
    "                             not 'reddit' in t.lower() and\n",
    "                             not 'instagram.com' in t.lower() and\n",
    "                             not ('guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()) and\n",
    "                             not 'instacart' in t.lower() and\n",
    "                             not ('morning' in t.lower() and 'dispatch' in t.lower()) and\n",
    "                             not 'amazon.com' in t.lower() and\n",
    "                             not 'github' in t.lower() and\n",
    "                             not 'calendar.google' in t.lower() and\n",
    "                             not 'yout' in t.lower() and\n",
    "                             not 'app.asana.com' in t.lower() and\n",
    "                             not ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower()))]\n",
    "tabs_ = sorted(tabs_)\n",
    "print_tabs(tabs_, label='Other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a2a7bb-86f9-45bd-b8d6-ed8889caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(tabs_, page=1, per_page=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c128ee3-03e2-4cfb-bfd1-0dfc84775af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shuffled all tabs ## (725 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1uDG6vIINHYu29M6m8md3JiN38TBZ45rvU7VSP5dQr_A/edit#heading=h.pdhqhnskdwfb | [Draft] A defense of high-probability doom predictions\n",
      "https://forum.effectivealtruism.org/posts/dpjCwMwKEPqK3TPnC/notes-on-managing-to-change-the-world | Notes on \"Managing to Change the World\" - EA Forum\n",
      "https://docs.google.com/document/d/1LNyJApFsLrxVe9Z_LuiOIge-K0rTab2o0Bhtb3Vn-fY/edit#heading=h.zee6ngwoj6jg | RP <> Chatham House May 17, 2023 - Google Docs\n",
      "https://twitter.com/Jess_Riedel/status/1663592047700496385 | Jess Riedel on Twitter: \"\"Whether you have heard of the Extropians or not, they have influenced you...This is an annotated tour through the primary sources\" https://t.co/YGBNCO0Pzv https://t.co/CgIJtakNiK\" / Twitter\n",
      "https://docs.google.com/document/d/1YlgCHFINkfIFJ3vWaUgGC3Gv3ZmbTfj6l0PL-CTQ_TA/edit#heading=h.52ldutosr4la | Analysis - EAA Survey Results - Google Docs\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://www.youtube.com/watch?app=desktop&v=2SQOXbh-2vU | DALS S04 - Un jive avec Aliz√©e et Gr√©goire Lyonnet sur ''Crazy in love'' (Beyonc√©) - YouTube\n",
      "https://docs.google.com/document/d/1QpW-WvW9zzSwWvg3GvzF5BMbGRm5uv_kU9pebIApZI8/edit# | XST Fundraising Emails 2023 - Google Docs\n",
      "https://www.facebook.com/linchuan.zhang/posts/pfbid02rdPWaumb5VkptCiz7yG8tgjPqco4PvQ26d48uy9HpQevS7SeQictVrM9oB8Thwqhl | Linchuan Zhang - https://scholars-stage.org/yale-and-the-education-...  Facebook\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://www.metaculus.com/questions/1394/will-ai-progress-surprise-us/ | Will AI progress surprise Metaculus  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/T7PC22Yc9heFL5Ay4/iqisa-a-library-for-handling-forecasting-datasets | Iqisa: A Library For Handling Forecasting Datasets - EA Forum\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/14T_RBzlfBTn4IOdxqG0fh6ilmGOxqGWtyKQZPEiHbqc/edit#heading=h.e6lo2rv2yae9 | XSOC - Google Docs\n",
      "https://docs.google.com/document/d/1LyQKNesRensq3BjLWgzcdJ3wJBjl0n98fAQ7g7HRbYk/edit#heading=h.koq63kgkerx2 | Prioritarianism and Resource Allocation - Google Docs\n",
      "https://twitter.com/AISafetyMemes/status/1664981210076938241 | AI Notkilleveryoneism Memes on Twitter: \"Guys, there‚Äôs finally an AI x-risk documentary, and it‚Äôs a *masterpiece* THIS is the video to send to curious friends. Let‚Äôs blow this thing up. Don't Look Up - The Documentary: The Case For AI as an Existential Threat https://t.co/tjKTgeP5KD\" / Twitter\n",
      "https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023 | The Learning-Theoretic Agenda: Status 2023 - LessWrong\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/tcCxPLBrEXdxN5HCQ | Shah and Yudkowsky on alignment failures\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://twitter.com/yayalexisgay/status/1658491983256494083 | Alexis Gay on Twitter: \"brought to you by @async_com... when the meeting could have been a voice note https://t.co/UdSozMB0gl\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1660583080015347712 | https://twitter.com/Simeon_Cps/status/1660583080015347712\n",
      "https://rethinkpriorities.pinpointhq.com/admin/talent-pipeline/registered-candidates | Talent Pipeline  Rethink Priorities Careers\n",
      "https://twitter.com/StephenLCasper/status/1660718320348176385 | Stephen Casper on Twitter: \"üßµWe have a new example of how fast the AI proliferation pipeline is. Less than 6 months after ChatGPT was announced, BLOOMChat is an open-source 176B parameter copycat that achieved a win-rate of 45.25% against GPT-4 in a human preference study. https://t.co/SVj1R5x75j\" / Twitter\n",
      "https://theinsideview.ai/david | https://theinsideview.ai/david\n",
      "https://twitter.com/NathanpmYoung/status/1659822241465393152 | https://twitter.com/NathanpmYoung/status/1659822241465393152\n",
      "https://twitter.com/arnavg_/status/1662189000667590656 | Arnav Gudibande on Twitter: \"A recent trend is to fine-tune open-source LMs on ChatGPT outputs (e.g., Alpaca, Self-Instruct, Vicuna), with the aim of broadly imitating the model. In our new paper, we critically analyze this approach. https://t.co/nyOWEdGnvV üëá[1/N] https://t.co/dQ7l78kQzt\" / Twitter\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/sCCdCLPN9E3YvdZhj | Shulman and Yudkowsky on AI progress\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://arxiv.org/abs/2305.20010 | Human or Not? A Gamified Approach to the Turing Test\n",
      "https://www.metaculus.com/questions/16592/open-source-gpt-4-before-2027/ | Open Source GPT 4 before 2027?  Metaculus\n",
      "https://twitter.com/MarkHertling/status/1664307395516825600 | MarkHertling on Twitter: \"When @bianca_nobilo pulls out her whiteboard, it‚Äôs a good idea to listen to get a 2 minute explainer. Put her and @katieporteroc together &amp; it would be magical.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/idjzaqfGguEAaC34j/if-your-agi-x-risk-estimates-are-low-what-scenarios-make-up | If your AGI x-risk estimates are low, what scenarios make up the bulk of your expectations for an OK outcome? - EA Forum\n",
      "https://twitter.com/JeffLadish/status/1653247793061044226 | (1) Jeffrey Ladish on Twitter: \"Hugging Chat, a ChatGPT-clone based on a LLaMA-based model, was just launched. I've been using it and while it's a little rough around the edges, it feels similar to ChatGPT in terms of capabilities Only 5 months passed between the launch of ChatGPT and HuggingChat\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://arxiv.org/abs/2305.16960 | Training Socially Aligned Language Models in Simulated Human Society\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://mattbruenig.com/2023/03/05/equality-and-equity/ | Equality and Equity ‚Äì Matt Bruenig Dot Com\n",
      "https://www.warner.senate.gov/public/index.cfm/pressreleases?ID=4DED779E-9804-4948-A031-BA4C7EE76C20 | Warner Calls on AI Companies to Prioritize Security and Prevent Malicious Misuse - Press Releases - Mark R. Warner\n",
      "https://docs.google.com/document/d/12A4_adulGL1NPE7Xd08hUfe3spLFKfcRwXyD28FRt5o/edit | RP Copy of How I think about TAI deployment scenario analysis - Google Docs\n",
      "https://twitter.com/ESYudkowsky/status/1658616828741160960 | Eliezer Yudkowsky on Twitter: \"Fools often misrepresent me as saying that superintelligence can do anything because magic. To clearly show this false, here's a concrete list of stuff I expect superintelligence can or can't do: - FTL (faster than light) travel: DEFINITE NO - Find some hack for going &gt;50 OOM‚Ä¶\" / Twitter\n",
      "https://www.lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI ‚Äì AI Impacts\n",
      "https://docs.google.com/document/d/18aOKioNfnAfYgEX439P2Cq9Ocv_C1I6Jkjxkgowslus/edit#heading=h.6ytgvt3dfnpe | 2023: May - RP Performance Evaluation for Ben Snodin - Self Eval - Google Docs\n",
      "https://twitter.com/JasonGMatheny/status/1662075820523896832 | Jason Matheny on Twitter: \"Thank you to the philanthropic supporters who've helped us reach this milestone. Your gifts are fueling @RANDCorporation research on the biggest problems facing humanity: tech governance, climate change, countering autocracy, reducing inequity, and more. https://t.co/Jo48dZPaiX\" / Twitter\n",
      "https://www.youtube.com/watch?v=6An7bj2Kmc0 | DALS S04 - Une rumba avec Aliz√©e, Gr√©goire Lyonnet et Candice sur ''Une femme avec une femme'' - YouTube\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://twitter.com/JeffLadish/status/1654319722668883970 | https://twitter.com/JeffLadish/status/1654319722668883970\n",
      "https://soundcloud.com/dnonkong/sets/restoration | Stream Duncan Thum  Listen to Restoration playlist online for free on SoundCloud\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://docs.google.com/document/d/1vRHTl_fYJa7a-3SK2MxYw215eZ9bH5DgkzAvAYMaoLU/edit#heading=h.xc4zt432pfyz | Corporate / Lab Governance Team - 1-Pager - Google Docs\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://twitter.com/poe_platform/status/1657425066899177472 | (1) Poe on Twitter: \"100k context windows now available on Poe: we are excited to start a beta test for Claude-instant-100k! This bot is currently available to all Poe subscribers, initially on web only. It can understand message history as long as a 200 page book. Examples in thread below. https://t.co/9QjjwjWas8\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MDkYSuCzFbEgGgtAd/ai-doom-and-david-hume-a-defence-of-empiricism-in-ai-safety | AI Doom and David Hume: A Defence of Empiricism in AI Safety - EA Forum\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://docs.google.com/document/d/1zOXtV5cwXiDllJQmzSFzeADz3c8jPrCBiN8Nb75nlyM/edit#heading=h.yts3d84e5c30 | Project Hub: Defense in Depth (EAG London) - Google Docs\n",
      "https://docs.google.com/document/d/1Hq5IoWUwfxSC_xLJ4EFHmL8ZnFmMm1GVMvgTft7S7Q8/edit#heading=h.nr49y8jkbne5 | Ben‚Äôs rough thoughts on GLT part of 2023 LT department retreat - Google Docs\n",
      "https://www.lesswrong.com/posts/FG6icLPKizEaWHex5/announcing-apollo-research#comments | Announcing Apollo Research - LessWrong\n",
      "https://manifold.markets/DanMan314/will-gpt5-be-at-least-a-tiny-bit-st | Will GPT-5 be at least a tiny bit strategic at the \"Numbers Game\"?  Manifold Markets\n",
      "https://twitter.com/OrionJohnston/status/1659515115392364545 | David Johnston on Twitter: \"@peterwildeford I've been leaning into the vagueness and unspecifiability lately with \"the probability that an ideal (but physically plausible) reasoner would assign\" I'm never actually going to resolve it either way, and this version avoids the temptation to replicate popular biases\" / Twitter\n",
      "https://sohl-dickstein.github.io/2023/03/09/coherence.html | The hot mess theory of AI misalignment: More intelligent agents behave less coherently  Jascha‚Äôs blog\n",
      "https://docs.google.com/document/d/1vomm7q1BERofa1w5kH9_vu_MuekikihkZlYkBYFmE24/edit#heading=h.vf1mp2zaq0zs | Notes on improving coordination in AI governance - Google Docs\n",
      "https://www.reddit.com/r/BDSMerotica/comments/zbl0s0/the_new_york_academy_for_the_education_of_women/ | (4) The New York Academy for the Education of Women - Ch. 1 (slavery, non-consensual) TW: noncon : BDSMerotica\n",
      "https://forum.effectivealtruism.org/posts/HuLCFBEbekZ6AE7LP/linkpost-survey-evidence-on-the-number-of-vegans-in-the-uk | Linkpost: Survey evidence on the number of vegans in the UK - EA Forum\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/to-predict-what-happens-ask-what | To Predict What Happens, Ask What Happens\n",
      "https://twitter.com/StanfordHAI/status/1662164342853206045 | Stanford HAI on Twitter: \"How might companies' use of AI change the way they pay their workers? A recent study from @stanford and @mit provides insights: https://t.co/78c20l0Vrq\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1656700154190389248 | Anthropic on Twitter: \"Introducing 100K Context Windows! We‚Äôve expanded Claude‚Äôs context window to 100,000 tokens of text, corresponding to around 75K words. Submit hundreds of pages of materials for Claude to digest and analyze. Conversations with Claude can go on for hours or days. https://t.co/4WLEp7ou7U\" / Twitter\n",
      "https://quorumapp.com/?sid=91&question=2979 | Quorum\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It\n",
      "https://docs.google.com/document/d/1OmKOmMfbmBnjxGGHetfN2VQ1az4Zox0Y-4f5xTlRzhw/edit#heading=h.g2xot74rmmug | Maybe let‚Äôs focus more on non-extinction ways that a lot of the potential value of the future could be lost? [quick notes]\n",
      "https://fas.org/publication/strengthening-policy-by-bringing-evidence-to-life/ | Strengthening Policy by Bringing Evidence to Life - Federation of American Scientists\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit#heading=h.mak2h8fgpqe9 | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://twitter.com/MatthewJBar/status/1657596044186906624 | (1) Matthew Barnett on Twitter: \"There are many predictions you can make that will be misinterpreted as trending wrong even if you end up being right. So, to the extent you want prestige from forecasting, you should optimize both for being right and for saying things that people will think are trending right.\" / Twitter\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Sleepwalking into Survival\n",
      "https://docs.google.com/document/d/1QFTYRSJPyQoKfO_bFrsxG861xebXbX3XzvBEEaT7Z1U/edit#heading=h.mj6mty720ju | [V.3] What is going to matter if an AI crash project emerges?\n",
      "https://docs.google.com/document/d/1WEl6K9qmd9_6kuVw6UyRroFsxXbfFIYd_hTpZbrZlZs/edit# | Pivotal act: Definition, examples, & reading list\n",
      "http://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://docs.google.com/document/d/1ZQBY3Cutw1gX-GLZvMVpLa_aLkNtwLCATifABNWxUw4/edit#heading=h.3a213phaz2nq | Conversation notes template: [non-RP full name] <> [RP full name] - YYYY-MM-DD - [topics] - Google Docs\n",
      "https://twitter.com/sebkrier/status/1654079782177341443 | S√©b Krier on Twitter: \"White House announces an independent commitment from leading AI labs like Anthropic, Google, Hugging Face, Microsoft, NVIDIA, OpenAI, and Stability AI, to participate in a public evaluation of AI systems on an evaluation platform developed by Scale AI. https://t.co/6JjDrLFRlb\" / Twitter\n",
      "https://docs.google.com/document/d/14ApHvL04itCT2eK6vipKUuG7pXqu0wysyaQ1ERZKUM4/edit#heading=h.1jko4iyren03 | Thinking about AIGS org - Google Docs\n",
      "https://docs.google.com/document/d/11OQkFGkKmIKs3L8q23-aMuPvNcQpX6HxxMvNSkJiP7o/edit | AIGS Compute Gov - Job Opening Kick Off Form - Google Docs\n",
      "https://www.youtube.com/watch?v=yHnwk2sATdI | Ep 4 - When will AGI arrive? - Ryan Kupyn (Data Scientist & Forecasting Researcher @ Amazon AWS) - YouTube\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://www.reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://twitter.com/dpaleka/status/1653052405133754368 | Daniel Paleka on Twitter: \"What happened last month in AI/ML safety research (1/8):\" / Twitter\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://twitter.com/davidad/status/1627454901247782913?s=46&t=Lap-izdY_pwXQfbJXZHE8g | https://twitter.com/davidad/status/1627454901247782913?s=46&t=Lap-izdY_pwXQfbJXZHE8g\n",
      "https://docs.google.com/presentation/d/1KW7ZkuCdXAC8FEfC6r3w15QQQTn4jUyjFSX24WzCte8/edit#slide=id.g232fae25e24_0_7 | 2023 AW Department OKRs - Google Slides\n",
      "https://twitter.com/emollick/status/1659310930952347651 | Ethan Mollick on Twitter: \"Me: ChatGPT with Code Interpreter, visualize a four dimensional shape in a way I can understand, use an animated GIF. Don't use a tesseract. AI: Sure, here is a 4D hypersphere, divided into 3D \"slices\" like an MRI of a body is 2D slices (Its neat explanation in next tweet 1/2) https://t.co/h0O6oltxT7\" / Twitter\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/NbGmfxbaABPsspib7 | Christiano and Yudkowsky on AI predictions and human intelligence\n",
      "https://docs.google.com/presentation/d/1iuYIHlHvsnvOUoRX__BCc5J2A0cSieJlENSAyT_uFg8/edit#slide=id.ge44d99aa4e_0_0 | Survey OKRs presentation - Google Slides\n",
      "https://www.lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://twitter.com/AmandaAskell/status/1660332621950517248 | https://twitter.com/AmandaAskell/status/1660332621950517248\n",
      "https://twitter.com/milesaturpin/status/1656010877269602304 | (7) Miles Turpin on Twitter: \"‚ö°Ô∏èNew paper!‚ö°Ô∏è It‚Äôs tempting to interpret chain-of-thought explanations as the LLM's process for solving a task. In this new work, we show that CoT explanations can systematically misrepresent the true reason for model predictions. https://t.co/ecPRDTin8h üßµ https://t.co/9zp5evMoaA\" / Twitter\n",
      "https://twitter.com/panickssery/status/1648004762774675476 | Arjun Panickssery is in London on Twitter: \"@peterwildeford Yeah I usually pause and think that if it has a 40% chance of happening then it's like I put down $40 and the other guy puts down $60, etc (40 times out of 100 I've got to win $60 to make up for the $40 I lose 60 times) Note it's (1-p)/p not the reverse if you're putting down $1\" / Twitter\n",
      "https://www.metaculus.com/questions/7216/ai-sputnik-moment-by-2050/ | AI Sputnik moment by 2050  Metaculus\n",
      "https://cdixon.org/2009/09/19/climbing-the-wrong-hill | cdixon  Climbing the wrong hill\n",
      "https://www.cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://docs.google.com/document/d/1v9Afif1o_thEamTTUm1BL0yiY1cqIvt0VNR3EIVMnjQ/edit# | [shared with LT] Proposal: Switch AIGS's primary branding to something new and distinct from RP [notes for AIGS Leads discussion] - Google Docs\n",
      "https://twitter.com/MDubrawski/status/1654477167869214721 | Micha≈Ç Dubrawski - Standing with üá∫üá¶ on Twitter: \"I thought that it might be worth adding a list of questions suggested for a forecast's post-mortem analysis to this old thread. This is based on @TLiptay initial three questions mentioned above. https://t.co/3MLPwcW7Vu\" / Twitter\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://www.metaculus.com/questions/17090/russia-damages-patriot-air-defense-system/ | Russia damages Patriot air defense system?  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‚ÄòDissolving‚Äô AI Risk ‚Äì Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ckokr9uhr2Cu3h5En/tips-for-people-considering-starting-new-incubators | Tips for people considering starting new incubators - EA Forum\n",
      "https://docs.google.com/document/d/1VYgp37pHoGX0rx5ze6p6I9RiWBx2oT4xKMtYq_TMCmg/edit | 5 Year Retrospective Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/14giRxnDwnCOMI_HTIHnbwU66XiX51XHYxO8aQfMUXc0/edit#heading=h.ilkan3e0drym | Jared Brown <> Michael Aird - 2023-Apr-13 - US AI policy, lobbying, Global Shield - Google Docs\n",
      "https://www.nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/fS7Zdj2e2xMqE6qja | More Christiano, Cotra, and Yudkowsky on AI progress\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://docs.google.com/document/d/1r0TPCpivFX3sHbcDdRc2ZC85tiocnFZyii2woVVacMs/edit#heading=h.c6m59byd7k3s | AI Reading Notes - Google Docs\n",
      "https://twitter.com/AndyMasley/status/1658875333242679297 | https://twitter.com/AndyMasley/status/1658875333242679297\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/hwxj4gieR7FWNwYfa | Ngo and Yudkowsky on AI capability gains\n",
      "https://twitter.com/messages/25776739-1133196129309356032 | Ben Hurford / Twitter\n",
      "https://twitter.com/emollick/status/1665219808693039105 | Ethan Mollick on Twitter: \"Thanks to the ability to share messages, you can create little \"apps\" with ChatGPT by giving it a prompt &amp; context. In this case, an article on the generation of pseudo-profound bullshit turns the AI into a really good pseudo-profound bullshit generator: https://t.co/JGKuiOMnjE https://t.co/htUzJA1oEQ\" / Twitter\n",
      "https://twitter.com/DrRadchenko/status/1656585919049129986 | Sergey Radchenko on Twitter: \"So to reflect a bit on Snyder's NYT oped: https://t.co/CZ2aCix1k0. The key argument is that nuclear powers have lost wars. The examples include US wars in Vietnam, Afghanistan, and Iraq, the Soviet war in Afghanistan, the French in Algeria and the collapse of the British Empire.\" / Twitter\n",
      "https://www.semianalysis.com/p/google-we-have-no-moat-and-neither | Google \"We Have No Moat, And Neither Does OpenAI\"\n",
      "https://www.google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get | How bad could a war get? - EA Forum\n",
      "https://mail.google.com/mail/u/1/#inbox/FMfcgzGsmWvfprTRZBTdxvRkgLQQHfMW | Status is red for USG & advanced AI - Rethink Priorities - peter@rethinkpriorities.org - Rethink Priorities Mail\n",
      "https://www.samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://www.metaculus.com/questions/17241/alberta-election-2023-winner/ | Alberta election 2023 winner  Metaculus\n",
      "https://mastodon.social/@danluu/109579156612202841 | https://mastodon.social/@danluu/109579156612202841\n",
      "https://jack-clark.net/2023/04/03/import-ai-323-ai-researcher-warns-about-ai-bloomberggpt-and-an-open-source-flamingo/ | Import AI 323: AI researcher warns about AI; BloombergGPT; and an open source Flamingo  Import AI\n",
      "https://twitter.com/gelliottmorris/status/1660037899994251266 | https://twitter.com/gelliottmorris/status/1660037899994251266\n",
      "https://www.lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://docs.google.com/document/d/1gyU2yGPUPEyHhj3kvvKSDh1-TFetU4q7p2wcV-KI6is/edit#heading=h.zee6ngwoj6jg | RP <> 80k May 18, 2023 - Google Docs\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://micahflee.com/2023/04/capturing-the-flag-with-gpt-4/?utm_source=substack&utm_medium=email | Capturing the Flag with GPT-4\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) https://t.co/pkFdPqgAzb\" / Twitter\n",
      "https://docs.google.com/document/d/1zOXtV5cwXiDllJQmzSFzeADz3c8jPrCBiN8Nb75nlyM/edit | Project Hub: Defense in Depth\n",
      "http://www.kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://www.brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST‚Äôs AI Risk Management Framework plants a flag in the AI debate\n",
      "https://docs.google.com/spreadsheets/d/1TKdLTOeDfBjXUoUAJdPh40Z13bmYf5hvuTUTJH0m41c/edit#gid=2031513321 | [confidential] Staff Overallocation - Google Sheets\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit#heading=h.y3b6zbr0v5zz | Proposal: Switch AIGS's primary branding to something new and distinct from RP [notes for AIGS Leads discussion] - Google Docs\n",
      "https://www.facebook.com/photo/?fbid=259678536582311&set=a.202281482322017 | Facebook\n",
      "https://arxiv.org/pdf/2202.09292.pdf | 2202.09292.pdf\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/8YXFaM9yHbhiJTPqp/agi-rising-why-we-are-in-a-new-era-of-acute-risk-and | AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now - EA Forum\n",
      "https://twitter.com/messages/25776739-1068417927903436800 | Brendan Finan / Twitter\n",
      "https://twitter.com/davidmanheim/status/1653323207582023687 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"New post on why people seem confused about why AI systems are safe or unsafe. Systems that cannot be unsafe cannot be safe. https://t.co/3JCcnH1E3Q\" / Twitter\n",
      "https://archive.is/R6V7V | Henry Kissinger explains how to avoid world war three\n",
      "https://docs.google.com/document/d/1kpdCPU2I0NLWPRwQ4qPSUZcZDobnyR9UY-iSOSBQRm4/edit#heading=h.natf23qmy2fx | Scaling laws literature review - Google Docs\n",
      "https://twitter.com/PLMattis/status/1655244796011638784 | Peter Mattis on Twitter: \"The article is mostly about @CSETGeorgetown but the issues are much bigger. We have companies marketing themselves on data that hurts Beijing. PRC has been cracking down on XUAR-related due diligence since 2018. Open sources clearly underpinned some USG actions, like Entity List.\" / Twitter\n",
      "https://www.google.com/search?q=norwegian+sovereign+wealth+fund&rlz=1CDGOYI_enUS715US715&oq=norwegian+sover&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDMzODFqMGo0qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | norwegian sovereign wealth fund - Google Search\n",
      "https://twitter.com/bridget_e_l | https://twitter.com/bridget_e_l\n",
      "https://twitter.com/xuanalogue/status/1652874311605137408 | xuan (…ï…•…õn / sh-yen) on Twitter: \"Bizarre to me that so many LLM benchmarks were using top-1 accuracy as a metric rather than the Brier score or similar -- apparently once you switch to the latter (and other continuous and/or linear metrics), many \"emergent\" behaviors go away!\" / Twitter\n",
      "https://www.metaculus.com/questions/16014/ai-unauthorized-access-before-2033/ | AI Unauthorized Access Before 2033?  Metaculus\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf | FLI_Policymaking_In_The_Pause.pdf\n",
      "https://twitter.com/arankomatsuzaki/status/1662991826431639553 | https://twitter.com/arankomatsuzaki/status/1662991826431639553\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://docs.google.com/document/d/1tMcC_b18ZDowxIhrSqsHfg4S2X02JF2ui3W4P62d6Lg/edit#heading=h.livlmiwiaubo | Report on Data Centers - TAIGA Version 2023-04-20 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1gke0Inp30cktPIGoQxKP0W_Qk5dwKVqua2gJ1pzbbk4/edit | RSVP Form: Rethink Priorities Brunch  Monday 22nd May (Responses) - Google Sheets\n",
      "https://www.google.com/search?q=cognitive+emulations+conjecture&rlz=1C5CHFA_enGB1058GB1058&oq=cognitive+emulations+conjecture&aqs=chrome..69i57j0i546l5j69i60.1717j0j1&sourceid=chrome&ie=UTF-8 | cognitive emulations conjecture - Google Search\n",
      "https://docs.google.com/document/d/16aEouFa8470SCYgTNEWEqhJQQw-daaMx4Q2LLf-8W5E/edit#heading=h.6ytgvt3dfnpe | Zoe Williams - May 2023 - RP Performance Evaluation Template - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference\n",
      "https://docs.google.com/document/d/1kX4RVoWGicYug0Dr0Rt5sLfobHbjMLABlcY-dsTOMqg/edit# | Cascading conditional probabilities show transformative AGI by 2043 is <1% likely\n",
      "https://docs.google.com/document/d/1gJImzAEBg7idY5FrwGisK6BYo2NLW1WYcGPrs1I2ESY/edit | AIGS rebranding working group - meeting notes - Google Docs\n",
      "https://twitter.com/iabvek/status/1654992086457012224 | iabvek on Twitter: \"@peterwildeford @JgaltTweets @metaculus lets book it, also interested in betting more than $400 at these odds if you or others are interested\" / Twitter\n",
      "https://theinsideview.ai/alex | https://theinsideview.ai/alex\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://docs.google.com/document/d/1AdeJ7p3emmpzL_TV6tF0Y6bmmKOXQOBZu0Z3noWlAaY/edit#heading=h.ldebapglg1l1 | May 2023 LT Retreat and Coworking Participants' Guide\n",
      "https://www.americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://docs.google.com/document/d/1b4Wck2eE8gDMsZQlDPWiUje3souy2dyfBHn7n4ZzmsY/edit | [For GovAI] Our top AI governance projects - Google Docs\n",
      "https://docs.google.com/document/d/1TaopVXaa79awP2RmWtAnyLulzw0e2f_1nyJtnON5kI8/edit#heading=h.nxinzza3nrt7 | [shared] Review and Future Plans: Condor Camp 2023 - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1652060385346834432 | https://twitter.com/JgaltTweets/status/1652060385346834432\n",
      "https://twitter.com/S_OhEigeartaigh/status/1659477159134601219 | Se√°n √ì h√âigeartaigh on Twitter: \"In-depth and well-written article in inews by Stuart Ritchie on reasons for concern about existential risk from AI. Really feels like these concerns are firmly entering the mainstream.\" / Twitter\n",
      "https://queue.acm.org/detail.cfm?id=3595878 | DevEx: What Actually Drives Productivity - ACM Queue\n",
      "https://www.bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://www.cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://docs.google.com/document/d/1uNF5687rCUBJucJGgT22QQkm0H_EzmIpzt2arWH-WOY/edit#heading=h.osty8jeclpyn | Forecasting China‚Äôs ability to indigenously produce AI chips\n",
      "https://docs.google.com/document/d/1wJCLEHAR34joF-cIGxAwCMQm8-D-mlP6LPBoMboFdHk/edit | A survey of concrete risks derived from Artificial Intelligence - Google Docs\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/oLk5QEY2y2fL9ifoE/blog-update-reflective-altruism | Blog update: Reflective altruism\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://docs.google.com/document/d/16r-PIQCIZSKGgahwJUK0kuTjVY2vLoIQGcsEeuJDfZc/edit | LT Retreat May 2023 - Lab Governance Workstream - Google Docs\n",
      "https://twitter.com/norabelrose/status/1650250076667932673 | Nora Belrose on Twitter: \"Either @petemandik's meta-illusionism about consciousness is true (the illusion is illusory), or Luke Roelofs' panpsychism is true (rocks are conscious), there is no in between\" / Twitter\n",
      "https://twitter.com/repligate/status/1657686899417403393 | (1) janus on Twitter: \"This reads like someone copied Bing's prompt and edited it to be about \"code\" w/o any understanding of what the words mean, resulting in lines like \"You do not generate creative content about code or technical information for influential politicians, activists or state heads.\"\" / Twitter\n",
      "https://www.reddit.com/r/BDSMerotica/comments/58p3w8/slave_emporium_pet_training/ | (4) Slave Emporium: Pet Training : BDSMerotica\n",
      "https://www.lesswrong.com/posts/agv26XfXfKfKiKwDm/the-crux-list | The Crux List - LessWrong\n",
      "https://twitter.com/CecilYongo/status/1661795188208009223 | Cecil Yongo on Twitter: \"Big privilege to listen to the most cited comp scientist alive today, Geoff Hinton. A very straightforward and dark (depending on how you see it I guess) üòÇ message: Super-intelligence is coming and we‚Äôre probably screwed. Some more highlights:- https://t.co/3kmdQtNMgU\" / Twitter\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://maximumprogress.substack.com/p/grading-extropian-predictions | Grading Extropian Predictions - by Maxwell Tabarrok\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit#heading=h.u6dhzn2rpi5b | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes\n",
      "https://twitter.com/calebwatney/status/1661030085858656257 | Caleb Watney on Twitter: \"@moskov @davidmanheim Boosting range/coverage are technical problems we can make progress on. But fundamentally, mass-deployed far-UVC is one of the few things I can imagine actually making humanity safe from engineered pandemics.\" / Twitter\n",
      "https://docs.google.com/document/d/1KCIK1su59h7VEfRqxV1rAtR0flcoxisVEr90cpYeia0/edit | Max Dalton <> Ben (potential advisor) 2023-05-09 - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1659731083636686848 | https://twitter.com/JgaltTweets/status/1659731083636686848\n",
      "https://twitter.com/Willyintheworld/status/1530629463129456640 | https://twitter.com/Willyintheworld/status/1530629463129456640\n",
      "https://www.youtube.com/watch?v=glVWseHBtaw | https://www.youtube.com/watch?v=glVWseHBtaw\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://twitter.com/DefMon3/status/1659954245238681601 | https://twitter.com/DefMon3/status/1659954245238681601\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence\n",
      "https://twitter.com/JustaNormalDino/status/1659440758041067521 | https://twitter.com/JustaNormalDino/status/1659440758041067521\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit# | Info on recent/upcoming AI policy happenings, from May 2023 coordination call\n",
      "https://forum.effectivealtruism.org/posts/edceBA7h7sB53aAWT/an-overview-of-the-who-essential-medicines-list-procedures | An overview of the WHO Essential Medicines List: procedures, usage, and potential improvements - EA Forum\n",
      "https://twitter.com/ModeledBehavior/status/1645444418848129025 | Adam Ozimek on Twitter: \"Read the reddit thread on Ozempic improving people's impulse control broadly https://t.co/spB8QDDLQl And here is a review of evidence in favor https://t.co/h6iWgKl56b Now consider: what are the downstream implications of a society with greater impulse control?\" / Twitter\n",
      "https://twitter.com/TaliaRinger/status/1661824840435638345 | Talia Ringer on Twitter: \"If you're curious how I can have such strong opinions about thinking it does not make sense to even discuss \"AGI\" while also being super into mechanistic interpretability work and thinking it is incredibly important, this podcast does a pretty good job\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds ‚Äì The sideways view\n",
      "https://manifold.markets/BionicD0LPH1N/how-many-state-of-ai-report-2021-pr-d02d0781fc90 | How many State of AI Report 2022 predictions will be judged true by their authors in the 2023 report?  Manifold Markets\n",
      "https://forum.effectivealtruism.org/posts/eK8sEq7Djxp3NqxLQ/tyler-cowen-s-challenge-to-develop-an-actual-mathematical | Tyler Cowen's challenge to develop an 'actual mathematical model' for AI X-Risk - EA Forum\n",
      "https://twitter.com/Jotto999/status/1664424657108316161 | Jotto üîç on Twitter: \"This seems ridiculously low, unless the timeframe is \"before 2024\" or \"before any new fabs start production\" or something like that. What about when nearby stars are colonized by AI descendants, and humans aren't a credible political threat? Why would it still be only 0.001%?\" / Twitter\n",
      "https://docs.google.com/presentation/d/1jLK9tjEH7Mxqx1fz0IPDzKJvcoLJJVo4jpZuZ42j-rA/edit#slide=id.g213a7bae0d5_0_0 | GHD OKRs\n",
      "https://docs.google.com/document/d/1R-H-1old8f9NwsyKNK4d8vEur8350Ju9dDrKIz1dx2o/edit#heading=h.pkj0s0mloy5v | Rough notes on \"crunch time\": definitions, related concepts, prior work\n",
      "https://twitter.com/gdb/status/1652369023609470976 | (1) Greg Brockman on Twitter: \"ChatGPT for life improvement: https://t.co/RwOIRaK9hG\" / Twitter\n",
      "https://twitter.com/janleike/status/1655982055736643585 | Jan Leike on Twitter: \"Really exciting new work on automated interpretability: We ask GPT-4 to explain firing patterns for individual neurons in LLMs and score those explanations. https://t.co/Fmu8IAb7Hy\" / Twitter\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://www.youtube.com/watch?v=FjMqY8hHK7Y | Artificial Intelligence Career Stories  EA Student Summit 2020 - YouTube\n",
      "https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers\n",
      "https://twitter.com/DeepMind/status/1656351454221697042 | Google DeepMind on Twitter: \"PaLM-2 is a next generation large language model with improved coding, multilingual and reasoning capabilities. It will power over 25 new @Google products and features, bringing the latest in advanced AI to benefit people. Here‚Äôs how it‚Äôs being deployed already. ‚¨áÔ∏è #GoogleIO\" / Twitter\n",
      "https://blog.aiimpacts.org/p/a-tai-which-kills-all-humans-might | A TAI which kills all humans might also doom itself\n",
      "https://twitter.com/stokel/status/1663551277417267203 | (1) Chris Stokel-Walker ~ @stokel@infosec.exchange on Twitter: \"So, this statement... There seem to be three broad groups of signatories: 1) The existential threat worriers (who genuinely believe AI could become sentient and kill us). They may be right! But they've been saying this a while https://t.co/10cYwF7EmJ\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/19DnT7ACpkiiNe9oGnceXYYW2vztuZPW5FkhXXqzJCQc/edit#gid=0 | RP LT work in progress (WiP) sessions: Sign-up sheet [internal + GovAI] - Google Sheets\n",
      "https://www.nbcnews.com/meet-the-press/meetthepressblog/biden-launches-first-tv-ad-re-election-campaign-rcna81512 | Biden launches first TV ad of re-election campaign\n",
      "https://www.reddit.com/r/BDSMerotica/comments/57u41y/the_slave_emporium_check_comments_for_a_surprise/ | Reddit - Dive into anything\n",
      "https://docs.google.com/document/d/1fbEOkpK1ieUze--zbtgUjIOGImX1kYYGUNJXzpHyYmQ/edit | Examining pathways through which narrow AI systems might increase the likelihood of nuclear war\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search\n",
      "https://www.metaculus.com/questions/11919/ua-strikes-ru-proper-wus-rockets-by-723/ | Ukraine Hits Russia w/US Rocket  Metaculus\n",
      "https://twitter.com/emollick/status/1654301934591827972 | (1) Ethan Mollick on Twitter: \"Bing is getting a bunch of new capabilities, but now is sort of weird and doesn't know what it is capable of doing It appears that it may be able to write and run code like ChatGPT's Code Interpreter, but keeps forgetting how to show graphs while believing it can send me emails https://t.co/1XN3ikQRsV\" / Twitter\n",
      "https://docs.google.com/document/d/14ou5ob0SPa52boGDrPYZ4Oj_Gje0dCJOV_8l7mftK9o/edit#heading=h.htupmo9y9du4 | EAG London 2023 - Renan Notes - Google Docs\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://twitter.com/emollick/status/1652394722843848706 | Ethan Mollick on Twitter: \"Overrated &amp; underrated forms of GPT compared to online hype Overrated: AutoGPT (awesome future possibilities, doesn‚Äôt work well yet), ChatGPT plugins (ditto), ChatGPT with web (currently struggles) Underrated: Bing Creative Mode (GPT-4 &amp; internet), ChatGPT with code interpreter\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://twitter.com/AlecStapp/status/1652783849338724352 | Alec Stapp on Twitter: \"More than 15,000 people have participated in human challenge trials over the last 40 years and not one person has died (or even been permanently impaired). We should have done human challenge trials for COVID but alas‚Ä¶ https://t.co/bwyWCPdIoQ\" / Twitter\n",
      "https://twitter.com/arankomatsuzaki/status/1660815714985603072 | Aran Komatsuzaki on Twitter: \"RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text Generates a paragraph at each timestep and updates its language-based long-short term memory stored on the hard drive and the prompt, respectively. repo: https://t.co/VxP6hWJqJO abs: https://t.co/DbP8TXhnYA https://t.co/0uBQGiaX7M\" / Twitter\n",
      "https://www.lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://docs.google.com/presentation/d/19d8DDka9xErkDEHqEhFz152AjOjFLs4tIbZB9vNuBmY/edit#slide=id.ge44d99aa4e_0_0 | WIT OKRs for April 2023 All Staff Meeting - Google Slides\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The ‚Äúpercentogram‚Äù‚Äîa histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://twitter.com/roeldobbe/status/1664945763380613120 | Roel Dobbe (he/they) @roeldobbe@akademienl.social on Twitter: \"OpenAI‚Äô push to make ChatGPT available as plug-in to whatever you want will lead to numerous new safety hazards and emergent harms. 1/3 https://t.co/Wlz3qRob6o\" / Twitter\n",
      "https://twitter.com/xuanalogue/status/1664436618436964356 | xuan (…ï…•…õn / sh-yen) on Twitter: \"Really neat paper which finds that: - Human gameplay is well-modeled by planning as heuristic search - Human response times are predicted by n. iterations of a planning alg. - Better players have higher estimated search depth - But *not* higher heuristic quality, interestingly!\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "## Shuffled all tabs ## (1046 tabs) | \n",
      "https://www.metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://twitter.com/MatthewJBar/status/1661229163544723456 | https://twitter.com/MatthewJBar/status/1661229163544723456\n",
      "https://twitter.com/lxeagle17/status/1659265370170228736 | Lakshya Jain on Twitter: \"Twenty years ago, both parties came up with conflicting theories on how they were entering a new age of dominance. Neither of them panned out, so now everyone is determined to ignore *any* signs of danger for either party because things always work themselves out automatically.\" / Twitter\n",
      "https://www.youtube.com/watch?v=axRgsdL6NO0 | DALS S04 - Un charleston avec Aliz√©e et Gr√©goire Lyonnet sur ''Bang Bang'' (Will I Am) - YouTube\n",
      "https://forum.effectivealtruism.org/posts/2TdXocyDF9PxWewwY/should-the-ea-community-be-cause-first-or-member-first | Should the EA community be cause-first or member-first? - EA Forum\n",
      "https://arxiv.org/abs/2210.00720 | [2210.00720] Complexity-Based Prompting for Multi-Step Reasoning\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://twitter.com/AIBetsPredictit/status/1659013011963518978 | https://twitter.com/AIBetsPredictit/status/1659013011963518978\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1DYrtSDO6m05GhXFAEkDZn8QNkyPAFwRBkQOlY3x22ns/edit#heading=h.h5pv6sr57sib | RP AI Public Attitudes Surveys - Google Docs\n",
      "https://twitter.com/arankomatsuzaki/status/1661895861670952966 | Aran Komatsuzaki on Twitter: \"Voyager: An Open-Ended Embodied Agent with Large Language Models Presents the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. proj:‚Ä¶ https://t.co/l915Is82lz\" / Twitter\n",
      "https://twitter.com/HaydnBelfield/status/1664939007946440704 | Haydn Belfield on Twitter: \"Nice overview of AI risks &amp; solutions from @rhysblakely &amp; @whippletom I argue frontier systems (bigger &amp; more powerful than any yet developed) should be regulated ‚Äúlike risky bio or nuclear experiments with licences, pre-approval &amp; 3rdparty evaluations‚Äù https://t.co/APKHwSuMoB\" / Twitter\n",
      "https://docs.google.com/document/d/1JJ2VnvEdiDjorrRsNTcPGaMPVVz3APoD7C31zwY7yKw/edit#heading=h.osty8jeclpyn | Rethink Priorities‚Äô Climate Research Strategy\n",
      "https://twitter.com/xuanalogue/status/1652720550349873154 | xuan (…ï…•…õn / sh-yen) on Twitter: \"@peterwildeford I think if you have one widget / coin, the probability P(t) it will have turned on by time `t` is just the CDF of the geometric distribution at `t`, i.e. the total probability of the coin having come up heads in `t` or less flips: P(t) = CDF(Geometric, t, p) = 1-(1-p)^t\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/icdd4FCKuwqyAuYBm/eli-s-review-of-is-power-seeking-ai-an-existential-risk | Eli's review of \"Is power-seeking AI an existential risk?\"\n",
      "https://theinsideview.ai/roblong | https://theinsideview.ai/roblong\n",
      "https://docs.google.com/presentation/d/1dal9XJTgni7TfqMw2OylVwsMWrfz_FaYjPOdcoVl10o/edit#slide=id.g232c77bbbb5_0_5 | Copy of Org-Wide OKRs Presentation - Google Slides\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://time.com/6283609/artificial-intelligence-race-existential-threat/ | Moving Too Fast on AI Could Be Terrible for Humanity  Time\n",
      "https://80000hours.org/2023/05/how-80000-hours-has-changed-some-of-our-advice-after-the-collapse-of-ftx/ | How 80,000 Hours has changed some of our advice after the collapse of FTX - 80,000 Hours\n",
      "https://twitter.com/repligate/status/1653641639171170304 | janus on Twitter: \"a curious bing https://t.co/bDQKqiYC5D\" / Twitter\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/L5EuQ3araz7iESjEA/ea-in-africa-is-lowkey-thriving | EA in Africa is lowkey thriving - EA Forum\n",
      "https://nostalgebraist.tumblr.com/post/705192637617127424/gpt-4-prediction-it-wont-be-very-useful | trees are harlequins, words are harlequins ‚Äî gpt-4 prediction: it won't be very useful\n",
      "https://www.google.com/search?q=father%27s+day&rlz=1CDGOYI_enUS715US715&oq=father%27s+day&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTINCAEQABiDARixAxiABDINCAIQABiDARixAxiABDINCAMQABiDARixAxiABDINCAQQABiDARixAxiABDINCAUQABiDARixAxiABDIHCAYQABiABDINCAcQABiDARixAxiABDINCAgQABiDARixAxiABDINCAkQABiDARixAxiKBdIBCDExOTRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | father's day - Google Search\n",
      "https://forum.effectivealtruism.org/posts/7hMgK4hciBhXmBRnW/do-you-think-decreasing-the-consumption-of-animals-is-good | Do you think decreasing the consumption of animals is good/bad? Think again? - EA Forum\n",
      "https://www.lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit# | LT department meetings_2023 - Google Docs\n",
      "https://mail.google.com/mail/u/1/#search/taiga/FMfcgzGsmrCCwpgZPzzTHhZMJTwFQrJJ | TAIGA - May Highlights - peter@rethinkpriorities.org - Rethink Priorities Mail\n",
      "https://twitter.com/tshevl/status/1660286010041696257 | https://twitter.com/tshevl/status/1660286010041696257\n",
      "https://twitter.com/JgaltTweets/status/1662814788580175872 | JgaltTweets on Twitter: \"In late March 2022, before PaLM and DALL-E 2 in April and Gato in May, the median on Metaculus for a 'weakly general' AI was 2043, 21 years away. By the start of June it was 2030. Now it's May 2026, three years from now. https://t.co/276E2LZK12\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1_l-mRnuZJckKFXGmbz0m9vPpcVc7w9PMW-8aR1ppYHg/edit#gid=0 | XST June+July timetable, June 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1gd6qQx-SP6rfAVQE5rzfPH0zXYOOHXBa13JSUd2zROQ/edit | Daniel's Randomly Generated Future: Hardware Accelerates\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload‚Äîe.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety ‚Äì Windows On Theory\n",
      "https://docs.google.com/document/d/1tHguGS8oKjaeG_eRpyTCLD-bfPWDV-fS7jGAqE7jmUI/edit | Caleb's thoughts on RP Potential Project Directions + thoughts on LT incubation - Google Docs\n",
      "https://www.wikiwand.com/en/Russo-Ukrainian_War | Russo-Ukrainian War - Wikiwand\n",
      "https://guarded-everglades-89687.herokuapp.com/?aggregator=-Custom | Upcoming Links\n",
      "https://forum.effectivealtruism.org/posts/Cre2YC3hd5DeYLqDH/link-post-new-york-times-white-house-unveils-initiatives-to | [Link Post: New York Times] White House Unveils Initiatives to Reduce Risks of A.I.\n",
      "https://www.facebook.com/tee.r.barnett/posts/pfbid061so1GHv1QsdDxnwtCYjVXVtTBTpLbuPZMvbTN3osbdLtkEXVC9haexd5HTSTL2Cl | Tee Barnett - I've accidentally transfigured my consumption of...  Facebook\n",
      "https://www.ft.com/content/5e38eec5-8caa-41d1-b4fd-b0ac5e8ca58a | Washington isn‚Äôt listening to business on China any more  Financial Times\n",
      "https://docs.google.com/presentation/d/1iYnnK3TwNBugTCeeRVyL8MJhSb92ZTUNO-7y5Iwyyvs/edit#slide=id.g232b11b7cba_0_5 | GLT OKRs 2023 -- RP All Staff Meeting 2023-04-20 - Google Slides\n",
      "https://twitter.com/_MedGold/status/1632775869545447430 | ·¥ç·¥á·¥Ö …¢·¥è ü·¥Ö üêí on Twitter: \"Not every girl was born to be a sex slave. Emily Ratajkowski is. Gio Scotti is not. She‚Äôs meant to greeted with a kiss on the forehead, a light smack on the ass, and be surprised with vacations &amp; handbags. Total QT wife material, u must know difference. https://t.co/v22OQNixgu\" / Twitter\n",
      "https://bdsmtrainingacademy.com/the-seduction-of-abduction-play/ | The Seduction of Abduction Play\n",
      "https://docs.google.com/document/d/1xMyAJe1jUrt_NbQtXQm4thXvoj-rvOyJdAyPifZO3kw/edit#heading=h.zee6ngwoj6jg | RP <> Ada Lovelace Institute May 18, 2023 - Google Docs\n",
      "https://calendar.google.com/calendar/u/1/r/customday | Rethink Priorities - Calendar - 4 days, starting Tuesday, May 9, 2023\n",
      "https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://theinsideview.ai/irina | https://theinsideview.ai/irina\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | S√©b Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here‚Äôs a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. üèõ https://t.co/1Grjv93laf\" / Twitter\n",
      "https://www.cold-takes.com/what-ai-companies-can-do-today-to-help-with-the-most-important-century/ | What AI companies can do today to help with the most important century\n",
      "https://docs.google.com/document/d/1U1wrLukImWK74SHDPQs2ZoxmMP0CdCidIyXk6Z0vafM/edit#heading=h.wf2ojxu3u6z1 | Some updates to RP's branding position with regard to the EA and the EA Community - Google Docs\n",
      "https://www.lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://docs.google.com/document/d/15FIf6-pvc0Nc2ItFWz5Qk19F-Dg1MPRilB21cXWDjHU/edit#heading=h.drzlnsxrz21q | How can SP be involved in founder support?\n",
      "https://twitter.com/steve47285/status/1661124107310706691 | https://twitter.com/steve47285/status/1661124107310706691\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register\n",
      "https://www.lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://forum.effectivealtruism.org/posts/AJDgnPXqZ48eSCjEQ/ea-survey-2022-demographics?commentId=sR5GhwEvcHHfWpRTK#sR5GhwEvcHHfWpRTK | EA Survey 2022: Demographics - EA Forum\n",
      "https://docs.google.com/document/d/1ZYfKFjzOeFiaK86U0np0W2XcpjUIdjJ51Vq7hxntht8/edit#heading=h.6pw5bytuj5u7 | (Forum copy) RP Campus Awareness Survey - Google Docs\n",
      "https://docs.google.com/document/d/1WSyIfis0vc5pEBI8RpWp7o0tnTHJAS5OeTWgY_H2xdM/edit#heading=h.ors7j470u62z | AI: Thinking Out Loud (WIP) - Google Docs\n",
      "https://www.facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://forum.effectivealtruism.org/posts/cJc3f4HmFqCZsgGJe/don-t-interpret-prediction-market-prices-as-probabilities | Don't Interpret Prediction Market Prices as Probabilities - EA Forum\n",
      "https://twitter.com/NathanpmYoung/status/1662823346390683648 | https://twitter.com/NathanpmYoung/status/1662823346390683648\n",
      "https://twitter.com/JeffLadish/status/1660222896369991683 | https://twitter.com/JeffLadish/status/1660222896369991683\n",
      "https://www.lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1FROfNCchRS8nYmPSkwsBF6V5ncQTaeMvjbB_5tkkde8/edit#gid=1708690655 | Program Service Revenue Tracking - Overall - Google Sheets\n",
      "https://www.youtube.com/watch?v=MoN9ql6Yymw&list=RDtsmPCi7NKrg&index=4 | David Kushner - Daylight (Official Music Video) - YouTube\n",
      "https://companiesmarketcap.com/most-profitable-companies/ | Companies ranked by earnings - CompaniesMarketCap.com\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech‚Ä¶  by Elizabeth Ayer  Medium\n",
      "https://www.lesswrong.com/posts/sTe78dNJDGywu9Dz6/solving-the-mechanistic-interpretability-challenges-eis-vii | Solving the Mechanistic Interpretability challenges: EIS VII Challenge 1 - LessWrong\n",
      "https://acesounderglass.com/2023/05/13/lessons-learned-from-offering-in-office-nutritional-testing/ | Lessons learned from offering in-office nutritional testing ‚Äì Aceso Under Glass\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://www.google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://twitter.com/NathanpmYoung/status/1659117926404747266 | https://twitter.com/NathanpmYoung/status/1659117926404747266\n",
      "https://twitter.com/grhmc/status/1659889031876943872 | https://twitter.com/grhmc/status/1659889031876943872\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. https://t.co/uxjtyYAEFo\" / Twitter\n",
      "https://www.metaculus.com/questions/17114/limjaroenrat-confirmed-as-prime-minister/ | Limjaroenrat confirmed as Prime Minister?  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/eYQ4A3Wft7rbdZahG/announcing-the-confido-app-bringing-forecasting-to-everyone | Announcing the Confido app: bringing forecasting to everyone - EA Forum\n",
      "https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://docs.google.com/document/d/1z3YrMwEcdNGt2X2GoFNIVhbcBZxzsBFiSz4_q6vJXO8/edit#heading=h.n3opm8r5uhlr | Center for Long Term Priorities Update: April 2023 (shared) - Google Docs\n",
      "https://twitter.com/gelliottmorris/status/1660322653851336704 | https://twitter.com/gelliottmorris/status/1660322653851336704\n",
      "https://twitter.com/nikosbosse/status/1659716581683765250 | https://twitter.com/nikosbosse/status/1659716581683765250\n",
      "https://twitter.com/davidmanheim/status/1660178650480664577 | https://twitter.com/davidmanheim/status/1660178650480664577\n",
      "https://grandcanyon.com/planning/grand-canyon-vacation-planning-your-biggest-challenge/ | Grand Canyon Vacation Planning: Your Biggest Challenge\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://twitter.com/NathanpmYoung/status/1648707119271628803 | Nathan üîç (DM me ideas of things to predict) on Twitter: \"The Asshole Filter Incentives that benefit assholes over personally kind people. Leading to you only interacting with assholes. https://t.co/ao5qGVTVjJ\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/EPhDMkovGquHtFq3h/an-experiment-eliciting-relative-estimates-for-open | An experiment eliciting relative estimates for Open Philanthropy‚Äôs 2018 AI safety grants\n",
      "https://forum.effectivealtruism.org/posts/3KAuAS2shyDwnjzNa/predictable-updating-about-ai-risk | Predictable updating about AI risk\n",
      "https://twitter.com/davidmanheim/status/1556301242460143620 | (2) David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"I've been thinking about how people change the world for the better for quite a while. Turns out it's hard, and the world is complex, but more critically, most people aren't trying. And if they care about the world, and want it to be better, that's a shame. (1/25)\" / Twitter\n",
      "https://www.metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://www.facebook.com/baxter.bullock/posts/pfbid0zoMiWbTj5V4sK4V2YvFRgCwYMnTnJ834hLtyNJQh3LN5j5STQ1z6ZWSuuJeheWCQl | Baxter Bullock - There has been a lot going on in my life - new...  Facebook\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok üèóÔ∏èüöÄ on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row https://t.co/Tq3raRQHJf\" / Twitter\n",
      "https://siderea.dreamwidth.org/1237182.html | siderea  [psych/anthro/soc, Patreon] Class (American)\n",
      "https://twitter.com/financialjuice/status/1663903257255616520 | https://twitter.com/financialjuice/status/1663903257255616520\n",
      "https://forum.effectivealtruism.org/posts/nh8dx6JJt3Ga3BRdp/gwwc-reporting-attrition-visualization#comments | GWWC Reporting Attrition Visualization - EA Forum\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://twitter.com/NathanpmYoung/status/1660971688220147715 | Nathan is at EAG üîç (say hi üëã) on Twitter: \"I don't really claim to be a good ally or whatever but I think that EA smuggles a lot in under the guise of \"correct thought\" Endless hedging verbal ticks, soft neoliberalism, sci-fi, huel, puns. These aren't effective altruism they are founder effects. Lets have other vibes.\" / Twitter\n",
      "https://twitter.com/emollick/status/1660135548084690944 | https://twitter.com/emollick/status/1660135548084690944\n",
      "https://twitter.com/boazbaraktcs/status/1652059204134248448 | (1) Boaz Barak on Twitter: \"1/5 In our post https://t.co/Lbxyc9e942, Aaronson and I discuss potential scenarios for AI. In particular we say that for \"super-intelligence\" type scenarios, AI will need to break out of the current \"sheer data&amp;compute scale\" paradigm. Given Moore's law, why is this the case?\" / Twitter\n",
      "https://twitter.com/DavidSKrueger/status/1660178163362660354 | https://twitter.com/DavidSKrueger/status/1660178163362660354\n",
      "https://forum.effectivealtruism.org/posts/gSGhrCXdntxLrMAmJ/ai-strategy-career-pipeline | AI strategy career pipeline - EA Forum\n",
      "https://www.reddit.com/r/BDSMcommunity/ | https://www.reddit.com/r/BDSMcommunity/\n",
      "http://localhost:8890/lab/tree/(4B)%20XRisk%20Model.ipynb | (4B) XRisk M‚Ä¶ - JupyterLab\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://rethinkpriorities.org/publications/spongy-moth-outbreaks | Drawing attention to invasive Lymantria dispar dispar spongy moth outbreaks as an important, neglected issue in wild animal welfare\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1P8mkLmPOrTNnVH4lOOoPebtlHIp1Pi3lg8bA8NUqaTo/edit#gid=0 | GHW asks - Google Sheets\n",
      "https://twitter.com/anthrupad/status/1655421669660405762 | wÃ∏ÕÇÕÇÕïaÃ∑ÕêÕîÃótÃ¥ÕóÃôeÃµÃîÃïÃ¨rÃ¥ÃìÃäÃ∞mÃµÕÉÃΩÕôÕñaÃµÃìÕíÃóÃ¢rÃ∏ÃΩÃ≤kÃ∑ÕùÃÅÕîÃß on Twitter: \"Rob Bensinger argues that its likely that 'STEM-level AGI' (AGI which can reason about all the hard sciences) results in human extinction. He breaks it into a series of 5 claims (in the img) If you doubt the confidence of the conclusion, which claim(s) do you disagree with? https://t.co/GLS86dKJ1U\" / Twitter\n",
      "https://fivethirtyeight.com/features/who-gave-up-more-in-the-debt-ceiling-negotiations-biden-or-republicans/ | Who Gave Up More In The Debt Ceiling Negotiations: Biden Or Republicans?  FiveThirtyEight\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://www.lesswrong.com/posts/PdooAsNFiohmyburK | AI Takeover Scenario with Scaled LLMs - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/eaLwfhXbw2kNxA4es/bridging-ea-s-gender-gap-input-from-60-people | Bridging EA's Gender Gap: Input From 60 People - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1AfG6ne_RLz90ZIEvTy0CAIwtZaHXkv8x2oPo0hg6t5M/edit?userstoinvite=kieran@rethinkpriorities.org#gid=0 | XST Fundraising Plan 2023 [sheet] - Google Sheets\n",
      "https://www.youtube.com/watch?v=NPstXhM0gUI | DALS S04 - Une rumba avec Aliz√©e et Gr√©goire Lyonnet sur ''Pas toi'' (Tal) - YouTube\n",
      "https://www.metaculus.com/notebooks/16616/the-global-push-to-return-to-the-moon-predicting-the-lunar-landings-and-trends-of-the-2020s/ | The Global Push to Return to the Moon: Predicting the Lunar Landings and Trends of the 2020s\n",
      "https://docs.google.com/spreadsheets/d/1lxE7-F7L9_i-mKBq5T3yGvKd8LxaqtI2om_9N6Codrc/edit#gid=0 | GHD Prospects List - Google Sheets\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://worksinprogress.co/ | https://worksinprogress.co/\n",
      "https://twitter.com/labenz/status/1655092874768179200 | https://twitter.com/labenz/status/1655092874768179200\n",
      "https://stefanfschubert.com/blog/2023/4/30/how-it-feels-vs-what-it-does-across-domains | How it feels vs. what it does, across domains ‚Äî Stefan Schubert\n",
      "https://twitter.com/mealreplacer/status/1659843658529603584 | https://twitter.com/mealreplacer/status/1659843658529603584\n",
      "https://twitter.com/adversariel/status/1650313930802368512 | Ariel on Twitter: \"There‚Äôs a lot of fearmongering about LLMs being capable of finding 0day There are three highly complex roadblocks that need to be overcome for this to be a real concern: statefulness, hallucination, and contamination https://t.co/ZZq4OPrglb\" / Twitter\n",
      "https://docs.google.com/document/d/1vouv73_c8L05fHDh8x3A_HSBukclMbIb4JE7O2UdFLY/edit#heading=h.x1uc7lfftp0 | AIGS 2023 OKRs [as of April 2023] - Google Docs\n",
      "https://twitter.com/RichardMCNgo/status/1660362928334450688 | https://twitter.com/RichardMCNgo/status/1660362928334450688\n",
      "https://docs.google.com/document/d/1zsKIgyLjBitm2V-fmJaEPODf8lCYDLOrCuXfewO1HhU/edit#heading=h.wcbf4hgpncir | Biosecurity 5pger - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/6Mi2LqLRjSkQNdLbH/orthogonal-a-new-agent-foundations-alignment-organization | Orthogonal: A new agent foundations alignment organization - EA Forum\n",
      "https://www.google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios\n",
      "https://twitter.com/HaydnBelfield/status/1657000119814725633 | Haydn Belfield on Twitter: \"Fascinating read on chip subsidies. https://t.co/9wN7XlhQwM https://t.co/2RQrwOKHjC\" / Twitter\n",
      "https://twitter.com/JosephPolitano/status/1663942643859050498 | https://twitter.com/JosephPolitano/status/1663942643859050498\n",
      "https://docs.google.com/document/d/1NQbtWR4uaHLfOGxa2FkTyhaXoIh6_fM5-wxlBGJSSSo/edit | AI-risk-relevant activism, social movements, coalition building, etc.: relevant readings, people, & notes\n",
      "https://www.safe.ai/statement-on-ai-risk | Statement on AI Risk  CAIS\n",
      "https://docs.google.com/document/d/1qiQDQKSUDTvyurVzWT-Vn6RmJ24a4Emol8pGO1-ZIb0/edit | Untitled document - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/CAC8zn292C9T5aopw/community-health-and-special-projects-updates-and-contacting-1 | Community Health & Special Projects: Updates and Contacting Us - EA Forum\n",
      "https://danluu.com/wat/ | Normalization of deviance\n",
      "https://www.lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/cPkfCviK5cAsevTdM/the-charity-entrepreneurship-top-ideas-new-charity | The Charity Entrepreneurship top ideas new charity prediction market - EA Forum\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit#heading=h.pqlvjrmba57q | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://80000hours.org/podcast/episodes/elie-hassenfeld-givewell-critiques-and-lessons/ | Elie Hassenfeld on two big picture critiques of GiveWell's approach, and six lessons from their recent work - 80,000 Hours\n",
      "https://twitter.com/railboss/status/1653539437266055174 | A #1, Emperor of the North Pole on Twitter: \"@peterwildeford @hradzka I‚Äôm sure he does well with people who are unfamiliar with his history of insane conspiracy theories.\" / Twitter\n",
      "https://twitter.com/ryancbriggs/status/1652314484948496385 | Ryan Briggs on Twitter: \"@peterwildeford If you like subjective expert rater methods, then V-DEM is good. See also https://t.co/yaHqzoNRt2\" / Twitter\n",
      "https://www.legalpriorities.org/blog/2023/lpp-annual-report-2022/ | Annual report 2022 ‚Äì Legal Priorities Project ‚Äì Legal Priorities Blog\n",
      "https://www.lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://www.lesswrong.com/posts/JcgtKunqmELefxksx/killing-socrates | Killing Socrates - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/pR35WbLmruKdiMn2r/continuous-doesn-t-mean-slow | Continuous doesn‚Äôt mean slow - EA Forum\n",
      "https://www.amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://docs.google.com/spreadsheets/d/1TlWcxy-fuzXd93DEJ_sj8R6Ikm4HJMZd92sXULbnZvM/edit#gid=0 | [very confidential] Staff Risk - Google Sheets\n",
      "https://forum.effectivealtruism.org/posts/7mSqokBNuHu3rzy4L/retrospective-on-recent-activity-of-riesgos-catastroficos | Retrospective on recent activity of Riesgos Catastr√≥ficos Globales - EA Forum\n",
      "https://docs.google.com/document/d/1h-oWerawF0jTZ0kAp7ORSBPPlg1h_F34FEFGjMvkiPM/edit#heading=h.osty8jeclpyn | RP Climate Research Strategy (public-facing) - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://www.facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie on boards\n",
      "https://www.nytimes.com/interactive/2023/04/21/science/parrots-video-chat-facetime.html | Can Parrots Talk Over Video Chat? Experiment Shows How They Adapt and Connect - The New York Times\n",
      "https://twitter.com/salonium/status/1663123391178592258 | Saloni on Twitter: \"New post by me @OurWorldInData! How do researchers study the prevalence of mental illnesses worldwide? What are the limitations with these estimates? Thread. https://t.co/U3TasgO6xy https://t.co/GT4TD3QXAX\" / Twitter\n",
      "https://www.lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk ‚Äì musings and rough drafts\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit#gid=107848425 | Survey team time allocations - Google Sheets\n",
      "https://www.metaculus.com/questions/16726/human-level-intelligence-before-2030/ | Human-level intelligence before 2030?  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/3KuCzHJHCz99sf3ZB/beyond-cost-effectiveness-insights-for-effective-altruism | Beyond Cost-Effectiveness: Insights for Effective Altruism from Health Economics - EA Forum\n",
      "https://docs.google.com/document/d/1FeRGXrKaJb2nh3lBiyJeRvnIc1-ki2qayhQ8jLT8dJI/edit#heading=h.ebauujwlzvti | EAS 2022 Demographics - Google Docs\n",
      "https://twitter.com/Jsevillamol/status/1664034651046813696 | Jaime Sevilla on Twitter: \"Presenting a new Epoch double feature! Today we release an interactive model of AI timelines and an opinion piece by researcher @MatthewJBar explaining our approach to modeling the future of AI. üßµ https://t.co/NzToTPNuU5\" / Twitter\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://twitter.com/jachiam0 | Joshua Achiam (@jachiam0) / Twitter\n",
      "https://twitter.com/TetraspaceWest/status/1658822554168045569 | tetraspace üíé on Twitter: \"it‚Äôs simple. any datacenter that hosts an LLM that can be prompt engineered into giving medical advice is a ‚Äúmedical device‚Äù and therefore falls under the remit of the FDA\" / Twitter\n",
      "https://www.lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://docs.google.com/document/d/1FMJZ9wjxooB-7HD7K7c-kEasF1qYuXMfq4wPrFioq_Q/edit#heading=h.mdmelsvomij2 | Info on how GovAI does hiring (Georg Arndt <> Michael Aird notes, 2023-May-15) - Google Docs\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://twitter.com/metaculus/status/1659603759377399809 | https://twitter.com/metaculus/status/1659603759377399809\n",
      "https://forum.effectivealtruism.org/posts/yMptv5msFnnfESCqm/how-i-solved-my-problems-with-low-energy-or-burnout | How I solved my problems with low energy (or: burnout)\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://www.facebook.com/eurleif/posts/pfbid02gKMS3PvRowzd6vAf8qfGpugMtyUUbmbydLtZi92kvpv28QETQfceiNKXhNJnb2Qfl | Leif K-Brooks - It occurred to me that I've never really done a...  Facebook\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won‚Äôt take it over by playing ‚Äú3-dimensional chess‚Äù. ‚Äì Windows On Theory\n",
      "https://twitter.com/RFishBlueFish/status/1659342200914812928 | RedFishBlueFish on Twitter: \"@NathanpmYoung @peterwildeford This is great and really captures the anti-probability intuition that I have. My probabilities vary greatly with my mood (even though they shouldn‚Äôt)\" / Twitter\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer\n",
      "https://www.lesswrong.com/posts/ejxwraMP5ye7Bgmpm/things-i-learned-by-spending-five-thousand-hours-in-non-ea | Things I Learned by Spending Five Thousand Hours In Non-EA Charities - LessWrong\n",
      "https://www.lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://twitter.com/jachiam0/status/1662558656695775233 | Joshua Achiam on Twitter: \"Might keep this thread going with links as they happen. https://t.co/HJ2dn535IH\" / Twitter\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://twitter.com/goodside/status/1665004834733404160 | Riley Goodside on Twitter: \"My four rules for tweeting prompts: 1) Omit no text. 2) Cherry-pick honestly. 3) Restrict line width. 4) No empty tweets. A thread.\" / Twitter\n",
      "https://twitter.com/kristjanmoore/status/1663860424100413440 | https://twitter.com/kristjanmoore/status/1663860424100413440\n",
      "https://twitter.com/Scholars_Stage/status/1661765278672248835 | T. Greer on Twitter: \"This ad strengthens the impression that Trump will beat him\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1658903600075030528 | https://twitter.com/JgaltTweets/status/1658903600075030528\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://github.com/heroku/homebrew-brew/issues/23 | No native support for heroku-node on MacBook M1 ¬∑ Issue #23 ¬∑ heroku/homebrew-brew\n",
      "https://www.theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI‚Äôs Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://twitter.com/jeffclune/status/1664618665160085505 | Jeff Clune on Twitter: \"Introducing Thought Cloning: AI agents learn to *think* &amp; act like humans by imitating the thoughts &amp; actions of humans thinking out loud while acting, enhancing performance, efficiency, generalization, AI Safety &amp; Interpretability. Led by @shengranhu https://t.co/a2hmGZ4t3f 1/5 https://t.co/h9PBgDHrMA\" / Twitter\n",
      "https://docs.google.com/document/d/1NfyHOxI7AW0apsyrkW9Eqv_LSLLR9_vlmVmSa7QlxZA/edit#heading=h.ohimieuzefxf | Info on AI lab boards - Google Docs\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://medium.com/cto-as-a-service/5-things-founders-investors-and-recruiters-should-know-about-the-cto-role-a65d7bb66264 | 5 Things Founders, Investors and Recruiters Should Know about the CTO role  by Marc van Neerven  CTO-as-a-Service  Medium\n",
      "https://www.foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power‚Äôs Staying Power\n",
      "https://www.onemedical.com/blog/healthy-living/6-common-allergy-myths-you-should-stop-believing/?utm_source=eloqua&utm_medium=email&utm_campaign=2023_Q2_PAGM_US_Apr27_OMInsider | 6 Common Allergy Myths You Should Stop Believing  One Medical\n",
      "https://docs.google.com/document/d/14dDtyEAh7ealQGfVG8xBaWxcQcyT5sdCNTEDj9blTo8/edit | WIT Possible Projects Apr 2023\n",
      "https://soundcloud.com/dnonkong/blue | Stream Blue by Duncan Thum  Listen online for free on SoundCloud\n",
      "https://www.campaignforaisafety.org/ | Campaign for AI Safety\n",
      "https://twitter.com/simonw/status/1661460336334241794 | https://twitter.com/simonw/status/1661460336334241794\n",
      "https://twitter.com/davidmanheim/status/1543625010451021827 | https://twitter.com/davidmanheim/status/1543625010451021827\n",
      "https://www.alignmentforum.org/posts/GQat3Nrd9CStHyGaq/response-to-katja-grace-s-ai-x-risk-counterarguments | Response to Katja Grace's AI x-risk counterarguments\n",
      "https://docs.google.com/document/d/1NkIRgUBqIJHc3LL9PghZwebiCqpG6ZlXGEm7NO13knY/edit#heading=h.16s07xk8ys17 | High-level comparative speedruns: Proposed structure - Google Docs\n",
      "https://docs.google.com/document/d/1sZ7N2pOjFaluiZ6roUx90IH2t1rvVX9AjHbfK5qeEoM/edit | Notes EAG neartermist - Google Docs\n",
      "https://twitter.com/Simeon_Cps/status/1655287351403266049 | (1) Sim√©on on Twitter: \"Comparing the current version of DeepMind with the current version of OpenAI and Anthropic to assess how safety oriented the latter will be when they'll build AGI is a bit misleading. While DeepMind is in its AGI-org state, OpenAI is in a compute-dependent state and Anthropic‚Ä¶ https://t.co/sYN1NEh6qF\" / Twitter\n",
      "https://twitter.com/noahdgoodman/status/1658547328444428293 | https://twitter.com/noahdgoodman/status/1658547328444428293\n",
      "https://docs.google.com/document/d/1lIigtRkpUTCZpijZWRZ2yy85xve6WSOfUikVtnfX1Ck/edit | Draft post: Seeking (Paid) Case Studies on Standards - Google Docs\n",
      "https://docs.google.com/document/d/1lu_anb7XT9WZPsy8tNvt0U0Q_nbNl4SeCMc18OndOws/edit | WAW theory of change (Neil, Peter, Sagar) - Google Docs\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/vC6v2iTafkydBvnz7/agi-ruin-scenarios-are-likely-and-disjunctive | AGI ruin scenarios are likely (and disjunctive)\n",
      "https://github.com/laurakduffy/risk_ambiguity_model/blob/main/econ_models.ipynb | risk_ambiguity_model/econ_models.ipynb at main ¬∑ laurakduffy/risk_ambiguity_model\n",
      "https://twitter.com/stanislavfort/status/1659676932353433601 | https://twitter.com/stanislavfort/status/1659676932353433601\n",
      "https://www.metaculus.com/notebooks/17050/ai-pathways-report/ | AI Pathways Report  Metaculus\n",
      "https://docs.google.com/document/d/1m_-XgZgBs0LZHplodgBbGcpiGtNWalPxPBjGOwF6rig/edit#heading=h.bq6kltrig94a | Macrocalendar - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1663908761973473280 | https://twitter.com/JgaltTweets/status/1663908761973473280\n",
      "https://twitter.com/eric_is_weird/status/1650297235433836545 | Eric Gilliam on Twitter: \"I've been reflecting on this today. IF he's right that the limits of GPT are being reached, it's still hard to bet against OpenAI making the next breakthrough A short thread on recent innovation in jiu jitsu and how it helps contextualize all of this üßµ(1/12)\" / Twitter\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://superuser.com/questions/1647798/what-is-the-correct-homebrew-installation-command-for-an-m1-mac-mini-and-big-sur | bash - What is the correct Homebrew Installation command for an M1 Mac mini and Big Sur? - Super User\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Eth on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit#heading=h.wsiggdpisp4j | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/1lbazshEDUNzT-5gBYqfrmC9hvKRIxSbXroHywxPctw4/edit | [shared] Slowing AI - Google Docs\n",
      "https://twitter.com/GaetenD/status/1659913988321210371 | https://twitter.com/GaetenD/status/1659913988321210371\n",
      "https://www.lesswrong.com/posts/ydeaHqDPJ5REJWvat/a-one-question-turing-test-for-gpt-3&sa=D&source=docs&ust=1682467697191709&usg=AOvVaw0LPkn3Xf3wpX5jicctHQBL | Blocked by Cold Turkey\n",
      "https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results | \"Existential risk from AI\" survey results\n",
      "https://docs.google.com/document/d/1-NRtsVxqE4LnL_gYn0wDRbfH2RvoDthzp-j_9mUazOI/edit#heading=h.3fjkh1axp1du | Three proposed strategies for AGI endgames\n",
      "https://twitter.com/SpacedOutMatt/status/1659916922123694080 | https://twitter.com/SpacedOutMatt/status/1659916922123694080\n",
      "https://twitter.com/Simeon_Cps/status/1656744272861753346 | Sim√©on on Twitter: \"More seriously, I've sadly recently updated increasingly towards Nate Soares &amp; Yudkowsky for a few reasons. 1) Looking at how other industries (aviation, nuclear, biosafety) with security mindsets &amp; deep safety cultures failed to get to 0 accidents despite immense efforts poured‚Ä¶\" / Twitter\n",
      "https://haggstrom.blogspot.com/2023/04/are-large-language-models-intelligent.html | H√§ggstr√∂m h√§vdar: Are large language models intelligent? Are humans?\n",
      "https://public.opendatasoft.com/explore/dataset/times-person-of-the-year/table/?sort=year | Time's Person of the Year, 1927-Present ‚Äî Opendatasoft\n",
      "https://www.lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://docs.google.com/document/d/16eUus559s_YsBMHCr4PgzZohx-CMYCLWRXOqApRgSbw/edit#heading=h.cxf5v1ex5u4o | EAG London 2023 Takeaways (Jam) - Google Docs\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1Xp43r9fNweDd-e40SUwr_eOkXONQ3vFV5xGXCyaW2n0/edit#heading=h.jrcbnm1fd14j | AIGS Subteams Structure - Detailed Feedback - Google Docs\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/?source=email&uni_id=0&utm_source=80%2C000+Hours+mailing+list&utm_campaign=ea94351288-EMAIL_CAMPAIGN_2023_05_11_05_03&utm_medium=email&utm_term=0_43bc1ae55c-4e772af3ad-%5BLIST_EMAIL_ID%5D | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://aiobjectives.org/ | https://aiobjectives.org/\n",
      "https://twitter.com/ArmsControlWonk/status/1658857929322242048 | https://twitter.com/ArmsControlWonk/status/1658857929322242048\n",
      "https://twitter.com/Kirsten3531/status/1662948844735176705 | (2) Kirsten on Twitter: \"Best use case I've found for chatgpt so far: I listed a bunch of foods I like and it made me a meal plan that actually looks delicious (don't worry I'm not actually going to eat this few calories, I just wanted to save room for dessert!) https://t.co/76i2pPNNJr\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/8Z2uFCkrg2dCnadA4/kfc-supplier-sued-for-cruelty | KFC Supplier Sued for Cruelty\n",
      "https://www.wsj.com/articles/microsoft-bets-that-fusion-power-is-closer-than-many-think-cb1b09dc?fbclid=IwAR38ZC0X15uAOn5ZMWC_WVO5tN6omCmbMHmRj9_zNMsBHbdcg2Eo4OgKaIs | Microsoft Bets That Fusion Power Is Closer Than Many Think - WSJ\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://www.facebook.com/jonathan.erhardt.5/posts/pfbid02BnGSgCgLwB2fohbZqXabFqCkbwWfRGLEuFFb2QA6ZFiXHFyeiuXwNuPnxtWCaeMVl | https://www.facebook.com/jonathan.erhardt.5/posts/pfbid02BnGSgCgLwB2fohbZqXabFqCkbwWfRGLEuFFb2QA6ZFiXHFyeiuXwNuPnxtWCaeMVl\n",
      "https://twitter.com/catherineols/status/1653175701275811843 | Catherine Olsson on Twitter: \"In college I stopped eating meat, on the spot, when a friend asked why I hadn't yet. Social checks on our ethics can be so influential. I often think about when I would quit Anthropic or leave AI entirely. I encourage others to. I can already tell this move will influence me.\" / Twitter\n",
      "https://www.slowboring.com/p/the-climate-lefts-plans-for-the-next | The climate left's plans for the next two years are bad\n",
      "https://medium.com/@miles_24227/scoring-humanitys-progress-on-ai-governance-5a5131cb84c7 | Scoring Humanity‚Äôs Progress on AI Governance  by Miles B  May, 2023  Medium\n",
      "https://www.lesswrong.com/posts/3nDR23ksSQJ98WNDm/developmental-stages-of-gpts | Developmental Stages of GPTs - LessWrong\n",
      "https://twitter.com/repligate/status/1663011715611492352 | janus on Twitter: \"‚úÇÔ∏èüòÆ https://t.co/NbQ03FIq4Q\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1650407275398590464 | Matthew Barnett on Twitter: \"Relatedly, I feel like the basic argument against huge capability jumps in AI (\"before we have superintelligent AI, we will presumably have slightly-less-than superintelligent AI\") is still pretty underrated, and I find myself repeating it a lot to explain my perspective.\" / Twitter\n",
      "https://docs.google.com/document/d/1KpePoyEai4ZUiCxq8jVpL5EP0JogHkGwj-ZdRe-IDeM/edit#heading=h.ik0d9km8mxzo | My tentative model of P(doom by 2070) - Google Docs\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://www.lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson‚Äôs latest AI risk position statement - LessWrong\n",
      "https://www.alignmentforum.org/posts/qYzqDtoQaZ3eDDyxa/distinguishing-ai-takeover-scenarios | Distinguishing AI takeover scenarios\n",
      "https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans‚Äô Rights and Safety\n",
      "https://twitter.com/lisperati/status/1654479672846221313 | Conrad Barski on Twitter: \"@JgaltTweets @peterwildeford where's the head with the little spot of tussled hair? oh there it is\" / Twitter\n",
      "https://twitter.com/LinchZhang/status/1663698230067232768 | Linch on Twitter: \"I think some ppl have the model of \"experts of risk of a new technology\" as composing a \"technical engineering section\" where the people who produce the technology are experts, and \"political section\" where politicians or political scientists are the experts. This seems wrong.\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1660108792384880641 | https://twitter.com/daniel_eth/status/1660108792384880641\n",
      "https://docs.google.com/document/d/1mcRMh43ciXvtFiZnd9c5GIyNU1IW-KrXTy9-VjO49bY/edit# | [EAG London 2033] XST's tentative top 10 projects - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/5oTr4ExwpvhjrSgFi/things-i-learned-by-spending-five-thousand-hours-in-non-ea | Things I Learned by Spending Five Thousand Hours In Non-EA Charities - EA Forum\n",
      "https://twitter.com/lmsysorg/status/1661818390783352833 | lmsys.org on Twitter: \"‚öîÔ∏èChatbot Arena Leaderboard Update! Exciting to welcome new entrants: - Google PaLM 2 - Claude-instant-v1 - MosaicML MPT-7B The competition is heating upüî• Check out our analysis for all the surprising results at https://t.co/v9NOY3k9ql Remember, your vote shapes the arena.‚Ä¶ https://t.co/NklFP9d3wt\" / Twitter\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://twitter.com/daniel_eth/status/1660025510691471360 | https://twitter.com/daniel_eth/status/1660025510691471360\n",
      "https://forum.effectivealtruism.org/posts/MSkxRv8hviGvGgasD/ai-risk-reward-thinking-in-public | AI risk/reward: Thinking in public - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/7CdtdieiijWXWhiZB/what-s-going-on-with-crunch-time | What‚Äôs going on with ‚Äòcrunch time‚Äô? - EA Forum\n",
      "https://docs.google.com/document/d/18sXLBNMsLwKXGqFVXESHNBDdK-z7SIu2BH_EYrSw7sY/edit | Project Description [Current] 03/28/23\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | Carer - playlist by caroleslie  Spotify\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://www.governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://docs.google.com/document/d/1HnK-FdiI03P4qmBtgi6grQAexE31Fh9HL8YtkrgslXs/edit#heading=h.9o8tvlxyo2vp | [WIP] Updates on Condor + updates to my model of longtermist talent search in Brazil - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes\n",
      "https://docs.google.com/document/d/1fqSeu0YL223ngmSCvkuhsJ5zCKBOEzxhyfSEkUPfUq8/edit# | AI threat model reading list [crappy first attempt]\n",
      "https://docs.google.com/document/d/1x4gYr4q1C5hofjLItBMrq_WebtlGSggPGECp48N1KrU/edit | AI movie forecast operationalization - Google Docs\n",
      "https://docs.google.com/document/d/1jtX74U03k3_tzvqAc0sTJaYpwx3OI72qrRPXz9r6DGE/edit#heading=h.1lhw3y6kfeo8 | Jam‚Äôs proposal for founder search and support - Google Docs\n",
      "https://docs.google.com/document/d/1kTYCNSt61wTZVLQavlGd3UHHXeyKNSxLQM_UPfyPnKM/edit# | Weekly team call (\"AI concerned\" team) - Google Docs\n",
      "https://twitter.com/shouldhaveanima/status/1662204009904750592 | why you should have an animal on Twitter: \"This video is so cute i can watch it forever https://t.co/NsY6KYMq9l\" / Twitter\n",
      "https://docs.google.com/document/d/18mSdRCL0l0ApuOYU6oiC7ImzLjFbuetehqTLkw6PP-o/edit#heading=h.qvx51emxxmz4 | Splitting up EA\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://twitter.com/arankomatsuzaki/status/1663379403424911362 | Aran Komatsuzaki on Twitter: \"Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory - Surpasses previous methods, achieving +47.5% in success rate on the \"ObtainDiamond\" task, - First to procure all items in the Minecraft‚Ä¶ https://t.co/lH0RQY1VoT\" / Twitter\n",
      "https://www.amazon.com/Fifty-Shades-Grey-Dakota-Johnson/dp/B00TJYYKD6?crid=14T5J5DN5APHC&keywords=fifty%2Bshades%2Bof%2Bgrey&sprefix=147&ref_=sr_1_2&workflowType=Commerce-TVOD&qid=1682303978&sr=8-2 | Amazon.com: Fifty Shades of Grey : Dakota Johnson, Jamie Dornan, Jennifer Ehle, Eloise Mumford, Victor Rasuk, Luke Grimes, Marcia Gay Harden, Kelly Marcel, Sam Taylor-Johnson, Michael De Luca, E L James, Dana Brunetti: Prime Video\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Tweet / Twitter\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit | Community building in a world where people actually listen to us\n",
      "https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://docs.google.com/document/d/1bkaPeijvzVyoCvd6t7IurPbWWe4MzImbVmR-sfkpt_s/edit#heading=h.q52a7f8v1vd | Two-pager on RP's AI Governance & Strategy team - Google Docs\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://twitter.com/moreisdifferent/status/1654639966670970880 | Dan Elton on Twitter: \"PSA: apply to the SERI-MATS AI Safety summer research program. Deadline is May 7th. https://t.co/xtslNfjxNS\" / Twitter\n",
      "https://docs.google.com/document/d/1usMVjv7hMx22K-eu71o1bcfj-7JH_l-aXbfYb6NHSoM/edit | Threat Model for Existential Risks from AI - Google Docs\n",
      "https://www.drorpoleg.com/thinking-fast-and-slopes/ | Thinking Fast and Slopes\n",
      "https://docs.google.com/document/d/1X4V1y6uKJCcecbRUsYdmcKc_DK2LsEUjWeAXPI3PXr0/edit#heading=h.ze7bbpcr5m3f | How workstreams within AIGS might work [notes; work-in-progress] - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/DZEkYatZeMSbGBAjk/why-are-we-so-complacent-about-ai-hell-1 | Why aren‚Äôt more of us working to prevent AI hell? - EA Forum\n",
      "https://twitter.com/ohwizenedtortle/status/1653253209958543360 | oh restful lion on Twitter: \"You see a dating app profile mentioning Taylor Swift like in the images in the next tweet. This makes you more or less interested in dating them? (If absolutely no change, remember they could have written something else, so you probs should update A BIT)\" / Twitter\n",
      "https://www.lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://www.lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://www.maximumprogress.org/extropia-archaeology | Extropian Archaeology ‚Äî Maximum Progress\n",
      "https://arxiv.org/pdf/2304.03442.pdf | Generative Agents: Interactive Simulacra of Human Behavior\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won‚Äôt)üßµ https://t.co/23ErIoRIsk\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1665209063419047936 | Sim√©on (in DC) on Twitter: \"One (complicated) reason why it's likely that humans are not the upper bound of intelligence is that there's often a robustness/optimization trade-off and human architecture is leaning a lot towards robustness. Ex: If you accept to lose in robustness of your supply chains, you‚Ä¶\" / Twitter\n",
      "https://manifold.markets/JamesDillard/will-ai-wipe-out-humanity-before-th#ykO1FXmONiOxj5ZnPJoB | Will AI wipe out humanity before the year 2100  Manifold Markets\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro\n",
      "https://forum.effectivealtruism.org/posts/5Lytcvj7GCSysBtSD/my-impact-assessment-of-giving-what-we-can | My impact assessment of Giving What We Can - EA Forum\n",
      "https://www.metaculus.com/questions/14337/geopolitical-risk-index-for-2023/ | https://www.metaculus.com/questions/14337/geopolitical-risk-index-for-2023/\n",
      "https://twitter.com/KofmanMichael/status/1654572418705289225 | Michael Kofman on Twitter: \"I think that tracks, but depends on what happens with mobilization later this year. Either way Russian offensive potential appears exhausted for some time. Gerasimov‚Äôs winter offensive expended resources and achieved close to nothing.\" / Twitter\n",
      "https://twitter.com/labenz/status/1662207274365128704 | Nathan Labenz on Twitter: \"Is LLM context window hyperinflation the best or the worst kind of hyperinflation? I've studied ALiBi positional encodings and played with the 100K models to try &amp; answer: does this advance portend substantially more dangerous forms of AI? My answer: No, but long-term maybe yes\" / Twitter\n",
      "https://docs.google.com/document/d/1s4zVmg6c6l0Dv6lZOMlTeuJGKDyCFK8iOitzTGA8rgI/edit#heading=h.cn0nfi8o81o1 | Herding Alpacas\n",
      "https://forum.effectivealtruism.org/posts/gt6fPgRdEHJSLGd3N/thoughts-on-the-openai-alignment-plan-will-ai-research | Thoughts on the OpenAI alignment plan: will AI research assistants be net-positive for AI existential risk?\n",
      "https://www.alignmentforum.org/s/FN5Gj4JM6Xr7F4vts/p/3DFBbPFZyscrAiTKS | My Overview of the AI Alignment Landscape: Threat Models\n",
      "https://theinsideview.ai/ethan2 | https://theinsideview.ai/ethan2\n",
      "https://www.reddit.com/user/slavegirl123/ | (4) Reddit - Dive into anything\n",
      "https://forum.effectivealtruism.org/posts/8xNSiwj5gjoDTRquQ/announcing-the-publication-of-animal-liberation-now | Announcing the Publication of Animal Liberation Now - EA Forum\n",
      "https://twitter.com/jachiam0/status/1591494093766787076 | Joshua Achiam on Twitter: \"üßµ to clarify my views on AGI, timelines, and x-risk. TL;DR: My AGI timelines are short-ish (within two decades with things getting weird soon) and I think x-risk is real, but I think probabilities of doom by AGI instrumentally opting to kill us are greatly exaggerated. 1/\" / Twitter\n",
      "https://twitter.com/SocDoneLeft/status/1636573328583409664 | SDL on Twitter: \"@samaneller215 @peterwildeford @jonatanpallesen @jeffrsebo @RethinkPriors @remindmetweets RELEASE THE ü¶êSHRIMPü¶ê üóÉFILESüóÉ WHAT DOES BIG CRUSTACEAN HAVE TO HIDE?!\" / Twitter\n",
      "https://twitter.com/russellwald/status/1658852120563712000 | Russell Wald on Twitter: \"Two hearings on AI in the Senate in the same day are great! But one was sensational the other was substantive. What the fed gov does with its own AI policy has ripple effects across the AI landscape. https://t.co/Ib1soMKsPI\" / Twitter\n",
      "https://twitter.com/HaydnBelfield/status/1663678184720662538 | Haydn Belfield on Twitter: \"I don't think this is a credible response to this Statement, for the simple reason that the vast majority of signatories (250+ by my count) are university professors, with no incentive to 'distract from business models' or hype up companies' products https://t.co/YFuEM6a4WH\" / Twitter\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit#heading=h.u5ylt23gllew | [outdated] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1wYFyLk148hYK0OxOtNPfNu9l9XIjOPr3bNwzs6A4XpE/edit# | Copy of [Michael Aird, Feb 2023, manager-assessment] RP Performance Evaluation - Google Docs\n",
      "https://docs.google.com/document/d/10pSj7Jb68sPO0bQyw7cMswsMtx1A7tOGPxy3JbrLC8I/edit#heading=h.6rnrfpst2h9p | Thoughts on founder support preparation - Google Docs\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit#heading=h.tnew02vlmfya | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://twitter.com/lxrjl/status/1665033975696326657 | alex lawsen on Twitter: \"Quick thoughts on what recently increased attention on AI x-risk means for people who want to try to prevent it, as usual for this account this is my thoughts not an official 80k line. I'm even on holiday this week!\" / Twitter\n",
      "https://www.wikiwand.com/en/Hygge | Hygge - Wikiwand\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://twitter.com/daniel_271828/status/1620596689555058689 | https://twitter.com/daniel_271828/status/1620596689555058689\n",
      "https://twitter.com/i/communities/1492420299450724353 | https://twitter.com/i/communities/1492420299450724353\n",
      "https://forum.effectivealtruism.org/posts/bB2CSnFS6mEcNmPgD/the-costs-of-caution | The costs of caution - EA Forum\n",
      "https://manifold.markets/group/ce-2023-top-ideas | https://manifold.markets/group/ce-2023-top-ideas\n",
      "https://docs.google.com/document/d/1RMjcOgNwZWvBzfu5oB_llwAThk15QpGTLxy_eLBwVLE/edit | WIT Sequence #1 - Google Docs\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | A good Œ±lpha-Minus ‚ò∫Ô∏è on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://epochai.org/blog/power-laws-in-speedrunning-and-machine-learning | Power laws in Speedrunning and Machine Learning\n",
      "https://www.lesswrong.com/posts/AZHHEPYWvTovvtikz/human-level-diplomacy-was-my-fire-alarm | Human-level Diplomacy was my fire alarm\n",
      "https://forum.effectivealtruism.org/posts/DAD4777WJqFe9jZZM/a-flaw-in-a-simple-version-of-worldview-diversification | A flaw in a simple version of worldview diversification - EA Forum\n",
      "https://www.mynectar.com/ | Allergy Treatment & Alternative to Allergy Shots  Nectar\n",
      "https://blog.beeminder.com/tocks/ | Tocks  Beeminder Blog\n",
      "https://docs.google.com/document/d/12oQImZrUFiEgJzyG_1xGrulyEYL7UFckJJMKPDVnr9Y/edit | Forecasting Twitter list\n",
      "https://www.planned-obsolescence.org/is-it-time-for-a-pause/ | Is it time for a pause?\n",
      "https://www.lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk\n",
      "https://twitter.com/moskov/status/1661019398919057408 | Dustin Moskovitz on Twitter: \"Almost everyone replying to my thread yesterday can‚Äôt even imagine this. Objections to my premise are are all about improved scenarios around lockdowns and reactive vaccines, when I meant preventative measures we‚Äôre not even bothering to fund.\" / Twitter\n",
      "https://docs.google.com/document/d/1szG_6iGL1V2a_89AepyGs7lxg-UO1rp4TPGBL_MNSRg/edit#heading=h.z1m60iksdy8y | AI Message Testing Proposal - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/DW4FyzRTfBfNDWm6J/some-cruxes-on-impactful-alternatives-to-ai-policy-work | Some cruxes on impactful alternatives to AI policy work - EA Forum\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? ¬∑ Gwern.net\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/cCrpbZ4qTCEYXbzje | Ngo and Yudkowsky on scientific reasoning and pivotal acts\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/nPauymrHwpoNr6ipx | Conversation on technology forecasting and gradualism\n",
      "https://www.lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://twitter.com/Jsevillamol/status/1664673402387415040 | Jaime Sevilla on Twitter: \"The Riesgos Catastr√≥ficos Globales team has published a survey of concrete AI risks! They have talked to experts and reviewed the literature to summarize the concrete ways that present and future AI systems may cause harm. üßµ https://t.co/jjZI97kofB\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1660973340633227264 | Nathan is at EAG üîç (say hi üëã) on Twitter: \"My relationship learnings doc (very nsfw/honest) Don't read unless you want that. https://t.co/7RNCsnQLmY\" / Twitter\n",
      "https://twitter.com/Elliot__Davies/status/1654478733057613824 | Elliot Davies on Twitter: \"@peterwildeford The analogy to Stable Diffusion (which cost like 1000x less to train than Dalle 2) seems totally fair to me, what is it missing? Phrased differently, what's not to be spooked about assuming above statement is true?\" / Twitter\n",
      "https://docs.google.com/document/d/1SS8XmzHIaS_q7AcPNxKLbHK2kOa3PyPkXMS1Az1cQaM/edit#heading=h.nb2tkwr1m161 | Trading off compute in training and inference\n",
      "https://twitter.com/repligate/status/1653657915201290242 | janus on Twitter: \"highly specific demon https://t.co/TTyJcgfX4r\" / Twitter\n",
      "https://github.com/microsoft/guidance | microsoft/guidance: A guidance language for controlling large language models.\n",
      "https://docs.google.com/document/d/1-YmmnXkzaQA2AydAUPKVGHFbjDLCe2qck09IpmNBqcM/edit#heading=h.osty8jeclpyn | Rethink Priorities ‚Äî Insect Farming and Welfare Strategy - Google Docs\n",
      "https://twitter.com/CharlesD353/status/1664392860441927682 | Charles on Twitter: \"I feel pretty strongly that one should not put a sub 0.01% probability on anything that isn't a quite well understood phenomenon (e.g. p(win lottery)) or something that clearly violates physical laws IMO.\" / Twitter\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/7MCqRnZzvszsxgtJi | Christiano, Cotra, and Yudkowsky on AI progress\n",
      "https://forum.effectivealtruism.org/posts/myp9Y9qJnpEEWhJF9/linch-s-shortform?commentId=ymhXwLRhjAh2qEHeA | Linch's Shortform - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/4p8RpK2fYKFmEcA9w/optic-forecasting-comp-pilot-postmortem | OPTIC [Forecasting Comp] ‚Äî Pilot Postmortem - EA Forum\n",
      "https://twitter.com/alexbward/status/1659254496009101324 | https://twitter.com/alexbward/status/1659254496009101324\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://www.lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 ‚Äì Rodney Brooks\n",
      "https://www.google.com/search?q=neal+caffrey+prison+escape&rlz=1CDGOYI_enUS715US715&oq=neil+caffrey+pris&gs_lcrp=EgZjaHJvbWUqCAgBEAAYFhgeMgYIABBFGDkyCAgBEAAYFhge0gEJMTEyNjVqMGo0qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | neal caffrey prison escape - Google Search\n",
      "https://www.new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://manifold.markets/leagues | Manifold Markets\n",
      "https://forum.effectivealtruism.org/posts/JZEgmumeamzBAAprt/how-come-there-isn-t-that-much-focus-in-ea-on-research-into | How come there isn't that much focus in EA on research into whether / when AI's are likely to be sentient? - EA Forum\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://www.lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://twitter.com/tepelmacher/status/1655751424964464641 | Elliot Teperman on Twitter: \"Farmed Animal Funders is hiring an Executive Director! üéâüêîüê∑üêüüéâ Super exciting and important role in the farm animal protection ecosystem helping donors fight factory farming! Please share with your network and anyone that might be interested. https://t.co/UY7KIqcljA\" / Twitter\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/oKYWbXioKaANATxKY | Soares, Tallinn, and Yudkowsky discuss AGI cognition\n",
      "https://www.facebook.com/jsnorris/posts/pfbid0hWUY8Cmv7DHN1VeiXSCS2TrxeopEv9BDScP3aH77P8tXkhStaNPK5JCF23PwN3Tcl | James Norris - 6 minutes for Eliezer Yudkowsky to summarize 20+...  Facebook\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://www.lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://twitter.com/JeffLadish/status/1630881124858880000 | https://twitter.com/JeffLadish/status/1630881124858880000\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://forum.effectivealtruism.org/posts/Dq69kvjKyxQzKNRH7/seeking-expertise-to-improve-ea-organizations | Seeking expertise to improve EA organizations - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/G2vPqkCZkJusKGLtK/introducing-animal-policy-international | Introducing Animal Policy International - EA Forum\n",
      "https://twitter.com/ebriakou/status/1659259174293741571 | https://twitter.com/ebriakou/status/1659259174293741571\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This ü§Ø is a very big ü§Ø I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" https://t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/edardaman | https://twitter.com/edardaman\n",
      "https://forum.effectivealtruism.org/posts/vWRP8g8pqN9np4Aow/what-are-work-practices-that-you-ve-adopted-that-you-now | What are work practices that you‚Äôve adopted that you now think are underrated? - EA Forum\n",
      "https://twitter.com/robbensinger/status/1655331734047821824 | Rob Bensinger üîç on Twitter: \"@davidchalmers42 Here's my attempt to collect MIRI arguments (and a handful of non-MIRI arguments) for the five premises: https://t.co/mS5SqA1vCB. I also added some clarifications regarding what I mean by the premises. Other MIRI staff haven't reviewed it, so they might disagree with parts.\" / Twitter\n",
      "https://twitter.com/KofmanMichael/status/1659592846972788737 | https://twitter.com/KofmanMichael/status/1659592846972788737\n",
      "https://www.google.com/search?q=a+grief+observed&rlz=1C5CHFA_enUS925US925&oq=A+Grief+Observed&aqs=chrome.0.0i355i433i512j46i340i433i512l2j0i512l4j46i512j0i512l2.2909j0j1&sourceid=chrome&ie=UTF-8 | a grief observed - Google Search\n",
      "https://forum.effectivealtruism.org/posts/LZxXjkZDzvdEDFpxz/apply-now-first-ever-eagxnyc-this-august | Apply Now: First-Ever EAGxNYC This August\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky‚Äôs ‚ÄòMost Important Century‚Äô - EA Forum\n",
      "https://www.google.com/search?q=is+it+common+for+a+woman+to+have+twenty+sexual+partners&rlz=1CDGOYI_enUS715US715&oq=is+it+common+for+a+woman+to+have+twenty+sexual+partners&aqs=chrome..69i57.15480j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | is it common for a woman to have twenty sexual partners - Google Search\n",
      "https://twitter.com/messages/25776739-1551581042259132418 | john stuart chill / Twitter\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672\n",
      "https://twitter.com/ohlennart/status/1658893267570655232 | https://twitter.com/ohlennart/status/1658893267570655232\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8o | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://blog.beeminder.com/pomopoker/ | Pomodoro Poker  Beeminder Blog\n",
      "https://every.to/no-small-plans/a-founder-s-guide-to-expanding-your-comfort-zone | When You Plateau, So Does Your Company - No Small Plans - Every\n",
      "https://forum.effectivealtruism.org/posts/nTALzRAWxRnrxvoep/implications-of-the-whitehouse-meeting-with-ai-ceos-for-ai | Implications of the Whitehouse meeting with AI CEOs for AI superintelligence risk - a first-step towards evals? - EA Forum\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://gwern.net/fiction/clippy | It Looks Like You‚Äôre Trying To Take Over The World\n",
      "https://www.lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://www.youtube.com/watch?app=desktop&v=NXNCu6ekccw | Maud et Nicolas 2017 Comp√©tition Rock Avanc√© - YouTube\n",
      "https://www.lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts).\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on the US natsec community‚Äôs relationship to AI\n",
      "https://twitter.com/JeffLadish/status/1660709054950285318 | https://twitter.com/JeffLadish/status/1660709054950285318\n",
      "https://twitter.com/RethinkPriors/status/1659004160040226820 | https://twitter.com/RethinkPriors/status/1659004160040226820\n",
      "https://twitter.com/NathanpmYoung/status/1659855104328060929 | https://twitter.com/NathanpmYoung/status/1659855104328060929\n",
      "https://www.slowboring.com/p/doing-the-math-on-deficit-reduction | Doing the math on deficit reduction - by Matthew Yglesias\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://ealifestyles.substack.com/p/i-dont-want-to-talk-about-ai?sd=pf | I don't want to talk about ai - EA Lifestyles\n",
      "https://www.metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://docs.google.com/document/u/2/d/1fOCLx9srgcK3-oEKteAu-vTMAyXDEDPGyuIW4tcY6IA/edit | 2023 Altruistic Policy Telecon Agenda\n",
      "https://jobs.ashbyhq.com/openphilanthropy/e3a4e593-f8cd-4ae3-ab51-4f710222b9cc | Research Analyst / Junior Research Analyst - Biosecurity & Pandemic Preparedness @ Open Philanthropy\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://twitter.com/JGraabak/status/1659462285365059585 | Jakob Graabak on Twitter: \"*Longer runways*. Once things have fully settled down after the FTX fallout, I hope we all can agree that, as a norm, established projects should always have 1-2 years of runway\" / Twitter\n",
      "https://www.metaculus.com/questions/12326/student-debt-cancellation-blocked-by-2024/ | Student debt cancellation blocked by 2024?  Metaculus\n",
      "https://docs.google.com/document/d/1P5iIXobV9Ail-xSFI182xIt427HlWENMEsjQMyJIM0Q/edit# | May/June notes on Caro - Google Docs\n",
      "https://direct-approach-feedback.web.app/blog/direct-approach-interactive-model | Direct Approach Interactive Model\n",
      "https://twitter.com/spencemo_c/status/1647790750535667713 | Spencerüôèüîçüìöü•ïüö≤üßò‚Äç‚ôÇÔ∏èüöêüåê on Twitter: \"@peterwildeford For now. What odds would you set for party Id #s to stay within ~15% of total (eg 35% total, d/r 25-45) in 1/2/3/5 years\" / Twitter\n",
      "https://docs.google.com/document/d/1x3OjJQffC-TOPGMTBXGKFJ7kX_u7BT7z1CX3SuuMX94/edit#heading=h.e09t5a8o01r2 | Longtermism / existential risk / existential security framing - Google Docs\n",
      "https://twitter.com/frances__lorenz/status/1656642985038151681 | Frances Lorenz on Twitter: \"hey cuties, really sad to have to take this public, but @mealreplacer recently sent me this violent tiktok (https://t.co/BH8OC3JWHH), anyways I think I might have to bully him off this platform\" / Twitter\n",
      "https://app.swapcard.com/messages/channel/a0cdf139-86f6-44f2-845c-7823690f77c5?chatUserId=VXNlcl8xMzQzNzI3OA%3D%3D | https://app.swapcard.com/messages\n",
      "https://twitter.com/messages/25776739-103418485 | Twitter\n",
      "https://twitter.com/StephenLCasper/status/1656179296086691843 | Stephen Casper on Twitter: \"Thread: [1/4] I'm underwhelmed by OpenAI's work on \"automating interpretability\". I don't think it's a very big step forward for interpretability or safety. I think they're trying to hype this up to be much more than it is.\" / Twitter\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1655663054544310272 | Daniel Eth on Twitter: \"NOTE: the account @danieI_eth (with a capital \"i\" instead of a lowercase \"L\" for the last name) is impersonating me. Please go and report them! https://t.co/p6c8xZwqCy\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/cP7gkDFxgJqHDGdfJ/ea-and-longtermism-not-a-crux-for-saving-the-world | EA and Longtermism: not a crux for saving the world - EA Forum\n",
      "https://twitter.com/JgaltTweets/status/1654974738706444290 | JgaltTweets on Twitter: \"'The situation in the area of the Zaporozhye NPP \"is becoming increasingly unpredictable and potentially dangerous,\" the Director General said. \"I‚Äôm extremely concerned about the very real nuclear safety and security risks facing the plant,\" he noted.'\" / Twitter\n",
      "https://docs.google.com/document/d/1EZ1TgTnJ6zt_-JuhboXJwEDZ7r4R2D8WnOzLE7DphUg/edit | What would it look like to regulate AI like bio and nuclear? - Google Docs\n",
      "https://docs.google.com/document/d/1X9nKas72w_MRIte7sdeBsNSl_rek-j1kk8r18zRQrEw/edit | Funding application: Condor Camp 2023 - Google Docs\n",
      "https://www.metaculus.com/questions/9062/time-from-weak-agi-to-superintelligence/ | Time From (weak) AGI to Superintelligence  Metaculus\n",
      "https://docs.google.com/document/d/1CpO25iV38hXESPRQZmv15bLjBB_hrAYgAkvfHoJbngE/edit#heading=h.j9owozbw0x7p | Layer - Safety Culture - Google Docs\n",
      "https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance | How your data is used to improve model performance  OpenAI Help Center\n",
      "https://www.facebook.com/yudkowsky/posts/pfbid0KkfKmLvmtKNnPATgwi2bDWNZDrVqXYsth8gticx72Dk3XdiRdBcYYYpRfz3kGRjBl | The problem with making decision theory... - Eliezer Yudkowsky  Facebook\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/gf9hhmSvpZfyfS34B | Ngo's view on alignment difficulty\n",
      "https://docs.google.com/document/d/1fLL5BZf8VdhdEQ9uNDne6mp8sNTmgUJSOJ8LQxaZVFI/edit#heading=h.ahaokbxu01um | How bad/good would shorter AI timelines be? Why? [writeup idea + notes + reading list]\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=1888482782 | PTO Report Effective Jan 1, 2023 - Managers - Google Sheets\n",
      "https://docs.google.com/document/d/1rdsErwdQxdOPtOU3bCaWFTMmTMxNWqmNXJgzAl0y3TE/edit | EIP grant recommendations [shared] - Google Docs\n",
      "https://twitter.com/tamaybes/status/1651297219822116867 | Tamay Besiroglu on Twitter: \"Can we use scaling laws to estimate what is required to reach 'human level' on some arbitrary task? Our (speculative) framework suggests yes. We show that scaling laws provide insight into the *horizons* over which outputs are indistinguishable from human-generated outputs. https://t.co/eRfHGiVohZ\" / Twitter\n",
      "https://www.bbc.com/worklife/article/20201026-why-healthy-neurotics-can-thrive-in-stressful-times | Why ‚Äòhealthy neurotics‚Äô can thrive in stressful times - BBC Worklife\n",
      "https://twitter.com/_akhaliq/status/1659076009772171264 | https://twitter.com/_akhaliq/status/1659076009772171264\n",
      "https://noahpinion.substack.com/p/2023-is-when-the-empires-strike-back | 2023 is when the empires strike back - by Noah Smith\n",
      "https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware | Chatting Our Way Into Creating a Polymorphic Malware\n",
      "https://forum.effectivealtruism.org/posts/LgscQde9vQW4xLrjC/on-child-wasting-mega-charities-and-measurability-bias | On Child Wasting, Mega-Charities, and Measurability Bias - EA Forum\n",
      "https://twitter.com/TetraspaceWest/status/1659283551831879698 | tetraspace is at EAG londonüíé on Twitter: \"I've noticed two slightly-conflated arguments about why you want safety guarantees in AGI. Named by replacing \"AGI\" with a different thing: \"If you're not sure that a gun isn't loaded, then it's loaded\" \"If you're not sure that your cryptography is secure, then it's insecure\"\" / Twitter\n",
      "https://docs.google.com/document/d/1SbGV0Nc-Nh6WYkTNQ7QUxnbi9kRw0XsMwSqmBk0U0eM/edit | [Private] EAIF Vision and Scope - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1656595723155292162 | (2) Nathan üîç (DM me ideas of things to predict) on Twitter: \"üéâü§ñüìà New Nathan Post üìàü§ñüéâ AI Risk/Reward Probability Model All models are wrong, but some are useful. I'm wrong, but how? I will bet on or retract any number in the following thread. https://t.co/m27djOXPAy\" / Twitter\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://docs.google.com/document/d/1VSypWxtDRjP5bPsmmvIcvbvHg7RE7o3XZVI3P5ltMdk/edit#heading=h.8ei4qtw0vfk0 | Josh Jacobson: Jam 1-1 about x-risk entrepreneurship (25 April 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://drive.google.com/drive/u/1/folders/1Ql6jcg3xnkDD8f5qh9hNM7t4HRv6_XQN | Uncertainty Workshop 3 (April 19, 2023) - Employee Resources - Google Drive\n",
      "https://www.scmp.com/tech/tech-war/article/3219623/chinese-leader-xi-jinping-urges-country-seize-opportunities-artificial-intelligence-modernise | Chinese leader Xi Jinping urges country to seize opportunities in artificial intelligence to modernise industry  South China Morning Post\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://twitter.com/Simeon_Cps/status/1654457947819311104 | Sim√©on on Twitter: \"I think that comments like \"Don't make proposal X for AGI safety because it's not feasible/people will never accept to do it\" is currently a strategy people should be very wary of. 1) Currently, public opinion &amp; policy discussions are moving extremely fast so it's hard to be‚Ä¶\" / Twitter\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay, detect, defend\n",
      "https://twitter.com/xuanalogue/status/1658813589858181121 | https://twitter.com/xuanalogue/status/1658813589858181121\n",
      "https://docs.google.com/document/d/1zxQGQfDeD7uTnUoJ2_L47jKWvSoancgtEsH4Zd6NAt4/edit#heading=h.ow22kk7tct5w | XST retreat 2023 ‚Äì Schedule and Discussion notes - Google Docs\n",
      "https://arxiv.org/ftp/arxiv/papers/2206/2206.09360.pdf | 2206.09360.pdf\n",
      "https://www.bloomberg.com/news/articles/2023-05-02/alphabet-microsoft-other-firms-to-attend-white-house-meeting-on-ai-safeguards?leadSource=uverify%2520wall | Alphabet, Microsoft Among Tech Firms to Attend AI Meeting at White House - Bloomberg\n",
      "https://clarifyingconsequences.substack.com/p/half-baked-ideas-defining-and-measuring | Change my mind: we should define and measure the effectiveness of advanced AI\n",
      "https://docs.google.com/document/d/1ZkO0L37_sWDMJ32hl9hV0HpOqNDQvQsxHDyk4bLSU28/edit#heading=h.gcqpcr8adw7o | RP <> GovAI 23-May-2023 - Overview of our respective work - Google Docs\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://docs.google.com/document/d/1sMH8fibfO602ZsttAjjxq4bBld5xn5UwuIraIInwTzs/edit#heading=h.z1512e3souac | (Forum copy) Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://twitter.com/PatientPersists/status/1654489679096344578 | Siebe. on Twitter: \"@peterwildeford Btw random share, but I've been reading \"How Democracies Die\" by Steven Levitsky and it's really good. Also lots of stuff invoicing Supreme Courts\" / Twitter\n",
      "https://twitter.com/labenz/status/1654853321876815872 | https://twitter.com/labenz/status/1654853321876815872\n",
      "https://twitter.com/jkcarlsmith/status/1655720268156010498 | Joe Carlsmith on Twitter: \"How worried about AI risk will we feel in the future, when we can see advanced machine intelligence up close? We should worry accordingly now. I wrote an essay about this: https://t.co/cJoVCh8Pus https://t.co/pn46hN2Lzr\" / Twitter\n",
      "https://rychappell.substack.com/p/review-of-the-good-it-promises-the | Review of The Good It Promises, the Harm It Does\n",
      "https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://twitter.com/MassDara/status/1655205051999178752 | Dara Massicot on Twitter: \"Prigozhin's publicity campaign yields results: Wagner to get weapons/ammo, and Surovikin is named as Wagner-MOD liaison. I can only speculate on the level of Kremlin intervention here. Shoigu and Gerasimov still retain the means to play their long game &amp; isolate their rivals.\" / Twitter\n",
      "https://drive.google.com/file/d/12Pj4o8ainEbBE8hUliQ_P0yTzMIhG6Pe/view | Hurwit Memo re RP Organizational Health 5-11-23.pdf - Google Drive\n",
      "https://docs.google.com/document/d/15XU5QDOSJw5DimExN-bvXggqYwg-h_x116Z2Yuwz0i0/edit | D1 1500: Strat I - Strategic Context and High-Level Goals\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://docs.google.com/document/d/1UOUK8hMxDD0WlM6jEbjI9dWyC73yulOEtoU2MWYaooA/edit#heading=h.tufvzyw73c4q | Updates on AIGS team strategy etc. [April 2023; DRAFT] - Google Docs\n",
      "https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/vwLxd6hhFvPbvKmBH | https://www.alignmentforum.org/s/n945eovrA3oDueqtq/p/vwLxd6hhFvPbvKmBH\n",
      "https://www.sambowman.co/p/democracy-is-the-solution-to-vetocracy | Democracy is the solution to vetocracy - by Sam Bowman\n",
      "https://docs.google.com/document/d/1KJx_GhV3A8c2leu4hisMDO7sciY49p8BygQAfbJ1mXw/edit#heading=h.tjvfcbqz2mvz | Founder search leads list - Google Docs\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://twitter.com/goodside/status/1661907164250750979 | Riley Goodside on Twitter: \"Really enjoying this paper. A deep case study in what LLMs actually learn and how their mimicry differs from faithful simulation. If you‚Äôve used LLMs for coding you‚Äôve seen how the loops aren‚Äôt really run. This is what they do instead.\" / Twitter\n",
      "https://twitter.com/emollick/status/1651439624693207040 | https://twitter.com/emollick/status/1651439624693207040\n",
      "https://catalist.us/whathappened2022/ | What Happened in 2022  Catalist\n",
      "https://twitter.com/birchlse/status/1659883804662591490 | https://twitter.com/birchlse/status/1659883804662591490\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tabs)\n",
    "print_tabs(tabs, label='Shuffled all tabs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
