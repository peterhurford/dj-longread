{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "334\n",
      "334\n",
      "334\n",
      "334\n",
      "332\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs_from_text(tab_text):\n",
    "    tabs = tab_text.split('\\n')\n",
    "    print('{} tabs opened!'.format(len(tabs)))\n",
    "    for t in tabs:\n",
    "        open_tab(t.split('|')[0].strip())\n",
    "        \n",
    "print('Loaded')\n",
    "\n",
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5fddf1-e942-4059-b414-48e28bdc58f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabs! (332)\n",
      "-\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://abs! (458) | \n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI ‚Äì AI Impacts\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities ‚Äì AI Impacts\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://airtable.com/appQbatI4fkmVLxHl/tblO0RqaTPXiz0jjp/viwo2rnDB1Py3Fisy?blocks=hide | Redux Again Again: Org Management - Airtable\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://askamanager.org/2012/02/dealing-with-domestic-abuse-in-the-workplace.html | dealing with domestic abuse in the workplace ‚Äî Ask a Manager\n",
      "https://askamanager.org/2023/05/i-think-my-employee-is-being-abused-by-her-partner.html | I think my employee is being abused by her partner ‚Äî Ask a Manager\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST‚Äôs AI Risk Management Framework plants a flag in the AI debate\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://cbsnews.com/news/india-train-accident-error-signaling-system-cause-railway-official/ | India train accident caused by signal system error, official says - CBS News\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities‚Äô Strategy: 2024 ‚Äì 2025 - Google Docs\n",
      "https://docs.google.com/document/d/15OerqofHlipOYys0h8ls2YqjLNCk2BwXKsETGlXINSo/edit | Surveys Squad Meeting Agendas - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://docs.google.com/document/d/1OiRXw-YbzYwRTs27SMVK8IDtyA1y_kYDKAUSvjAIBtU/edit | Laptop setup - Google Docs\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows ‚Äì 2023/06/07 - Google Docs\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1Z8nhklNjtdswXLCoaw25uqalCZHun3axWbJI850VXs0/edit | XST Funder Tracker - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings ‚Äì 2023 Q2-Q3 - Google Docs\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro - Google Docs\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain‚Äôs AI dreams reality\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://exploratory-altruism.org/team-partners/ | Team & Partners ‚Äì Centre for exploratory altruism research\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl | facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://facebook.com/messages/t/692924124/ | Messenger  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://facebook.com/photo/?fbid=1292510184710822&set=gm.1988967891457920&idorvanity=1317320115289371 | Facebook\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection ¬∑ Getting started with tpot\n",
      "https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864 | No, GPT4 can‚Äôt ace MIT\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion‚Äôs AI Benefactor Has A History Of Exaggeration\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power‚Äôs Staying Power\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge ‚Äî Forgotten Trek\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky‚Äôs ‚ÄòMost Important Century‚Äô - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‚ÄòDissolving‚Äô AI Risk ‚Äì Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://forum.effectivealtruism.org/users/caroj?from=post_header | CaroJ - EA Forum\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://gwern.net/fiction/clippy | It Looks Like You‚Äôre Trying To Take Over The World\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? ¬∑ Gwern.net\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model ‚Äì Deconfusion Device ‚Äì Failing to understand the world, learning a little along the way\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life‚Ä¶  by K. Mintner  Jun, 2023  Medium\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson‚Äôs latest AI risk position statement - LessWrong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://manifold.markets/NathanHelmBurger/will-gpt5-be-capable-of-recursive-s | Will GPT-5 be capable of recursive self-improvement?  Manifold Markets\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out ‚Ä¶\" - Mastodon\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology ‚Äî Maximum Progress\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech‚Ä¶  by Elizabeth Ayer  Medium\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk ‚Äì musings and rough drafts\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment ‚Ä¢ The Lunar - Podcast Addict\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact ‚Äî Rethink Priorities\n",
      "https://rochanconsulting.substack.com/p/ukraine-conflict-monitor-82a | Ukraine Conflict Monitor - by Konrad Muzyka\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 ‚Äì Rodney Brooks\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds ‚Äì The sideways view\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It‚Äôs infuriatingly hard to understand how closed models train on their input\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women‚Äôs Pleasure\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The ‚Äúpercentogram‚Äù‚Äîa histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI‚Äôs Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us ‚Äî and can we make it safe?\n",
      "https://theworkback.com/asana-ai-principles/ | Asana‚Äôs 5 guiding principles for human-centered AI\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com¬Æ - USPS Tracking¬Æ Results\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | Œ±lpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won‚Äôt)üßµ t.co/23ErIoRIsk\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok üèóÔ∏èüöÄ on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith üêáüá∫üá¶ on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload‚Äîe.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This ü§Ø is a very big ü§Ø I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://twitter.com/messages/25776739-363201363 | Micha≈Ç Dubrawski - Standing with üá∫üá¶ / Twitter\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | S√©b Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here‚Äôs a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. üèõ t.co/1Grjv93laf\" / Twitter\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I‚Äôm honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ŸÑ()(ŸÑ() 'yoav))))üëæ on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans‚Äô Rights and Safety\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won‚Äôt take it over by playing ‚Äú3-dimensional chess‚Äù. ‚Äì Windows On Theory\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety ‚Äì Windows On Theory\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak ‚Äì Windows On Theory\n"
     ]
    }
   ],
   "source": [
    "tabs = ['https://' + t for t in sorted([t.replace('http://', '').replace('https://', '').replace('www.', '') for t in tabs])]\n",
    "\n",
    "print('Tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df311d-c9c6-4ace-a7c9-7ed21b34d78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled tabs! (332)\n",
      "-\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows ‚Äì 2023/06/07 - Google Docs\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds ‚Äì The sideways view\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ŸÑ()(ŸÑ() 'yoav))))üëæ on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It‚Äôs infuriatingly hard to understand how closed models train on their input\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology ‚Äî Maximum Progress\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://forum.effectivealtruism.org/users/caroj?from=post_header | CaroJ - EA Forum\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women‚Äôs Pleasure\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 ‚Äì Rodney Brooks\n",
      "https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864 | No, GPT4 can‚Äôt ace MIT\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment ‚Ä¢ The Lunar - Podcast Addict\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://manifold.markets/NathanHelmBurger/will-gpt5-be-capable-of-recursive-s | Will GPT-5 be capable of recursive self-improvement?  Manifold Markets\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com¬Æ - USPS Tracking¬Æ Results\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge ‚Äî Forgotten Trek\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain‚Äôs AI dreams reality\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I‚Äôm honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://facebook.com/photo/?fbid=1292510184710822&set=gm.1988967891457920&idorvanity=1317320115289371 | Facebook\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://airtable.com/appQbatI4fkmVLxHl/tblO0RqaTPXiz0jjp/viwo2rnDB1Py3Fisy?blocks=hide | Redux Again Again: Org Management - Airtable\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety ‚Äì Windows On Theory\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk ‚Äì musings and rough drafts\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://docs.google.com/document/d/15OerqofHlipOYys0h8ls2YqjLNCk2BwXKsETGlXINSo/edit | Surveys Squad Meeting Agendas - Google Docs\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl | facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | Œ±lpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload‚Äîe.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://askamanager.org/2023/05/i-think-my-employee-is-being-abused-by-her-partner.html | I think my employee is being abused by her partner ‚Äî Ask a Manager\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1OiRXw-YbzYwRTs27SMVK8IDtyA1y_kYDKAUSvjAIBtU/edit | Laptop setup - Google Docs\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection ¬∑ Getting started with tpot\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? ¬∑ Gwern.net\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://theworkback.com/asana-ai-principles/ | Asana‚Äôs 5 guiding principles for human-centered AI\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ t.co/Nikto4prZV\" / Twitter\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak ‚Äì Windows On Theory\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://facebook.com/messages/t/692924124/ | Messenger  Facebook\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out ‚Ä¶\" - Mastodon\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The ‚Äúpercentogram‚Äù‚Äîa histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI ‚Äì AI Impacts\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok üèóÔ∏èüöÄ on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST‚Äôs AI Risk Management Framework plants a flag in the AI debate\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power‚Äôs Staying Power\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model ‚Äì Deconfusion Device ‚Äì Failing to understand the world, learning a little along the way\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://docs.google.com/document/d/1Z8nhklNjtdswXLCoaw25uqalCZHun3axWbJI850VXs0/edit | XST Funder Tracker - Google Docs\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life‚Ä¶  by K. Mintner  Jun, 2023  Medium\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky‚Äôs ‚ÄòMost Important Century‚Äô - EA Forum\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech‚Ä¶  by Elizabeth Ayer  Medium\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact ‚Äî Rethink Priorities\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://gwern.net/fiction/clippy | It Looks Like You‚Äôre Trying To Take Over The World\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion‚Äôs AI Benefactor Has A History Of Exaggeration\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://exploratory-altruism.org/team-partners/ | Team & Partners ‚Äì Centre for exploratory altruism research\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://twitter.com/messages/25776739-363201363 | Micha≈Ç Dubrawski - Standing with üá∫üá¶ / Twitter\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This ü§Ø is a very big ü§Ø I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans‚Äô Rights and Safety\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won‚Äôt)üßµ t.co/23ErIoRIsk\" / Twitter\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us ‚Äî and can we make it safe?\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson‚Äôs latest AI risk position statement - LessWrong\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://rochanconsulting.substack.com/p/ukraine-conflict-monitor-82a | Ukraine Conflict Monitor - by Konrad Muzyka\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://abs! (458) | \n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI‚Äôs Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro - Google Docs\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‚ÄòDissolving‚Äô AI Risk ‚Äì Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://askamanager.org/2012/02/dealing-with-domestic-abuse-in-the-workplace.html | dealing with domestic abuse in the workplace ‚Äî Ask a Manager\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith üêáüá∫üá¶ on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool ‚Äî AI ‚Ä¢ Objectives ‚Ä¢ Institute\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities ‚Äì AI Impacts\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won‚Äôt take it over by playing ‚Äú3-dimensional chess‚Äù. ‚Äì Windows On Theory\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings ‚Äì 2023 Q2-Q3 - Google Docs\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://cbsnews.com/news/india-train-accident-error-signaling-system-cause-railway-official/ | India train accident caused by signal system error, official says - CBS News\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | S√©b Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here‚Äôs a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. üèõ t.co/1Grjv93laf\" / Twitter\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities‚Äô Strategy: 2024 ‚Äì 2025 - Google Docs\n"
     ]
    }
   ],
   "source": [
    "print('Shuffled tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "random.shuffle(tabs)\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7eece4-8649-45d2-bd1f-5d0e2554c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tabs opened!\n"
     ]
    }
   ],
   "source": [
    "open_tabs_from_text(\"\"\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cec14-6156-40a7-90b6-9498596a18b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
