{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs(tabs, page=1, per_page=10):\n",
    "    page_start = (page - 1) * per_page\n",
    "    total_pages = int(np.ceil(len(tabs) / per_page))\n",
    "    if page > total_pages:\n",
    "        raise ValueError('Cannot open page {}, only have {} pages'.format(page, total_pages))\n",
    "    page_end = page * per_page\n",
    "    if page_end > len(tabs):\n",
    "        page_end = len(tabs)\n",
    "    paged_tabs = tabs[page_start:page_end]\n",
    "    print('Opening page {}/{} (tabs {}-{} of {})'.format(page, total_pages, page_start, page_end, len(tabs)))\n",
    "    \n",
    "    for tab in paged_tabs:\n",
    "        open_tab(tab)\n",
    "\n",
    "        \n",
    "def open_random_n_tabs(tabs, n=5):\n",
    "    tabs = random.sample(tabs, len(tabs))\n",
    "    open_tabs(tabs, page=1, per_page=n)\n",
    "    return tabs[5:]\n",
    "\n",
    "        \n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "471\n",
      "471\n",
      "470\n",
      "469\n"
     ]
    }
   ],
   "source": [
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Messages ## (2 tabs)\n",
      "\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower())], label='Messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c2b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Facebook ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if 'facebook.com' in t.lower() and 'messages' not in t.lower()], label='Facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d6e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Twitter ## (104 tabs)\n",
      "\n",
      "https://twitter.com/RichardMCNgo/status/1644309681358159873 | Richard Ngo on Twitter: \"It's very important to choose your intellectual opponents wisely; I think the alignment community could do this much better. It's easy to focus on the loudest critics. But the silent majority can often already see their mistakes, and want ideas tested against stronger opponents.\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What’s the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/WSJ/status/1646993010373132288 | The Wall Street Journal on Twitter: \"Elon Musk has created a new artificial intelligence company called https://t.co/61zh22yDCS that is incorporated in Nevada https://t.co/2lWIrZGDIw\" / Twitter\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://twitter.com/krishnanrohit/status/1646484052646547456 | https://twitter.com/krishnanrohit/status/1646484052646547456\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter 上的 Boaz Barak：\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds…\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1609933725604929537 | Ben Kuhn on Twitter: \"People sometimes ask me the hardest decision I've made as a manager. My hot take is that actually ~no particular call is too hard. What's hard (in a fast growing org) is what I think of as the \"decision firehose\"—life comes at you too fast to even make all the easy calls well.\" / Twitter\n",
      "https://twitter.com/a_m_mastroianni/status/1645851495974281218 | Adam Mastroianni on Twitter: \"There are two kinds of problems: strong-link problems and weak-link problems. Weak-link: quality depends on how good the *worst* things are Strong-link: quality depends on how good the *best* things are https://t.co/8pllaxfRzo\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1646558364137029655 | (1) Shakeel on Twitter: \"So many criticisms of AI regulation come down to \"but what about China\". This seems to miss the fact that without access to high-end GPUs (e.g. Nvidia A100 and H100, which China doesn't have access to anymore), China cannot build highly-advanced AI systems.\" / Twitter\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's a🧵. 1/10\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Eth💡 on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Eth💡 on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: • People are starting to wake up to idea that AGI might not be that far away • Worries about AI X-risk aren't actually that complicated • Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/peterhartree/status/1646777653352087556 | Peter Hartree on Twitter: \"GPT-4 can autonomously synthesise aspirin in a cloud lab. Novel compounds too… https://t.co/eWe3xSoHL8 https://t.co/I6i5upaECZ\" / Twitter\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can’t learn from because they would rather have recriminations.\" / Twitter\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend 😂 https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://twitter.com/boazbaraktcs/status/1646524501855981569 | Boaz Barak on Twitter: \"1/9 A thread with pictures about my blog on AI safety https://t.co/LszJU36Hcv First, as AI gets integrated with our society, safety is paramount. However more powerful systems not necessarily riskier.\" / Twitter\n",
      "https://twitter.com/SofiaHCBBG/status/1646803872655060992 | Sofia Horta e Costa on Twitter: \"All of this happened in China this week. A thread. 1/10\" / Twitter\n",
      "https://twitter.com/dharmesh/status/1646581646030786560 | dharmesh on Twitter: \"\"We are *not* currently training GPT-5. We're working on doing more things with GPT-4.\" @sama at MIT\" / Twitter\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?🧵 https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1646479826629345282 | (1) Nathan 🔍 (DM me ideas of things to predict) on Twitter: \"ladies and gentlemen, the @FinancialTimes https://t.co/dQ2V5g0JZI\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan 🔍 on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nuño Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what “unicorn” means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://twitter.com/NathanLands/status/1643563068759130112 | Nathan Lands on Twitter: \"Thought Q1 was crazy? It's about to get even crazier with \"AutoGPTs\"! 🤯 Google is in big trouble. Here's why:\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Eth💡 on Twitter: \"@peterwildeford @StefanFSchubert Money that isn’t used on AI risk reduction can also be saved for later - I think it’s pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger 🔍 on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers… https://t.co/gWU49p7asN\" / Twitter\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | Sully on Twitter: \"Whoa.. still not convinced of AI Agents? This might change your mind... I pretended to be a fake shoe company and gave AutoGPT a simple objective: - Do market research for waterproof shoes - Get the top 5 competitors and give me a report of their pros &amp; cons Here's how it went: https://t.co/mFttG4PXrk\" / Twitter\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://twitter.com/swyx/status/1644352579462369280 | https://twitter.com/swyx/status/1644352579462369280\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | Sam Bowman on Twitter: \"I’m sharing a draft of a slightly-opinionated survey paper I’ve been working on for the last couple of months. It's meant for a broad audience—not just LLM researchers. (🧵) https://t.co/sukGTb9cZC\" / Twitter\n",
      "https://twitter.com/labenz/status/1646508947669393408 | Nathan Labenz on Twitter: \"I’ve said “GPT-4 can’t do science”, but this new paper says it can “Emergent autonomous scientific research capabilities of LLMs” This would be the first GPT-4 capability that I tried &amp; failed to demonstrate during Red Team testing Will report back! https://t.co/pdkEqC7NAz\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" This👇is a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger 🔍 on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1646796408329236482 | Jeffrey Ladish on Twitter: \"Interesting thread on AutoGPTs, programmatic scaffolding that allows GPT-4 to store content to a database, and repeatedly call itself to help carry out steps in a plan. It will be very interesting to see how good these frameworks get\" / Twitter\n",
      "https://twitter.com/DanHendrycks/status/1646899553319403521 | Dan Hendrycks on Twitter: \"Since Senator Schumer is pushing for Congress to regulate AI, here are five promising AI policy ideas: * external red teaming * interagency oversight commission * internal audit committees * external incident investigation team * safety research funding (🧵below)\" / Twitter\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it 👏 - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don’t think it’s very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a “mechanistic” level. We need a different kind of interpretability.\" / Twitter\n",
      "https://twitter.com/ohlennart/status/1645058017119854592 | Lennart Heim on Twitter: \"It's not that simple to throw $1B of compute on a single model. You can only scale the number of chips and increase the length of the training. $1B would mean ~160,000 TPUv4 chips for 6 months (or even more, the bigger the discount). I'm not aware of clusters of this size. 🧵1/ https://t.co/J6tEkpFLc9\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | Séb Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1646817534237347841 | Daniel Eth💡 on Twitter: \"@peterwildeford Do you have a clip for this segment?\" / Twitter\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://twitter.com/jjvincent/status/1646854261349777410 | James Vincent on Twitter: \"Sam Altman has confirmed OpenAI is not training GPT-5 and 'won’t for some time.' if you're worried about AI safety, though, I don't think this is a meaningful statement. i wrote a little about why, and the AI world's treatment of vague metrics: https://t.co/SpQpXEp0b4 https://t.co/f1AemX3SnR\" / Twitter\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/EchelonInsights/status/1646261614520287232 | https://twitter.com/EchelonInsights/status/1646261614520287232\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Eth💡 on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there’s a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft’s prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or… https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental…\" / Twitter\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine’s Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their “AGI roadmap” 👀 I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z…\" / Twitter\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos 🏴‍☠️ on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd…\" / Twitter\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Eth💡 on Twitter: \"So GPT-4 is able to prompt injection attack itself…\" / Twitter\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@🏡) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I’m not a security expert, but overall I’m impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. 🧵 on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI — one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes 🧵\" / Twitter\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ✨🧠📈⚛️📈🦾📈🤖📈✨ on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 🤯 It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! 🔥 https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Eth💡 on Twitter: \"This is my answer to the question “why might an AI attempt takeover before it was confident it could win?” and correspondingly one reason I think we’ll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We’re “pivoting” Elicit with GPT-4 😉 Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to “pivot” it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… https://t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n"
     ]
    }
   ],
   "source": [
    "twitter_tabs = sorted([t for t in tabs if 'twitter.com' in t.lower() and 'messages' not in t.lower()])\n",
    "print_tabs(twitter_tabs, label='Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8d623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(twitter_tabs, page=1, per_page=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4635d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google Docs ## (176 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/10_Co_t2cduhCWri7bw7Pm7iMMKUNvEjw0dEyMOEYMwE/edit# | [second draft] Updated prioritisation model + process - Google Docs\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here 🤠 - Google Docs\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | Two hypothetical \"success story\" nearcasts - Google Docs\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance – Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/12yOxzRW8hrEVR_wUXtGDmOmwjm94DTgWBnfDC5v-pXU/edit?pli=1#heading=h.hbn3g4b3o4xg | Longtermism (LT) hiring - standing meetings - 2022-2023 - Google Docs\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit#heading=h.fctpogr60cwp | Jannik Schilling <> Ben 2023-03-27 - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey’s work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/100F5jl6l94LmE9eI6rBeql5cXa79qjh3QvuMl6184fA/edit#gid=79902821 | 2023 Apr Lights - Google Sheets\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/1RtM3Ix7NwWilcTGeS_Jla60RpURrQl6zbrQO1RDKXcI/edit#heading=h.i86pzhzf9drt | Project plan: Founder support - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1-XmkDaopuz6vQPF2D-wmPJmqmaNYSEUF_cKwZJ6_c44/edit#heading=h.qvtjdr95relh | Peter <> Michael - 1-1s - 2022 Q4 & 2023 Q1 - Google Docs\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=867920322 | PTO Report Effective Jan 1, 2023 - Managers\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit#heading=h.j7w06lr7knz3 | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit#heading=h.s3e88e9gt76x | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit#heading=h.1wg6rarmxccd | Cybersecurity for AI policy and governance - Google Docs\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit#heading=h.il6vz7ptaefx | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI’s People, Programs, and Research [November 2022; Funder Copy] - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/1SbGV0Nc-Nh6WYkTNQ7QUxnbi9kRw0XsMwSqmBk0U0eM/edit | [Private] EAIF Vision and Scope - Google Docs\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop “Aligned” AI, What’s the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 “Expert Survey on Progress in AI” survey - Google Docs\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1UOUK8hMxDD0WlM6jEbjI9dWyC73yulOEtoU2MWYaooA/edit# | Updates on AIGS team strategy etc. [April 2023; DRAFT] - Google Docs\n",
      "https://docs.google.com/document/d/1Z4sam-7rOxDgrYOkEj60CdGf1HsBmA_1y5P9LphB96M/edit | Introductory email for AI adversarial collaboration project (\"AI concerned\" camp) - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit#heading=h.zcigfw87auta | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://docs.google.com/document/d/1myLSKVWsR3XnwENN_2hJTkFk7qwi2ZC2ebaE_rWyT9E/edit | New Hires Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://drive.google.com/drive/u/1/folders/1uLBBm_DC4Z8XdlwFe_1wfd2LsZdgvvoU | Uncertainty Workshop 2 (April 3, 2023) - Employee Resources - Google Drive\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/spreadsheets/d/1f9vdJ2gawzhfUmF2T3SYw4ho_hwwyvQjAqDmUt7c7ck/edit#gid=0 | MOCHA for RP Communications subteam (March 2023) - Google Sheets\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit#heading=h.bvjsvl1l7r2e | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit# | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I’m considering for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://docs.google.com/document/d/1JRTPn9g-3lmu9iF-MsZDZemP6yH1On5-BMKOOdubYSM/edit | AI x-risk model pseudocode - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit#heading=h.7x9f7hw35ztc | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit#heading=h.897xbq127gy6 | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit#heading=h.eq0rk0ee0vgs | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: “Primers” on the internal organizational structure of leading AI labs and/or on x-risk-concerned people’s social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl – 2023/01/27 - Google Docs\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success without dignity: a nearcasting story of avoiding catastrophe by luck - Google Docs\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it’s for, and how to use it - Google Docs\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://docs.google.com/document/d/1lG6_8CrS3PuCSrZQLyWL2Sd5dYAzfdgluHk24FD13nI/edit | AIGS team OKRs for 2023 [draft]\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://docs.google.com/document/d/18lcwJow6J64YI2SMvDHP5QSkWEeoQ0oX_RLZfEgMXhk/edit# | Memo: RP, EA, and our relationship to the community - Google Docs\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n"
     ]
    }
   ],
   "source": [
    "doc_tabs = sorted([t for t in tabs if ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower())])\n",
    "print_tabs(doc_tabs, label='Google Docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(doc_tabs, page=1, per_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479f45a0-d63f-474d-aa76-2ddab5a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = copy(doc_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e71249-4e0e-47aa-9fcd-69b9219f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = open_random_n_tabs(doc_tabs_, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6311fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google search ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('google.com' in t.lower() and 'search' in t.lower() and\n",
    "                                   not ('docs.google' in t.lower() or 'sheets.google' in t.lower()))]),\n",
    "           label='Google search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b9762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EAFo/LW ## (23 tabs)\n",
      "\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarassment - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/hw8ePRLJop7kSEZK3/ais-accelerating-ai-research | AIs accelerating AI research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://www.lesswrong.com/posts/Ccv8PinXRgRTKpGaj/what-we-ve-learned-so-far-from-our-technological-temptations | What we’ve learned so far from our technological temptations project - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & “The correct response to uncertainty is *not* half-speed” - EA Forum\n",
      "https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities | AGI Ruin: A List of Lethalities - LessWrong\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://www.lesswrong.com/posts/jkY6QdCfAXHJk3kea/the-petertodd-phenomenon | The ‘ petertodd’ phenomenon - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/LpNzsWd6AhKaLrnb6/impact-accelerator-program-for-ea-professionals | Impact Accelerator Program for EA Professionals - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Qoecey2umNjcqEGHP/apply-to-greater-than-30-ai-safety-funders-in-one#comments | Apply to >30 AI safety funders in one application with the Nonlinear Network - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/2DzLY6YP2z5zRDAGA/a-freshman-year-during-the-ai-midgame-my-approach-to-the | A freshman year during the AI midgame: my approach to the next year - EA Forum\n"
     ]
    }
   ],
   "source": [
    "ea_fo_tabs = sorted([t for t in tabs if ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower())])\n",
    "print_tabs(ea_fo_tabs, label='EAFo/LW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffa8f80-4aa6-4afe-8c6a-59194d69895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(ea_fo_tabs, page=1, per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ae2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metaculus etc. ## (12 tabs)\n",
      "\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower())]), label='Metaculus etc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72bdaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Wikipedia ## (9 tabs)\n",
      "\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('wikipedia' in t.lower() or 'wikiwand' in t.lower())]), label='Wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reddit ## (2 tabs)\n",
      "\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'reddit' in t.lower()]), label='Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedf293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## localhost ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()]), label='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677f610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Chores ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instacart' in t.lower()]), label='Chores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fce865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Amazon ## (2 tabs)\n",
      "\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'amazon.com' in t.lower()]), label='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d46af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Morning Dispatch ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'morning' in t.lower() and 'dispatch' in t.lower()]), label='Morning Dispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "108d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GitHub ## (8 tabs)\n",
      "\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://github.com/jmcarpenter2/swifter | jmcarpenter2/swifter: A package which efficiently applies any function to a pandas dataframe or series in the fastest available manner\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'github.com' in t.lower()]), label='GitHub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d911bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube ## (7 tabs)\n",
      "\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together “Audio” ft. Rita Ora - YouTube\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'yout' in t.lower()]), label='YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2649c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instagram ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instagram.com' in t.lower()]), label='Instagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab0e02f2-e275-486f-98d3-37d3218dc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asana ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'app.asana.com' in t.lower()]), label='Asana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc70c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Other ## (126 tabs)\n",
      "\n",
      "https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | Subscribe to read  Financial Times\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized » Blog Archive » Should GPT exist?\n",
      "https://www.axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://www.eagoodgovernance.com/organizations | Organizations — EA Good Governance Project\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4’s successes, and GPT-4’s failures - by Gary Marcus\n",
      "https://noahpinion.substack.com/p/europe-is-not-ready-to-be-a-third | Europe is not ready to be a \"third superpower\"\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://sites.google.com/view/adaptive-agent/ | Home\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? – The Scholar's Stage\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://substack.com/notes?utm_source=feed-email-digest | (3) Notes  Substack\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman | OpenAI’s CEO confirms the company isn’t training GPT-5 and ‘won’t for some time’ - The Verge\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy’s Newsletter  Substack\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://epochai.org/blog/announcing-trends-dashboard | Announcing Epoch’s dashboard of key trends and figures in Machine Learning\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://www.alignmentforum.org/s/aERZoriyHfCqvWkzg | Modeling Transformative AI Risk (MTAIR) - AI Alignment Forum\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://arxiv.org/pdf/2304.05332.pdf | Emergent autonomous scientific research capabilities of large language models\n",
      "https://openai.com/blog/planning-for-agi-and-beyond?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://open.spotify.com/user/carory | Spotify – carory\n",
      "https://warontherocks.com/2023/04/how-large-language-models-can-revolutionize-military-planning/ | HOW LARGE-LANGUAGE MODELS CAN REVOLUTIONIZE MILITARY PLANNING\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell’s Uncertainty Problem – MetaCausal\n",
      "https://www.dask.org/ | Dask  Scale the Python tools you love\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell’s Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more…) – Shotgun Debugging\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) — First Year in Review\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://blog.givewell.org/2023/04/10/expected-funds-raised-through-2025/ | How much funding does GiveWell expect to raise through 2025?\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs · Gwern.net\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/ | Why ChatGPT and Bing Chat are so good at making things up  Ars Technica\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | (3) Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://quorumapp.com/ | Quorum\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism – AI Impacts\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II — Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://www.amrfundingcircle.com/ | https://www.amrfundingcircle.com/\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://warontherocks.com/2023/04/ais-inhuman-advantage/ | AI’s Inhuman Advantage - War on the Rocks\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://warontherocks.com/episode/the-insider/28581/ais-inhuman-advantage/ | AI's Inhuman Advantage - War on the Rocks\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://ruyacoffee.com/ | Rüya Coffee  For the Immigrant Dream\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world’s hottest technology with billions from Microsoft  Fortune\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - AI Alignment Forum\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? – AI Impacts\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022) – Adapt Research Ltd\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity’s demise: “we must eliminate them” - Dexerto\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‘could kill everyone’  News  The Times\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett’s Blog\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n"
     ]
    }
   ],
   "source": [
    "tabs_ = [t for t in tabs if (not ('google.com' in t.lower() and 'search' in t.lower() and not ('docs.google' in t.lower() or 'sheets.google' in t.lower())) and\n",
    "                             not ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower()) and\n",
    "                             not 'facebook.com' in t.lower() and\n",
    "                             not 'twitter.com' in t.lower() and\n",
    "                             not ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower()) and\n",
    "                             not ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower()) and\n",
    "                             not ('wikipedia' in t.lower() or 'wikiwand' in t.lower()) and\n",
    "                             not 'reddit' in t.lower() and\n",
    "                             not 'instagram.com' in t.lower() and\n",
    "                             not ('guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()) and\n",
    "                             not 'instacart' in t.lower() and\n",
    "                             not ('morning' in t.lower() and 'dispatch' in t.lower()) and\n",
    "                             not 'amazon.com' in t.lower() and\n",
    "                             not 'github' in t.lower() and\n",
    "                             not 'calendar.google' in t.lower() and\n",
    "                             not 'yout' in t.lower() and\n",
    "                             not 'app.asana.com' in t.lower() and\n",
    "                             not ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower()))]\n",
    "tabs_ = sorted(tabs_)\n",
    "print_tabs(tabs_, label='Other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a2a7bb-86f9-45bd-b8d6-ed8889caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(tabs_, page=1, per_page=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c128ee3-03e2-4cfb-bfd1-0dfc84775af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shuffled all tabs ## (469 tabs)\n",
      "\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://warontherocks.com/2023/04/how-large-language-models-can-revolutionize-military-planning/ | HOW LARGE-LANGUAGE MODELS CAN REVOLUTIONIZE MILITARY PLANNING\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don’t think it’s very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a “mechanistic” level. We need a different kind of interpretability.\" / Twitter\n",
      "https://quorumapp.com/ | Quorum\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022) – Adapt Research Ltd\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://twitter.com/DanHendrycks/status/1646899553319403521 | Dan Hendrycks on Twitter: \"Since Senator Schumer is pushing for Congress to regulate AI, here are five promising AI policy ideas: * external red teaming * interagency oversight commission * internal audit committees * external incident investigation team * safety research funding (🧵below)\" / Twitter\n",
      "https://warontherocks.com/episode/the-insider/28581/ais-inhuman-advantage/ | AI's Inhuman Advantage - War on the Rocks\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Eth💡 on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & “The correct response to uncertainty is *not* half-speed” - EA Forum\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Eth💡 on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: • People are starting to wake up to idea that AGI might not be that far away • Worries about AI X-risk aren't actually that complicated • Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/krishnanrohit/status/1646484052646547456 | https://twitter.com/krishnanrohit/status/1646484052646547456\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds…\" / Twitter\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop “Aligned” AI, What’s the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more…) – Shotgun Debugging\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://www.amrfundingcircle.com/ | https://www.amrfundingcircle.com/\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://docs.google.com/document/d/12yOxzRW8hrEVR_wUXtGDmOmwjm94DTgWBnfDC5v-pXU/edit?pli=1#heading=h.hbn3g4b3o4xg | Longtermism (LT) hiring - standing meetings - 2022-2023 - Google Docs\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://open.spotify.com/user/carory | Spotify – carory\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://forum.effectivealtruism.org/posts/2DzLY6YP2z5zRDAGA/a-freshman-year-during-the-ai-midgame-my-approach-to-the | A freshman year during the AI midgame: my approach to the next year - EA Forum\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy’s Newsletter  Substack\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://twitter.com/NathanLands/status/1643563068759130112 | Nathan Lands on Twitter: \"Thought Q1 was crazy? It's about to get even crazier with \"AutoGPTs\"! 🤯 Google is in big trouble. Here's why:\" / Twitter\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what “unicorn” means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://twitter.com/jjvincent/status/1646854261349777410 | James Vincent on Twitter: \"Sam Altman has confirmed OpenAI is not training GPT-5 and 'won’t for some time.' if you're worried about AI safety, though, I don't think this is a meaningful statement. i wrote a little about why, and the AI world's treatment of vague metrics: https://t.co/SpQpXEp0b4 https://t.co/f1AemX3SnR\" / Twitter\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) — First Year in Review\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit#heading=h.7x9f7hw35ztc | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://twitter.com/ohlennart/status/1645058017119854592 | Lennart Heim on Twitter: \"It's not that simple to throw $1B of compute on a single model. You can only scale the number of chips and increase the length of the training. $1B would mean ~160,000 TPUv4 chips for 6 months (or even more, the bigger the discount). I'm not aware of clusters of this size. 🧵1/ https://t.co/J6tEkpFLc9\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their “AGI roadmap” 👀 I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z…\" / Twitter\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://docs.google.com/document/d/10_Co_t2cduhCWri7bw7Pm7iMMKUNvEjw0dEyMOEYMwE/edit# | [second draft] Updated prioritisation model + process - Google Docs\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I’m not a security expert, but overall I’m impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. 🧵 on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit#heading=h.bvjsvl1l7r2e | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nuño Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl – 2023/01/27 - Google Docs\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit#heading=h.897xbq127gy6 | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://www.eagoodgovernance.com/organizations | Organizations — EA Good Governance Project\n",
      "https://www.axios.com/2023/04/13/congress-regulate-ai-tech | Scoop: Schumer lays groundwork for Congress to regulate AI\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/Qoecey2umNjcqEGHP/apply-to-greater-than-30-ai-safety-funders-in-one#comments | Apply to >30 AI safety funders in one application with the Nonlinear Network - EA Forum\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger 🔍 on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here 🤠 - Google Docs\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 “Expert Survey on Progress in AI” survey - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit# | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://sites.google.com/view/adaptive-agent/ | Home\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance – Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism – AI Impacts\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarassment - LessWrong\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman | OpenAI’s CEO confirms the company isn’t training GPT-5 and ‘won’t for some time’ - The Verge\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? – The Scholar's Stage\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://docs.google.com/document/d/1-XmkDaopuz6vQPF2D-wmPJmqmaNYSEUF_cKwZJ6_c44/edit#heading=h.qvtjdr95relh | Peter <> Michael - 1-1s - 2022 Q4 & 2023 Q1 - Google Docs\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | Subscribe to read  Financial Times\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://warontherocks.com/2023/04/ais-inhuman-advantage/ | AI’s Inhuman Advantage - War on the Rocks\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… https://t.co/Nikto4prZV\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/hw8ePRLJop7kSEZK3/ais-accelerating-ai-research | AIs accelerating AI research - EA Forum\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs · Gwern.net\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=867920322 | PTO Report Effective Jan 1, 2023 - Managers\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit#heading=h.1wg6rarmxccd | Cybersecurity for AI policy and governance - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit#heading=h.eq0rk0ee0vgs | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://twitter.com/swyx/status/1644352579462369280 | https://twitter.com/swyx/status/1644352579462369280\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4’s successes, and GPT-4’s failures - by Gary Marcus\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://forum.effectivealtruism.org/posts/LpNzsWd6AhKaLrnb6/impact-accelerator-program-for-ea-professionals | Impact Accelerator Program for EA Professionals - EA Forum\n",
      "https://drive.google.com/drive/u/1/folders/1uLBBm_DC4Z8XdlwFe_1wfd2LsZdgvvoU | Uncertainty Workshop 2 (April 3, 2023) - Employee Resources - Google Drive\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Z4sam-7rOxDgrYOkEj60CdGf1HsBmA_1y5P9LphB96M/edit | Introductory email for AI adversarial collaboration project (\"AI concerned\" camp) - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit#heading=h.il6vz7ptaefx | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://www.lesswrong.com/posts/jkY6QdCfAXHJk3kea/the-petertodd-phenomenon | The ‘ petertodd’ phenomenon - LessWrong\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" This👇is a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Eth💡 on Twitter: \"This is my answer to the question “why might an AI attempt takeover before it was confident it could win?” and correspondingly one reason I think we’ll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1646817534237347841 | Daniel Eth💡 on Twitter: \"@peterwildeford Do you have a clip for this segment?\" / Twitter\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit#heading=h.fctpogr60cwp | Jannik Schilling <> Ben 2023-03-27 - Google Docs\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Eth💡 on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there’s a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://substack.com/notes?utm_source=feed-email-digest | (3) Notes  Substack\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft’s prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or… https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend 😂 https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | Sully on Twitter: \"Whoa.. still not convinced of AI Agents? This might change your mind... I pretended to be a fake shoe company and gave AutoGPT a simple objective: - Do market research for waterproof shoes - Get the top 5 competitors and give me a report of their pros &amp; cons Here's how it went: https://t.co/mFttG4PXrk\" / Twitter\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together “Audio” ft. Rita Ora - YouTube\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‘could kill everyone’  News  The Times\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://github.com/jmcarpenter2/swifter | jmcarpenter2/swifter: A package which efficiently applies any function to a pandas dataframe or series in the fastest available manner\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://docs.google.com/document/d/1SbGV0Nc-Nh6WYkTNQ7QUxnbi9kRw0XsMwSqmBk0U0eM/edit | [Private] EAIF Vision and Scope - Google Docs\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can’t learn from because they would rather have recriminations.\" / Twitter\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://twitter.com/benskuhn/status/1609933725604929537 | Ben Kuhn on Twitter: \"People sometimes ask me the hardest decision I've made as a manager. My hot take is that actually ~no particular call is too hard. What's hard (in a fast growing org) is what I think of as the \"decision firehose\"—life comes at you too fast to even make all the easy calls well.\" / Twitter\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://twitter.com/WSJ/status/1646993010373132288 | The Wall Street Journal on Twitter: \"Elon Musk has created a new artificial intelligence company called https://t.co/61zh22yDCS that is incorporated in Nevada https://t.co/2lWIrZGDIw\" / Twitter\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://ruyacoffee.com/ | Rüya Coffee  For the Immigrant Dream\n",
      "https://twitter.com/ShakeelHashim/status/1646558364137029655 | (1) Shakeel on Twitter: \"So many criticisms of AI regulation come down to \"but what about China\". This seems to miss the fact that without access to high-end GPUs (e.g. Nvidia A100 and H100, which China doesn't have access to anymore), China cannot build highly-advanced AI systems.\" / Twitter\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's a🧵. 1/10\" / Twitter\n",
      "https://docs.google.com/document/d/1UOUK8hMxDD0WlM6jEbjI9dWyC73yulOEtoU2MWYaooA/edit# | Updates on AIGS team strategy etc. [April 2023; DRAFT] - Google Docs\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://arxiv.org/pdf/2304.05332.pdf | Emergent autonomous scientific research capabilities of large language models\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | Two hypothetical \"success story\" nearcasts - Google Docs\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://twitter.com/EchelonInsights/status/1646261614520287232 | https://twitter.com/EchelonInsights/status/1646261614520287232\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell’s Uncertainty Problem – MetaCausal\n",
      "https://openai.com/blog/planning-for-agi-and-beyond?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/ | Why ChatGPT and Bing Chat are so good at making things up  Ars Technica\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1lG6_8CrS3PuCSrZQLyWL2Sd5dYAzfdgluHk24FD13nI/edit | AIGS team OKRs for 2023 [draft]\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@🏡) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://twitter.com/JeffLadish/status/1646796408329236482 | Jeffrey Ladish on Twitter: \"Interesting thread on AutoGPTs, programmatic scaffolding that allows GPT-4 to store content to a database, and repeatedly call itself to help carry out steps in a plan. It will be very interesting to see how good these frameworks get\" / Twitter\n",
      "https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities | AGI Ruin: A List of Lethalities - LessWrong\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter 上的 Boaz Barak：\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://twitter.com/RichardMCNgo/status/1644309681358159873 | Richard Ngo on Twitter: \"It's very important to choose your intellectual opponents wisely; I think the alignment community could do this much better. It's easy to focus on the loudest critics. But the silent majority can often already see their mistakes, and want ideas tested against stronger opponents.\" / Twitter\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II — Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit#heading=h.s3e88e9gt76x | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://twitter.com/boazbaraktcs/status/1646524501855981569 | Boaz Barak on Twitter: \"1/9 A thread with pictures about my blog on AI safety https://t.co/LszJU36Hcv First, as AI gets integrated with our society, safety is paramount. However more powerful systems not necessarily riskier.\" / Twitter\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: “Primers” on the internal organizational structure of leading AI labs and/or on x-risk-concerned people’s social/political capital with AI labs - Google Docs\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?🧵 https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://twitter.com/dharmesh/status/1646581646030786560 | dharmesh on Twitter: \"\"We are *not* currently training GPT-5. We're working on doing more things with GPT-4.\" @sama at MIT\" / Twitter\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://twitter.com/labenz/status/1646508947669393408 | Nathan Labenz on Twitter: \"I’ve said “GPT-4 can’t do science”, but this new paper says it can “Emergent autonomous scientific research capabilities of LLMs” This would be the first GPT-4 capability that I tried &amp; failed to demonstrate during Red Team testing Will report back! https://t.co/pdkEqC7NAz\" / Twitter\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett’s Blog\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1JRTPn9g-3lmu9iF-MsZDZemP6yH1On5-BMKOOdubYSM/edit | AI x-risk model pseudocode - Google Docs\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://docs.google.com/document/d/1myLSKVWsR3XnwENN_2hJTkFk7qwi2ZC2ebaE_rWyT9E/edit | New Hires Reading List - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Eth💡 on Twitter: \"So GPT-4 is able to prompt injection attack itself…\" / Twitter\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey’s work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it’s for, and how to use it - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental…\" / Twitter\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | (3) Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I’m considering for 2023 - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized » Blog Archive » Should GPT exist?\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://www.alignmentforum.org/s/aERZoriyHfCqvWkzg | Modeling Transformative AI Risk (MTAIR) - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers… https://t.co/gWU49p7asN\" / Twitter\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What’s the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success without dignity: a nearcasting story of avoiding catastrophe by luck - Google Docs\n",
      "https://blog.givewell.org/2023/04/10/expected-funds-raised-through-2025/ | How much funding does GiveWell expect to raise through 2025?\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://aypan17.github.io/machiavelli/ | The MACHIAVELLI Benchmark\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity’s demise: “we must eliminate them” - Dexerto\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? – AI Impacts\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it 👏 - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1646479826629345282 | (1) Nathan 🔍 (DM me ideas of things to predict) on Twitter: \"ladies and gentlemen, the @FinancialTimes https://t.co/dQ2V5g0JZI\" / Twitter\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://twitter.com/peterhartree/status/1646777653352087556 | Peter Hartree on Twitter: \"GPT-4 can autonomously synthesise aspirin in a cloud lab. Novel compounds too… https://t.co/eWe3xSoHL8 https://t.co/I6i5upaECZ\" / Twitter\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit#heading=h.zcigfw87auta | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI — one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes 🧵\" / Twitter\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos 🏴‍☠️ on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd…\" / Twitter\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/100F5jl6l94LmE9eI6rBeql5cXa79qjh3QvuMl6184fA/edit#gid=79902821 | 2023 Apr Lights - Google Sheets\n",
      "https://epochai.org/blog/announcing-trends-dashboard | Announcing Epoch’s dashboard of key trends and figures in Machine Learning\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI’s People, Programs, and Research [November 2022; Funder Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1f9vdJ2gawzhfUmF2T3SYw4ho_hwwyvQjAqDmUt7c7ck/edit#gid=0 | MOCHA for RP Communications subteam (March 2023) - Google Sheets\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | Sam Bowman on Twitter: \"I’m sharing a draft of a slightly-opinionated survey paper I’ve been working on for the last couple of months. It's meant for a broad audience—not just LLM researchers. (🧵) https://t.co/sukGTb9cZC\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | Séb Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger 🔍 on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/a_m_mastroianni/status/1645851495974281218 | Adam Mastroianni on Twitter: \"There are two kinds of problems: strong-link problems and weak-link problems. Weak-link: quality depends on how good the *worst* things are Strong-link: quality depends on how good the *best* things are https://t.co/8pllaxfRzo\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://twitter.com/SofiaHCBBG/status/1646803872655060992 | Sofia Horta e Costa on Twitter: \"All of this happened in China this week. A thread. 1/10\" / Twitter\n",
      "https://twitter.com/leopoldasch/status/1643384705088364544 | Leopold Aschenbrenner on Twitter: \"GPT-4 can encode secret messages (and hide them from a user) (!!)\" / Twitter\n",
      "https://docs.google.com/document/d/1RtM3Ix7NwWilcTGeS_Jla60RpURrQl6zbrQO1RDKXcI/edit#heading=h.i86pzhzf9drt | Project plan: Founder support - Google Docs\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We’re “pivoting” Elicit with GPT-4 😉 Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to “pivot” it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://noahpinion.substack.com/p/europe-is-not-ready-to-be-a-third | Europe is not ready to be a \"third superpower\"\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit#heading=h.j7w06lr7knz3 | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan 🔍 on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://www.lesswrong.com/posts/Ccv8PinXRgRTKpGaj/what-we-ve-learned-so-far-from-our-technological-temptations | What we’ve learned so far from our technological temptations project - LessWrong\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine’s Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.dask.org/ | Dask  Scale the Python tools you love\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Eth💡 on Twitter: \"@peterwildeford @StefanFSchubert Money that isn’t used on AI risk reduction can also be saved for later - I think it’s pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ✨🧠📈⚛️📈🦾📈🤖📈✨ on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 🤯 It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! 🔥 https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell’s Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/18lcwJow6J64YI2SMvDHP5QSkWEeoQ0oX_RLZfEgMXhk/edit# | Memo: RP, EA, and our relationship to the community - Google Docs\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world’s hottest technology with billions from Microsoft  Fortune\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tabs)\n",
    "print_tabs(tabs, label='Shuffled all tabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875f10-ecdd-43fd-b849-196c6bd1977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
