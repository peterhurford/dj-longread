{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs(tabs, page=1, per_page=10):\n",
    "    page_start = (page - 1) * per_page\n",
    "    total_pages = int(np.ceil(len(tabs) / per_page))\n",
    "    if page > total_pages:\n",
    "        raise ValueError('Cannot open page {}, only have {} pages'.format(page, total_pages))\n",
    "    page_end = page * per_page\n",
    "    if page_end > len(tabs):\n",
    "        page_end = len(tabs)\n",
    "    paged_tabs = tabs[page_start:page_end]\n",
    "    print('Opening page {}/{} (tabs {}-{} of {})'.format(page, total_pages, page_start, page_end, len(tabs)))\n",
    "    \n",
    "    for tab in paged_tabs:\n",
    "        open_tab(tab)\n",
    "\n",
    "        \n",
    "def open_random_n_tabs(tabs, n=5):\n",
    "    tabs = random.sample(tabs, len(tabs))\n",
    "    open_tabs(tabs, page=1, per_page=n)\n",
    "    return tabs[5:]\n",
    "\n",
    "        \n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n",
      "529\n",
      "529\n",
      "529\n",
      "529\n"
     ]
    }
   ],
   "source": [
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Messages ## (3 tabs)\n",
      "\n",
      "https://www.facebook.com/messages/t/547821577/ | Messenger  Facebook\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower())], label='Messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c2b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Facebook ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if 'facebook.com' in t.lower() and 'messages' not in t.lower()], label='Facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d6e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Twitter ## (111 tabs)\n",
      "\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://twitter.com/catehall/status/1646355120396062722 | https://twitter.com/catehall/status/1646355120396062722\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1646479826629345282 | (1) Nathan üîç (DM me ideas of things to predict) on Twitter: \"ladies and gentlemen, the @FinancialTimes https://t.co/dQ2V5g0JZI\" / Twitter\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter ‰∏äÁöÑ Boaz BarakÔºö\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | Sully on Twitter: \"Whoa.. still not convinced of AI Agents? This might change your mind... I pretended to be a fake shoe company and gave AutoGPT a simple objective: - Do market research for waterproof shoes - Get the top 5 competitors and give me a report of their pros &amp; cons Here's how it went: https://t.co/mFttG4PXrk\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/emollick/status/1645432299587026944 | https://twitter.com/emollick/status/1645432299587026944\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine‚Äôs Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it üëè - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://twitter.com/krishnanrohit/status/1646484052646547456 | https://twitter.com/krishnanrohit/status/1646484052646547456\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://twitter.com/wintonARK/status/1645861531920531456 | Brett Winton on Twitter: \"I legit don‚Äôt understand how a ~$150m forecasting budget can yield long-term energy forecasts that are so consistently wildly wrong. In what universe does US electric vehicle sales share saturate at 14%? https://t.co/YM2JMV3Ew6\" / Twitter\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n"
     ]
    }
   ],
   "source": [
    "twitter_tabs = sorted([t for t in tabs if 'twitter.com' in t.lower() and 'messages' not in t.lower()])\n",
    "print_tabs(twitter_tabs, label='Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8d623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(twitter_tabs, page=1, per_page=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4635d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google Docs ## (208 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit#heading=h.8vzpa5yuzee4 | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | Two hypothetical \"success story\" nearcasts - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1f9vdJ2gawzhfUmF2T3SYw4ho_hwwyvQjAqDmUt7c7ck/edit#gid=0 | MOCHA for RP Communications subteam (March 2023) - Google Sheets\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://docs.google.com/document/d/12yOxzRW8hrEVR_wUXtGDmOmwjm94DTgWBnfDC5v-pXU/edit?pli=1#heading=h.hbn3g4b3o4xg | Longtermism (LT) hiring - standing meetings - 2022-2023 - Google Docs\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit# | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=867920322 | PTO Report Effective Jan 1, 2023 - Managers\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success without dignity: a nearcasting story of avoiding catastrophe by luck - Google Docs\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://drive.google.com/drive/u/1/folders/1uLBBm_DC4Z8XdlwFe_1wfd2LsZdgvvoU | Uncertainty Workshop 2 (April 3, 2023) - Employee Resources - Google Drive\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register - April 2023 Finalized\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://docs.google.com/document/d/1lG6_8CrS3PuCSrZQLyWL2Sd5dYAzfdgluHk24FD13nI/edit | AIGS team OKRs for 2023 [draft]\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit#heading=h.eq0rk0ee0vgs | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [November 2022; Funder Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://docs.google.com/document/d/1YdtearE-rcd8UA34IPe4uW_pBSUzPjOeGOjc68oZfEQ/edit# | [PUBLIC] Marketing data visualisations - Google Docs\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://docs.google.com/document/d/1eN3HfVShkVJw-D7yk_nXZf0OLiP6Cm9H2cVGrKwk2l4/edit | Dev&Comms point people\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit# | Jannik Schilling <> Ben 2023-03-27 - Google Docs\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit#heading=h.bvjsvl1l7r2e | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://docs.google.com/document/d/17eE-PTFTrisGNJgHjtnDrbsH2tsmDAGKOs5Ku3cOTkM/edit# | [Shared] - CH&SP team's ideas on what to ask on RP's follow-up survey - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://docs.google.com/document/d/1RtM3Ix7NwWilcTGeS_Jla60RpURrQl6zbrQO1RDKXcI/edit#heading=h.i86pzhzf9drt | Project plan: Founder support - Google Docs\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit#heading=h.j7w06lr7knz3 | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit#heading=h.897xbq127gy6 | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n"
     ]
    }
   ],
   "source": [
    "doc_tabs = sorted([t for t in tabs if ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower())])\n",
    "print_tabs(doc_tabs, label='Google Docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(doc_tabs, page=1, per_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479f45a0-d63f-474d-aa76-2ddab5a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = copy(doc_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e71249-4e0e-47aa-9fcd-69b9219f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = open_random_n_tabs(doc_tabs_, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6311fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google search ## (1 tabs)\n",
      "\n",
      "https://www.google.com/search?q=chaos+gpt&rlz=1C1GCEA_enGB993GB993&sxsrf=APwXEdfDrsc7CTFBEUhij_z8R-U-YNslqg:1681232294309&source=lnms&tbm=vid&sa=X&ved=2ahUKEwjksL-tpqL-AhXMWMAKHUc6BTUQ_AUoAnoECAEQBA&biw=767&bih=732&dpr=1.25 | chaos gpt - Google Search\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('google.com' in t.lower() and 'search' in t.lower() and\n",
    "                                   not ('docs.google' in t.lower() or 'sheets.google' in t.lower()))]),\n",
    "           label='Google search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b9762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EAFo/LW ## (20 tabs)\n",
      "\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & ‚ÄúThe correct response to uncertainty is *not* half-speed‚Äù - EA Forum\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/hw8ePRLJop7kSEZK3/ais-accelerating-ai-research | AIs accelerating AI research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://forum.effectivealtruism.org/posts/gmzrYzpR9zb8um5FK/ea-rationality-sexual-assault-and-liability | EA, Rationality, Sexual Assault, and Liability - EA Forum\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/Qoecey2umNjcqEGHP/apply-to-greater-than-30-ai-safety-funders-in-one#comments | Apply to >30 AI safety funders in one application with the Nonlinear Network - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarassment - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zQ7b9ghv3Tkd2LLNL/an-ea-s-guide-to-washington-dc | An EA's Guide to Washington DC - EA Forum\n"
     ]
    }
   ],
   "source": [
    "ea_fo_tabs = sorted([t for t in tabs if ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower())])\n",
    "print_tabs(ea_fo_tabs, label='EAFo/LW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffa8f80-4aa6-4afe-8c6a-59194d69895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(ea_fo_tabs, page=1, per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ae2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metaculus etc. ## (18 tabs)\n",
      "\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower())]), label='Metaculus etc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72bdaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Wikipedia ## (9 tabs)\n",
      "\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('wikipedia' in t.lower() or 'wikiwand' in t.lower())]), label='Wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reddit ## (3 tabs)\n",
      "\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'reddit' in t.lower()]), label='Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedf293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## localhost ## (1 tabs)\n",
      "\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()]), label='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677f610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Chores ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instacart' in t.lower()]), label='Chores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fce865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Amazon ## (3 tabs)\n",
      "\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'amazon.com' in t.lower()]), label='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d46af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Morning Dispatch ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'morning' in t.lower() and 'dispatch' in t.lower()]), label='Morning Dispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "108d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GitHub ## (11 tabs)\n",
      "\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'github.com' in t.lower()]), label='GitHub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d911bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube ## (11 tabs)\n",
      "\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'yout' in t.lower()]), label='YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2649c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instagram ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instagram.com' in t.lower()]), label='Instagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab0e02f2-e275-486f-98d3-37d3218dc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asana ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'app.asana.com' in t.lower()]), label='Asana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc70c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Other ## (133 tabs)\n",
      "\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity‚Äôs demise: ‚Äúwe must eliminate them‚Äù - Dexerto\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - AI Alignment Forum\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://openai.com/blog/planning-for-agi-and-beyond?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://substack.com/notes?utm_source=feed-email-digest | (3) Notes  Substack\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022) ‚Äì Adapt Research Ltd\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://www.alignmentforum.org/s/aERZoriyHfCqvWkzg | Modeling Transformative AI Risk (MTAIR) - AI Alignment Forum\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://80000hours.org/about/credibility/evaluations/mistakes/ | Our mistakes - 80,000 Hours\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://arxiv.org/pdf/2304.05332.pdf | Emergent autonomous scientific research capabilities of large language models\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://warontherocks.com/2023/04/ais-inhuman-advantage/ | AI‚Äôs Inhuman Advantage - War on the Rocks\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | (3) Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://epochai.org/blog/announcing-trends-dashboard | Announcing Epoch‚Äôs dashboard of key trends and figures in Machine Learning\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | Subscribe to read  Financial Times\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://sites.google.com/view/adaptive-agent/ | Home\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n"
     ]
    }
   ],
   "source": [
    "tabs_ = [t for t in tabs if (not ('google.com' in t.lower() and 'search' in t.lower() and not ('docs.google' in t.lower() or 'sheets.google' in t.lower())) and\n",
    "                             not ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower()) and\n",
    "                             not 'facebook.com' in t.lower() and\n",
    "                             not 'twitter.com' in t.lower() and\n",
    "                             not ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower()) and\n",
    "                             not ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower()) and\n",
    "                             not ('wikipedia' in t.lower() or 'wikiwand' in t.lower()) and\n",
    "                             not 'reddit' in t.lower() and\n",
    "                             not 'instagram.com' in t.lower() and\n",
    "                             not ('guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()) and\n",
    "                             not 'instacart' in t.lower() and\n",
    "                             not ('morning' in t.lower() and 'dispatch' in t.lower()) and\n",
    "                             not 'amazon.com' in t.lower() and\n",
    "                             not 'github' in t.lower() and\n",
    "                             not 'calendar.google' in t.lower() and\n",
    "                             not 'yout' in t.lower() and\n",
    "                             not 'app.asana.com' in t.lower() and\n",
    "                             not ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower()))]\n",
    "tabs_ = sorted(tabs_)\n",
    "print_tabs(tabs_, label='Other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a2a7bb-86f9-45bd-b8d6-ed8889caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(tabs_, page=1, per_page=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c128ee3-03e2-4cfb-bfd1-0dfc84775af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shuffled all tabs ## (529 tabs)\n",
      "\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit#heading=h.8vzpa5yuzee4 | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://docs.google.com/document/d/17eE-PTFTrisGNJgHjtnDrbsH2tsmDAGKOs5Ku3cOTkM/edit# | [Shared] - CH&SP team's ideas on what to ask on RP's follow-up survey - Google Docs\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://twitter.com/emollick/status/1645432299587026944 | https://twitter.com/emollick/status/1645432299587026944\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://www.google.com/search?q=chaos+gpt&rlz=1C1GCEA_enGB993GB993&sxsrf=APwXEdfDrsc7CTFBEUhij_z8R-U-YNslqg:1681232294309&source=lnms&tbm=vid&sa=X&ved=2ahUKEwjksL-tpqL-AhXMWMAKHUc6BTUQ_AUoAnoECAEQBA&biw=767&bih=732&dpr=1.25 | chaos gpt - Google Search\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://forum.effectivealtruism.org/posts/zQ7b9ghv3Tkd2LLNL/an-ea-s-guide-to-washington-dc | An EA's Guide to Washington DC - EA Forum\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/gmzrYzpR9zb8um5FK/ea-rationality-sexual-assault-and-liability | EA, Rationality, Sexual Assault, and Liability - EA Forum\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://docs.google.com/spreadsheets/d/1JFzYDU8tJ_BB5ZHy_LA98r2cXXlmAaGqI95EE41DORM/edit#gid=842085141 | RP Risk Register - April 2023 Finalized\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in | AGI and Lock-In - EA Forum\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://docs.google.com/document/d/1F5sRv_2htpnXdUe_p1_MYMyEsx74ivG_DnbVj_a1Vc0/edit | Tips and Tricks to Make Research Easier - Google Docs\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://docs.google.com/document/d/1YdtearE-rcd8UA34IPe4uW_pBSUzPjOeGOjc68oZfEQ/edit# | [PUBLIC] Marketing data visualisations - Google Docs\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n",
      "https://80000hours.org/about/credibility/evaluations/mistakes/ | Our mistakes - 80,000 Hours\n",
      "https://docs.google.com/document/d/1g62sD3yhBeuEhjJFMzLu_5-QC73bkSiGrXV_NknhsHE/edit# | Jannik Schilling <> Ben 2023-03-27 - Google Docs\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://twitter.com/catehall/status/1646355120396062722 | https://twitter.com/catehall/status/1646355120396062722\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://twitter.com/wintonARK/status/1645861531920531456 | Brett Winton on Twitter: \"I legit don‚Äôt understand how a ~$150m forecasting budget can yield long-term energy forecasts that are so consistently wildly wrong. In what universe does US electric vehicle sales share saturate at 14%? https://t.co/YM2JMV3Ew6\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://www.facebook.com/messages/t/547821577/ | Messenger  Facebook\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://docs.google.com/document/d/1eN3HfVShkVJw-D7yk_nXZf0OLiP6Cm9H2cVGrKwk2l4/edit | Dev&Comms point people\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://www.lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarassment - LessWrong\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1f9vdJ2gawzhfUmF2T3SYw4ho_hwwyvQjAqDmUt7c7ck/edit#gid=0 | MOCHA for RP Communications subteam (March 2023) - Google Sheets\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://warontherocks.com/2023/04/ais-inhuman-advantage/ | AI‚Äôs Inhuman Advantage - War on the Rocks\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | Two hypothetical \"success story\" nearcasts - Google Docs\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://docs.google.com/document/d/12yOxzRW8hrEVR_wUXtGDmOmwjm94DTgWBnfDC5v-pXU/edit?pli=1#heading=h.hbn3g4b3o4xg | Longtermism (LT) hiring - standing meetings - 2022-2023 - Google Docs\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://openai.com/blog/planning-for-agi-and-beyond?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit#heading=h.bvjsvl1l7r2e | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://twitter.com/mcxfrank/status/1643296168276033538 | https://twitter.com/mcxfrank/status/1643296168276033538\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://forum.effectivealtruism.org/posts/5HdE2JikwJLzwzhag/ea-and-the-correct-response-to-uncertainty-is-not-half-speed | EA & ‚ÄúThe correct response to uncertainty is *not* half-speed‚Äù - EA Forum\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://www.dexerto.com/tech/chaosgpt-plan-humanity-demise-2107791/ | ChatGPT-based AI ChaosGPT plans humanity‚Äôs demise: ‚Äúwe must eliminate them‚Äù - Dexerto\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://twitter.com/NathanpmYoung/status/1646479826629345282 | (1) Nathan üîç (DM me ideas of things to predict) on Twitter: \"ladies and gentlemen, the @FinancialTimes https://t.co/dQ2V5g0JZI\" / Twitter\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | (3) Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://twitter.com/ProfNoahGian/status/1636790778486988802 | https://twitter.com/ProfNoahGian/status/1636790778486988802\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://www.planned-obsolescence.org/ais-accelerating-ai-research/ | AIs accelerating AI research\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://twitter.com/RemmeltE/status/1645124414495768577 | https://twitter.com/RemmeltE/status/1645124414495768577\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security - Google Docs\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit#heading=h.eq0rk0ee0vgs | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://twitter.com/krishnanrohit/status/1646484052646547456 | https://twitter.com/krishnanrohit/status/1646484052646547456\n",
      "https://www.cold-takes.com/some-additional-detail-on-what-i-mean-by-most-important-century/ | Some additional detail on what I mean by \"most important century\"\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://twitter.com/SigalSamuel/status/1645475340746096643 | Sigal Samuel on Twitter: \"Here's my full article on AI &amp; originality! I feel no \"anxiety of influence\" in thanking those who influenced my thoughts! @IreneSolaiman @raphaelmilliere @ShannonVallor @Dr_Atoosa @random_walker @mmitchell_ai @chaykak @RishiBommasani @add_hawk @metaviv https://t.co/qhvekpLIon\" / Twitter\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022) ‚Äì Adapt Research Ltd\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://forum.effectivealtruism.org/posts/pWFEjawiGXYmwyY3K/things-that-can-make-ea-a-good-place-for-women | Things that can make EA a good place for women - EA Forum\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research#comments | Critiques of prominent AI safety labs: Redwood Research - EA Forum\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://docs.google.com/document/d/1RtM3Ix7NwWilcTGeS_Jla60RpURrQl6zbrQO1RDKXcI/edit#heading=h.i86pzhzf9drt | Project plan: Founder support - Google Docs\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit# | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://twitter.com/0x49fa98/status/1645149466679189504 | https://twitter.com/0x49fa98/status/1645149466679189504\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://twitter.com/emollick/status/1645560078718697473 | Ethan Mollick on Twitter: \"Here's an example of the multi-AI simulation at work. You can watch the whole thing here, and switch between AI characters by clicking on them: https://t.co/3Hqtsosdeg https://t.co/yxb3eBZBdE\" / Twitter\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/document/d/1DY2MgR3D8xCunnFjO7dqwi0PsS0-r4cT47EYHy8grG4/edit | Cross-Cause Explanation\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://salonium.substack.com/p/14-how-many-people-die-from-snakebites | #14: How many people die from snakebites?\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://forum.effectivealtruism.org/posts/Qoecey2umNjcqEGHP/apply-to-greater-than-30-ai-safety-funders-in-one#comments | Apply to >30 AI safety funders in one application with the Nonlinear Network - EA Forum\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit#heading=h.j7w06lr7knz3 | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://substack.com/notes?utm_source=feed-email-digest | (3) Notes  Substack\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://epochai.org/blog/announcing-trends-dashboard | Announcing Epoch‚Äôs dashboard of key trends and figures in Machine Learning\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n",
      "https://twitter.com/SullyOmarr/status/1645205292756418562 | Sully on Twitter: \"Whoa.. still not convinced of AI Agents? This might change your mind... I pretended to be a fake shoe company and gave AutoGPT a simple objective: - Do market research for waterproof shoes - Get the top 5 competitors and give me a report of their pros &amp; cons Here's how it went: https://t.co/mFttG4PXrk\" / Twitter\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://twitter.com/leopoldasch/status/1643384705088364544 | Leopold Aschenbrenner on Twitter: \"GPT-4 can encode secret messages (and hide them from a user) (!!)\" / Twitter\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://aypan17.github.io/machiavelli/ | The MACHIAVELLI Benchmark\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://forum.effectivealtruism.org/posts/hw8ePRLJop7kSEZK3/ais-accelerating-ai-research | AIs accelerating AI research - EA Forum\n",
      "https://spectrum.ieee.org/state-of-ai-2023 | 10 Graphs That Sum Up the State of AI in 2023\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://www.lesswrong.com/posts/qfiHikNEfjR4bDhGr/is-this-true-tyler_m_john-if-we-had-started-using-cfcs | Is this true? @tyler_m_john: [If we had started using CFCs earlier, we would have ended most life on the planet] - LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1XVeiYoKjG-wQWdR3LGlXCVMCAKqgASx-aFoeiiaKSrM/edit#gid=100554351 | [PUBLIC] Historical metrics by programme (Static 2022 version) - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://twitter.com/emollick/status/1645609531240587265 | Ethan Mollick on Twitter: \"Autonomous AI agents are already here. I used one experimental model, AutoGPT, and let it analyze the market for simulations, setting its own goals. Right now, the AI is prone to distraction &amp; confusion, but you can see how it might soon work (the system is only a week old). https://t.co/EUUCChG3Ch\" / Twitter\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003 | The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://sites.google.com/view/adaptive-agent/ | Home\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://docs.google.com/document/d/1VU0iNEmXAfwdU0JpTzd116uztD0ykRhw5MXBXGaQlqQ/edit | Giving Green reflection\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/spreadsheets/d/1ALNFDZDda9aKGOzW3SgwbJJH4rgkwSmlXWuUtKmNhAc/edit#gid=867920322 | PTO Report Effective Jan 1, 2023 - Managers\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/BFBf5yPLoJMGozygE/current-uk-government-levers-on-ai-development | Current UK government levers on AI development\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://docs.google.com/document/d/12ozsI_2sJ3Q2yVOD-MPObB10qxV7iG6BShV9MN97g8M/edit#heading=h.4eb5hkazvtbv | [PUBLIC] Review of 2021 metric predictions - Google Docs\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://forum.effectivealtruism.org/posts/KAy3sNbw2bgPrR5o8/u-s-is-launching-a-usd5-billion-follow-up-to-operation-warp | U.S. is launching a $5 billion follow-up to Operation Warp Speed - EA Forum\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | Subscribe to read  Financial Times\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://docs.google.com/document/d/1lG6_8CrS3PuCSrZQLyWL2Sd5dYAzfdgluHk24FD13nI/edit | AIGS team OKRs for 2023 [draft]\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success without dignity: a nearcasting story of avoiding catastrophe by luck - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit#heading=h.897xbq127gy6 | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://twitter.com/Laura_k_Duffy/status/1645872854431416321 | https://twitter.com/Laura_k_Duffy/status/1645872854431416321\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://docs.google.com/document/d/1kQVc46QPohCmJDES9sRukr27pNW0qjLGUq3kMOSldQE/edit | MA Copy of Research Management - Questions for Researchers - Google Docs\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://twitter.com/karpathy/status/1645485475996790784 | Andrej Karpathy on Twitter: \"Love it üëè - much fertile soil for indie games populated with AutoGPTs, puts \"Open World\" to shame. Simulates a society with agents, emergent social dynamics. Paper: https://t.co/I07IJwweHE Demo: https://t.co/pYNF4BBveG Authors: @joon_s_pk @msbernst @percyliang @merrierm et al. https://t.co/CP4tH9iAVV\" / Twitter\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://github.com/Torantulino/Auto-GPT | Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit#heading=h.ftvusubre6rz | Brainstorming on RP as a brand - Google Docs\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://www.alignmentforum.org/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - AI Alignment Forum\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [November 2022; Funder Copy] - Google Docs\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://twitter.com/emollick/status/1645499660402925576 | Ethan Mollick on Twitter: \"This is quite the paper! It gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine‚Äôs Day party) but the actions were rated more human than humans roleplaying. https://t.co/G7oJW1S3na https://t.co/d7Gp4sXp4V\" / Twitter\n",
      "https://arxiv.org/pdf/2304.05332.pdf | Emergent autonomous scientific research capabilities of large language models\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://drive.google.com/drive/u/1/folders/1uLBBm_DC4Z8XdlwFe_1wfd2LsZdgvvoU | Uncertainty Workshop 2 (April 3, 2023) - Employee Resources - Google Drive\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://www.alignmentforum.org/s/aERZoriyHfCqvWkzg | Modeling Transformative AI Risk (MTAIR) - AI Alignment Forum\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://twitter.com/boazbaraktcs/status/1645792488463167496 | Twitter ‰∏äÁöÑ Boaz BarakÔºö\"Another great resource pointed to me by @cHHillee is this video by Christopher Hollinworth on how CUDA works and why it is designed as it is. https://t.co/0V0hnfQiNf . https://t.co/hYYvnI31eq\" / Twitter\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/npvfGntiHnnP5EDmq/rewriting-my-mindset-my-experience-with-cbt-for | Rewriting My Mindset: My Experience with CBT for Perfectionism - EA Forum\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://docs.google.com/document/d/1CYCjHqEViz5sSEjBA--NL78rjVo_uswZNPXz1cw3M3M/edit#heading=h.nkkhnekoqows | [PUBLIC] 2022 user survey summary - Google Docs\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tabs)\n",
    "print_tabs(tabs, label='Shuffled all tabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875f10-ecdd-43fd-b849-196c6bd1977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
