{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "368\n",
      "368\n",
      "367\n",
      "367\n",
      "366\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs_from_text(tab_text):\n",
    "    tabs = tab_text.split('\\n')\n",
    "    print('{} tabs opened!'.format(len(tabs)))\n",
    "    for t in tabs:\n",
    "        open_tab(t.split('|')[0].strip())\n",
    "        \n",
    "print('Loaded')\n",
    "\n",
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5fddf1-e942-4059-b414-48e28bdc58f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabs! (366)\n",
      "-\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities – AI Impacts\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://airtable.com/appQbatI4fkmVLxHl/tblO0RqaTPXiz0jjp/viwo2rnDB1Py3Fisy?blocks=hide | Redux Again Again: Org Management - Airtable\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://askamanager.org/2012/02/dealing-with-domestic-abuse-in-the-workplace.html | dealing with domestic abuse in the workplace — Ask a Manager\n",
      "https://askamanager.org/2023/05/i-think-my-employee-is-being-abused-by-her-partner.html | I think my employee is being abused by her partner — Ask a Manager\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://bloomberg.com/opinion/articles/2023-06-18/i-95-repair-in-philadelphia-why-can-t-all-projects-be-this-fast?utm_campaign=socialflow-organic&utm_content=view&utm_source=twitter&cmpid%3D=socialflow-twitter-view&utm_medium=social&leadSource=uverify%20wall | I-95 Repair in Philadelphia: Why Can't All Projects Be This Fast? - Bloomberg\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://docs.google.com/document/d/10Alxne5NLtN8Ggwcnsj9R9D-WaA1-uDdJ_WQlp8zYdQ/edit | Ashwin <> JueYan - Google Docs\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities’ Strategy: 2024 – 2025 - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings – 2023 Q2-Q3 - Google Docs\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1uD9b-lrczR2r4LxppInaDQhOSvN0YYDi7MfuSyp1b-w/edit#heading=h.pn9w2hrth81s | Metaculus AI tournament analysis - Google Docs\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro - Google Docs\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://docs.google.com/document/d/1ziNrskp-v_jWihUakPIhSLqdu6WJY-mA0152RUcLqQc/edit | AIGS Leads notes (Michael, Peter, Zoe, often Ashwin) - 2023 May-Sep - Google Docs\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1DQ5_kPO4MNSunBNuhk_8yEOQkEVy4addPyV5NV3EIvM/edit#gid=458139455 | Caro Career Comparison Table\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1SEMBvi9lZaCyTncBADOHyIjGdlfkRDkNagOSIA3x4js/edit#gid=0 | Blog calendar\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain’s AI dreams reality\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://exploratory-altruism.org/team-partners/ | Team & Partners – Centre for exploratory altruism research\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl | facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://facebook.com/messages/t/692924124/ | Messenger  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid0KsTRs5YSTfGh2s8wia8Ji3tuYSKM5DqDMJ64WQWGzj7cjKtDNHd5A4aegn6V6Agpl | Ozzie Gooen - Meta has been doing really well since its low in Nov...  Facebook\n",
      "https://facebook.com/photo/?fbid=1292510184710822&set=gm.1988967891457920&idorvanity=1317320115289371 | Facebook\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection · Getting started with tpot\n",
      "https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864 | No, GPT4 can’t ace MIT\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion’s AI Benefactor Has A History Of Exaggeration\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power’s Staying Power\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge — Forgotten Trek\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/KYApMdtPsveYPAoZk/longtermists-are-perceived-as-power-seeking | Longtermists are perceived as power-seeking - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/SZJBE3fuk2majqwJQ/principles-for-ai-welfare-research | Principles for AI Welfare Research - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/WMdEJjLAHmdwyA5Wm/we-can-all-help-solve-funding-constraints-what-stops-us | We can all help solve funding constraints. What stops us? - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/czsP5iWmz3wLtz7LT/question-and-answer-based-ea-communities | Question and Answer-based EA Communities - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://forum.effectivealtruism.org/users/caroj?from=post_header | CaroJ - EA Forum\n",
      "https://ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | We must slow down the race to God-like AI\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://google.com/search?q=honest+trailers+john+wick+2&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+john+sick&gs_lcrp=EgZjaHJvbWUqCQgDEAAYDRiABDIGCAAQRRg5MgkIARAAGA0YgAQyCQgCEAAYDRiABDIJCAMQABgNGIAE0gEIOTUxNGowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers john wick 2 - Google Search\n",
      "https://google.com/search?q=honest+trailers+star+trek&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+tre&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIKCAMQABiGAxiKBTIKCAQQABiGAxiKBdIBCDY1MTFqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star trek - Google Search\n",
      "https://google.com/search?q=honest+trailers+star+wars&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+wars&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQLhiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjIICAUQABgWGB4yCAgGEAAYFhgeMggIBxAAGBYYHjIICAgQABgWGB4yCggJEAAYhgMYigXSAQkxMTc2NmowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star wars - Google Search\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://gwern.net/fiction/clippy | It Looks Like You’re Trying To Take Over The World\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://jeffsebodotnet.files.wordpress.com/2023/06/moral-consideration-for-ai-systems-by-2030-4.pdf | Moral Consideration for AI Systems by 2030.docx\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model – Deconfusion Device – Failing to understand the world, learning a little along the way\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson’s latest AI risk position statement - LessWrong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://manifold.markets/NathanHelmBurger/will-gpt5-be-capable-of-recursive-s | Will GPT-5 be capable of recursive self-improvement?  Manifold Markets\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out …\" - Mastodon\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://metaculus.com/tournament/biosecurity-tournament/ | Biosecurity Tournament - Metaculus\n",
      "https://metaculus.com/tournament/future-of-china/ | China and Global Cooperation - Metaculus\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://ntia.gov/issues/artificial-intelligence/request-for-comments | AI Accountability Policy Request for Comment  National Telecommunications and Information Administration\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact — Rethink Priorities\n",
      "https://rochanconsulting.substack.com/p/ukraine-conflict-monitor-82a | Ukraine Conflict Monitor - by Konrad Muzyka\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 – Rodney Brooks\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It’s infuriatingly hard to understand how closed models train on their input\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women’s Pleasure\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI’s Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com® - USPS Tracking® Results\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | αlpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won’t)🧵 t.co/23ErIoRIsk\" / Twitter\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://twitter.com/EthanJPerez/status/1671222828518227968 | twitter.com/EthanJPerez/status/1671222828518227968\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | Jeffrey Ladish on Twitter: \"I really appreciate that @RishiSunak is explicitly acknowledge the existential and catastrophic risks faced by AI. To have a competent global response we have to start here Also, accelerating AI development ⏩ is probably the single most dangerous thing you can do in the world\" / Twitter\n",
      "https://twitter.com/LuiseWoehlke/status/1670430498387111936 | Luise Wöhlke on Twitter: \"☀️🌴 I wrote a much-needed update to my June 2022 post on spending summer in the Bay Area, aka my love letter to the Bay. ☀️🌴 If you've read it and are considering going, I recommend you read the updates which strike a more critical note! :) t.co/y9UxkTqLLV t.co/9eY3R3LjZY\" / Twitter\n",
      "https://twitter.com/LukeyEllsberg/status/1670153020795936771 | lukey on Twitter: \"May my grandfather @DanielEllsberg’s memory be a blessing in the only way that would have matter to him - as an example of how we may all rise to the challenge of responsibility &amp; love for humanity. t.co/QODXZnSO97\" / Twitter\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok 🏗️🚀 on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://twitter.com/NiklasLauffer/status/1670854905513512960 | Niklas Lauffer on Twitter: \"🤝🤔𝙒𝙝𝙖𝙩 𝙙𝙤 𝙬𝙚 𝙣𝙚𝙚𝙙 𝙩𝙤 𝙠𝙣𝙤𝙬 𝙖𝙗𝙤𝙪𝙩 𝙚𝙖𝙘𝙝 𝙤𝙩𝙝𝙚𝙧 𝙩𝙤 𝙨𝙪𝙘𝙘𝙚𝙨𝙨𝙛𝙪𝙡𝙡𝙮 𝙘𝙤𝙡𝙡𝙖𝙗𝙤𝙧𝙖𝙩𝙚?? In our new ICML paper, we provide a method that determines exactly the information you need to be an optimal teammate in multiagent games. [1/10] t.co/DERhRtguLd\" / Twitter\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith 🐇🇺🇦 on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://twitter.com/Simeon_Cps/status/1671141803951628290 | Siméon on Twitter: \"That's what a basic incentive theory would predict. 1 question: is there any evidence that they lobbied to strengthen or try to have a more stringent regulation along certain axis? E.g. try to regulate the development of AI systems, have third party auditing, regulate…\" / Twitter\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/amasad/status/1670473919504220160 | Amjad Masad on Twitter: \"There is a non-zero chance BabyAGI will self-replicate inside Replit and take over our cloud. If it happens it happens.\" / Twitter\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://twitter.com/benedictcooney/status/1670693039327649792 | (1) Benedict Cooney on Twitter: \"We did say a shake-up was necessary t.co/i36Z87oNRs\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://twitter.com/gunsnrosesgirl3/status/1670471946679492610 | Science girl on Twitter: \"Seals have short front flippers and un-rotatable rear flipper so cannot walk on land, they propel themselves forward and achieve locomotion by a method called galumphing t.co/Mm9HY3X6Yi\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://twitter.com/jankulveit/status/1670735364707721216 | Jan Kulveit on Twitter: \"Fascinating &amp; seems reproducible! Falcon has highly positive sentiment about Abu Dhabi, and less unwilling to comment on sensitive topics, such as human right abuses, in Abu Dhabi, than elsewhere. Could have various causes, but it's an important reminder that open source-model… t.co/kWtUqU55fN\" / Twitter\n",
      "https://twitter.com/jerryjliu0/status/1670466808384745472 | Jerry Liu on Twitter: \"Agents 🤖 built with the @OpenAI function API can do advanced data analysis out of the box 🕵️ We’re excited to introduce a brand-new cookbook highlighting these tasks + limitations! 🧑‍🍳👇 - Vector db auto-retrieval - Joint Text-to-SQL + Semantic Search t.co/keofhxZ5tX\" / Twitter\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | Peter Wildeford on Twitter: \"RT @hearthisidea: → Why focus on reducing existential risk from AI? → How could we come up with plans for doing that? What are some promisi…\" / Twitter\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | Séb Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here’s a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. 🏛 t.co/1Grjv93laf\" / Twitter\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I’m honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://twitter.com/teortaxesTex/status/1663897107642630145 | Teortaxes on Twitter: \"Rationalists are unable to inspect their abnormality. They are moral cripples who have stumbled on a crutch in the form of quasi-economic theory of maximizing utility, found that it fits, and reasoned that they're smart, ergo it's convergent for *all* intelligent entities. t.co/kAPYisWPOn\" / Twitter\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://twitter.com/tomgoldsteincs/status/1670893835793186816 | Tom Goldstein on Twitter: \"Training an LLM takes about 1 trillion words. That’s about 30,000 years of typing. But where does this data come from? And what does this have to do with the Reddit protests? Here’s how OpenAI trains models on “the entire internet.” 🧵📜\" / Twitter\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won’t take it over by playing “3-dimensional chess”. – Windows On Theory\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak – Windows On Theory\n",
      "https://youtube.com/watch?v=DCFmJNICqKM | Selena Gomez, Kygo - Be My Mistake - YouTube\n"
     ]
    }
   ],
   "source": [
    "tabs = ['https://' + t for t in sorted([t.replace('http://', '').replace('https://', '').replace('www.', '') for t in tabs])]\n",
    "\n",
    "print('Tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df311d-c9c6-4ace-a7c9-7ed21b34d78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled tabs! (366)\n",
      "-\n",
      "https://docs.google.com/document/d/1SlzqK4uNLgAUsXWqCcit9RS4d-egVbHnieBddY52Yrw/edit#heading=h.8c9v2t95n6m | XST <> AIGS collaboration and information flows – 2023/06/07 - Google Docs\n",
      "https://twitter.com/LuiseWoehlke/status/1670430498387111936 | Luise Wöhlke on Twitter: \"☀️🌴 I wrote a much-needed update to my June 2022 post on spending summer in the Bay Area, aka my love letter to the Bay. ☀️🌴 If you've read it and are considering going, I recommend you read the updates which strike a more critical note! :) t.co/y9UxkTqLLV t.co/9eY3R3LjZY\" / Twitter\n",
      "https://statmodeling.stat.columbia.edu/2023/04/13/the-percentogram-a-histogram-binned-by-percentages-of-the-cumulative-distribution-rather-than-using-fixed-bin-widths/ | The “percentogram”—a histogram binned by percentages of the cumulative distribution, rather than using fixed bin widths  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://reddit.com/r/mlscaling/comments/uznkhw/comment/iab8vy2/?context=3 | (4) GPT-3 2nd Anniversary : mlscaling\n",
      "https://thezvi.substack.com/p/ai-11-in-search-of-a-moat | AI #11: In Search of a Moat - by Zvi Mowshowitz\n",
      "https://lesswrong.com/posts/4ufbirCCLsFiscWuY/a-proposed-method-for-forecasting-ai#Summary_of_the_Direct_Approach | A proposed method for forecasting transformative AI - LessWrong\n",
      "https://lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff\n",
      "https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/ | Thoughts on AI safety – Windows On Theory\n",
      "https://thezvi.substack.com/p/ai-4-introducing-gpt-4 | AI #4: Introducing GPT-4 - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1ikmEY9bW6BpkqF-D9feWYnTPx0yG-v1HDUcPsmMSduc/edit#heading=h.j9owozbw0x7p | Layer - Requirement Specification and Tracing - Google Docs\n",
      "https://thezvi.substack.com/p/the-crux-list | The Crux List - by Zvi Mowshowitz\n",
      "https://lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is | (My understanding of) What Everyone in Technical Alignment is Doing and Why\n",
      "https://arxiv.org/abs/2303.09377 | [2303.09377] Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?\n",
      "https://institute.global/insights/politics-and-governance/new-national-purpose-ai-promises-world-leading-future-of-britain | A New National Purpose: AI Promises a World-Leading Future of Britain\n",
      "https://twitter.com/simonw/status/1670115933640171520 | Simon Willison on Twitter: \"I released a major update to my LLM CLI tool today - version 0.4, which adds conversation mode and prompt templates so you can store and re-use interesting prompts: t.co/UUA2ubgSuM t.co/qunPygLph8\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-10-code-interpreter-and-george | AI #10: Code Interpreter and Geoff Hinton\n",
      "https://troof.blog/posts/nootropics/ | What I learned gathering thousands of nootropic ratings  Troof\n",
      "https://forum.effectivealtruism.org/posts/czsP5iWmz3wLtz7LT/question-and-answer-based-ea-communities | Question and Answer-based EA Communities - EA Forum\n",
      "https://metaculus.com/questions/13531/ukraine-to-cut-land-bridge-to-crimea-by-2024/ | Crimea-Russia Land Bridge Severed by 2024?  Metaculus\n",
      "https://huggingface.co/blog/falcon | The Falcon has landed in the Hugging Face ecosystem\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx | My updates after FTX - EA Forum\n",
      "https://twitter.com/GovAI_/status/1669731551058313221 | Centre for the Governance of AI (GovAI) on Twitter: \"We have a new blog post up from @nikhilmulani &amp; @jesswhittles: \"Proposing a Foundation Model Information-Sharing Regime for the UK\" Link below: t.co/ngtYBDFjPH\" / Twitter\n",
      "https://lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai | Concrete Reasons for Hope about AI - LessWrong\n",
      "https://reddit.com/r/BDSMcommunity/ | reddit.com/r/BDSMcommunity/\n",
      "https://start.omgyes.com/join/pricing | OMGYES.com - The Science of Women’s Pleasure\n",
      "https://lesswrong.com/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model | Refining the Sharp Left Turn threat model, part 1: claims and mechanisms\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List - Google Docs\n",
      "https://docs.google.com/document/d/1JTHziStX0dFjFWa2Gp8RYfKXJJM69nvAB0mGtCUpgdw/edit#heading=h.j9owozbw0x7p | Layer - Isolation of Digital Systems - Google Docs\n",
      "https://rodneybrooks.com/predictions-scorecard-2023-january-01/ | Predictions Scorecard, 2023 January 01 – Rodney Brooks\n",
      "https://politico.com/news/2023/05/16/the-government-plots-its-ai-approach-00097262 | On AI, the government gets ready to throw its weight around - POLITICO\n",
      "https://lesswrong.com/posts/a5NxvzFGddj2e8uXQ/updating-drexler-s-cais-model | Updating Drexler's CAIS model - LessWrong\n",
      "https://lesswrong.com/posts/KJRBb43nDxk6mwLcR/ai-doom-from-an-llm-plateau-ist-perspective | AI doom from an LLM-plateau-ist perspective\n",
      "https://docs.google.com/spreadsheets/d/1DQ5_kPO4MNSunBNuhk_8yEOQkEVy4addPyV5NV3EIvM/edit#gid=458139455 | Caro Career Comparison Table\n",
      "https://ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2 | We must slow down the race to God-like AI\n",
      "https://karpathy.github.io/2022/03/14/lecun1989/ | Deep Neural Nets: 33 years ago and 33 years from now\n",
      "https://docs.google.com/document/d/10Alxne5NLtN8Ggwcnsj9R9D-WaA1-uDdJ_WQlp8zYdQ/edit | Ashwin <> JueYan - Google Docs\n",
      "https://montrealethics.ai/foundations-for-the-future-institution-building-for-the-purpose-of-artificial-intelligence-governance/ | Foundations for the future: institution building for the purpose of artificial intelligence governance\n",
      "https://mastodon.social/@danluu/109579156612202841 | Dan Luu: \"Now that ChatGPT has been out …\" - Mastodon\n",
      "https://cset.georgetown.edu/event/uplifting-cyber-defense/ | Uplifting Cyber Defense - Center for Security and Emerging Technology\n",
      "https://twitter.com/jerryjliu0/status/1670466808384745472 | Jerry Liu on Twitter: \"Agents 🤖 built with the @OpenAI function API can do advanced data analysis out of the box 🕵️ We’re excited to introduce a brand-new cookbook highlighting these tasks + limitations! 🧑‍🍳👇 - Vector db auto-retrieval - Joint Text-to-SQL + Semantic Search t.co/keofhxZ5tX\" / Twitter\n",
      "https://eroticroomandboard.com/ | Romantic B&B in Salinas, CA  Bed & Bondage  Monterey Stay and Play\n",
      "https://drive.google.com/drive/u/1/folders/1e8jlP-nTCSTRhMOfBBnkk8AkhmIdcVud | USG involvement in advanced AI [Shared folder] [AA, June 2023] - Google Drive\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://ineffectivealtruismblog.com/2023/06/03/exaggerating-the-risks-part-8-carlsmith-wrap-up/ | Exaggerating the risks (Part 8: Carlsmith wrap-up) - Reflective altruism\n",
      "https://lesswrong.com/posts/oktnxsng7Dbc4aoZP/human-level-full-press-diplomacy-some-bare-facts | Human-level Full-Press Diplomacy (some bare facts). - LessWrong\n",
      "https://eto.tech/ | eto.tech/\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0TDYtLjHNMyk3YPTiz0ktUUjNVcjMUyjPzEsvBgCbmwoM&q=let+em+in+wings&rlz=1CDGOYI_enUS715US715&oq=let+em+in+win&gs_lcrp=EgZjaHJvbWUqBwgBEC4YgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBggCEEUYOTIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDQ4MDRqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | let em in wings - Google Search\n",
      "https://google.com/search?q=honest+trailers+star+trek&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+tre&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIKCAMQABiGAxiKBTIKCAQQABiGAxiKBdIBCDY1MTFqMGo3qAIAsAIA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star trek - Google Search\n",
      "https://docs.google.com/document/d/1UsRIgm1mFUJNr5UNOmx7j4Q4-lCeVn7OC3euP0kLDnU/edit#heading=h.ni0hbuwqtlub | HAIKU Central Doc - High-speed AI Governance Kollektiv Upskilling - Google Docs\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not… t.co/Nikto4prZV\" / Twitter\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid08o48vhcYDbbrxphoM5R5sMM4Qa8NQk9tXLzbnbY4pnRXjTC38dRYDvHWYoBZtNPal | Ozzie Gooen - Why should we expect boards to be effective?...  Facebook\n",
      "https://forum.effectivealtruism.org/users/caroj?from=post_header | CaroJ - EA Forum\n",
      "https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864 | No, GPT4 can’t ace MIT\n",
      "https://forum.effectivealtruism.org/posts/Pfayu5Bf2apKreueD/a-playbook-for-ai-risk-reduction-focused-on-misaligned-ai | A Playbook for AI Risk Reduction (focused on misaligned AI) - EA Forum\n",
      "https://facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl | facebook.com/caroline.jeanmaire/posts/pfbid0QoMyxNV1BMgfVi5XtMuckbiUJE9aFzZmsFA4n4kPXfZZe6QL8Vw2vKeT6FKMXUXjl\n",
      "https://metaculus.com/questions/17447/ai-movie-before-2029/ | Will there be a commercially successful and/or award-winning AI movie before 2029?\n",
      "https://twitter.com/peterwildeford/status/1671174311283924993 | Peter Wildeford on Twitter: \"RT @hearthisidea: → Why focus on reducing existential risk from AI? → How could we come up with plans for doing that? What are some promisi…\" / Twitter\n",
      "https://docs.google.com/document/d/1ghEgQeMA56UAffquWhlnJNseNh8NdMLA4NFuTdDsiiU/edit#heading=h.n27z5n7sidxc | Draft: Sleepwalking into Survival - Google Docs\n",
      "https://facebook.com/topsecret.gov/posts/pfbid02pz9Mj8T6MSYbp7y8YjqN2hD3MdC3rpaa7GqceKRS7o8uPVDJ2VJVjCPY8nyBhX9Ll | Jai Dhyani - In 2018, the ACM Turing Award was awarded to three... - Facebook\n",
      "https://metaculus.com/questions/16505/time-from-tai-to-superintelligence/ | Time From TAI to Superintelligence  Metaculus\n",
      "https://github.com/InternLM/InternLM-techreport | InternLM/InternLM-techreport\n",
      "https://facebook.com/photo/?fbid=1292510184710822&set=gm.1988967891457920&idorvanity=1317320115289371 | Facebook\n",
      "https://docs.google.com/document/d/1QsJ8PNqfvvdtkMHclNLqtVP2SVM5dhsj4GMeFztjGBY/edit#heading=h.w6y052tqvke3 | Exploring future AI compute paradigms - Google Docs\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://governance.ai/post/annual-report-2022 | Annual Report 2022  GovAI Blog\n",
      "https://alignmentforum.org/posts/EjsA2M8p8ERyFHLLY/takeaways-from-the-mechanistic-interpretability-challenges | Takeaways from the Mechanistic Interpretability Challenges - AI Alignment Forum\n",
      "https://thezvi.substack.com/p/ai-7-free-agency | AI #7: Free Agency - by Zvi Mowshowitz\n",
      "https://twitter.com/labenz/status/1655092874768179200 | Nathan Labenz on Twitter: \"Quick followup micro-thread: Google edition. I used OpenAI for core analysis because they are clear leaders, but Google has most of the same advantages! t.co/65ex3oa90n\" / Twitter\n",
      "https://cold-takes.com/ai-could-defeat-all-of-us-combined/ | AI Could Defeat All Of Us Combined\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit#heading=h.1cytsywlk7ba | [narrowly shared copy] How might the US national security sphere orient & react to increasingly powerful AI? - Google Docs\n",
      "https://ai.objectives.institute/blog/introducing-talk-to-the-city-our-collective-deliberation-tool | Introducing: Talk to the City - Our Collective Deliberation Tool — AI • Objectives • Institute\n",
      "https://twitter.com/messages/25776739-363201363 | Michał Dubrawski - Standing with 🇺🇦 / Twitter\n",
      "https://lesswrong.com/posts/hAnKgips7kPyxJRY3/ai-governance-and-strategy-priorities-talent-gaps-and | AI Governance & Strategy: Priorities, talent gaps, & opportunities - LessWrong\n",
      "https://windowsontheory.org/author/hardeasy/ | Boaz Barak – Windows On Theory\n",
      "https://thezvi.substack.com/p/types-and-degrees-of-alignment | Types and Degrees of Alignment - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1ziNrskp-v_jWihUakPIhSLqdu6WJY-mA0152RUcLqQc/edit | AIGS Leads notes (Michael, Peter, Zoe, often Ashwin) - 2023 May-Sep - Google Docs\n",
      "https://thezvi.substack.com/p/ai-5-level-one-bard | AI #5: Level One Bard - by Zvi Mowshowitz\n",
      "https://aiobjectives.org/blog/mapping-the-discourse-on-ai-safety-amp-ethics | Mapping the Discourse on AI Safety & Ethics — AI • Objectives • Institute\n",
      "https://manifold.markets/NathanHelmBurger/will-gpt5-be-capable-of-recursive-s | Will GPT-5 be capable of recursive self-improvement?  Manifold Markets\n",
      "https://cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/ | Transformative AI issues (not just misalignment): an overview\n",
      "https://forum.effectivealtruism.org/posts/NPHJBby6KjDC7iNYK/what-can-superintelligent-ani-tell-us-about-superintelligent | What can superintelligent ANI tell us about superintelligent AGI? - EA Forum\n",
      "https://lesswrong.com/posts/wkws2WgraeN8AYJjv/llms-don-t-have-a-coherent-model-of-the-world-what-it-means | \"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters - LessWrong\n",
      "https://docs.google.com/document/d/1h8puRZCvETJLUjhdaKHvaKzZRAMAl3K33Vk1AIBpepw/edit#heading=h.mldxlxsjceuj | Michael's key todos in June/July - Google Docs\n",
      "https://microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/ | ChatGPT for Robotics\n",
      "https://lesswrong.com/posts/qJgz2YapqpFEDTLKn/deepmind-alignment-team-opinions-on-agi-ruin-arguments | DeepMind alignment team opinions on AGI ruin arguments - LessWrong\n",
      "https://bloomberg.com/news/articles/2019-04-06/the-google-ai-ethics-board-with-actual-power-is-still-around?leadSource=uverify%20wall#xj4y7vzkg | The Google AI Ethics Board With Actual Power Is Still Around - Bloomberg\n",
      "https://forum.effectivealtruism.org/posts/weJZjku3HiNgQC4ER/a-note-of-caution-about-recent-ai-risk-coverage | A note of caution about recent AI risk coverage - EA Forum\n",
      "https://thezvi.substack.com/p/stages-of-survival | Stages of Survival - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1e7j0aCbgbiJexe3JKbk4GTGtEFjzQgVQEpRkW36mGnI/edit#heading=h.4nf1i3lahpm5 | Crazy AI soon - Ashwin hot take (early June 2023) - Google Docs\n",
      "https://theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt?utm_term=popular-articles&utm_source=sg&utm_medium=email&utm_campaign=article_email&utm_content=article-10441 | OpenAI’s Losses Doubled to $540 Million as It Developed ChatGPT\n",
      "https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens | AI #9: The Merge and the Million Tokens - by Zvi Mowshowitz\n",
      "https://philarchive.org/rec/ASSWHC | Guive Assadi, Will Humanity Choose Its Future? - PhilArchive\n",
      "https://docs.google.com/spreadsheets/d/1hcYteAFXujvTI3KlzUf0FL_du5jwu6cuLPEmPGJ0X5U/edit#gid=0 | Defense in Depth: Matrix of Layers - Google Sheets\n",
      "https://docs.google.com/document/d/1rg2N-6XHPixsSk8JYl_TrwBhtpKcBFGfv3idJh7Fj8c/edit#heading=h.mofxbjxxdw6n | What would an investigation / whistleblowing org be like? - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/WMdEJjLAHmdwyA5Wm/we-can-all-help-solve-funding-constraints-what-stops-us | We can all help solve funding constraints. What stops us? - EA Forum\n",
      "https://lesswrong.com/posts/X6pKMHS5xAeiNaFts/the-ones-who-endure | The ones who endure - LessWrong\n",
      "https://docs.google.com/spreadsheets/d/1NI5r6taFz_C4LEKJuePA02p9ef11LQilpud4w39l6Jg/edit#gid=2015911701 | 2023 Team/Department OKR Tracking - Google Sheets\n",
      "https://gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence?fbclid=IwAR1b6xdp2X_qD3r7IBaHdtNGjz7T1sLSdOOJNtm-9AP2h6PGKzsfDbzkBxo | UK to host first global summit on Artificial Intelligence - GOV.UK\n",
      "https://arxiv.org/abs/2108.12427 | [2108.12427] Why and How Governments Should Monitor AI Development\n",
      "https://twitter.com/AlphaMinus2/status/1641130452789477409 | αlpha-Minus on Twitter: \"@peterwildeford What are your TAI timelines? :)\" / Twitter\n",
      "https://docs.google.com/document/d/1jH2UpXhi6uFF9nU6PZwbEurNArW5Zi5fPba-uM0MVPE/edit#heading=h.deq8lzwofh50 | Final Draft Report - CEA Animal Ballot Initiatives - Google Docs\n",
      "https://metaculus.com/tournament/biosecurity-tournament/ | Biosecurity Tournament - Metaculus\n",
      "https://blog.aiimpacts.org/p/framing-ai-strategy | Framing AI strategy - by Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1HeuDspWp4VRyWNS5IKOxqZWZoCTpU8k3LU4X3adpVFw/edit#heading=h.zee6ngwoj6jg | RP <> DeepMind May 17, 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1TsHZ3YXvz4Rs_rBihugjqS7gPDhxBq96cXu7JoJOYxs/edit#heading=h.js018c8h01q3 | Notes from lunch convo w/ Michael Aird re: XST AI upskilling [5/6/23] - Google Docs\n",
      "https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3 | Meetings *are* the work. Wherein I take aim at the common tech…  by Elizabeth Ayer  Medium\n",
      "https://lesswrong.com/posts/x5aTiznxJ4o9EGdj9/uncertainty-about-the-future-does-not-imply-that-agi-will-go | Uncertainty about the future does not imply that AGI will go well - LessWrong\n",
      "https://80000hours.org/podcast/episodes/tom-davidson-how-quickly-ai-could-transform-the-world/ | Tom Davidson on how quickly AI could transform the world - 80,000 Hours\n",
      "https://twitter.com/messages/25776739-1148306976176132096 | Juan Cambeiro / Twitter\n",
      "https://lesswrong.com/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer | Where I agree and disagree with Eliezer - LessWrong\n",
      "https://twitter.com/jankulveit/status/1670735364707721216 | Jan Kulveit on Twitter: \"Fascinating &amp; seems reproducible! Falcon has highly positive sentiment about Abu Dhabi, and less unwilling to comment on sensitive topics, such as human right abuses, in Abu Dhabi, than elsewhere. Could have various causes, but it's an important reminder that open source-model… t.co/kWtUqU55fN\" / Twitter\n",
      "https://anthropic.com/index/charting-a-path-to-ai-accountability | Anthropic  Charting a Path to AI Accountability\n",
      "https://openai.com/blog/governance-of-superintelligence | Governance of superintelligence\n",
      "https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by | Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post] - EA Forum\n",
      "https://docs.google.com/document/d/1ddkN8tmeiGVe7v-_77zV4RgP2taIo6ee49TITqi2Xhs/edit#heading=h.b43hif7jzg78 | XST strategy meetings – 2023 Q2-Q3 - Google Docs\n",
      "https://nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://forum.effectivealtruism.org/posts/ozSBaNLysue9MmFqs/aptitudes-for-ai-governance-work | Aptitudes for AI governance work - EA Forum\n",
      "https://lesswrong.com/posts/rtM3jFaoQn3eoAiPh/explaining-the-twitter-postrat-scene | Explaining the Twitter Postrat Scene - LessWrong\n",
      "https://lesswrong.com/posts/tZExpBovNhrBvCZSb/how-could-you-possibly-choose-what-an-ai-wants | How could you possibly choose what an AI wants? - LessWrong\n",
      "https://twitter.com/LukeyEllsberg/status/1670153020795936771 | lukey on Twitter: \"May my grandfather @DanielEllsberg’s memory be a blessing in the only way that would have matter to him - as an example of how we may all rise to the challenge of responsibility &amp; love for humanity. t.co/QODXZnSO97\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-14-a-very-good-sentence | AI #14: A Very Good Sentence - by Zvi Mowshowitz\n",
      "https://twitter.com/emollick/status/1655684207321006086 | Ethan Mollick on Twitter: \"Hey ChatGPT Code Interpreter: Create code that would win me a science fair. I am a high schooler. Pick whatever field you want, and make sure you run the code and give me the results and how to present it. Give me visualizations, and a way to explain them. Now give me a speech. t.co/uxjtyYAEFo\" / Twitter\n",
      "https://rochanconsulting.substack.com/p/ukraine-conflict-monitor-82a | Ukraine Conflict Monitor - by Konrad Muzyka\n",
      "https://metaculus.com/questions/4931/when-will-the-woke-index-in-us-elite-media-top/ | Woke Index in US Media  Metaculus\n",
      "https://twitter.com/yoavgo/status/1670119840240074753 | (((ل()(ل() 'yoav))))👾 on Twitter: \"text-to-image models dont understand sentence structure, which manifests in many bad ways. we tackle one of them and promote linking properties to (only) the entities they modify. the gist is to identify sentence structure (with a parser) and then intervene in the cross attention\" / Twitter\n",
      "https://docs.google.com/document/d/11OxTcv8WChkPd_WeYIdpNIaZRDGbfo8D64JAmV1qZYg/edit#heading=h.xt1ei6i054ae | Building Credibility via Cobranding and Affiliation - Google Docs\n",
      "https://thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr | How does AI threaten us — and can we make it safe?\n",
      "https://exploratory-altruism.org/team-partners/ | Team & Partners – Centre for exploratory altruism research\n",
      "https://mwstory.substack.com/p/why-i-generally-dont-recommend-internal | Why I generally don't recommend internal prediction markets or forecasting tournaments to organisations\n",
      "https://rethinkpriorities.org/publications/historical-global-health-rd-hits | Historical Global Health R&D \"hits\": Development, main sources of funding, and impact — Rethink Priorities\n",
      "https://docs.google.com/spreadsheets/d/1AT3zaPwqov9OtbdO_Bpc3HuwX5rv4O0OHb77Y671QhY/edit#gid=988618460 | Analysis of OpenBook Grants - 1st Feb 2023 - Google Sheets\n",
      "https://new.ox.ac.uk/news/oxford-institute-charity-announced | Oxford Institute of Charity announced  New College\n",
      "https://kinkfriendly.org/wp-content/uploads/2010/12/kinkfriendly_org_rope_101_compressed.pdf | Rope_Bondage_101_v2\n",
      "https://docs.google.com/document/d/12Jd1XQMS00sAtA_K-Fcj0daPtfa-kXmjIqEHTvnn3ZQ/edit | Rethink Priorities’ Strategy: 2024 – 2025 - Google Docs\n",
      "https://forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=1f9dc79675c5 | Stable Diffusion’s AI Benefactor Has A History Of Exaggeration\n",
      "https://twitter.com/teortaxesTex/status/1663897107642630145 | Teortaxes on Twitter: \"Rationalists are unable to inspect their abnormality. They are moral cripples who have stumbled on a crutch in the form of quasi-economic theory of maximizing utility, found that it fits, and reasoned that they're smart, ergo it's convergent for *all* intelligent entities. t.co/kAPYisWPOn\" / Twitter\n",
      "https://docs.google.com/document/d/1wd7WEsaPXQB_IauqXEcE1RIyKmvrjC3tVrz6B0KXxeo/edit | Value of the Future After Perils - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/L6ZmggEJw8ri4KB8X/my-highly-personal-skepticism-braindump-on-existential-risk | My highly personal skepticism braindump on existential risk from artificial intelligence. - EA Forum\n",
      "https://facebook.com/messages/t/1428387474/ | facebook.com/messages/t/1428387474/\n",
      "https://thezvi.substack.com/p/on-autogpt | On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/1zU6IPAi6iyiHIDjY4sG6eQKcvL3T_p5CjnEs-B5omuw/edit | Ben <> Michael re AI Governance landscape 2023-06-15 - Google Docs\n",
      "https://google.com/search?q=federally+funded+ffrdc&rlz=1CDGOYI_enUS715US715&oq=federally+funded+ffrdc&aqs=chrome..69i57j0i546l2.5365j1j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | federally funded ffrdc - Google Search\n",
      "https://twitter.com/amasad/status/1670473919504220160 | Amjad Masad on Twitter: \"There is a non-zero chance BabyAGI will self-replicate inside Replit and take over our cloud. If it happens it happens.\" / Twitter\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit#heading=h.z6v8ty7j4wlh | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://sideways-view.com/2018/02/24/takeoff-speeds/ | Takeoff speeds – The sideways view\n",
      "https://twitter.com/rajiinio/status/1669326789758394369 | Deb Raji on Twitter: \"It annoys me how much those advocating for existential risk expect us to believe them based on pure ethos (ie. authority of who says it)... do you know how many *years* of research it took to convince people machine learning models *might* be biased? And some are still in denial!\" / Twitter\n",
      "https://jeffsebodotnet.files.wordpress.com/2023/06/moral-consideration-for-ai-systems-by-2030-4.pdf | Moral Consideration for AI Systems by 2030.docx\n",
      "https://lesswrong.com/posts/RydETq379eoWqBFvj/updates-and-reflections-on-optimal-exercise-after-nearly-a | Updates and Reflections on Optimal Exercise after Nearly a Decade - LessWrong\n",
      "https://deepmind.com/blog/an-early-warning-system-for-novel-ai-risks | An early warning system for novel AI risks\n",
      "https://psyarxiv.com/gq9r6/ | PsyArXiv Preprints  Informal evidence on identifying top talent\n",
      "https://facebook.com/spencer.greenberg/posts/pfbid0nhUqkz62MP5eKZgrTpAkxY95j67t43fF4Cg8YJgC1GPX6hLbjcnsfh4qQNzfVY3ql | 9 tools I use that save me time every week:... - Spencer Greenberg  Facebook\n",
      "https://twitter.com/MatthewJBar/status/1670211794869321730 | Matthew Barnett on Twitter: \"I have now bet @sandersted my inflation-adjusted $1000 to his $4000 that transformative AI will arrive before 2043, defined by explosive growth (in world GDP or energy consumption). The bet conditions can be found in a Google Doc linked in the next tweet.\" / Twitter\n",
      "https://lesswrong.com/posts/gGSvwd62TJAxxhcGh/yudkowsky-vs-hanson-on-foom-whose-predictions-were-better | Yudkowsky vs Hanson on FOOM: Whose Predictions Were Better? - LessWrong\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1&nd=1 | happy calm songs:) - playlist by nataliebrogan13  Spotify\n",
      "https://twitter.com/sebkrier/status/1664642737700757512 | Séb Krier on Twitter: \"A lot of people in AI policy are talking about licensing in the context of AI risk. Here’s a little thread exploring what this means, what it could look like, and some challenges worth keeping in mind. 🏛 t.co/1Grjv93laf\" / Twitter\n",
      "https://whitehouse.gov/ostp/ai-bill-of-rights/ | Blueprint for an AI Bill of Rights - OSTP - The White House\n",
      "https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards | Seeking (Paid) Case Studies on Standards - EA Forum\n",
      "https://flightfromperfection.com/getting-started-with-tpot.html | Flight From Perfection · Getting started with tpot\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/H5beCesFybASmwhcM/sam-clarke-s-shortform | Sam Clarke's Shortform - EA Forum\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1TE7W8lqyDVzIDI1aSoEV8Q23doDcGrCl7X0P28ggB2I/edit#heading=h.kaohbuk3ldg | Overview of tentative founder search strategy for AIPLUS - Google Docs\n",
      "https://facebook.com/messages/t/692924124/ | Messenger  Facebook\n",
      "https://twitter.com/EthanJPerez/status/1671222828518227968 | twitter.com/EthanJPerez/status/1671222828518227968\n",
      "https://rootsofprogress.org/wright-brothers-and-safe-technology-development | Developing a technology with safety in mind\n",
      "https://docs.google.com/document/d/1fqTkdMvXL1Qp1PGvHNWop8tNR9jSKUTZWWdc6HTYTwM/edit#heading=h.b1mk6ygyrd9z | Copy of 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://oneusefulthing.org/p/assigning-ai-seven-ways-of-using | Assigning AI: Seven Ways of Using AI in Class\n",
      "https://twitter.com/emollick/status/1652170706312896512 | Ethan Mollick on Twitter: \"This 🤯 is a very big 🤯 I have access to the new GPT Code Interpreter. I uploaded an XLS file, no context: \"Can you do visualizations &amp; descriptive analyses to help me understand the data? \"Can you try regressions and look for patterns?\" \"Can you run regression diagnostics?\" t.co/s3CV5nQtl3\" / Twitter\n",
      "https://kathrynmintner.medium.com/an-evening-in-the-life-with-osdd-609e71fd8096 | An Evening in the Life with OSDD. Part of an ongoing series about life…  by K. Mintner  Jun, 2023  Medium\n",
      "https://podcastaddict.com/the-lunar-society/episode/159208871 | Carl Shulman - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment • The Lunar - Podcast Addict\n",
      "https://manifold.markets/elibutchad/will-gpt5-be-more-competent-than-me | Will GPT-5 be more competent than me in my area of expertise?  Manifold Markets\n",
      "https://twitter.com/tomgoldsteincs/status/1670893835793186816 | Tom Goldstein on Twitter: \"Training an LLM takes about 1 trillion words. That’s about 30,000 years of typing. But where does this data come from? And what does this have to do with the Reddit protests? Here’s how OpenAI trains models on “the entire internet.” 🧵📜\" / Twitter\n",
      "https://theworkback.com/asana-ai-principles/ | Asana’s 5 guiding principles for human-centered AI\n",
      "https://80000hours.org/podcast/episodes/rohin-shah-deepmind-doomers-and-doubters/ | Rohin Shah on DeepMind and trying to fairly hear out both AI doomers and doubters - 80,000 Hours\n",
      "https://wikiwand.com/en/Spider-Man:_Across_the_Spider-Verse | Spider-Man: Across the Spider-Verse - Wikiwand\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/1HsUiJ9AMacQTk98ImDKyS660EbYHNbZzmNKlXC0xF1s/edit#heading=h.oyy6uniuf2wi | Community building in a world where people actually listen to us - Google Docs\n",
      "https://en.pourdemain.ch/ | Pour Demain: Today for tomorrow\n",
      "https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how | Anthropic: Core Views on AI Safety: When, Why, What, and How - EA Forum\n",
      "https://cetas.turing.ac.uk/publications/autonomous-cyber-defence | Autonomous Cyber Defence  Centre for Emerging Technology and Security\n",
      "https://twitter.com/tkalil2050/status/1670193175712112640 | Thomas Kalil on Twitter: \"$2 million in prizes for best ideas for market-shaping to solve problems in climate change and pandemic preparedness - with deadline of July 21, 2023. Supported by @SchmidtFutures t.co/wZcON5rtrF @econD47 #econtwitter\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/TCsanzwKGqfBBTye9/the-wild-and-wacky-claims-of-karnofsky-s-most-important | The 'Wild' and 'Wacky' Claims of Karnofsky’s ‘Most Important Century’ - EA Forum\n",
      "https://campaignforaisafety.org/dissecting-support-for-sub-statements-of/ | Dissecting support for a logical case on lack of safety\n",
      "https://hackernoon.com/how-i-solved-the-passman-ctf-challenge-with-gpt-4 | How I Solved the Passman CTF Challenge with GPT-4  HackerNoon\n",
      "https://dynomight.net/aliens/ | I still think it's very unlikely we're observing alien aircraft\n",
      "https://lesswrong.com/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications | AI alignment is distinct from its near-term applications\n",
      "https://twitter.com/JacobSteinhardt/status/1666865408299917313 | Jacob Steinhardt on Twitter: \"Many people, including me, have been surprised by recent developments in machine learning. To be less surprised in the future, we should make and discuss specific projections about future models. In this spirit, I predict properties of models in 2030: t.co/aB5YtN8jaG\" / Twitter\n",
      "https://sarahconstantin.substack.com/p/why-i-am-not-an-ai-doomer | Why I am Not An AI Doomer - by Sarah Constantin\n",
      "https://theinsideview.ai/roblong | theinsideview.ai/roblong\n",
      "https://lesswrong.com/posts/gq9GR6duzcuxyxZtD/approximation-is-expensive-but-the-lunch-is-cheap | Approximation is expensive, but the lunch is cheap - LessWrong\n",
      "https://theinsideview.ai/alex | theinsideview.ai/alex\n",
      "https://twitter.com/lawhsw/status/1669998912751697920 | harry law on Twitter: \"1/ I’ve seen a few people ask whether AI is having a ‘limits to growth’ moment, so here’s a 🧵on the 1972 limits to growth report, why predictions of the future are used to inform policymaking, and what the relevance is for anyone interested in governing powerful models t.co/B6bFEl5Uiv\" / Twitter\n",
      "https://lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization | A central AI alignment problem: capabilities generalization, and the sharp left turn\n",
      "https://economist.com/britain/2023/06/14/how-to-make-britains-ai-dreams-reality | How to make Britain’s AI dreams reality\n",
      "https://twitter.com/MTabarrok/status/1665057406043209729 | Maxwell Tabarrok 🏗️🚀 on Twitter: \"Most of these events were too far out to evaluate, but Drexler's record continues to be way off I suspect he is predicting nanotech in the early 21st and then predicting space exploration a decade or so after advanced nanotech But the premise never happened so 9 wrong in a row t.co/Tq3raRQHJf\" / Twitter\n",
      "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217 | The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\n",
      "https://simonwillison.net/2023/Jun/4/closed-model-training/ | It’s infuriatingly hard to understand how closed models train on their input\n",
      "https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/ | Likelihood of discontinuous progress around the development of AGI – AI Impacts\n",
      "https://cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://thetimes.co.uk/article/how-ill-help-make-the-ai-revolution-safe-mj0zx00k6 | How I’ll help make the AI revolution safe\n",
      "https://metaculus.com/notebooks/10688/how-much-of-ai-progress-is-from-scaling-compute-and-how-far-will-it-scale/ | How much of AI progress is from scaling compute? And how far will it scale?  Metaculus\n",
      "https://hai.stanford.edu/news/assessing-political-bias-language-models?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202306161425_sf179193900&utm_campaign=&sf179193900=1 | Assessing Political Bias in Language Models\n",
      "https://docs.google.com/spreadsheets/d/11Uuc_bkm473J0rbi4yhJO290J3SLpIMkwNhbpUcIfdc/edit#gid=0 | Project twitter.com/peterwildeford/status/1549119432680738816 - Google Sheets\n",
      "https://facebook.com/robbensinger/posts/pfbid02f7McdFNWAA1fXMzzy3BVmwBgAFfU57c2z9N4MgycH7Anyg3Wm71Z8yfNQbKJbMf2l | (1) Rob Bensinger - (Copying over an email I sent some family...  Facebook\n",
      "https://lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://highmodernism.substack.com/p/security-mindset-in-the-manhattan | Security Mindset in the Manhattan Project\n",
      "https://twitter.com/gunsnrosesgirl3/status/1670471946679492610 | Science girl on Twitter: \"Seals have short front flippers and un-rotatable rear flipper so cannot walk on land, they propel themselves forward and achieve locomotion by a method called galumphing t.co/Mm9HY3X6Yi\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/JQxvZZdPG5KYjyBfg/four-mindset-disagreements-behind-existential-risk | Four mindset disagreements behind existential risk disagreements in ML - EA Forum\n",
      "https://amazon.co.uk/High-Output-Management-Andrew-Grove/dp/0679762884 | High Output Management: Amazon.co.uk: Grove, Andrew S.: 9780679762881: Books\n",
      "https://nti.org/analysis/articles/cyber/ | The Cyber-Nuclear Threat: Explained\n",
      "https://docs.google.com/document/d/1xFlAx71HEjIHQI36r8gP2Dg0SdI3sz9lLnm5KPw0kno/edit#heading=h.fmkwnd6gv8xf | AI risk from program search - Google Docs\n",
      "https://myenglishroutine.com/english-terms-endearment/ | The Sweetest English Terms of Endearment to Call Your Loved Ones - My English Routine\n",
      "https://thezvi.substack.com/p/ai-12-the-quest-for-sane-regulations | AI #12: The Quest for Sane Regulations - by Zvi Mowshowitz\n",
      "https://lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding | Success without dignity: a nearcasting story of avoiding catastrophe by luck - LessWrong\n",
      "https://bbc.com/news/technology-65779181?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_campaign=Social_Flow&at_ptr_name=twitter&at_link_origin=BBCPolitics&at_link_id=75C7DDFA-00AE-11EE-98BF-4FA2D772BE90&at_format=link&at_bbc_team=editorial&at_link_type=web_link&at_campaign_type=owned&at_medium=social | Powerful artificial intelligence ban possible, government adviser warns - BBC News\n",
      "https://twitter.com/JeffLadish/status/1670889537168621569 | Jeffrey Ladish on Twitter: \"I really appreciate that @RishiSunak is explicitly acknowledge the existential and catastrophic risks faced by AI. To have a competent global response we have to start here Also, accelerating AI development ⏩ is probably the single most dangerous thing you can do in the world\" / Twitter\n",
      "https://theworkback.com/asana-dustin-moskovitz-on-artificial-intelligence/ | AI can make work more human\": Dustin Moskovitz, Asana co-founder and CEO\n",
      "https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit#heading=h.uskcgipunmm1 | Welfare Range and P(Sentience) Distributions - Google Docs\n",
      "https://nathanpmyoung.substack.com/p/artificial-intelligence-riskreward?fbclid=IwAR3APvRCKpl0YFkLINgY9MIRCGpclfQwKLBIfWL8tcpFxTymg2LM_YWfP8 | Artificial Intelligence Risk/Reward: My Sketchy Model\n",
      "https://twitter.com/ReflectiveAlt/status/1670013174844915712 | Reflective Altruism on Twitter: \"New post on excessive spending within the effective altruism movement: t.co/tzyxRksBKh\" / Twitter\n",
      "https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks | Extrapolating performance in language modeling benchmarks\n",
      "https://youtube.com/watch?v=DCFmJNICqKM | Selena Gomez, Kygo - Be My Mistake - YouTube\n",
      "https://docs.google.com/spreadsheets/d/1vLsL0QRtF7z9B4Jn5nu0xXUQXyZA0y4ej98UptRWNDU/edit#gid=0 | Name longlist - AIGS rebranding - Google Sheets\n",
      "https://gwern.net/fiction/clippy | It Looks Like You’re Trying To Take Over The World\n",
      "https://thegradientpub.substack.com/p/talia-ringer-formal-verification?r=2qha5&utm_campaign=post&utm_medium=web#details | Talia Ringer: Formal Verification and Deep Learning\n",
      "https://docs.google.com/document/d/1qxc_XDErDFeQGsYE52vLi1lIJIRL5VL9i1Hi-Btj9Mg/edit#heading=h.du5okd8r0imu | Info on recent/upcoming AI policy happenings, from May 2023 coordination call - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/nKWc4EzRjkpcbDA3A/ai-risk-management-framework-or-nist | AI Risk Management Framework  NIST - EA Forum\n",
      "https://google.com/search?q=ad+astra&rlz=1CDGOYI_enUS715US715&oq=ad+astra&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YgwEY1AIYsQMYgAQyEAgCEC4YgwEY1AIYsQMYgAQyBwgDEAAYgAQyCggEEAAYsQMYgAQyEAgFEC4YxwEYsQMY0QMYgAQyCggGEAAYsQMYgAQyBwgHEAAYgAQyBwgIEAAYgAQyEAgJEC4YrwEYxwEYsQMYgATSAQgzMzE5ajBqN6gCALACAA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | ad astra - Google Search\n",
      "https://twitter.com/DAlperovitch/status/1653375041751375872 | Dmitri Alperovitch on Twitter: \"*NEW* @GeopolDecanted episode: I talk with one of the smartest thinkers on AI policy and tech developments (former WH and DeepMind) about the profound positive and negative military and societal developments we might experience soon (and those we won’t)🧵 t.co/23ErIoRIsk\" / Twitter\n",
      "https://lesswrong.com/posts/sbGau4QBwToYWEg4k/llms-sometimes-generate-purely-negatively-reinforced-text | LLMs Sometimes Generate Purely Negatively-Reinforced Text - LessWrong\n",
      "https://maximumprogress.org/extropia-archaeology | Extropian Archaeology — Maximum Progress\n",
      "https://docs.google.com/presentation/d/1HLj_1v7Hnr8xO0qqfSqucsKbCz7s2fTzsP7gpqT7TA8/edit#slide=id.p | EAG London Talk (Ben Garfinkel) - Google Slides\n",
      "https://thezvi.substack.com/p/ai-6-agents-of-change | AI #6: Agents of Change - by Zvi Mowshowitz\n",
      "https://open.spotify.com/episode/3ZGRLXOInWtr8zLWRdsIPd?si=QTs79BJLRc6Sga9RoILQag&context=spotify%3Ashow%3A7vz4RYsD5MulTCrcH478t1&nd=1 | 3 Steps To Finding Your North Star: An Exciting New Approach To Designing Your Life - The Mel Robbins Podcast  Podcast on Spotify\n",
      "https://voyager.minedojo.org/ | Voyager  An Open-Ended Embodied Agent with Large Language Models\n",
      "https://docs.google.com/spreadsheets/d/1SEMBvi9lZaCyTncBADOHyIjGdlfkRDkNagOSIA3x4js/edit#gid=0 | Blog calendar\n",
      "https://docs.google.com/spreadsheets/d/1waiXbSXZs54_plxa7u9sRQTxMbNaEwbve0sBTGT5BvY/edit#gid=0 | GLT current guesses re asks from SP -- April 2023 - Google Sheets\n",
      "https://wikiwand.com/en/Treaty_of_Tordesillas | Treaty of Tordesillas - Wikiwand\n",
      "https://twitter.com/messages/25776739-77344628 | Brandon Goldman / Twitter\n",
      "https://twitter.com/messages/25776739-1272666807904563200 | Matthew Barnett / Twitter\n",
      "https://newyorker.com/humor/daily-shouts/another-warning-letter-from-ai-researchers-and-executives | Another Warning Letter from A.I. Researchers and Executives  The New Yorker\n",
      "https://reddit.com/r/slatestarcodex/comments/13j5963/contra_scott_on_ai_races/ | (4) Contra Scott on AI Races : slatestarcodex\n",
      "https://docs.google.com/document/d/1bY5cKyw6PhsmcvJuTWym1jEeHEo0xZqz8B_qhthwcBE/edit | EV of the Future and Counterfactual Credit (New Version) - Google Docs\n",
      "https://samstack.io/p/notes-on-effective-altruism?utm_source=share&utm_medium=android | Notes on Effective Altruism - by Sam Atis - Samstack\n",
      "https://tellingthefuture.substack.com/p/what-kind-of-future-will-ai-bring | What Kind of Future Will AI Bring?\n",
      "https://pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://fullfocus.co/yes-you-can-stay-on-top-of-email/ | Yes, You Can Stay on Top of Email\n",
      "https://docs.google.com/document/d/1dwr2qpaWdCqr_IDhcTT69TmEA5aWfiNftasn5iJ_qhA/edit | Premises to get to Strong LT - Google Docs\n",
      "https://lightroom.adobe.com/shares/de80b361304440e6800ae5de3f5a2bfb?invite_id=98d9240825d7486c9b21aace95156888 | Kentucky 2023 by William Hurford\n",
      "https://joshuablake.github.io/blog/gamma-poisson/ | Improve your forecasts of events: use the gamma-Poisson model – Deconfusion Device – Failing to understand the world, learning a little along the way\n",
      "https://wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://macroscience.org/p/on-macroscience | On Macroscience - by Tim Hwang - Macroscience\n",
      "https://mail.google.com/mail/u/0/#inbox | Inbox - peter@peterhurford.com - Peter Hurford Mail\n",
      "https://infogram.com/1p9zelp0zeg5pyi72nknnymj2xsd27wzv9 | Revised (February 2023) Meta-Analytic Validity Coefficients for Predictors of Job Performance - Infogram\n",
      "https://lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai | What should you change in response to an \"emergency\"? And AI risk - LessWrong\n",
      "https://twitter.com/DAlperovitch/status/1670066541650485249 | Dmitri Alperovitch on Twitter: \"@Tatarigami_UA @ProfPaulPoast The determining factor to their decision to invade will be whether they can pull it off - and quickly to present a fait accompli to the world and minimize opposition And that determination will be based on assessment of their own capabilities and those of Taiwan and allies\" / Twitter\n",
      "https://lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with | Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)\n",
      "https://thezvi.substack.com/p/ai-2 | AI #2 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://forum.effectivealtruism.org/posts/XTBGAWAXR25atu39P/third-wave-effective-altruism | Third Wave Effective Altruism - EA Forum\n",
      "https://twitter.com/benedictcooney/status/1670693039327649792 | (1) Benedict Cooney on Twitter: \"We did say a shake-up was necessary t.co/i36Z87oNRs\" / Twitter\n",
      "https://theinsideview.ai/david | theinsideview.ai/david\n",
      "https://twitter.com/TheZvi/status/1654550601798172677 | Zvi Mowshowitz on Twitter: \"This thread is 20 polls about possible futures. What do we value? What would we consider a doomed future, versus a good future? Each Tweet will present a general description of a potential future scenario. The vote is on how you would view this future, if it somehow happened.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/fsaogRokXxby6LFd7/a-compute-based-framework-for-thinking-about-the-future-of | A compute-based framework for thinking about the future of AI - EA Forum\n",
      "https://docs.google.com/document/d/1rvuzMKK3ap7ODD6vWAnZq4RuPberN-d-WHzAYvqO3FU/edit#heading=h.ud0ejn79h6fv | [RP-internal copy] Bid: build a lobbying apparatus for AI regulations, including for big asks that aren't yet feasible - Google Docs\n",
      "https://gwern.net/morning-writing | What Is The Morning Writing Effect? · Gwern.net\n",
      "https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/ | My current summary of the state of AI risk – musings and rough drafts\n",
      "https://metaculus.com/questions/17469/reddit-api-pricing-change-before-july-1/ | Reddit API Pricing Change Before July 1?  Metaculus\n",
      "https://arxiv.org/abs/2306.06924 | [2306.06924] TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI\n",
      "https://lesswrong.com/posts/uxnjXBwr79uxLkifG/comments-on-openai-s-planning-for-agi-and-beyond | Comments on OpenAI's \"Planning for AGI and beyond\" - LessWrong\n",
      "https://docs.google.com/document/d/1w3YEAY6yzqYOIjK5BRhnWbwTN5iV3OOtHf0R67uxecg/edit | Things to say to Caro - Google Docs\n",
      "https://askamanager.org/2012/02/dealing-with-domestic-abuse-in-the-workplace.html | dealing with domestic abuse in the workplace — Ask a Manager\n",
      "https://docs.google.com/document/d/1X8Rq7LYH40Gz5oFLf1zZzwr0pwdB69MuR2fNDlg13KE/edit | Are we prepared for the September hiring round? - Google Docs\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit#heading=h.grts0kyn5j76 | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://twitter.com/Simeon_Cps/status/1671141803951628290 | Siméon on Twitter: \"That's what a basic incentive theory would predict. 1 question: is there any evidence that they lobbied to strengthen or try to have a more stringent regulation along certain axis? E.g. try to regulate the development of AI systems, have third party auditing, regulate…\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case | Counterarguments to the basic AI risk case - EA Forum\n",
      "https://docs.google.com/document/d/1Gkju5VWLldE4COF278hLeWjsVQPHtdgYncCaFeNYcIw/edit | How the Strong-LT Model Works, What it Says, and Whether We Should Trust It - Google Docs\n",
      "https://google.com/search?q=honest+trailers+john+wick+2&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+john+sick&gs_lcrp=EgZjaHJvbWUqCQgDEAAYDRiABDIGCAAQRRg5MgkIARAAGA0YgAQyCQgCEAAYDRiABDIJCAMQABgNGIAE0gEIOTUxNGowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers john wick 2 - Google Search\n",
      "https://forum.effectivealtruism.org/posts/SZJBE3fuk2majqwJQ/principles-for-ai-welfare-research | Principles for AI Welfare Research - EA Forum\n",
      "https://google.com/search?q=honest+trailers+star+wars&rlz=1CDGOYI_enUS715US715&oq=honest+trailers+star+wars&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQLhiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjIICAUQABgWGB4yCAgGEAAYFhgeMggIBxAAGBYYHjIICAgQABgWGB4yCggJEAAYhgMYigXSAQkxMTc2NmowajeoAgCwAgA&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | honest trailers star wars - Google Search\n",
      "https://docs.google.com/document/d/1nCqjJXydfPQGRTKT71jQn8yXi4FSHnVSdfZbhQUMa1I/edit | Lifland Review of JC Alignment Report - Google Docs\n",
      "https://twitter.com/NiklasLauffer/status/1670854905513512960 | Niklas Lauffer on Twitter: \"🤝🤔𝙒𝙝𝙖𝙩 𝙙𝙤 𝙬𝙚 𝙣𝙚𝙚𝙙 𝙩𝙤 𝙠𝙣𝙤𝙬 𝙖𝙗𝙤𝙪𝙩 𝙚𝙖𝙘𝙝 𝙤𝙩𝙝𝙚𝙧 𝙩𝙤 𝙨𝙪𝙘𝙘𝙚𝙨𝙨𝙛𝙪𝙡𝙡𝙮 𝙘𝙤𝙡𝙡𝙖𝙗𝙤𝙧𝙖𝙩𝙚?? In our new ICML paper, we provide a method that determines exactly the information you need to be an optimal teammate in multiagent games. [1/10] t.co/DERhRtguLd\" / Twitter\n",
      "https://bloomberg.com/opinion/articles/2023-06-18/i-95-repair-in-philadelphia-why-can-t-all-projects-be-this-fast?utm_campaign=socialflow-organic&utm_content=view&utm_source=twitter&cmpid%3D=socialflow-twitter-view&utm_medium=social&leadSource=uverify%20wall | I-95 Repair in Philadelphia: Why Can't All Projects Be This Fast? - Bloomberg\n",
      "https://twitter.com/Noahpinion/status/1668541414618316800 | Noah Smith 🐇🇺🇦 on Twitter: \"\"Model collapse\" is interesting, because just a few months ago I talked to a couple AI people who said they thought synthetic data would allow LLMs to get around data limitations. Model collapse is the exact opposite of that. t.co/v9SVHHB0TT\" / Twitter\n",
      "https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly | We Aren't Close To Creating A Rapidly Self-Improving AI\n",
      "https://lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://tools.usps.com/go/TrackConfirmAction?tRef=fullpage&tLc=2&text28777=&tLabels=9405516903019599722222&utm_source=Iterable&utm_medium=email&utm_campaign=campaign_Order%20Shipped | USPS.com® - USPS Tracking® Results\n",
      "https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance | A summary of current work in AI governance - EA Forum\n",
      "https://americanprogress.org/article/the-needed-executive-actions-to-address-the-challenges-of-artificial-intelligence/ | The Needed Executive Actions to Address the Challenges of Artificial Intelligence - Center for American Progress\n",
      "https://cold-takes.com/why-would-ai-aim-to-defeat-humanity/ | Why Would AI \"Aim\" To Defeat Humanity?\n",
      "https://lesswrong.com/posts/RaNhnNjExip36NMxM/advice-for-newly-busy-people | Advice for newly busy people - LessWrong\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit#heading=h.tnew02vlmfya | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment | Clarifying some key hypotheses in AI alignment - LessWrong\n",
      "https://forgottentrek.com/feature-films/designing-the-enterprise-e-bridge/ | Designing the Enterprise-E's Bridge — Forgotten Trek\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit#heading=h.mtpqcbgdzbmj | [Public] Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://facebook.com/ozzie.gooen/posts/pfbid0KsTRs5YSTfGh2s8wia8Ji3tuYSKM5DqDMJ64WQWGzj7cjKtDNHd5A4aegn6V6Agpl | Ozzie Gooen - Meta has been doing really well since its low in Nov...  Facebook\n",
      "https://philpapers.org/archive/VOLHDA.pdf | Microsoft Word - Vold & Harris - How does AI pose an Xrisk .docx\n",
      "https://docs.google.com/document/d/1FlGPHU3UtBRj4mBPkEZyBQmAuZXnyvHU-yaH-TiNt8w/edit | Garfinkel Review of JC Alignment Report - Google Docs\n",
      "https://openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/ | (Request for Information) Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption - Open Philanthropy\n",
      "https://lesswrong.com/posts/PQtEqmyqHWDa2vf5H/a-quick-guide-to-confronting-doom | A Quick Guide to Confronting Doom\n",
      "https://metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning | metaculus.com/questions/?status=open&has_group=false&order_by=-publish_time&main-feed=true&search=include:comp-sci--ai-and-machinelearning\n",
      "https://docs.google.com/document/d/1EUVM2MKpyB9Uet5rJTd61DBKTVmzXgpRXAJm-KPRGCo/edit | Proposal: Coordination around AI advocacy and policy lobbying in the US (AI APLUS) - Google Docs\n",
      "https://docs.google.com/document/d/1Weh2vqYRT-l1SpuufyZ4_ldNoOuIg8QodpNskkYG04U/edit#heading=h.81xq1jfr7jcz | Backgrounder on US Natsec & AI [internal copy] - Google Docs\n",
      "https://lesswrong.com/posts/AL6DRuE8s4yLn3yBo/robin-hanson-s-latest-ai-risk-position-statement | Robin Hanson’s latest AI risk position statement - LessWrong\n",
      "https://airtable.com/appQbatI4fkmVLxHl/tblO0RqaTPXiz0jjp/viwo2rnDB1Py3Fisy?blocks=hide | Redux Again Again: Org Management - Airtable\n",
      "https://twitter.com/ohlennart/status/1669745972400861188 | Lennart Heim on Twitter: \"How could we build a collaborative ecosystem to enable access to the world's most impactful models? A year ago, we (@Manderljung, @tshevl, and I) wrote an article on how an access method could look. Back then with a focus on the US NAIRR, but still timely. t.co/lbso8h6n9R t.co/7I3Jr28R4Q\" / Twitter\n",
      "https://theworkback.com/too-many-meetings/ | Too many meetings? There's a bold solution for business leaders.\n",
      "https://twitter.com/soundboy/status/1670343527723679744 | Ian Hogarth on Twitter: \"I’m honoured to be appointed as the Chair of the UK's AI Foundation Model Taskforce. A thread on why I'm doing this and how you might be able to help us.\" / Twitter\n",
      "https://lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal | Cognitive Emulation: A Naive AI Safety Proposal - LessWrong\n",
      "https://kathrynmintner.medium.com/profile-of-an-osdd-system-with-q-a-3fddf1ae75e1 | Profile of an OSDD System with Q&A  by K. Mintner  Jun, 2023  Medium\n",
      "https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/ | AI will change the world, but won’t take it over by playing “3-dimensional chess”. – Windows On Theory\n",
      "https://theinsideview.ai/victoria | Victoria Krakovna on AGI Ruin, The Sharp Left Turn And Paradigms Of AI Alignment\n",
      "https://forum.effectivealtruism.org/posts/LqjG4bAxHfmHC5iut/why-i-spoke-to-time-magazine-and-my-experience-as-a-female | Why I Spoke to TIME Magazine, and My Experience as a Female AI Researcher in Silicon Valley - EA Forum\n",
      "https://docs.google.com/document/d/1-PP0d9Csu8fA2p_cEc57Vgz6ct4uoV6wrfsqlmns1G4/edit | WIT Retreat Agenda - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/KYApMdtPsveYPAoZk/longtermists-are-perceived-as-power-seeking | Longtermists are perceived as power-seeking - EA Forum\n",
      "https://arxiv.org/abs/2303.16200 | Natural Selection Favors AIs over Humans\n",
      "https://jeffreyladish.com/my-vision-of-a-good-future-part-i/ | My vision of a good future, part I - jeffreyladish.com\n",
      "https://brookings.edu/blog/techtank/2023/02/15/nists-ai-risk-management-framework-plants-a-flag-in-the-ai-debate/ | NIST’s AI Risk Management Framework plants a flag in the AI debate\n",
      "https://ntia.gov/issues/artificial-intelligence/request-for-comments | AI Accountability Policy Request for Comment  National Telecommunications and Information Administration\n",
      "https://skunkledger.substack.com/p/the-monad-laws | The Monad Laws - by BLAP - Skunk Ledger\n",
      "https://docs.google.com/document/d/11YKTKRumtlheK_9Dv9ECKwwoTeSG3RNcs6qUSajzqDw/edit | 2023.05.22 AI Reference Classes - Google Docs\n",
      "https://metaculus.com/tournament/future-of-china/ | China and Global Cooperation - Metaculus\n",
      "https://lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2 | Inside the mind of a superhuman Go model: How does Leela Zero read ladders? - LessWrong\n",
      "https://nytimes.com/2023/05/04/technology/us-ai-research-regulation.html?partner=slack&smid=sl-share | White House Unveils Initiatives to Reduce Risks of AI - The New York Times\n",
      "https://80000hours.org/podcast/episodes/ben-garfinkel-classic-ai-risk-arguments/ | BenGarfinkelonscrutinisingclassicAIrisk arguments\n",
      "https://lesswrong.com/s/xMdkfEJhDNCL2KweB | Slowing AI - LessWrong\n",
      "https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf | Google Secure AI Framework\n",
      "https://twitter.com/backus/status/1652433895793516544 | John Backus on Twitter: \"The code interpreter feature on ChatGPT is the most mind blowing thing I've seen yet. All I did was upload a CSV of SF crime data and ask it to visualize trends(!!) t.co/pkFdPqgAzb\" / Twitter\n",
      "https://google.com/search?gs_ssp=eJzj4tVP1zc0zDM2rEo3t6wwYPQSK8hJrCxWKE_NyVEozyzJUMgvyUgtKgYA7bgM-Q&q=plays+well+with+others&rlz=1C5CHFA_enUS925US925&oq=plays+well+with+&aqs=chrome.1.0i512j46i340i512l2j69i57j0i512l6.956070j0j1&sourceid=chrome&ie=UTF-8 | plays well with others - Google Search\n",
      "https://docs.google.com/spreadsheets/d/1V-i6fIov4srOALnFSA0H7z6RI-VkS4i0coGocI1nDG0/edit#gid=0 | GHD team projects - Google Sheets\n",
      "https://theinsideview.ai/ethan2 | theinsideview.ai/ethan2\n",
      "https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference | Ingroup Deference - EA Forum\n",
      "https://thezvi.substack.com/p/ai-13-potential-algorithmic-improvements | AI #13: Potential Algorithmic Improvements\n",
      "https://twitter.com/davidmanheim/status/1670146830741434372 | David Manheim - bsky:@davidmanheim.alter.org.il on Twitter: \"@peterwildeford Yes - but there's a bunch of work on this already, and it's been flagged as a key concern for EAs for around a decade. My comment on the post @Jotto999 highlighted is here: t.co/76Vi6jzTkP\" / Twitter\n",
      "https://lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects | Six Dimensions of Operational Adequacy in AGI Projects - LessWrong\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate – Windows On Theory\n",
      "https://lesswrong.com/posts/mSF4KTxAGRG3EHmhb/ai-x-risk-approximately-ordered-by-embarassment | AI x-risk, approximately ordered by embarrassment\n",
      "https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future | ‘Dissolving’ AI Risk – Parameter Uncertainty in AI Future Forecasting - EA Forum\n",
      "https://twitter.com/benskuhn/status/1606407189161091072 | Ben Kuhn on Twitter: \"A thing I often find myself suggesting to new managers is to \"exert more backpressure.\" Backpressure is a concept from fluid dynamics (and distributed systems) meaning the way in which a system resists overload—e.g. by slowing down, dropping requests, or completely failing.\" / Twitter\n",
      "https://docs.google.com/document/d/1JataZjU6aIon_tB1_dqMp7lXzPQYT7Uqu5m5DKMbdb4/edit#heading=h.mfc0g6vdbaom | Evals, safe scaling, & related policy/regulation: relevant readings, people, & notes - Google Docs\n",
      "https://lesswrong.com/posts/pFaLqTHqBtAYfzAgx/the-dictatorship-problem | The Dictatorship Problem - LessWrong\n",
      "https://drive.google.com/file/d/1-W5vx__PxZY4IEqWkQ0BqQw5hi3133Pu/view | Delay detect defend - GCBR roadmap draft (ask before resharing).pdf - Google Drive\n",
      "https://thezvi.substack.com/p/eliezer-yudkowskys-letter-in-time | Eliezer Yudkowsky's Letter in Time Magazine\n",
      "https://twitter.com/AnthropicAI/status/1669737555846377472 | Anthropic on Twitter: \"Introducing our new Trust Portal, a way for you to easily find information about our certifications and compliance policies. We're excited to support use cases across a wide range of industries. t.co/snoalEUbij t.co/KLdLPDZtva\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1670876145355485194 | Helen Toner on Twitter: \"Belated, but - I was delighted to be included in this group! Huge props to @alondra and co for pulling us together on short notice and turning around a submission to NTIA's request for comments on AI accountability. Some of the key points from our submission: 🧵 t.co/GvweqXmeen\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1jRzemyEtoOBzj0KOKizErdN_tbJUKN-hxJ-TE6yh15Y/edit#gid=1673404152 | Copy of Growthology Scorecard Cycle\n",
      "https://davidmanheim.substack.com/p/brief-thoughts-on-data-reporting | Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation\n",
      "https://aiimpacts.org/relevant-pre-agi-possibilities/ | Relevant pre-AGI possibilities – AI Impacts\n",
      "https://whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/ | Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety\n",
      "https://nytimes.com/2023/05/23/opinion/ai-chatbot-relationships.html | Opinion  My A.I. Lover - The New York Times\n",
      "https://theinsideview.ai/irina | theinsideview.ai/irina\n",
      "https://lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt | On AutoGPT - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/MAS8riyKsZut4geWy/but-why-would-the-ai-kill-us | But why would the AI kill us? - EA Forum\n",
      "https://lesswrong.com/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance | Extrapolating GPT-N performance - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/gsPmsdXWFmkwezc5L/some-talent-needs-in-ai-governance | Some talent needs in AI governance - EA Forum\n",
      "https://askamanager.org/2023/05/i-think-my-employee-is-being-abused-by-her-partner.html | I think my employee is being abused by her partner — Ask a Manager\n",
      "https://forum.effectivealtruism.org/posts/P98Pas4cirMQp3cJy/clarifying-and-predicting-agi | Clarifying and predicting AGI - EA Forum\n",
      "https://arxiv.org/abs/2305.15324 | Model evaluation for extreme risks\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://ineffectivealtruismblog.com/2023/06/17/billionaire-philanthropy-part-6-from-efficiency-to-extravagance/ | Billionaire philanthropy: (Part 6: From efficiency to extravagance) - Reflective altruism\n",
      "https://lesswrong.com/posts/QzkTfj4HGpLEdNjXX/an-artificially-structured-argument-for-expecting-agi-ruin | An artificially structured argument for expecting AGI ruin - LessWrong\n",
      "https://thezvi.substack.com/p/ai-8-people-can-do-reasonable-things | AI #8: People Can Do Reasonable Things - by Zvi Mowshowitz\n",
      "https://docs.google.com/document/d/1uD9b-lrczR2r4LxppInaDQhOSvN0YYDi7MfuSyp1b-w/edit#heading=h.pn9w2hrth81s | Metaculus AI tournament analysis - Google Docs\n",
      "https://planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://foreignaffairs.com/united-states/china-multipolarity-myth?utm_medium=social | The Myth of Multipolarity: American Power’s Staying Power\n"
     ]
    }
   ],
   "source": [
    "print('Shuffled tabs! ({})'.format(len(tabs)))\n",
    "\n",
    "random.shuffle(tabs)\n",
    "\n",
    "print('-')\n",
    "for t in tabs:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7eece4-8649-45d2-bd1f-5d0e2554c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tabs opened!\n"
     ]
    }
   ],
   "source": [
    "open_tabs_from_text(\"\"\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cec14-6156-40a7-90b6-9498596a18b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
