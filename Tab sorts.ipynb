{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40568205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def print_tabs(tabs, label=None, shuffled=True):\n",
    "    if shuffled:\n",
    "        tabs = random.sample(tabs, len(tabs))\n",
    "    if label:\n",
    "        print('## {} ## ({} tabs)'.format(label, len(tabs)))\n",
    "    else:\n",
    "        print('({} tabs)'.format(len(tabs)))\n",
    "    print('')\n",
    "    for tab in tabs:\n",
    "        print(tab.replace('\\n', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_tab(tab):\n",
    "    url = tab.split('|')[0].replace(' ', '')\n",
    "    webbrowser.open(url, new=2, autoraise=False)\n",
    "    \n",
    "    \n",
    "def open_tabs(tabs, page=1, per_page=10):\n",
    "    page_start = (page - 1) * per_page\n",
    "    total_pages = int(np.ceil(len(tabs) / per_page))\n",
    "    if page > total_pages:\n",
    "        raise ValueError('Cannot open page {}, only have {} pages'.format(page, total_pages))\n",
    "    page_end = page * per_page\n",
    "    if page_end > len(tabs):\n",
    "        page_end = len(tabs)\n",
    "    paged_tabs = tabs[page_start:page_end]\n",
    "    print('Opening page {}/{} (tabs {}-{} of {})'.format(page, total_pages, page_start, page_end, len(tabs)))\n",
    "    \n",
    "    for tab in paged_tabs:\n",
    "        open_tab(tab)\n",
    "\n",
    "        \n",
    "def open_random_n_tabs(tabs, n=5):\n",
    "    tabs = random.sample(tabs, len(tabs))\n",
    "    open_tabs(tabs, page=1, per_page=n)\n",
    "    return tabs[5:]\n",
    "\n",
    "        \n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n",
      "688\n",
      "687\n",
      "687\n",
      "687\n"
     ]
    }
   ],
   "source": [
    "tab_file = open('/Users/peterhurford/Documents/alltabs.txt', 'r')\n",
    "tabs = tab_file.readlines()\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = [t for t in tabs if t != '\\n']\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = sorted(list(set(tabs)))\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(k, v) for k, v in dict([(t.split('|')[0].strip(), ''.join(t.split('|')[1:]).strip()) for t in tabs]).items()]\n",
    "print(len(tabs))\n",
    "\n",
    "tabs = ['{} | {}'.format(v, k) for k, v in dict([(''.join(t.split('|')[1:]).strip(), t.split('|')[0].strip()) for t in tabs]).items()]\n",
    "print(len(tabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Messages ## (4 tabs)\n",
      "\n",
      "https://www.facebook.com/messages/t/688615094/ | Messenger  Facebook\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://twitter.com/messages/25776739-779118444440592384 | Tom Liptay / Twitter\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower())], label='Messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c2b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Facebook ## (1 tabs)\n",
      "\n",
      "https://www.facebook.com/jeffladish/posts/pfbid0SjNagfzWSoV8RWNtZF2Kqq4CWRchu1sHLcLdsWFa5ERQyMdsx9jvvrR78JjmSvWnl | https://www.facebook.com/jeffladish/posts/pfbid0SjNagfzWSoV8RWNtZF2Kqq4CWRchu1sHLcLdsWFa5ERQyMdsx9jvvrR78JjmSvWnl\n"
     ]
    }
   ],
   "source": [
    "print_tabs([t for t in tabs if 'facebook.com' in t.lower() and 'messages' not in t.lower()], label='Facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d6e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Twitter ## (142 tabs)\n",
      "\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635830145658544129 | Daniel Ethüí° on Twitter: \"If it wasn‚Äôt dead already, this should put to rest the idea that LLMs are just stochastic parrots without any understanding\" / Twitter\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://twitter.com/Rainmaker1973/status/1644248670160801792 | Massimo on Twitter: \"When traffic cones along a road in New Zealand began mysteriously moving around, the Transport Agency set up a CCTV to pin down the culprits It turned out a Kea parrot moved them to get attention from humans &amp; get fed [read more: https://t.co/U2cecFOeXh] https://t.co/mqGE37IIpr\" / Twitter\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://twitter.com/RomanHauksson/status/1640612961835261953 | Roman Hauksson on Twitter: \"@absurdlymax @austinc3301 @peterwildeford played with Bing Chat a bit and came up with \"proportional perception\" and \"dimensional discernment\"? ü§∑‚Äç‚ôÇÔ∏è\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1623941659779280896 | Daniel Ethüí° on Twitter: \"Hmm, I‚Äôm slightly worried about moves in this direction - especially since I think we‚Äôre currently much closer to the danger zone of ‚Äútoo cold‚Äù than ‚Äútoo hot‚Äù https://t.co/nJZPKSvqIz\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1630961114375761922 | Daniel Paleka on Twitter: \"No one sees ChatGPT for the first time and thinks \"just some n-gram correlations\" or \"no real knowledge inside\". Those unintuitive beliefs trickle down from some experts, who should know better than to teach their controversial theories as established fact: üßµ (1/12)\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643167977372815360 | https://twitter.com/MatthewJBar/status/1643167977372815360\n",
      "https://twitter.com/HamishDoodles/status/1636088496086474758 | Hamish McDoodles on Twitter: \"@peterwildeford @JacobPeacock1 But it's what I actually believe is the correct answer to your question, so if I'm actually missing something then expressing how I think about this and getting roasted is a good way to find that out.\" / Twitter\n",
      "https://twitter.com/anthrupad/status/1641678142006763523 | wÃ∏ÕÇÕÇÕïaÃ∑ÕêÕîÃótÃ¥ÕóÃôeÃµÃîÃïÃ¨rÃ¥ÃìÃäÃ∞mÃµÕÉÃΩÕôÕñaÃµÃìÕíÃóÃ¢rÃ∏ÃΩÃ≤kÃ∑ÕùÃÅÕîÃß on Twitter: \"Here's a snippet from the White House's \"Blueprint for an AI Bill of Rights\" Concerns regarding x-risk from AGI aren't explicitly mentioned and it doesn't seem to suggest we've got a plan in place for preparing for the potential arrival of superintelligent systems https://t.co/nfqesbITrR\" / Twitter\n",
      "https://twitter.com/ozyfrantz | (1) ozy brennan ü¶ô (@ozyfrantz) / Twitter\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1640379280990560258 | Michael C. Frank on Twitter: \"The take-home here is that we are off by 4-5 orders of input magnitude in the emergence of adaptive behaviors. (That's the figure from above). The big broad cognitive science question is - which factors account for that gap? I'll think about four broad ones. https://t.co/QZfUiwJO8X\" / Twitter\n",
      "https://twitter.com/SSGamblers | Star Spangled Gamblers (@SSGamblers) / Twitter\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | (1) Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://twitter.com/DrRadchenko/status/1638417468967505920 | Sergey Radchenko on Twitter: \"The Xi-Putin summit has ended and it's time to take a quick look at where we stand. At the start of the summit I mentioned that, much as Mao during his meeting with Stalin in 1949, Putin wanted something that \"looked good but also tasted delicious.\" The results are disappointing.\" / Twitter\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://twitter.com/yonashav/status/1636823304940994568 | https://twitter.com/yonashav/status/1636823304940994568\n",
      "https://twitter.com/JgaltTweets/status/1643496690740068357 | (1) JgaltTweets on Twitter: \"I'd like to see a variation on this in which participants are presented with 10-20 actual &amp; potential dangers and asked to rank them according to how much of a threat they think they pose to the human race; should include things like climate change, nukes, terrorism, aliens, etc\" / Twitter\n",
      "https://twitter.com/swift_centre | The Swift Centre (@swift_centre) / Twitter\n",
      "https://twitter.com/Jsevillamol/status/1640997070650720256 | Jaime Sevilla on Twitter: \"I share a big part of Matthew's frustration, though I disagree with the bottom line and I have signed the letter. Why? I explain below üßµ\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1636508502498897921 | Jeffrey Ladish on Twitter: \"I've decided to donate $240 to both GovAI and MIRI to offset the $480 I plan to spend on ChatGPT Plus over the next two years ($20/month). I don't have a super strong view on ethical offsets but they feel right to me in this case. One reason is that it seems useful to actually‚Ä¶\" / Twitter\n",
      "https://twitter.com/davidchalmers42/status/1640357701417938945 | David Chalmers on Twitter: \"@rgblong in the terms i used, it arguably doesn't have an e-understanding of unicorns, e.g. knowing what it's like to see a unicorn. it arguably has a b-understanding (behavior) and r-understanding (recognitional) on performance-based readings. i-understanding (inferential) is tricky.\" / Twitter\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://twitter.com/davidchalmers42/status/1640334105941344261 | David Chalmers on Twitter: \"my slides for last friday's #phildeeplearning debate on \"do language models need sensory grounding for meaning and understanding\" are now online at https://t.co/Ffl1hIzp30. i was on the \"no\" side. my final summary slide with a slightly more nuanced view is below. https://t.co/t2QELGHUXf\" / Twitter\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://twitter.com/YosarianTwo/status/1635780666632687617 | Yosarian2 on Twitter: \"Holy shit. GPT-4, on it's own; was able to hire a human TaskRabbit worker to solve a CAPACHA for it and convinced the human to go along with it. https://t.co/xVuQnyUUry\" / Twitter\n",
      "https://twitter.com/leopoldasch | https://twitter.com/leopoldasch\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1639194473350717442 | Jeffrey Ladish on Twitter: \"AI takeover is very likely üßµ This is true even if AI alignment turns out to be relatively easy. I do not think it will be easy, but this would not change the conclusion All you need to conclude AI takeover is that future AI systems will be very powerful and agentic...\" / Twitter\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643385498092834817 | Jeffrey Ladish on Twitter: \"This is exactly it. I don't pretend to know exactly how this transition will go. I'm confused about agents and goals and optimization. But we are talking about rapidly filling the world with things we don't begin to understand that will be far, far smarter than us\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1643428537821720578 | Eliezer Yudkowsky on Twitter: \"So the actual scary part to me is that GPT4 understands what it means to say, \"Compress this in a way where *you* can decompress it.\" Humans take for granted that we know our own capabilities, that we reflect, that we can imagine how we would react to a future input, we can‚Ä¶\" / Twitter\n",
      "https://twitter.com/lxrjl/status/1639397697084874752 | alex lawsen on Twitter: \"\"Why would you think AI might end up displaying [deception/power-seeking/other scary thing]?\" \"People will design them to\" \"But those theorems might not apply to the real wo.... WAIT WHAT?\" \"People will design them to\"\" / Twitter\n",
      "https://twitter.com/T_Goody3/status/1638203321704955904 | Trey on Twitter: \"I used code-davinci-002 recently to do a simple dev task, and it began responding with occasional eery, uncomfortable, human-like mental breakdowns in the comments (see attached). Completely unprompted, @OpenAI have you seen this? https://t.co/1qWyrpYsc9\" / Twitter\n",
      "https://twitter.com/EpistemicHope/status/1633341593531961345 | Eli Tyre on Twitter: \"Sometimes, people say, \"Wow! given LLMs, and other recent AI develpments, it looks like we're at the start of a slow takeoff.\" I think that's only half right.\" / Twitter\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/mattyglesias/status/1635936611937517583 | Matthew Yglesias on Twitter: \"A lot of talk about how tech is viewed by non-tech people, but this survey has 31% of active machine learning researchers saying AI work is going to make the world worse. Median respondent says 5% odds of human extinction. https://t.co/BxwFnevki7 https://t.co/nxx1dCnSYI\" / Twitter\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://twitter.com/JeffLadish/status/1628503073755906049 | Jeffrey Ladish on Twitter: \"I think the AI situation is pretty dire right now. And at the same time, I feel pretty motivated to pull together and go out there and fight for a good world / galaxy / universe @So8res has a great post called \"detach the grim-o-meter\", where he recommends not feeling obligated‚Ä¶\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://twitter.com/birchlse/status/1628736918362923008 | Jonathan Birch on Twitter: \"I've written an @aeonmag piece on animal and AI sentience with @KristinAndrewz. It's the first time I've written about what I see as the hardest problem in the AI case, the \"gaming problem\". üßµ(1/5) https://t.co/pCOijaMI5D\" / Twitter\n",
      "https://twitter.com/TaylorWWebb/status/1641172201792761856 | (1) Taylor Webb on Twitter: \"Major update to our paper on emergent analogy in LLMs, with a number of additional tests and behavioral experiments, and a preliminary test of GPT-4. https://t.co/mvzvIJh1dI\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1637874864089341957 | Nathan is at EAGx Camüîç (join convos I'm in üëã) on Twitter: \"@StefanFSchubert I guess the likelihood is already included in timeline forecasts, right? To forecast impact I guess we'd need specific actions that might a cause a slow down?\" / Twitter\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639040220191678464 | Rob Bensinger üîç on Twitter: \"Actions are definitely not \"where the bad things could happen\", unless you're also treating text outputs as \"actions\". Which you probably should. Talking to people is not in a different magisterium from \"acting on the world\", and unaligned ASI with a text channel is not safe.\" / Twitter\n",
      "https://twitter.com/yonashav/status/1633494288624484353 | Yo Shavit on Twitter: \"Ah shit this is actually very fun, but GPT-3.5-scale LMs shouldn‚Äôt be able to intuitively sample the space of fun emergent game mechanics yet‚Ä¶ right? https://t.co/lrjSTHqPPi\" / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://twitter.com/AnthropicAI/status/1641463526291312643 | Anthropic on Twitter: \"Today we are releasing the new Claude App for @SlackHQ, in beta. Now every company in the world has the chance to have a ‚Äúvirtual teammate‚Äù who can help make work more fun and productive. https://t.co/YNpIH5caBP\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639061235164659712 | Rob Bensinger üîç on Twitter: \"@RosieCampbell OK, I was partly kidding. I do think most likely AI surprises look pessimistic, but some would look optimistic. See https://t.co/IS2jxBQHXd Links: 1. https://t.co/htpadcWU1v 2. https://t.co/6TbJACvNsa 3. https://t.co/StpwXHREvn. https://t.co/nHZpEm0Yg5\" / Twitter\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://twitter.com/natalia__coelho/status/1636609751902744577 | Nat√°lia üîç on Twitter: \"People have high expectations for GPT-12 \"Will a game of Pong be played with a galaxy as the ball before 2040?\" https://t.co/dC1ZjX2cp8 https://t.co/PlTWzdEUt9\" / Twitter\n",
      "https://twitter.com/MelMitchell1 | (7) Melanie Mitchell (@MelMitchell1) / Twitter\n",
      "https://twitter.com/peterwildeford/status/1619784538196176897 | Peter Wildeford is a Laura Duffy neolib stan acct on Twitter: \"Second winner of the \"what strictly text-based task can an 8 year old reliably do that GPT3 cannot reliably do when given expert-level prompt engineering\" challenge by @EzraJNewman The second $40 prize will be awarded.\" / Twitter\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://twitter.com/douglasmack/status/1638705593258061826 | (1) Doug Mack on Twitter: \"30 years after this was published, it still might be my favorite lede of all time https://t.co/vfxH2I0zOs\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://twitter.com/benparr/status/1635684322261729282 | Ben Parr on Twitter: \"üö® HUGE news in AI: Google just launched Generative AI across ALL of Google Workspace -- Gmail, Docs, Sheets, Slides, Images -- EVERYTHING. They made a video showing off the new AI's capabilities. It's AWESOME. https://t.co/bL9uxafrvW\" / Twitter\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://twitter.com/mcxfrank/status/1640379247373197313 | Michael C. Frank on Twitter: \"How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. üßµ https://t.co/hayhUU5Iv6\" / Twitter\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://twitter.com/QualyThe/status/1637817473801105413 | Qualy the lightbulb on Twitter: \"arguing with a rationalist like üòä https://t.co/o9vXAH6MOt\" / Twitter\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/gwern/status/1636739854586335232 | https://twitter.com/gwern/status/1636739854586335232\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://twitter.com/Caro_Jeanmaire/status/1641921736760229895 | Caroline Jeanmaire on Twitter: \"This is one of my favorite papers to explain the threat model of advanced AI (and it even has pictures!)\" / Twitter\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://twitter.com/SolarxPvP/status/1635866783763636225 | SolarxPvPü•ã on Twitter: \"Why aren't AI doomer people scared of extraterrestrial AIs? Earlier civilizations could have developed them, and if there were earlier ones, they already should have gotten here. AIs wouldn't get bored or need money for the long trip. They would get here faster.\" / Twitter\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://twitter.com/harries_matthew/status/1630493459499941892 | Matthew Harries on Twitter: \"I seem to be in a minority of one on this, and I'm aware I don't know what's happening behind closed doors, but based on the public evidence I am very sceptical about the idea that China's language on nuclear threats in its Ukraine paper is a clear win. /1 https://t.co/9dQei78al5\" / Twitter\n"
     ]
    }
   ],
   "source": [
    "twitter_tabs = sorted([t for t in tabs if 'twitter.com' in t.lower() and 'messages' not in t.lower()])\n",
    "print_tabs(twitter_tabs, label='Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8d623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(twitter_tabs, page=1, per_page=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4635d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google Docs ## (280 tabs)\n",
      "\n",
      "https://docs.google.com/document/d/1gn77WcyIeuTK3ZKAgWdD-3VTUYcx4cNhbSSieE1rSN4/edit | RP LT work-in-progress (WiP) sessions: Session notes [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success Without Dignity - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://docs.google.com/document/d/1qVXta8izrX3gmPVSX-QjuDTCg3TSkjbrWkKPm6PdBPQ/edit | RP Copy of Projects Alex would be excited about - March 2023\n",
      "https://docs.google.com/document/d/1mWa6pM65MqVnWgpMLSv0IejP526_0OjGCMbNbDz89jg/edit | Mike McCormick <> Renan/Linch on LT entrepreneurialism - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/1JlEfNtOWdRJC4t_5lyMKGmIxVIIe143oYYQNxWKEM7g/edit#heading=h.g4t1dqegifc2 | [v. C] Intermediate goals suggested by survey respondents ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1ZG0XIP6ItkSBfWPaH6n2Fd0J7A6dvYtfFAy1S7YyhSY/edit | Biggest Mistakes we‚Äôre making - Google Docs\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1mrmbcjLfpubTdEs6l0QIqXYiJz3006oE6-IvuDD8Mu8/edit | Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://docs.google.com/document/d/18bOeTikuNvI0G34UCgZQkySi87_3lqhLDF9JGkTxUl0/edit | [2023.02.12 (Feb)] Defense-in-Depth Compiled Report [Master Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1YSgdVuvYWnBE4CAPvMRA3pfsSlZTl-93uYji5n6zC3Q/edit | [Forum experiment] Strategy investigation: Cause area intersections - Google Docs\n",
      "https://docs.google.com/document/d/1wo__OjZaQ4skvw-Rqoz-9LyXQPBv7XY3UuAd4BVaODw/edit | Longtermist incubation Q1+Q2 2023 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1p7KAFI8_oQVHS3nXNAaWqIPExb87MsBWo9pS98gcQQc/edit | RP AIGS project options spreadsheet - Google Sheets\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://docs.google.com/document/d/1Bp-95XalxsgQQ1q1-PCW030oXaWUP5Dpkdj4TnbNfF0/edit | [mini-copy for my discussion table] What I think the AI plan is - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1OMeHukuwa9ghOe_ZaPusNMnBwzkDSq7yRto_IkGl5tM/edit | [final draft] Project idea solicitation plan - Google Docs\n",
      "https://docs.google.com/document/d/1fXTIN6goXqEmGA8Hyg5oeD6MK3En7dtF0lTFz8MDxKs/edit | GLT Strategy for 2023 v0.4 2023-03-30\n",
      "https://docs.google.com/document/d/1qh1jUCLKAbteof6u2DcYaZJaNHHp5HvZJlV1eIpqXWs/edit | RP Campus Awareness Survey - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1TlWcxy-fuzXd93DEJ_sj8R6Ikm4HJMZd92sXULbnZvM/edit | [very confidential] Staff Risk - Google Sheets\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://docs.google.com/document/d/1af7rhUUr0hhtnkl3VjXmFEA6W_DlG_V4sVfc1jL4sng/edit | [shared] T3A: 2023-02 Investor pitch - Google Docs\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1EtQjv-YFS3LD8YfW8RpmlD03XmIZrStTBEXerLqWp0o/edit#heading=h.ssso4t7fjkoa | Deliberative Decision Making Procedures (v1) - Google Docs\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://docs.google.com/document/d/1cgyL0QbR26XWqbR8GoUOe2nMcAy_rXK1eKKhrwBHyc8/edit | EA Scandal Risk Write-up 2 - Google Docs\n",
      "https://docs.google.com/document/d/14YxJ6wO6j3Rn95XUdHxomNVi3eLmaJeaPgygqHcscn8/edit#heading=h.e7ui0mg6b3y4 | AR Reflections on the Ops Retreat - Google Docs\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/document/d/1tNDNbjg63Vx03w0iV5Cy3Lyw9azZBuevRQFowcWTG1E/edit#heading=h.oopq92wv47s1 | Prioritization of different kinds of technical compute governance research [shared] - Google Docs\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://docs.google.com/document/d/1J4TK6twjcF3hop5ZoEVR-_FVnnRdABFSm0WZkuuhU6c/edit | EPE'22 Process Debrief - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://docs.google.com/document/d/1qa1QkVQzDMQ-q_xvXuqYLToKwePoCOyPlo-8ydfzEcg/edit | 6219476ee801e140e5433082   Patchd, Inc.  2023-03-02T01:05:24Z - Google Docs\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://docs.google.com/document/d/1PidPXJWKKqCbWGzWQ7IySDnOkiK5rX0n2naaSjz7q3g/edit#heading=h.6ytgvt3dfnpe | Kieran Greig Copy of Oct-Nov - RP Performance Evaluation Template - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://docs.google.com/document/d/19UAquUto2Xw4FCKLlM2YMxcnWQMaT_cVgu-lSMO6YJ0/edit | Existential Security Additional Memo Topics [Brainstorm] - Google Docs\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1bue7VzQPZ9Uy7drOShVdF1h0_uSAB9wQsSA4gcBvPGg/edit | Takeaways from EAGx Cambridge convos about GLT‚Äôs strategy (mostly entrepreneurship stuff) - Google Docs\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1jWEO-Y7flKK9um9Dz1Lz_o-vhj3S6EaewDgRRUdKI-s/edit | Magnify Mentoring ‚Äì Evaluation (EAIF) ‚Äì 63d99c2d65a55348e903a1c3 - Google Docs\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://docs.google.com/document/d/1zeKyneX_8hcmmDq467FuIR9y6Zxz0iQNicOcCz_dcfw/edit | AW Department changes & updates\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://docs.google.com/document/d/1Psa11UEeLNsJ8XpT8R44GeyW0nhUfuDmZK6JA72mP_A/edit | v2 AI Safety Bounties - Google Docs\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1eDltvvbQDa8iRaVeuVjaZiiJn_KzzgYw_QDnjWTa2EQ/edit | Ops Costs by LT vs Other - Google Sheets\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1Bk25Q7Om8UjnOoua0Zq5pXlzfqK1mwY9Dx1QGvAXemo/edit | Ben‚Äôs GLT strategy work stack - Google Sheets\n",
      "https://docs.google.com/document/d/1UU7cn5YQ7sMC7Ps6GhkuNc6gMcWvLgXw3rgxqhArtJw/edit | Template monthly check-in - Google Docs\n",
      "https://docs.google.com/document/d/1o54DtHVMc0uvgRv3K_eO0wWxV46Jk8B7HBhu_IiWfm8/edit | [summit copy] Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://docs.google.com/document/d/1cRIjKlYIlAOEUChV-1BU9qzepYVYijKs1tEdxU1k6Hk/edit | [Shareable] OECD AI governance plans - LAISR notes - Google Docs\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1gBy6iOa2xt5O8FfbImBqOsMgOL3NBorQPsN2uKOfcSM/edit#gid=0 | LAISR 2022 Invitees, with emails (for ops staff) - Google Sheets\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://docs.google.com/document/d/174p91cNwjVFD4TF-YTUK7JMjM4_TgdYmyQnElkwb1_E/edit | EOI changelog - Google Docs\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://docs.google.com/document/d/18hsS6rsQmnZcOZJ7Lz2K9jhgosNtS-NXhle7w_BVRLA/edit | AI Safety - Half Year Summary - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://docs.google.com/document/d/1NTSMdsQ6_Yn9xvfMIIx2AYTEKE-FYXwNCJh8E4LyXQQ/edit | Why+How to Speak Openly about AI Risk Outside EA - Google Docs\n",
      "https://docs.google.com/document/d/1VvYj9o6IrbDWUQGq3HVLfjIroVEbdGFBXrfO84qOChI/edit | Communication to RP staff on organizational realignment - Google Docs\n",
      "https://docs.google.com/document/d/1oKQc5QKfEjRQHPU2g6kQBUadhOmFwTg40NH-EW_nrjU/edit#heading=h.za992j72817 | [Shareable] Coordination between labs - LAISR discn summary - Google Docs\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://docs.google.com/document/d/13NW35AVd2Xl7Ka5iImdD89cqzgN9nX2FKCjdDBFanZM/edit | 2023 Ops Retreat Notes\n",
      "https://docs.google.com/document/d/1G3MsnzEmMQ11RzJeGe8WChbFRIHhi_yWVDW_tW1EdD0/edit | Coordinating AI development around a moving bright line - Google Docs\n",
      "https://docs.google.com/document/d/1xiOtTn_3RhvrMHIwRWehbI-Sx3DU0AoveemMF9LQi3c/edit | Onni Aarne's research agenda for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1IkJyu-mO0cdCptxKzBD_DaUk3jW7JhKaSoEGSs9P5rY/edit | Updating my EA community building takes after recent scandals and reduced funding - Google Docs\n",
      "https://docs.google.com/document/d/1O3uRzsBG0QqzPy7QgK0c4S3Hm4GQBKzFp0rG5eXcBDs/edit | Friday & Saturday Schedule ‚Äî Summit on Existential Security - Google Docs\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://docs.google.com/document/d/1PmUuUro7BN_5qJgsZgvTzu64nEk1Zdcu8Wv58cDs9FA/edit | Robert de Neufville ‚Äì Evaluation (EAIF) ‚Äì 63d3561a97b4f8799801fb48 - Google Docs\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://docs.google.com/document/d/1BZv1lRGmS6k_WsMzOLeu9gVIJc9C6nEQKByT5I0UnyI/edit | Project idea: Backgrounder on AI lab safety processes - Google Docs\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1v14aMi7GhpNhk5ahmqgZVeYCKVvSdf9Bsoz8yfR6MpM/edit | The AI playbook as I see it - Google Docs\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://docs.google.com/document/d/15HUEdn4MIQDZLmfhnR0Lhobp8c9YFkIKQI0bFloy32M/edit | USG involvement in advanced AI [shared with RP, Epoch, etc.] - Google Docs\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://docs.google.com/document/d/1e9vWPSCfuMD_elWVFdVdLJhqwWSiQBQKHu-8mvfxAHk/edit | How GLT can work with Mike McCormick and possible strategy updates from that - Google Docs\n",
      "https://docs.google.com/document/d/1iI6iMmNfSH7SB1iAR7QfE0t5wemXB7j6PYARCi_Pl0c/edit | Tianxia analyses - Google Docs\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1nI4Sg7-80bStu0HlkH7ZEfn1OXAZUjfGSqKd9VwGFAE/edit | [summit copy] Defense against misaligned AI - Google Docs\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://docs.google.com/document/d/1s3QGFJ8Ochosksl4JgQCWekJrsY3YFAfGgEiEt6zFpA/edit | How Will the AI Supply Chain Evolve? v4 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jdYBDLrhBgVaf1WqjIlFiksyTemD-U9eIka1Amtwkno/edit | 2023 Jan Lights - Google Sheets\n",
      "https://docs.google.com/document/d/1CbS0ofRMI83BH-Y8moiaLLchUNRtNglLeqkvrmztxso/edit | memo: moratorium on AI scaling? - Google Docs\n",
      "https://docs.google.com/document/d/1mCHfBSUPOCDktuh52foodKy0hiRC5CzRl4C5sAGHto0/edit | 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit | Survey team time allocations - Google Sheets\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://docs.google.com/presentation/d/1yRLDkc7sxGa5eNPB6_IGoEy7dvoPVS6K0EYTd_VceF0/edit | IR Game Rules Intro - Google Slides\n",
      "https://docs.google.com/document/d/1kU3dhaxWK6DyT9Z5RRTXCPvNb1QLkGcf3GgnYHKtamQ/edit | Marcus Personal Ops Retreat notes 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1c_Rwt4lcIjzLc-7N5nZ5CaHClvklkLHBxdrQ8X08L9Q/edit | April/May notes on Caro\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://docs.google.com/document/d/1I6I3qEBhk8hHacJW7ufBZV_-plFq5SDcy_EGw3941ZQ/edit | 2023-02-09 Peter Wildeford - Google Docs\n",
      "https://docs.google.com/document/d/1btLsQqXy5eiaqYKlWEg7FSXbisAblw1PgQtVCJz5l3c/edit | Good cop bad cop in AI safety advocacy - Google Docs\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://docs.google.com/document/d/1XIT-avqFFFO9RnzSJz1BOT3Rw_MzsAwJipxLEoe4YWU/edit | Key points from my conversations w/ people about longtermist incubation - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://docs.google.com/document/d/1mZmox0G910jw7I9jCoDC6vowz_PcrHRfFoW04G59XMA/edit | [PUBLIC] 80,000 Hours two-year review: 2021-2022 - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://docs.google.com/document/d/1iVmi58PLVUaSSu5Qm2F_OBFFNmUxjPVvpt1f6qLGx_k/edit | Bimonthly Hiring and Budgeting Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1fNQ5ycBbZL-Qo0LuXBM0otPPUHGpXW_F98WNlFjekGE/edit | DiD Redrafted Proposal for Jonas - Google Docs\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://docs.google.com/document/d/17Dd7kdgx6TGExC6UtrwiXl4UkrJzTBx8LDmZsdILF9I/edit | AIGS strategy proposal for Q2 2023 [AIGS Leads discussion notes] - Google Docs\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://docs.google.com/document/d/1DIExQFqzkJdngxPUPn1txvBNUuBJeSrE19hwgLUZAgs/edit | PW Self Reflection Nov 2022 - Google Docs\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://docs.google.com/document/d/1hYo758MviVBd_C_OTaFZ4jfG2ZzUyU6dO-WdfCWv81Q/edit | [STUB] Mechanisms for Coordinating Resource Allocation - Google Docs\n",
      "https://docs.google.com/document/d/1Yg0xcj24B6h_wqSGu2_6sv4CJGKGsLL4OhioKBZBwZw/edit | Will the US or a closely allied government control and/or heavily resource the first successful TAI project?\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://docs.google.com/document/d/1VyQJK2dIwvz0yelzT4GjBPXFwdS6PCCwMjFTHTEAAsQ/edit | How does bee learning compare with machine learning? [Public] - Google Docs\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://docs.google.com/document/d/1qV_mNjkpTZEbvS6VUAbTuOYziRgnmAkQcU6zyku_St8/edit | Ben‚Äôs longtermist incubator notes 2022-12-19 - Google Docs\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit | Brainstorming on RP as a brand\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | 04a - Hypothetical \"success stories\" to accompany \"Nearcast-based 'deployment problem' analysis\" - Google Docs\n",
      "https://docs.google.com/document/d/1y8qqleaBMDg3QnBSzmUY4mkZPZoPOaC3fF-vSSkskWY/edit#heading=h.b9zrlpr5ztu9 | Comments on the default approach - Google Docs\n",
      "https://docs.google.com/document/d/1gZ26LP_yGupj72JJ6GVhbtfcwr5ZiOgYh3qJaWdVgag/edit | Ben West <> Renan - Google Docs\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://docs.google.com/document/d/1nxylL1-BwIrg7-G0vDk3K4COpAIpjmIAfwkaN5V1fwk/edit | AIs and moral patienthood - Google Docs\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://docs.google.com/document/d/1uVi0jGpFU6qstOGTVrC8ZRnARa79HDw7L6t_A0nVWOg/edit | EA Crisis Management - Google Docs\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://docs.google.com/document/d/1QlHu2N4BeoRsHZYymVImg023mk-XGjR32cucXB_INOg/edit | Collection of AIGS-related lists of contacts - Google Docs\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1Dl567qFbzH9uqqwdVOWw3npjLSNohMdIWlRMwxVa3LI/edit | 2022-Jan-18 Longtermism fundraising coordination meeting - Google Docs\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [Funder Copy] - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://docs.google.com/document/d/1oInPr-bzqtAULzonDajiT8M10LF50WNfiuaaIkElk4g/edit#heading=h.217anus74gpx | [Shareable] Cost-effectiveness of boosting US AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1gHzQovSnLHxbRalowex0eCAOVgvN5tafvpG2gEMKNH4/edit | Cost-of-living adjustments - Google Docs\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://docs.google.com/document/d/1nOlvwsgDNqsz3bilB1VX7Ml9EokMf_4QQMxIktzQCHE/edit | Projects to increase transparency, cooperation and trustworthiness of top AI labs - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://docs.google.com/document/d/1WY2DmyvKrHQmRBQFGo04HTXMnCIJQs1nhm2UkjLTBGw/edit | Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://docs.google.com/document/d/1YAJ0uVLDHb887LQKMd0HNSF167eksCjSkhKVo9rvEfg/edit | [West] Thoughts on recent PRC statements on international AI ethics and governance - Google Doc\n",
      "https://docs.google.com/document/d/1zhi1NypU0hUE2JM-ewUsC7Tkvw25eLbQPnpUrDjsq48/edit | Meeting Notes - Peter/Zoe 1-1s - Google Docs\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://docs.google.com/document/d/1nZVNE5jLAh0E9n9B2uIe4K-XNLylicnUXmr07jpXtCc/edit | Possible directions for USG-AI project - Google Docs\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://docs.google.com/document/d/1ohA9rzGL8OHQWHsW65Z4HNs4-S8Yr3DJGTxIMruCGyo/edit | [Summit copy] Suppose you align AGI and have a DSA - what then? - Google Docs\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Doc\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1SYBPKllt9Etbbi3ymB4LwWHI6ZiFjlTrthuGSaDBLNs/edit | Main summary: International safety agreements - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n"
     ]
    }
   ],
   "source": [
    "doc_tabs = sorted([t for t in tabs if ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower())])\n",
    "print_tabs(doc_tabs, label='Google Docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(doc_tabs, page=1, per_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479f45a0-d63f-474d-aa76-2ddab5a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = copy(doc_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e71249-4e0e-47aa-9fcd-69b9219f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_tabs_ = open_random_n_tabs(doc_tabs_, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6311fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Google search ## (2 tabs)\n",
      "\n",
      "https://www.google.com/search?q=learn+how+to+seduce&rlz=1CDGOYI_enUS715US715&oq=learn+how+to+seduce&aqs=chrome..69i57j0i15i22i30i625j0i22i30l2j0i15i22i30.6783j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | learn how to seduce - Google Search\n",
      "https://www.google.com/search?q=2024+eclipse&rlz=1C5CHFA_enUS925US925&oq=2024+ecl&aqs=chrome.0.0i131i433i512l2j69i57j0i512l7.1363j0j1&sourceid=chrome&ie=UTF-8 | 2024 eclipse - Google Search\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('google.com' in t.lower() and 'search' in t.lower() and\n",
    "                                   not ('docs.google' in t.lower() or 'sheets.google' in t.lower()))]),\n",
    "           label='Google search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b9762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## EAFo/LW ## (10 tabs)\n",
      "\n",
      "https://forum.effectivealtruism.org/posts/ZvMPNLFBHur9qopw9/is-it-time-for-a-pause | Is it time for a pause? - EA Forum\n",
      "https://www.lesswrong.com/posts/DXByibGtvFixSsyfs/ai-6-agents-of-change | AI #6: Agents of Change - LessWrong\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://forum.effectivealtruism.org/posts/a2KEyLaXzBADb8jgg/can-we-evaluate-the-tool-versus-agent-agi-prediction | Can we evaluate the \"tool versus agent\" AGI prediction?\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n"
     ]
    }
   ],
   "source": [
    "ea_fo_tabs = sorted([t for t in tabs if ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower())])\n",
    "print_tabs(ea_fo_tabs, label='EAFo/LW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffa8f80-4aa6-4afe-8c6a-59194d69895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(ea_fo_tabs, page=1, per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ae2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metaculus etc. ## (29 tabs)\n",
      "\n",
      "https://www.metaculus.com/questions/12997/world-population/ | World Population  Metaculus\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n",
      "https://www.metaculus.com/questions/13787/petaflops-during-gpt-4-training/ | PetaFLOPs during GPT-4 training  Metaculus\n",
      "https://www.metaculus.com/questions/13045/per-capita-primary-energy-consumption/ | Per Capita Primary Energy Consumption  Metaculus\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://manifoldmarkets.notion.site/Manifold-Markets-Seed-Memo-36868a1b0d574111b45d28c0b3fe3254 | Manifold Markets: Seed+ Memo\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://manifold.markets/IsaacKing/if-we-survive-general-artificial-in?r=RWxpZXplcll1ZGtvd3NreQ | If we survive general artificial intelligence, what will be the reason?  Manifold Markets\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://www.metaculus.com/questions/13003/oecd-trust-in-government/ | OECD Trust in Government  Metaculus\n",
      "https://www.metaculus.com/questions/12991/us-gdp-per-hour-worked-productivity/ | US GDP Per Hour Worked (Productivity)  Metaculus\n",
      "https://www.metaculus.com/questions/13021/cagr-gdp-growth-per-capita/ | CAGR GDP Growth Per Capita  Metaculus\n",
      "https://manifold.markets/ACXBot/8-will-a-nuclear-weapon-be-detonate | 8. Will a nuclear weapon be detonated (including tests and accidents) in 2023?  Manifold Markets\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower())]), label='Metaculus etc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72bdaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Wikipedia ## (14 tabs)\n",
      "\n",
      "https://www.wikiwand.com/en/Perfect_Match_(TV_series) | Perfect Match (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/The_Case_of_the_Golden_Idol | The Case of the Golden Idol - Wikiwand\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://www.wikiwand.com/en/Kaleidoscope_(American_TV_series) | Kaleidoscope (American TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://www.wikiwand.com/en/Superbad#Reception | Superbad - Wikiwand\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if ('wikipedia' in t.lower() or 'wikiwand' in t.lower())]), label='Wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reddit ## (7 tabs)\n",
      "\n",
      "https://www.reddit.com/r/CPTSD/comments/11fl8s4/comment/jak7abx/?utm_source=reddit&utm_medium=web2x&context=3 | (4) Did any of the abusers or people who caused chaos in your life that contributed to the ptsd ever change or recognise what they did? : CPTSD\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://www.reddit.com/r/Stargate/comments/6lp112/when_theres_an_unscheduled_offworld_activation/ | (2) When there's an unscheduled offworld activation but no iris code : Stargate\n",
      "https://indianexpress.com/article/technology/reddit-users-are-jailbreaking-chatgpt-and-calling-it-dan-do-anything-now/ | Reddit users are jailbreaking ChatGPT and calling it DAN ‚Äî Do Anything Now  Technology News,The Indian Express\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'reddit' in t.lower()]), label='Reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedf293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## localhost ## (1 tabs)\n",
      "\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()]), label='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677f610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Chores ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instacart' in t.lower()]), label='Chores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fce865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Amazon ## (7 tabs)\n",
      "\n",
      "https://www.amazon.com/s?k=anker+laptop+power+bank&sprefix=anker+lapt%2Caps%2C160&ref=nb_sb_ss_ts-doa-p_2_10 | Amazon.com : anker laptop power bank\n",
      "https://smile.amazon.com/How-Calm-Your-Mind-Productivity-ebook/dp/B09WM9PTD9?ref_=ast_sto_dp&sa-no-redirect=1 | AmazonSmile: How to Calm Your Mind: Finding Presence and Productivity in Anxious Times eBook : Bailey, Chris: Kindle Store\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://smile.amazon.com/Retractable-Keychain/s?k=Retractable+Keychain&sa-no-redirect=1 | Amazon.com : Retractable Keychain\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://smile.amazon.com/Elegant-Puzzle-Systems-Engineering-Management/dp/1732265186?sa-no-redirect=1 | AmazonSmile: An Elegant Puzzle: Systems of Engineering Management: 9781732265189: Larson, Will: Books\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'amazon.com' in t.lower()]), label='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d46af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Morning Dispatch ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'morning' in t.lower() and 'dispatch' in t.lower()]), label='Morning Dispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "108d879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GitHub ## (11 tabs)\n",
      "\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n",
      "https://github.com/peterhurford/future-assessment-model/blob/main/(3A)%20Initial%20TAI%20Spend%20Model.ipynb | future-assessment-model/(3A) Initial TAI Spend Model.ipynb at main ¬∑ peterhurford/future-assessment-model\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'github.com' in t.lower()]), label='GitHub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d911bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube ## (17 tabs)\n",
      "\n",
      "https://www.youtube.com/watch?v=Iv9vphCwsaU | https://www.youtube.com/watch?v=Iv9vphCwsaU\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=xtNrm-EXRjI | Markus Anderljung Regulating increasingly advanced AI some hypotheses - YouTube\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://www.youtube.com/watch?v=gI5SOUrW7Nc | https://www.youtube.com/watch?v=gI5SOUrW7Nc\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://www.youtube.com/watch?v=dVxMrVJ58as | First 18 Things to Do for Productivity // New Macbook Pro! - YouTube\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'yout' in t.lower()]), label='YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2649c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instagram ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'instagram.com' in t.lower()]), label='Instagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab0e02f2-e275-486f-98d3-37d3218dc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asana ## (0 tabs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tabs(sorted([t for t in tabs if 'app.asana.com' in t.lower()]), label='Asana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc70c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Other ## (170 tabs)\n",
      "\n",
      "https://pasteurs-cube.ghost.io/ghost/#/editor/post/63f2a8300e4dd0004d15adae | ChatGPT is not a stochastic parrot (plus digital sentience and answering just how freaked out we should be right now?) - Pasteur's Cube\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://garymarcus.substack.com/p/this-week-in-ai-doublespeak | This Week in AI Doublespeak - by Gary Marcus\n",
      "https://astralcodexten.substack.com/p/openais-planning-for-agi-and-beyond | OpenAI's \"Planning For AGI And Beyond\" - by Scott Alexander\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "http://shfhs.org/ | http://shfhs.org/\n",
      "https://muddyclothes.substack.com/p/the-rocky-history-of-ai-in-china | The rocky history of AI in China: from neglect to national priority\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://oneusefulthing.substack.com/p/the-future-soon-what-i-learned-from | The future, soon: what I learned from Bing's AI\n",
      "https://www.cold-takes.com/high-level-hopes-for-ai-alignment/ | High-level hopes for AI alignment\n",
      "https://nymag.com/intelligencer/2023/03/on-with-kara-swisher-sam-altman-on-the-ai-revolution.html | ‚ÄòOn With Kara Swisher‚Äô: Sam Altman on the GPT-4 Revolution\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://nunosempere.com/blog/2023/03/15/fit-beta/ | Find a beta distribution that fits your desired confidence interval\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://magazine.sebastianraschka.com/p/ahead-of-ai-4-a-big-year-for-ai | Ahead of AI #4: A Big Year For AI - by Sebastian Raschka\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://sites.google.com/view/adaptive-agent/ | Human-Timescale Adaptation in an Open-Ended Task Space\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?sd=pf | What did they know, and when did they know it? The Microsoft Bing edition.\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://confido.institute/ | https://confido.institute/\n",
      "https://www.economist.com/briefing/2023/03/30/americas-commercial-sanctions-on-china-could-get-much-worse | America‚Äôs commercial sanctions on China could get much worse  The Economist\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://www.alignmentforum.org/posts/etNJcXCsKC6izQQZj/pivotal-outcomes-and-pivotal-processes | Pivotal outcomes and pivotal processes - AI Alignment Forum\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://garymarcus.substack.com/p/the-first-known-chatbot-associated | The first known chatbot associated death - by Gary Marcus\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/ | In defense of prompt engineering\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://www.oneusefulthing.org/p/my-class-required-ai-heres-what-ive?fbclid=IwAR03DvA57jfUfx2R27nHDMSybKiPsMIFyLTnC43l-Kj4jiCCsGUIElXPH7s | My class required AI. Here's what I've learned so far.\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ | Update on ARC's recent eval efforts\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n",
      "https://thebulletin.org/2023/01/researchers-hacked-a-labs-pathogen-containment-system-was-it-a-good-idea-to-publish-the-results/ | Researchers hacked a lab's pathogen containment system. Was it a good idea to publish the results? - Bulletin of the Atomic Scientists\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://ealifestyles.substack.com/p/welcome-to-the-ea-lifestyles-substack?utm_source=twitter&utm_campaign=auto_share&r=242xrl | welcome to the ea lifestyles substack - EA Lifestyles\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://www.bryantresearch.co.uk/insights/institutional-change?fbclid=IwAR2kEV1sDJpgiiTKhWLAz4JqY3WTwdqShDuVg_4Z-ZMiv7h_TpXwhNj1YG4 | Bryant Research - Institutional Change\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://openai.com/blog/planning-for-agi-and-beyond/?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://onthinktanks.org/ | On Think Tanks  Independent research, ideas and advice\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://www.oneusefulthing.org/p/how-to-use-chatgpt-to-boost-your | How to... use ChatGPT to boost your writing\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://www.rei.com/blog/climb/new-survey-finds-nearly-one-third-of-respondents-have-experienced-sexual-harassment-or-assault-while-climbing?utm_source=Sailthru&utm_medium=email&utm_campaign=Future%20Perfect%20Wednesday:%202/15/23&utm_term=Future%20Perfect | Survey Reveals Sexual Harassment & Assault While Climbing - REI Co-op Journal\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://oneusefulthing.substack.com/p/the-practical-guide-to-using-ai-to | The practical guide to using AI to do stuff\n",
      "https://www.pasteurscube.com/notes-on-managing-to-change-the-world/ | Notes on \"Managing to Change the World\"\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://cdn.openai.com/papers/gpt-4-system-card.pdf | gpt-4-system-card.pdf\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://www.washingtonpost.com/archive/opinions/1987/04/12/sexpionage-why-we-cant-resist-those-kgb-sirens/900e1e59-1a7b-455f-93cf-22e67394512b/ | SEXPIONAGE WHY WE CAN'T RESIST THOSE KGB SIRENS - The Washington Post\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://www.governance.ai/research-paper/thinking-about-risks-from-ai-accidents-misuse-and-structure | Thinking About Risks From AI: Accidents, Misuse and Structure  GovAI\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai | The secret history of Elon Musk, Sam Altman, and OpenAI  Semafor\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://thefuturesociety.org/new-year-new-tfs/ | New year. New TFS. - The Future Society\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022)\n",
      "https://thehill.com/policy/technology/3872614-us-copyright-office-rules-ai-generated-artwork-content-not-legally-protected/ | US Copyright Office rules AI-generated artwork, content not legally protected  The Hill\n",
      "https://www.personalhackathon.com/ | Personal Hackathon - A day dedicated to maximizing your productivity\n",
      "https://tellingthefuture.substack.com/p/new-year-new-forecasts | New Year, New Forecasts - by Robert de Neufville\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://www.tiktok.com/@ripmercury/video/7213924265328987435?_r=1&_t=8b2U4JLHX59 | https://www.tiktok.com/@ripmercury/video/7213924265328987435?_r=1&_t=8b2U4JLHX59\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://osf.io/458cx | OSF\n",
      "https://astralcodexten.substack.com/p/half-an-hour-before-dawn-in-san-francisco | Half An Hour Before Dawn In San Francisco\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://arxiv.org/pdf/2303.12712.pdf | 2303.12712.pdf\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://world.hey.com/dhh/inspiration-is-perishable-f2c8652e | Inspiration is perishable\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n",
      "https://garymarcus.substack.com/p/the-sparks-of-agi-or-the-end-of-science | The Sparks of AGI? Or the End of Science?\n",
      "https://rodneybrooks.com/what-will-transformers-transform/ | What Will Transformers Transform? ‚Äì Rodney Brooks\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://laion.ai/blog/petition/ | Petition for keeping up the progress tempo on AI research while securing its transparency and safety.  LAION\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://www.nytimes.com/guides/well/how-to-have-a-better-relationship?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | How to Have a Better Relationship - Well Guides - The New York Times\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://aisnakeoil.substack.com/p/people-keep-anthropomorphizing-ai?r=1vxw01&utm_campaign=post&utm_medium=email | People keep anthropomorphizing AI. Here‚Äôs why\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n"
     ]
    }
   ],
   "source": [
    "tabs_ = [t for t in tabs if (not ('google.com' in t.lower() and 'search' in t.lower() and not ('docs.google' in t.lower() or 'sheets.google' in t.lower())) and\n",
    "                             not ('docs.google' in t.lower() or 'sheets.google' in t.lower() or 'drive.google' in t.lower()) and\n",
    "                             not 'facebook.com' in t.lower() and\n",
    "                             not 'twitter.com' in t.lower() and\n",
    "                             not ('forum.effectivealtruism' in t.lower() or 'lesswrong' in t.lower()) and\n",
    "                             not ('metaculus' in t.lower() or 'manifold' in t.lower() or 'predictit' in t.lower()) and\n",
    "                             not ('wikipedia' in t.lower() or 'wikiwand' in t.lower()) and\n",
    "                             not 'reddit' in t.lower() and\n",
    "                             not 'instagram.com' in t.lower() and\n",
    "                             not ('guarded-everglades-89687.herokuapp.com' in t.lower() or 'localhost' in t.lower()) and\n",
    "                             not 'instacart' in t.lower() and\n",
    "                             not ('morning' in t.lower() and 'dispatch' in t.lower()) and\n",
    "                             not 'amazon.com' in t.lower() and\n",
    "                             not 'github' in t.lower() and\n",
    "                             not 'calendar.google' in t.lower() and\n",
    "                             not 'yout' in t.lower() and\n",
    "                             not 'app.asana.com' in t.lower() and\n",
    "                             not ('messages/' in t.lower() or 'inbox/' in t.lower() or 'mail.google' in t.lower() or 'swapcard' in t.lower()))]\n",
    "tabs_ = sorted(tabs_)\n",
    "print_tabs(tabs_, label='Other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a2a7bb-86f9-45bd-b8d6-ed8889caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_tabs(tabs_, page=1, per_page=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c128ee3-03e2-4cfb-bfd1-0dfc84775af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shuffled all tabs ## (687 tabs)\n",
      "\n",
      "https://www.nytimes.com/guides/well/how-to-have-a-better-relationship?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | How to Have a Better Relationship - Well Guides - The New York Times\n",
      "https://quri.substack.com/p/eli-lifland-on-navigating-the-ai?fbclid=IwAR2mPO6XMabu0UrWDzFzyljIFOXmROPnsM-JvQWBPWkD4q7J7oRXg_UKBp4 | Eli Lifland, on Navigating the AI Alignment Landscape\n",
      "https://twitter.com/DrRadchenko/status/1638417468967505920 | Sergey Radchenko on Twitter: \"The Xi-Putin summit has ended and it's time to take a quick look at where we stand. At the start of the summit I mentioned that, much as Mao during his meeting with Stalin in 1949, Putin wanted something that \"looked good but also tasted delicious.\" The results are disappointing.\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1TlWcxy-fuzXd93DEJ_sj8R6Ikm4HJMZd92sXULbnZvM/edit | [very confidential] Staff Risk - Google Sheets\n",
      "https://docs.google.com/document/d/1qh1jUCLKAbteof6u2DcYaZJaNHHp5HvZJlV1eIpqXWs/edit | RP Campus Awareness Survey - Google Docs\n",
      "https://bounded-regret.ghost.io/emergent-deception-optimization/ | Emergent Deception and Emergent Optimization\n",
      "https://docs.google.com/document/d/1O3uRzsBG0QqzPy7QgK0c4S3Hm4GQBKzFp0rG5eXcBDs/edit | Friday & Saturday Schedule ‚Äî Summit on Existential Security - Google Docs\n",
      "https://muddyclothes.substack.com/p/the-rocky-history-of-ai-in-china | The rocky history of AI in China: from neglect to national priority\n",
      "https://docs.google.com/document/d/1ohA9rzGL8OHQWHsW65Z4HNs4-S8Yr3DJGTxIMruCGyo/edit | [Summit copy] Suppose you align AGI and have a DSA - what then? - Google Docs\n",
      "https://docs.google.com/document/d/1mZmox0G910jw7I9jCoDC6vowz_PcrHRfFoW04G59XMA/edit | [PUBLIC] 80,000 Hours two-year review: 2021-2022 - Google Docs\n",
      "https://docs.google.com/document/d/1hIGzcva5Wb8E1gdSGe22jWcZHvU91wjhgz-AYDx7lRI/edit | [Forum version] \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Doc\n",
      "https://thezvi.substack.com/p/ai-1-sydney-and-bing | AI #1: Sydney and Bing - by Zvi Mowshowitz\n",
      "https://www.facebook.com/jeffladish/posts/pfbid0SjNagfzWSoV8RWNtZF2Kqq4CWRchu1sHLcLdsWFa5ERQyMdsx9jvvrR78JjmSvWnl | https://www.facebook.com/jeffladish/posts/pfbid0SjNagfzWSoV8RWNtZF2Kqq4CWRchu1sHLcLdsWFa5ERQyMdsx9jvvrR78JjmSvWnl\n",
      "https://www.tiktok.com/@ripmercury/video/7213924265328987435?_r=1&_t=8b2U4JLHX59 | https://www.tiktok.com/@ripmercury/video/7213924265328987435?_r=1&_t=8b2U4JLHX59\n",
      "https://www.wikiwand.com/en/Perfect_Match_(TV_series) | Perfect Match (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1jWEO-Y7flKK9um9Dz1Lz_o-vhj3S6EaewDgRRUdKI-s/edit | Magnify Mentoring ‚Äì Evaluation (EAIF) ‚Äì 63d99c2d65a55348e903a1c3 - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1623941659779280896 | Daniel Ethüí° on Twitter: \"Hmm, I‚Äôm slightly worried about moves in this direction - especially since I think we‚Äôre currently much closer to the danger zone of ‚Äútoo cold‚Äù than ‚Äútoo hot‚Äù https://t.co/nJZPKSvqIz\" / Twitter\n",
      "https://www.planned-obsolescence.org/aligned-vs-good/ | \"Aligned\" shouldn't be a synonym for \"good\"\n",
      "https://twitter.com/Caro_Jeanmaire/status/1641921736760229895 | Caroline Jeanmaire on Twitter: \"This is one of my favorite papers to explain the threat model of advanced AI (and it even has pictures!)\" / Twitter\n",
      "https://docs.google.com/document/d/19UAquUto2Xw4FCKLlM2YMxcnWQMaT_cVgu-lSMO6YJ0/edit | Existential Security Additional Memo Topics [Brainstorm] - Google Docs\n",
      "https://docs.google.com/document/d/1DtVnxjgqYKOcX79p4rRvbrTDAiddYtbfmSWVHqjjGfs/edit | Concrete research questions that might help inform AI governance efforts - Google Docs\n",
      "https://www.wikiwand.com/en/The_Case_of_the_Golden_Idol | The Case of the Golden Idol - Wikiwand\n",
      "https://manifold.markets/ACXBot/8-will-a-nuclear-weapon-be-detonate | 8. Will a nuclear weapon be detonated (including tests and accidents) in 2023?  Manifold Markets\n",
      "https://docs.google.com/document/d/1QlHu2N4BeoRsHZYymVImg023mk-XGjR32cucXB_INOg/edit | Collection of AIGS-related lists of contacts - Google Docs\n",
      "https://docs.google.com/document/d/1gZ26LP_yGupj72JJ6GVhbtfcwr5ZiOgYh3qJaWdVgag/edit | Ben West <> Renan - Google Docs\n",
      "https://github.com/thunlp/TAADpapers | https://github.com/thunlp/TAADpapers\n",
      "https://twitter.com/RomanHauksson/status/1640612961835261953 | Roman Hauksson on Twitter: \"@absurdlymax @austinc3301 @peterwildeford played with Bing Chat a bit and came up with \"proportional perception\" and \"dimensional discernment\"? ü§∑‚Äç‚ôÇÔ∏è\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1643428537821720578 | Eliezer Yudkowsky on Twitter: \"So the actual scary part to me is that GPT4 understands what it means to say, \"Compress this in a way where *you* can decompress it.\" Humans take for granted that we know our own capabilities, that we reflect, that we can imagine how we would react to a future input, we can‚Ä¶\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1eDltvvbQDa8iRaVeuVjaZiiJn_KzzgYw_QDnjWTa2EQ/edit | Ops Costs by LT vs Other - Google Sheets\n",
      "https://www.lesswrong.com/posts/DXByibGtvFixSsyfs/ai-6-agents-of-change | AI #6: Agents of Change - LessWrong\n",
      "https://docs.google.com/document/d/1slsvQ8uwhf666PaUcU-2bb8KjGdyuxHOKWF6Rr-DanE/edit | Ensuring a high-quality environment for GLT strategy setting (and that other GLT things are high quality)\n",
      "https://80000hours.org/podcast/episodes/robert-long-artificial-sentience/ | Robert Long on why large language models like GPT (probably) aren't conscious - 80,000 Hours\n",
      "https://docs.google.com/spreadsheets/d/1Bk25Q7Om8UjnOoua0Zq5pXlzfqK1mwY9Dx1QGvAXemo/edit | Ben‚Äôs GLT strategy work stack - Google Sheets\n",
      "https://docs.google.com/document/d/1monK6BvWqoyOpwY74DenxVan2_n-PAtUFVF-_wI4V8E/edit | Warning shots, galvanizing events, etc.: Relevant readings, people, & notes - Google Docs\n",
      "https://twitter.com/Scholars_Stage/status/1637913075817803778 | T. Greer on Twitter: \"Despairing a bit as I read the Iraq commentary on Twitter. Like Covid, something people can‚Äôt learn from because they would rather have recriminations.\" / Twitter\n",
      "https://www.reddit.com/r/Stargate/comments/6lp112/when_theres_an_unscheduled_offworld_activation/ | (2) When there's an unscheduled offworld activation but no iris code : Stargate\n",
      "https://www.planned-obsolescence.org/situational-awareness/ | Situational awareness\n",
      "https://pasteurs-cube.ghost.io/ghost/#/editor/post/63f2a8300e4dd0004d15adae | ChatGPT is not a stochastic parrot (plus digital sentience and answering just how freaked out we should be right now?) - Pasteur's Cube\n",
      "https://twitter.com/daniel_eth/status/1635830145658544129 | Daniel Ethüí° on Twitter: \"If it wasn‚Äôt dead already, this should put to rest the idea that LLMs are just stochastic parrots without any understanding\" / Twitter\n",
      "https://twitter.com/WilliamAEden/status/1630690003830599680 | William Eden on Twitter: \"My Twitter timeline is full of panicked takes about imminent AI apocalypse and certain doom. I think this is starting to get overplayed, and so I want to make a long thread about why I'm personally not worried yet. Get ready for a big one... 1/n\" / Twitter\n",
      "https://twitter.com/yonashav/status/1636823304940994568 | https://twitter.com/yonashav/status/1636823304940994568\n",
      "https://twitter.com/mpshanahan/status/1627808857945788418 | Murray Shanahan on Twitter: \"My recent tweets about anthropomorphism in #AI have got some attention, so I thought I should follow up with more explanation. Here's aüßµ. 1/10\" / Twitter\n",
      "https://twitter.com/anthrupad/status/1641678142006763523 | wÃ∏ÕÇÕÇÕïaÃ∑ÕêÕîÃótÃ¥ÕóÃôeÃµÃîÃïÃ¨rÃ¥ÃìÃäÃ∞mÃµÕÉÃΩÕôÕñaÃµÃìÕíÃóÃ¢rÃ∏ÃΩÃ≤kÃ∑ÕùÃÅÕîÃß on Twitter: \"Here's a snippet from the White House's \"Blueprint for an AI Bill of Rights\" Concerns regarding x-risk from AGI aren't explicitly mentioned and it doesn't seem to suggest we've got a plan in place for preparing for the potential arrival of superintelligent systems https://t.co/nfqesbITrR\" / Twitter\n",
      "https://matthewbarnett.substack.com/p/a-reply-to-michael-huemer-on-ai?fbclid=IwAR27LTtkb5R9fsNeFf83LFDA6kVsFQ3njChrkRkWTU4BLHqusznn9Dw8E5g | A reply to Michael Huemer on AI - Matthew Barnett‚Äôs Blog\n",
      "https://docs.google.com/document/d/1qV_mNjkpTZEbvS6VUAbTuOYziRgnmAkQcU6zyku_St8/edit | Ben‚Äôs longtermist incubator notes 2022-12-19 - Google Docs\n",
      "https://docs.google.com/document/d/1NJg3Rvrkdmrtr63HkU_cxfFMBwjKQLxhcbQo5u56XlM/edit | [for AIGS managers] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - thoughts on AIGS team - Google Docs\n",
      "https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf | International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf\n",
      "https://twitter.com/peterwildeford/status/1619784538196176897 | Peter Wildeford is a Laura Duffy neolib stan acct on Twitter: \"Second winner of the \"what strictly text-based task can an 8 year old reliably do that GPT3 cannot reliably do when given expert-level prompt engineering\" challenge by @EzraJNewman The second $40 prize will be awarded.\" / Twitter\n",
      "https://forum.effectivealtruism.org/posts/a2KEyLaXzBADb8jgg/can-we-evaluate-the-tool-versus-agent-agi-prediction | Can we evaluate the \"tool versus agent\" AGI prediction?\n",
      "https://docs.google.com/document/d/1NTSMdsQ6_Yn9xvfMIIx2AYTEKE-FYXwNCJh8E4LyXQQ/edit | Why+How to Speak Openly about AI Risk Outside EA - Google Docs\n",
      "https://docs.google.com/document/d/1VvYj9o6IrbDWUQGq3HVLfjIroVEbdGFBXrfO84qOChI/edit | Communication to RP staff on organizational realignment - Google Docs\n",
      "https://docs.google.com/document/d/15HUEdn4MIQDZLmfhnR0Lhobp8c9YFkIKQI0bFloy32M/edit | USG involvement in advanced AI [shared with RP, Epoch, etc.] - Google Docs\n",
      "https://smile.amazon.com/Elegant-Puzzle-Systems-Engineering-Management/dp/1732265186?sa-no-redirect=1 | AmazonSmile: An Elegant Puzzle: Systems of Engineering Management: 9781732265189: Larson, Will: Books\n",
      "https://twitter.com/DrJimFan/status/1634244545360609289 | Jim Fan on Twitter: \"*If* GPT-4 is multimodal, we can predict with reasonable confidence what GPT-4 *might* be capable of, given Microsoft‚Äôs prior work Kosmos-1: - Visual IQ test: yes, the ones that humans take! - OCR-free reading comprehension: input a screenshot, scanned document, street sign, or‚Ä¶ https://t.co/q5uWMKGUMK\" / Twitter\n",
      "https://docs.google.com/document/d/1c_Rwt4lcIjzLc-7N5nZ5CaHClvklkLHBxdrQ8X08L9Q/edit | April/May notes on Caro\n",
      "https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai | The secret history of Elon Musk, Sam Altman, and OpenAI  Semafor\n",
      "https://forum.effectivealtruism.org/posts/ZvMPNLFBHur9qopw9/is-it-time-for-a-pause | Is it time for a pause? - EA Forum\n",
      "https://docs.google.com/document/d/1KLvbDEe-LK5648p-TLyxpz9tXt5lioGmGQUrQThAeFY/edit | Thoughts on Evals and a nearcast - Google Docs\n",
      "https://twitter.com/robbensinger/status/1639061235164659712 | Rob Bensinger üîç on Twitter: \"@RosieCampbell OK, I was partly kidding. I do think most likely AI surprises look pessimistic, but some would look optimistic. See https://t.co/IS2jxBQHXd Links: 1. https://t.co/htpadcWU1v 2. https://t.co/6TbJACvNsa 3. https://t.co/StpwXHREvn. https://t.co/nHZpEm0Yg5\" / Twitter\n",
      "https://www.facebook.com/messages/t/688615094/ | Messenger  Facebook\n",
      "https://docs.google.com/document/d/1iVmi58PLVUaSSu5Qm2F_OBFFNmUxjPVvpt1f6qLGx_k/edit | Bimonthly Hiring and Budgeting Meeting Agenda - Google Docs\n",
      "https://static1.squarespace.com/static/5f04bd57a1c21d767782adb8/t/6405fe70b8470d4e49a59d82/1678114416880/JEDI+Committee+March2023.pdf | JEDI Committee March2023\n",
      "https://www.youtube.com/watch?v=dVxMrVJ58as | First 18 Things to Do for Productivity // New Macbook Pro! - YouTube\n",
      "https://adaptresearchwriting.com/2023/02/05/us-takes-action-to-avert-human-existential-catastrophe-the-global-catastrophic-risk-management-act-2022/ | US takes action to avert human existential catastrophe: The Global Catastrophic Risk Management Act (2022)\n",
      "https://docs.google.com/document/d/1y8qqleaBMDg3QnBSzmUY4mkZPZoPOaC3fF-vSSkskWY/edit#heading=h.b9zrlpr5ztu9 | Comments on the default approach - Google Docs\n",
      "https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ | If Artificial General Intelligence has an okay outcome, what will be the reason?  Manifold Markets\n",
      "https://twitter.com/sebkrier/status/1635719266853847081 | S√©b Krier on Twitter: \"Some interesting excerpts relevant to AI safety: https://t.co/4EH9DPko5o\" / Twitter\n",
      "https://docs.google.com/document/d/1QSGLIrOvi2Ncec10TVS0NNDvJdFMN6g9DWGG2HPhxuQ/edit | Tweet thread about switching to safety - Google Docs\n",
      "https://twitter.com/T_Goody3/status/1638203321704955904 | Trey on Twitter: \"I used code-davinci-002 recently to do a simple dev task, and it began responding with occasional eery, uncomfortable, human-like mental breakdowns in the comments (see attached). Completely unprompted, @OpenAI have you seen this? https://t.co/1qWyrpYsc9\" / Twitter\n",
      "https://docs.google.com/document/d/174p91cNwjVFD4TF-YTUK7JMjM4_TgdYmyQnElkwb1_E/edit | EOI changelog - Google Docs\n",
      "https://docs.google.com/document/d/1UU7cn5YQ7sMC7Ps6GhkuNc6gMcWvLgXw3rgxqhArtJw/edit | Template monthly check-in - Google Docs\n",
      "https://astralcodexten.substack.com/p/openais-planning-for-agi-and-beyond | OpenAI's \"Planning For AGI And Beyond\" - by Scott Alexander\n",
      "https://docs.google.com/document/d/1zBjHUs5Im06ZEYD8Ww6if-IpuLDpnlNMWvOJQPTfJjM/edit | Planning Actions for a Time when Crunchiness is High (PATCH) - Google Docs\n",
      "https://garymarcus.substack.com/p/gpt-4s-successes-and-gpt-4s-failures | GPT-4‚Äôs successes, and GPT-4‚Äôs failures - by Gary Marcus\n",
      "https://openai.com/blog/planning-for-agi-and-beyond/?fbclid=IwAR2j3YfgY3Mih_KFJxd35BwZWIGfmBBGsWTQsaHbAyWvaVHxgLH2febaEr4 | Planning for AGI and beyond\n",
      "https://docs.google.com/document/d/1DShZ7mECzRU54_-w9xwN2W80SpBXsLM9MP0oGfRNVz8/edit | Bottlenecks in the AI alignment workforce - Google Docs\n",
      "https://mediachomp.com/beekeepers-are-mildly-eldritch-gods/?fbclid=IwAR3hUyJ0_pT9EHbXWSNKqLpuCvzM4BZzGqZqKuDCzgA3dZxGZLg3pG6mawQ | Beekeepers Are Mildly Eldritch Gods - Media Chomp\n",
      "https://manifoldmarkets.notion.site/Manifold-Markets-Seed-Memo-36868a1b0d574111b45d28c0b3fe3254 | Manifold Markets: Seed+ Memo\n",
      "https://docs.google.com/document/d/19L0k0B0-0gW7t96Q-hpNIknCEry57Hklgt2FXFDUH78/edit | [SES copy] Misuse of AI should be a core priority in AI risk reduction - Google Docs\n",
      "https://docs.google.com/document/d/1iI6iMmNfSH7SB1iAR7QfE0t5wemXB7j6PYARCi_Pl0c/edit | Tianxia analyses - Google Docs\n",
      "https://scholars-stage.org/has-technological-progress-stalled/ | Has Technological Progress Stalled? ‚Äì The Scholar's Stage\n",
      "https://www.metaculus.com/questions/13787/petaflops-during-gpt-4-training/ | PetaFLOPs during GPT-4 training  Metaculus\n",
      "https://www.amazon.com/s?k=anker+laptop+power+bank&sprefix=anker+lapt%2Caps%2C160&ref=nb_sb_ss_ts-doa-p_2_10 | Amazon.com : anker laptop power bank\n",
      "https://oneusefulthing.substack.com/p/the-future-soon-what-i-learned-from | The future, soon: what I learned from Bing's AI\n",
      "https://docs.google.com/document/d/1DnzXUUgVrkAMQivwv3u46UKDaxoJUOqTbZkTF_e9Pvk/edit | CLTP <> Michael Aird - 2023-Feb-20 - misc AI gov & China stuff - Google Docs\n",
      "https://twitter.com/DanHendrycks/status/1644371530787467264 | Dan Hendrycks on Twitter: \"Do models like GPT-4 behave safely when given the ability to act? We develop the Machiavelli benchmark to measure deception, power-seeking tendencies, and other unethical behaviors in complex interactive environments that simulate the real world. Paper: https://t.co/mJkIXGfVgF https://t.co/NWi6AXm4f3\" / Twitter\n",
      "https://docs.google.com/document/d/1G6GxpFZFdQxyPXWV6m7af1Gl_jwGc9QxCYG8NOIHGJY/edit | GPT-4, predicting capabilities, and the Wizard of Oz effect - Google Docs\n",
      "https://docs.google.com/forms/d/e/1FAIpQLSeUsjp9WbqgvlngQ_PbVundwVTUjPuwdRwEs8_KGlv9D-V4fw/viewform | EA Funds manager form\n",
      "https://docs.google.com/document/d/1YlXUQsLd8Dxzwqn02Pxuq29eSNVyqpXeCgHMchRYkPw/edit | Notes - Special Projects / Longtermism teams sync - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1625641716991803392 | Daniel Ethüí° on Twitter: \"@peterwildeford @StefanFSchubert Money that isn‚Äôt used on AI risk reduction can also be saved for later - I think it‚Äôs pretty likely that more opportunities for effective funding will open up\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1fc9NmNpfR223zXxeUKLez5k5C9vD0TEbJT1QQArvuY0/edit | AI Qualitative Surveys - Google Sheets\n",
      "https://www.forourposterity.com/want-to-win-the-agi-race-solve-alignment/ | Want to win the AGI race? Solve alignment.\n",
      "https://www.reddit.com/r/GPT3/comments/10ffrk8/i_built_a_youtube_video_summarizer_using_gpt3/ | (2) I built a YouTube Video Summarizer using GPT3 : GPT3\n",
      "https://docs.google.com/document/d/1zhi1NypU0hUE2JM-ewUsC7Tkvw25eLbQPnpUrDjsq48/edit | Meeting Notes - Peter/Zoe 1-1s - Google Docs\n",
      "https://docs.google.com/document/d/1Eownqc9mtyE9cK2b93fWXAwD6wfKsafSETXmo95yl5c/edit | ALERT vision doc - Google Docs\n",
      "https://docs.google.com/document/d/1Wa3XimPWvNoQGHaKxIGWWpP4QqzkATnjawlY2hSQmoc/edit#heading=h.on6on651ly2x | Safe Scaling Regulations Summary (Summit copy) - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1640638607919841281 | (1) Jeffrey Ladish on Twitter: \"I've been wondering recently what goals a language model might have if one were scaled up to a superintelligence If the system was inner aligned with its training objective, it would be a next-token predictor. If so, I think such a system would kill all of us\" / Twitter\n",
      "https://docs.google.com/document/d/1mrmbcjLfpubTdEs6l0QIqXYiJz3006oE6-IvuDD8Mu8/edit | Proposal: We should do more EA movement building research - Google Docs\n",
      "https://docs.google.com/document/d/1hKZNRSLm7zubKZmfA7vsXvkIofprQLGUoW43CYXPRrk/edit | Some Key Ways in Which I've Changed My Mind Over the Last Several Years - Google Docs\n",
      "https://twitter.com/venturetwins/status/1622243944649347074 | Justine Moore on Twitter: \"As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now). They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. https://t.co/DfYB2QhRnx\" / Twitter\n",
      "https://www.wikiwand.com/en/Hybrid_warfare | Hybrid warfare - Wikiwand\n",
      "https://docs.google.com/spreadsheets/d/1_S_OPoTpFB07sjPDEhZ-g3kGj7wE4nfflNFTculL_BE/edit | RP Fundraising Forecast [2023 + 2024 predictions] - Google Sheets\n",
      "https://docs.google.com/document/d/1Dl567qFbzH9uqqwdVOWw3npjLSNohMdIWlRMwxVa3LI/edit | 2022-Jan-18 Longtermism fundraising coordination meeting - Google Docs\n",
      "https://www.youtube.com/watch?v=3a6xb6vj6AA | Opening session: Toby Ord  Toby Ord  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/18bOeTikuNvI0G34UCgZQkySi87_3lqhLDF9JGkTxUl0/edit | [2023.02.12 (Feb)] Defense-in-Depth Compiled Report [Master Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1nI4Sg7-80bStu0HlkH7ZEfn1OXAZUjfGSqKd9VwGFAE/edit | [summit copy] Defense against misaligned AI - Google Docs\n",
      "https://www.metaculus.com/questions/13021/cagr-gdp-growth-per-capita/ | CAGR GDP Growth Per Capita  Metaculus\n",
      "https://uploads-ssl.webflow.com/614b70a71b9f71c9c240c7a7/6373783123f06c4e6b71dada_Ord_lessons_atomic_bomb_2022%20(2).pdf | Microsoft Word - Atomic Bomb Lessons 3.doc\n",
      "https://docs.google.com/document/d/1S7W6ICDO6YYNx4D3XxYMq3hUzbYEMI9rMRUeo_jZ57Y/edit#heading=h.aqlr4k5imil3 | Tentative practical tips for using chatbots in research - Google Docs\n",
      "https://docs.google.com/document/d/1mvXftkdZH7a0UeTmWB5gjZybfO9DA0EkF0eqnI1J-YM/edit#heading=h.j5ztyj2lzfgi | AI safety/governance field-builders should learn from gov-led AI talent pipeline interventions - Google Docs\n",
      "https://world.hey.com/dhh/inspiration-is-perishable-f2c8652e | Inspiration is perishable\n",
      "https://docs.google.com/document/d/1JlEfNtOWdRJC4t_5lyMKGmIxVIIe143oYYQNxWKEM7g/edit#heading=h.g4t1dqegifc2 | [v. C] Intermediate goals suggested by survey respondents ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://docs.google.com/document/d/1IXUtN7Y64JjXpFALJrLa0c60czHoxcC368v4KsK1TFg/edit#heading=h.ym06pzukxfry | Ashwin <> Jeff Alstott on RP & RAND - Google Docs\n",
      "https://www.wikiwand.com/en/Temptation_Island_(TV_series) | Temptation Island (TV series) - Wikiwand\n",
      "https://twitter.com/daniel_eth/status/1618123427239591942 | Daniel Ethüí° on Twitter: \"What if public AI discourse winds up... fine? A few reasons to think it might: ‚Ä¢ People are starting to wake up to idea that AGI might not be that far away ‚Ä¢ Worries about AI X-risk aren't actually that complicated ‚Ä¢ Potential solutions aren't *that* crazy sounding either 1/12\" / Twitter\n",
      "https://twitter.com/MichaelJDickens | Michael Dickens (@MichaelJDickens) / Twitter\n",
      "https://twitter.com/RichardMCNgo/status/1642642080198475776 | Richard Ngo on Twitter: \"@robbensinger @adamdangelo @moskov @ESYudkowsky @ylecun My take: A) The type of reasoning outlined by Rob above is incapable of justifying such high credences about unprecedented large-scale future events. B) It just shouldn't matter because any reasonable credences here are unacceptably high, and recommend most of the same things.\" / Twitter\n",
      "https://aisnakeoil.substack.com/p/people-keep-anthropomorphizing-ai?r=1vxw01&utm_campaign=post&utm_medium=email | People keep anthropomorphizing AI. Here‚Äôs why\n",
      "https://twitter.com/davidchalmers42/status/1640334105941344261 | David Chalmers on Twitter: \"my slides for last friday's #phildeeplearning debate on \"do language models need sensory grounding for meaning and understanding\" are now online at https://t.co/Ffl1hIzp30. i was on the \"no\" side. my final summary slide with a slightly more nuanced view is below. https://t.co/t2QELGHUXf\" / Twitter\n",
      "https://twitter.com/yonashav/status/1633494288624484353 | Yo Shavit on Twitter: \"Ah shit this is actually very fun, but GPT-3.5-scale LMs shouldn‚Äôt be able to intuitively sample the space of fun emergent game mechanics yet‚Ä¶ right? https://t.co/lrjSTHqPPi\" / Twitter\n",
      "https://www.governance.ai/research-paper/thinking-about-risks-from-ai-accidents-misuse-and-structure | Thinking About Risks From AI: Accidents, Misuse and Structure  GovAI\n",
      "https://twitter.com/EthanJPerez/status/1642965205134233604 | Ethan Perez on Twitter: \"I spent a day red teaming the ChatGPT+Code Interpreter model for safety failures. I‚Äôm not a security expert, but overall I‚Äôm impressed with how the model responds to code-specific jailbreaking attempts &amp; have some requests for improvements. üßµ on my takeways+requests to @OpenAI:\" / Twitter\n",
      "https://docs.google.com/document/d/1tW363WoW_uMD_M-LlWjcsU_IIoInPdO-D4PYOLvaaK4/edit#heading=h.o5ok48temzls | [Shareable] The values argument for US vs China AI progress - Google Docs\n",
      "https://docs.google.com/document/d/1YSgdVuvYWnBE4CAPvMRA3pfsSlZTl-93uYji5n6zC3Q/edit | [Forum experiment] Strategy investigation: Cause area intersections - Google Docs\n",
      "https://ealifestyles.substack.com/p/welcome-to-the-ea-lifestyles-substack?utm_source=twitter&utm_campaign=auto_share&r=242xrl | welcome to the ea lifestyles substack - EA Lifestyles\n",
      "https://twitter.com/gdb/status/1641560965442576385 | Greg Brockman on Twitter: \"Deploying GPT-4 subject to adversarial pressures of real world has been a great practice run for practical AI alignment. Just getting started, but encouraged by degree of alignment we've achieved so far (and the engineering process we've been maturing to improve issues).\" / Twitter\n",
      "https://docs.google.com/document/d/1FmCK6rpAv2uAqgZzIxI1Jm2ga0bOgHS_u6WFDx_Blgo/edit#heading=h.bcufhgg27mdc | PATCH scenario [shared outside RP] - Google Docs\n",
      "https://mindingourway.com/detach-the-grim-o-meter/ | Detach the grim-o-meter\n",
      "https://twitter.com/utopiannotions/status/1639151645547429888 | Conor James on Twitter: \"Years ago, no-one around me had heard of GPT-3 &amp; I'd run around telling everyone. Today, despite ChatGPT going stratospheric in popularity (&amp; GPT-4 cranking up capabilities), I still encounter many people that haven't heard of GPT at all. This is frankly insane to me\" / Twitter\n",
      "https://twitter.com/JeffLadish/status/1643029834011148288 | https://twitter.com/JeffLadish/status/1643029834011148288\n",
      "https://twitter.com/lxrjl/status/1639397697084874752 | alex lawsen on Twitter: \"\"Why would you think AI might end up displaying [deception/power-seeking/other scary thing]?\" \"People will design them to\" \"But those theorems might not apply to the real wo.... WAIT WHAT?\" \"People will design them to\"\" / Twitter\n",
      "https://guarded-everglades-89687.herokuapp.com/admin/link/link/135167/change/?_changelist_filters=q%3Dcoinbase | How we make decisions at Coinbase  Change link  Django site admin\n",
      "https://docs.google.com/document/d/18d7p2ZBCk5LSjFql0CjKOEX4Cmniqp-_Gyknsc26i9o/edit | GovAI‚Äôs People, Programs, and Research [Funder Copy] - Google Docs\n",
      "https://docs.google.com/document/d/1HXNoVFUNHoeawY-iU3kqaCNUwaCTrCVWzFH3FvbYvVw/edit | Priority GCR cause area - Google Docs\n",
      "https://docs.google.com/document/d/1DmqsdeqncXV6knbdRxDYl-PDJ3y0lYI_YWXFzzOBxS8/edit | Project idea: Collection of actions it might be good for AI labs to take - Google Docs\n",
      "https://docs.google.com/document/d/1ZG0XIP6ItkSBfWPaH6n2Fd0J7A6dvYtfFAy1S7YyhSY/edit | Biggest Mistakes we‚Äôre making - Google Docs\n",
      "https://twitter.com/iScienceLuvr/status/1640969386159898630 | Tanishq Mathew Abraham on Twitter: \"It's just for pretend üòÇ https://t.co/cjFTkzExBw\" / Twitter\n",
      "https://moea.substack.com/p/2023-april-updates | 2023 April Updates - by David Nash\n",
      "https://docs.google.com/document/d/1SfPiTtNPGzObmt6CbYRCmFLsZL-w4T2nijmjx7-fyy0/edit | Social media feedback from candidates (Feb. 2023) - Google Docs\n",
      "https://baseratesblog.substack.com/p/deep-hope | Deep hope - by Ollie Base - Base Rates\n",
      "https://thebulletin.org/2023/01/researchers-hacked-a-labs-pathogen-containment-system-was-it-a-good-idea-to-publish-the-results/ | Researchers hacked a lab's pathogen containment system. Was it a good idea to publish the results? - Bulletin of the Atomic Scientists\n",
      "https://docs.google.com/document/d/1v0Ox5M5l8l8NMRQ0uI8DWZaT8U5yqWLInyRcu3jXrTY/edit | AIGS stakeholders database Airtable: what it is, what it‚Äôs for, and how to use it - Google Docs\n",
      "https://docs.google.com/document/d/1JjpH_UsqiVinHeOzf7A7Lu8bD6ZiDJANECbsRro6a8A/edit | Possible structural changes to the organization - Google Docs\n",
      "https://docs.google.com/document/d/1o54DtHVMc0uvgRv3K_eO0wWxV46Jk8B7HBhu_IiWfm8/edit | [summit copy] Proposal: We should do more EA movement building research - Google Docs\n",
      "https://twitter.com/mcxfrank/status/1640379280990560258 | Michael C. Frank on Twitter: \"The take-home here is that we are off by 4-5 orders of input magnitude in the emergence of adaptive behaviors. (That's the figure from above). The big broad cognitive science question is - which factors account for that gap? I'll think about four broad ones. https://t.co/QZfUiwJO8X\" / Twitter\n",
      "https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId=zfzHshctWZYo8JkLe | By Default, GPTs Think In Plain Sight - LessWrong\n",
      "https://twitter.com/michalkosinski/status/1636683810631974912 | Michal Kosinski on Twitter: \"1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes. https://t.co/nf2Aq6aLMu\" / Twitter\n",
      "https://twitter.com/Jsevillamol/status/1640997070650720256 | Jaime Sevilla on Twitter: \"I share a big part of Matthew's frustration, though I disagree with the bottom line and I have signed the letter. Why? I explain below üßµ\" / Twitter\n",
      "https://twitter.com/goodside/status/1641435052775989248 | (1) Riley Goodside on Twitter: \"What pre-LLM alignment research has proven useful for aligning LLMs? What‚Äôs the evidence we can make progress in an empirical vacuum?\" / Twitter\n",
      "https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live | https://twitter.com/search?q=from%3A%40peterwildeford%20Your%20view%20of%20Elon%20Musk&src=typed_query&f=live\n",
      "https://smile.amazon.com/How-Calm-Your-Mind-Productivity-ebook/dp/B09WM9PTD9?ref_=ast_sto_dp&sa-no-redirect=1 | AmazonSmile: How to Calm Your Mind: Finding Presence and Productivity in Anxious Times eBook : Bailey, Chris: Kindle Store\n",
      "https://docs.google.com/document/d/1LMtP7ws_mevBJr1fxMfLEFCQdkfhw3lPv6HeJg7nkEs/edit#heading=h.ilkan3e0drym | Kelsey Piper <> Michael Aird - 2022-Dec-03 - Kelsey‚Äôs work, distillation, getting good AI risk messaging by non-EAs, comms for AI crunch time - Google Docs\n",
      "https://scottaaronson.blog/?p=7042 | Shtetl-Optimized ¬ª Blog Archive ¬ª Should GPT exist?\n",
      "https://docs.google.com/document/d/1U4LmTV4SlTRc32DxeX0zKuY3lKdr6MUW1yYyCTittsA/edit | APB: All-points bulletin on AGI-predictive benchmarks - Google Docs\n",
      "https://www.wikiwand.com/en/Objective_structured_clinical_examination | Objective structured clinical examination - Wikiwand\n",
      "https://docs.google.com/document/d/1yJA2M27zio23Q-yFNBe6lJSm7QMDggpW0nkTJATne60/edit | Would on-chip mechanisms for export control enforcement be net-positive? - Google Docs\n",
      "https://www.reddit.com/r/OkCupid/comments/2y6bkr/going_for_drinks_tonight_our_first_date_how_do_i/ | (1) Going for drinks tonight. Our first date. How do i not screw it up? : OkCupid\n",
      "https://docs.google.com/document/d/1qCFHCqcmR-ntnuq6-26u5wbUYzwkxnGgnIlrzjcosB8/edit | Peter - Workshop on Allocating Manager Time - Google Docs\n",
      "https://twitter.com/sleepinyourhat/status/1642614846796734464 | https://twitter.com/sleepinyourhat/status/1642614846796734464\n",
      "https://twitter.com/mcxfrank/status/1640379247373197313 | Michael C. Frank on Twitter: \"How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. üßµ https://t.co/hayhUU5Iv6\" / Twitter\n",
      "https://www.youtube.com/watch?v=7U_LhzgwJ4U | https://www.youtube.com/watch?v=7U_LhzgwJ4U\n",
      "https://docs.google.com/document/d/1nOlvwsgDNqsz3bilB1VX7Ml9EokMf_4QQMxIktzQCHE/edit | Projects to increase transparency, cooperation and trustworthiness of top AI labs - Google Docs\n",
      "https://arxiv.org/abs/2303.08721 | [2303.08721] Artificial Influence: An Analysis Of AI-Driven Persuasion\n",
      "https://astralcodexten.substack.com/p/half-an-hour-before-dawn-in-san-francisco | Half An Hour Before Dawn In San Francisco\n",
      "https://www.metaculus.com/questions/14273/covid-variant-evasion-of-vaccinines-in-2023/ | COVID Variant Evasion of Vaccines in 2023  Metaculus\n",
      "https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate | Did ChatGPT Really Pass Graduate-Level Exams?\n",
      "https://docs.google.com/document/d/1ShDMT1IOFMGx5wRaJZwdw3X8dc_XYeZfA0V0iayMEvQ/edit | Free \"Designated Feedback-Givers\" Here ü§† - Google Docs\n",
      "https://rodneybrooks.com/what-will-transformers-transform/ | What Will Transformers Transform? ‚Äì Rodney Brooks\n",
      "https://www.wikiwand.com/en/Moon_Knight_(TV_series) | Moon Knight (TV series) - Wikiwand\n",
      "https://blog.nickwinter.net/posts/the-120-hour-workweek-epic-coding-time-lapse | Nick Winter's Blog  The 120-Hour Workweek - Epic Coding Time-Lapse\n",
      "https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html | Opinion  This Changes Everything - The New York Times\n",
      "https://docs.google.com/document/d/1azmoDCGM_DsgHZNwlnnXxxJcTMK0OA6xRU4XRd9W1_k/edit | Ashwin <> Hjalmar Wijk on evals & policy, Feb 2023 - Google Docs\n",
      "https://twitter.com/MatthewJBar/status/1630848045389864961 | Matthew Barnett on Twitter: \"A really confusing part of the AI takeoff debate is that a \"slow takeoff\" often means something like \"the economy will double every month or so but it will take at least a few years for us to enter that regime\" rather than \"things will go slowly\".\" / Twitter\n",
      "https://docs.google.com/document/d/1P2q7rcESdbmqkzcUZdR6nZlYkt1tQr4oJIu1J3gGB3w/edit | AI Safety Bounties v3 - Google Docs\n",
      "https://smile.amazon.com/The-Making-of-Manager-audiobook/dp/B07NGSZGFG/?sa-no-redirect=1 | AmazonSmile: The Making of a Manager: What to Do When Everyone Looks to You (Audible Audio Edition): Julie Zhuo, Karissa Vacker, Julie Zhuo, Penguin Audio: Audible Books & Originals\n",
      "https://www.metacausal.com/givewells-uncertainty-problem/ | GiveWell‚Äôs Uncertainty Problem ‚Äì MetaCausal\n",
      "https://www.youtube.com/watch?v=r8tgeEM-vQQ&list=PL0AF4BB0A8F7172BC&index=5 | Mark Isham - Freedom - YouTube\n",
      "https://twitter.com/rgblong/status/1640355054644350976 | Robert Long is in NYC on Twitter: \"one question I wanted to ask participants in this debate: in what sense (if any) does text-only GPT-4 fail to understand what ‚Äúunicorn‚Äù means? https://t.co/H69ILCRSpf\" / Twitter\n",
      "https://docs.google.com/document/d/1eibcQySCAfZarUgy4m9a_yz3hZDVXO9hxkZm4vjvVYg/edit | Leveraging hardware security features for AI governance [shared.x] - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1636508502498897921 | Jeffrey Ladish on Twitter: \"I've decided to donate $240 to both GovAI and MIRI to offset the $480 I plan to spend on ChatGPT Plus over the next two years ($20/month). I don't have a super strong view on ethical offsets but they feel right to me in this case. One reason is that it seems useful to actually‚Ä¶\" / Twitter\n",
      "https://twitter.com/EpistemicHope/status/1633341593531961345 | Eli Tyre on Twitter: \"Sometimes, people say, \"Wow! given LLMs, and other recent AI develpments, it looks like we're at the start of a slow takeoff.\" I think that's only half right.\" / Twitter\n",
      "https://www.wikiwand.com/en/Superbad#Reception | Superbad - Wikiwand\n",
      "https://docs.google.com/document/d/1iocO_5_3J0wjQXLIdKnLIAHwFP_LE07AJrwcgmL_mnw/edit | RP AI Governance & Strategy team funding proposal [Feb 2023] - Google Docs\n",
      "https://docs.google.com/document/d/1af7rhUUr0hhtnkl3VjXmFEA6W_DlG_V4sVfc1jL4sng/edit | [shared] T3A: 2023-02 Investor pitch - Google Docs\n",
      "https://docs.google.com/document/d/1YYZLaUe4To9YFcEm-kF6McTkRZ0v29qcmNkV66ETMYs/edit | Survey ideas about AI - Google Docs\n",
      "https://docs.google.com/document/d/1E5e938Ldl7MK8Y6CktGl8uFkSzVSsH_aj8NYVtJFO5I/edit | Evals Hackathon - Google Docs\n",
      "https://fortune.com/longform/chatgpt-openai-sam-altman-microsoft/ | The inside story of ChatGPT: How OpenAI founder Sam Altman built the world‚Äôs hottest technology with billions from Microsoft  Fortune\n",
      "https://www.oneusefulthing.org/p/my-class-required-ai-heres-what-ive?fbclid=IwAR03DvA57jfUfx2R27nHDMSybKiPsMIFyLTnC43l-Kj4jiCCsGUIElXPH7s | My class required AI. Here's what I've learned so far.\n",
      "https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1 | https://open.spotify.com/playlist/3sQnnyhDxKAtwqfzF24BsT?si=3u7M2IojRLyIBIK3hrmCLg&utm_source=native-share-menu&nd=1\n",
      "https://www.youtube.com/watch?v=ruDrVMBCLaw | Avicii - Lonely Together ‚ÄúAudio‚Äù ft. Rita Ora - YouTube\n",
      "https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/abs/moral-status-for-malware-the-difficulty-of-defining-advanced-artificial-intelligence/461B67A3A47A674A56B667DD63DEB59F | Moral Status for Malware! The Difficulty of Defining Advanced Artificial Intelligence  Cambridge Quarterly of Healthcare Ethics  Cambridge Core\n",
      "https://twitter.com/Wertwhile/status/1609177422074896386 | Joel Wertheimer on Twitter: \"Have so many complaints about this article I don't know where to begin. https://t.co/qWsSZR3sAs\" / Twitter\n",
      "https://twitter.com/benskuhn/status/1630611607029157888 | Ben Kuhn on Twitter: \"A lot of talk about managing focuses on \"decisionmaking\": how to run decision meetings, who gets to sign off on what, how they flow up + down the hierarchy... But IMO, management isn't (mainly) about decisions; it's about understanding and tweaking a complex system (of people).\" / Twitter\n",
      "https://www.cnas.org/publications/podcast/ai-enters-the-dogfight | AI Enters the Dogfight  Center for a New American Security (en-US)\n",
      "https://docs.google.com/document/d/1RoPAEF_Zp0GMTjqaGGLlMYU6iLWPnPS7aqSSXApWVjE/edit | Advice on how to learn forecasting - Google Docs\n",
      "https://www.google.com/search?q=learn+how+to+seduce&rlz=1CDGOYI_enUS715US715&oq=learn+how+to+seduce&aqs=chrome..69i57j0i15i22i30i625j0i22i30l2j0i15i22i30.6783j0j7&hl=en-US&sourceid=chrome-mobile&ie=UTF-8 | learn how to seduce - Google Search\n",
      "https://www.youtube.com/watch?v=sMoVOPHGe-k | What's new in Open Philanthropy's global health & wellbeing work?  James Snowden  EAG Bay Area 23 - YouTube\n",
      "http://shfhs.org/ | http://shfhs.org/\n",
      "https://twitter.com/ozyfrantz | (1) ozy brennan ü¶ô (@ozyfrantz) / Twitter\n",
      "https://twitter.com/messages/1414875069558534150 | Metaculites (off the (track) record) / Twitter\n",
      "https://www.metaculus.com/questions/13003/oecd-trust-in-government/ | OECD Trust in Government  Metaculus\n",
      "https://docs.google.com/document/d/1PidPXJWKKqCbWGzWQ7IySDnOkiK5rX0n2naaSjz7q3g/edit#heading=h.6ytgvt3dfnpe | Kieran Greig Copy of Oct-Nov - RP Performance Evaluation Template - Google Docs\n",
      "https://twitter.com/JeffDean/status/1635681300295323649 | Jeff Dean (@üè°) on Twitter: \"In December, we discussed Med-PaLM, at that time a SOTA medical LLM that achieved a 67.6% score on the USMLE MedQA evaluation (passing is 60%). Today, we're describing Med-PaLM2, which improves on this by +18% with a score of 85.4% (\"expert performance\")! Kudos to all involved!\" / Twitter\n",
      "https://twitter.com/NathanpmYoung/status/1637874864089341957 | Nathan is at EAGx Camüîç (join convos I'm in üëã) on Twitter: \"@StefanFSchubert I guess the likelihood is already included in timeline forecasts, right? To forecast impact I guess we'd need specific actions that might a cause a slow down?\" / Twitter\n",
      "https://docs.google.com/document/d/1IvDH8TuQDL0fyaupho2dj1NIME2wOvYzOQqE4VbA5zc/edit#heading=h.adl3u1ai4218 | Research note: US govt's role in R&D funding - Google Docs\n",
      "https://docs.google.com/document/d/1wo__OjZaQ4skvw-Rqoz-9LyXQPBv7XY3UuAd4BVaODw/edit | Longtermist incubation Q1+Q2 2023 - Google Docs\n",
      "https://twitter.com/natalia__coelho/status/1636609751902744577 | Nat√°lia üîç on Twitter: \"People have high expectations for GPT-12 \"Will a game of Pong be played with a galaxy as the ball before 2040?\" https://t.co/dC1ZjX2cp8 https://t.co/PlTWzdEUt9\" / Twitter\n",
      "https://www.quantifiedintuitions.org/botec | Quantified Intuitions\n",
      "https://docs.google.com/document/d/1oKQc5QKfEjRQHPU2g6kQBUadhOmFwTg40NH-EW_nrjU/edit#heading=h.za992j72817 | [Shareable] Coordination between labs - LAISR discn summary - Google Docs\n",
      "https://magazine.sebastianraschka.com/p/ahead-of-ai-4-a-big-year-for-ai | Ahead of AI #4: A Big Year For AI - by Sebastian Raschka\n",
      "https://www.economist.com/briefing/2023/03/30/americas-commercial-sanctions-on-china-could-get-much-worse | America‚Äôs commercial sanctions on China could get much worse  The Economist\n",
      "https://docs.google.com/document/d/1jZsrNV2ah7xRCR0I1EWH4wRpkFMY3vmwxI08S46c9sk/edit | 36 More Questions That Lead to Even More Love - Google Docs\n",
      "https://docs.google.com/document/d/1PjEKV7pePw10EIPWDz7td6p7uHj4FkSwSmHQElXtWPk/edit | Government willingness to spend + overall likelihood of government involvement - Google Docs\n",
      "https://twitter.com/davidchalmers42/status/1640357701417938945 | David Chalmers on Twitter: \"@rgblong in the terms i used, it arguably doesn't have an e-understanding of unicorns, e.g. knowing what it's like to see a unicorn. it arguably has a b-understanding (behavior) and r-understanding (recognitional) on performance-based readings. i-understanding (inferential) is tricky.\" / Twitter\n",
      "https://docs.google.com/document/d/1edeoGgx0n_icwK-5DY9157VwHsp69J6P-cpttCtxG7A/edit | ALERT_Fiscal Sponsorship Application - Google Docs\n",
      "https://www.alignmentforum.org/posts/TWorNr22hhYegE4RT/models-don-t-get-reward | Models Don't \"Get Reward\" - AI Alignment Forum\n",
      "https://twitter.com/okimstillhungry/status/1632839664095690752 | Hispanic Shaun King on Twitter: \"Everytime I see this womans face, it is accompanied by one of the most alarming paragraphs I've ever read.\" / Twitter\n",
      "https://twitter.com/SolarxPvP/status/1635866783763636225 | SolarxPvPü•ã on Twitter: \"Why aren't AI doomer people scared of extraterrestrial AIs? Earlier civilizations could have developed them, and if there were earlier ones, they already should have gotten here. AIs wouldn't get bored or need money for the long trip. They would get here faster.\" / Twitter\n",
      "https://www.oneusefulthing.org/p/blinded-by-analogies | Blinded by Analogies - by Ethan Mollick - One Useful Thing\n",
      "https://twitter.com/stanislavfort/status/1635965177010040833 | Stanislav Fort ‚ú®üß†üìà‚öõÔ∏èüìàü¶æüìàü§ñüìà‚ú® on Twitter: \"I have just zero-shot made a functional Python game mashup between Pong &amp; the Game of Life with GPT-4 ü§Ø It literally spat out the code which ran on the 1st try, including the score, rainbow tiles evolving according to the Game of Life rules &amp; w/ controllable paddles! Wild! üî• https://t.co/wEhmFfahLZ\" / Twitter\n",
      "https://docs.google.com/presentation/d/1dZp2JjX3uzwPWJhC4dTKov9h8NjkoSCEcEpercaeE_A/edit | Instability Events - Google Slides\n",
      "https://takeoffspeeds.com/playground.html | Playground\n",
      "https://docs.google.com/document/d/1h548mrEBu9j4NTw5dYXiPhnxsunG8FXoSIl8slYqFnk/edit#heading=h.cn4swffgcf5a | [Will]CERI speedrun - Google Docs\n",
      "https://docs.google.com/document/d/1StEofAAvYrYFrjFBiDWa8aCUj3W65VvSbv_OSKjTmao/edit | Interim Report for Luke on Expert Networks - Google Docs\n",
      "https://www.metaculus.com/questions/13045/per-capita-primary-energy-consumption/ | Per Capita Primary Energy Consumption  Metaculus\n",
      "https://www.youtube.com/watch?v=uoRgnKg1MZs | https://www.youtube.com/watch?v=uoRgnKg1MZs\n",
      "https://www.youtube.com/watch?v=WmD5cQ9e_So | Closing session  Marcus Davis and Peter Wildeford  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/document/d/1aemMGJruc0uLAOb5Zk_rx4_INkVoMVTcPHKfvolvW7E/edit | How might misaligned goals come about? SUMMIT COPY - Google Docs\n",
      "https://twitter.com/HamishDoodles/status/1636088496086474758 | Hamish McDoodles on Twitter: \"@peterwildeford @JacobPeacock1 But it's what I actually believe is the correct answer to your question, so if I'm actually missing something then expressing how I think about this and getting roasted is a good way to find that out.\" / Twitter\n",
      "https://www.youtube.com/watch?v=gI5SOUrW7Nc | https://www.youtube.com/watch?v=gI5SOUrW7Nc\n",
      "https://forum.effectivealtruism.org/posts/v3MBEovqqNkAQQPh5/exercise-things-we-got-wrong | Exercise: Things we got wrong - EA Forum\n",
      "https://docs.google.com/document/d/1tNDNbjg63Vx03w0iV5Cy3Lyw9azZBuevRQFowcWTG1E/edit#heading=h.oopq92wv47s1 | Prioritization of different kinds of technical compute governance research [shared] - Google Docs\n",
      "https://docs.google.com/document/d/1e5MlYsJWPh8Hyh67oWNBWaom-ITj02WxK1SmvG9qQMk/edit | Idea: Set up a natsec subteam at AIGS\n",
      "https://arxiv.org/pdf/2303.12712.pdf | 2303.12712.pdf\n",
      "https://www.planned-obsolescence.org/what-were-doing-here/ | What we're doing here\n",
      "https://bounded-regret.ghost.io/principles-for-productive-group-meetings/ | Principles for Productive Group Meetings\n",
      "https://thehill.com/policy/technology/3872614-us-copyright-office-rules-ai-generated-artwork-content-not-legally-protected/ | US Copyright Office rules AI-generated artwork, content not legally protected  The Hill\n",
      "https://docs.google.com/document/d/1uATkMdi5xIH9TeHdm-f5syiJHMkiW1EDnpTwGAbTrOc/edit#heading=h.eiz0h26jtop0 | LT department meetings_2023 - Google Docs\n",
      "https://docs.google.com/document/d/1SYBPKllt9Etbbi3ymB4LwWHI6ZiFjlTrthuGSaDBLNs/edit | Main summary: International safety agreements - Google Docs\n",
      "https://polaris-ventures.org/ | https://polaris-ventures.org/\n",
      "https://twitter.com/benskuhn/status/1632119010149167104 | Ben Kuhn on Twitter: \"I've been reflecting recently on Wave's growth spurt in 2019-21. Most teams grew 2-4x a year for multiple years, and culture and effectiveness stayed remarkably strong compared to what I'd have expected (or heard of elsewhere). Some thoughts on what might have helped:\" / Twitter\n",
      "https://docs.google.com/document/d/1Wto87-T_eU9fLaaPu3XJzRtMXUyexlYgijeRWb0SuSY/edit | 2023 Org-Wide Strategic OKRs V2.0 - Google Docs\n",
      "https://docs.google.com/document/d/1NjlekCtUwD4TCWYxSv1yH2Cvg99y7QTGxkALpN1owkE/edit | CEO Self-Development Plan\n",
      "https://experiencemachines.substack.com/p/dangers-on-both-sides-risks-from | Dangers on both sides: risks from under-attributing and over-attributing AI sentience\n",
      "https://twitter.com/JeffLadish/status/1642090475061641216 | Jeffrey Ladish on Twitter: \"I don't think GPT-4 poses a significant risk of takeover. I think by default GPT-5 probably poses only a small risk but I am not confident about that. Imagining GPT-6 starts to feel like a significant takeover risk I can't predict how capabilities will scale but that's my guess\" / Twitter\n",
      "https://twitter.com/i/lists/1626618826971353088 | https://twitter.com/i/lists/1626618826971353088\n",
      "https://docs.google.com/document/d/16GQ2FbwF-GWG28wzFg6gTlAVRYHbGIzwMTC6egPXnMg/edit | [work in progress] Project plan: Project idea research for incubation - Google Docs\n",
      "https://twitter.com/calebwatney/status/1627766787554017280 | Caleb Watney on Twitter: \"This feels like an underrated dimension to the Bing/Syndey debacle. Because Syndey could search the web and integrate the outcry into the predicted output, her dark alter-ego had a self-reinforcing mechanism that reflected our own anxieties about her (and AI more broadly). https://t.co/cDU3KOryXx\" / Twitter\n",
      "https://docs.google.com/document/d/1pwwNHvNeJneBA2t2xaP31lVv1lSpa36w8kdryoS5768/edit#heading=h.lhr5aah9j67a | TAIG - FR2 - Literature Review of Transformative AI Governance - Google Docs\n",
      "https://docs.google.com/document/d/1UktVvd8kxkHfxTw7spzbfj_GzstS-1S98MpKf_c6q50/edit | Aidan Fitzsimons ‚Äì Evaluation (EAIF) ‚Äì 63feef2ebba108bac20cbafc - Google Docs\n",
      "https://docs.google.com/document/d/1bMXGnKUjy9qGV7u336ScagAHLgbaLHqsNfUXVE7L6G0/edit | 2023-02 TAI Timelines Workshops - Winter Fellows 2023 - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1639428548103639042 | Jeffrey Ladish on Twitter: \"I think my current AI existential risk reduction portfolio, that is where I would spend money if I were a major donor, is roughly as follows: 1/3 Slowing down AGI, e.g. compute regulation, training run regulation, lab agreements to slow down / moratoriums 1/3 Fundamental‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit | Scoring forecasts from the 2016 ‚ÄúExpert Survey on Progress in AI‚Äù survey - Google Docs\n",
      "https://docs.google.com/document/d/1srRr2sudZnIdRR0jMTKHt7OuP9msGV11ksWN0o9-VSo/edit | Technical AI work to prevent catastrophic misuse: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/1wbSkicGGw6iiZmCnS_Zl-J-4CCgooEteJ4PlRZ8pNNo/edit# | GLT 2023 high-level timetable v0.3 2023-03-30 - Google Docs\n",
      "https://docs.google.com/document/d/1Yzdr7sW716VveShglkfTOYcoYyQOR06yUC2ldMDjJu4/edit | Toward trustworthy AGI projects [2022-09-26 draft] - Google Docs\n",
      "https://docs.google.com/document/d/1IkJyu-mO0cdCptxKzBD_DaUk3jW7JhKaSoEGSs9P5rY/edit | Updating my EA community building takes after recent scandals and reduced funding - Google Docs\n",
      "https://www.metaculus.com/questions/12979/total-annual-investment-in-ai-companies/ | Total Annual Investment in AI Companies  Metaculus\n",
      "https://twitter.com/labenz/status/1635754212452696072 | Nathan Labenz on Twitter: \"Humbled to be credited as a Red Teamer in the GPT-4 Technical Report. I spent 2 months testing GPT-4, and I have no doubt it will change the world. Research paper here: https://t.co/FNJMJ3KG92\" / Twitter\n",
      "https://docs.google.com/document/d/1_pDno3wm9b5iWZsvzqI-3B16LNmaY6m36ocuLm32RiE/edit | Draft for NMI: Recent Trends in China‚Äôs Large-Scale Pre-Trained AI Model Landscape - Google Docs\n",
      "https://twitter.com/nikosbosse/status/1631745587623198735 | Nikos Bosse on Twitter: \"Excited to share a new piece where I compare two prediction platforms, Metaculus and Manifold Markets, in terms of their performance, based on a set of 64 questions that were identical on both platforms. Conflict note: I'm employed by Metaculus. https://t.co/03ko2QIhJk 1/\" / Twitter\n",
      "https://www.amazon.com/Seeing-into-Future-History-Prediction/dp/1789142296/ | Seeing into the Future: A Short History of Prediction: Creveld, Martin van: 9781789142297: Amazon.com: Books\n",
      "https://docs.google.com/document/d/1dVN6YWRKVb1YaFyJLjtQ7qSqXOSS492XvwRaLdqIUuA/edit | Assuming We Develop ‚ÄúAligned‚Äù AI, What‚Äôs the Plan for Preventing a Catastrophe From Misaligned AI?\n",
      "https://docs.google.com/document/d/1n-FGenzNuyR0TaqoAd8vckrzZWVZg1zHUbjnd0_rFbI/edit#heading=h.pobicrnq8r4a | [Shareable] LAISR next steps planning - outreach to non-ODA labs - Google Docs\n",
      "https://oneusefulthing.substack.com/p/the-practical-guide-to-using-ai-to | The practical guide to using AI to do stuff\n",
      "https://sites.google.com/view/adaptive-agent/ | Human-Timescale Adaptation in an Open-Ended Task Space\n",
      "https://twitter.com/icreatelife/status/1636421935436267520 | Kris Kashtanova on Twitter: \"Probably the most eventful week AI has ever seen: Monday: - Stanford releases Alpaca 7B - Google announces Med-PaLM 2 a new medical LLM Tuesday: - OpenAI releases GPT4 - Anthropic releases Claude - Google announces the PaLM API &amp; MakerSuite - Adept raises $350M - Google adds‚Ä¶\" / Twitter\n",
      "https://twitter.com/gwern/status/1636739854586335232 | https://twitter.com/gwern/status/1636739854586335232\n",
      "https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/ | Date Weakly General AI is Publicly Known  Metaculus\n",
      "https://twitter.com/swift_centre | The Swift Centre (@swift_centre) / Twitter\n",
      "https://docs.google.com/document/d/1JQFlgkLXub3qEff0rgQ5XPtD6CfJnVD5wqg9LhfIEhA/edit | Cybersecurity for AI policy and governance\n",
      "https://joshvarty.com/2014/07/17/the-95-hour-work-week-and-why-it-should-have-been-more/ | The 95 Hour Work Week (And why it should have been more‚Ä¶) ‚Äì Shotgun Debugging\n",
      "https://twitter.com/Yozarian22/status/1636093338158878723 | Yoz on Twitter: \"@peterwildeford I really think it's going to be awhile before LLMs get as good at multimodal input as they are at text. There just isn't the same volume of data out there to train on.\" / Twitter\n",
      "https://docs.google.com/document/d/1opL3w6AaasnVCit77SWxgX7Vg6E5FHCE3Px0i5FPg_E/edit | RP Lobbying Guide - Google Docs\n",
      "https://rethinkpriorities.slack.com/files/U0185RQLU7J/F04PJTFJT0R/browningveit2021positive_welfare.pdf?origin_team=T017UKD8KU1&origin_channel=G019CKCMFPT | Positive Wild Animal Welfare\n",
      "https://twitter.com/george__mack/status/1642197538647445504 | https://twitter.com/george__mack/status/1642197538647445504\n",
      "https://garymarcus.substack.com/p/the-open-letter-controversy | The Open Letter Controversy - by Gary Marcus\n",
      "https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ | Update on ARC's recent eval efforts\n",
      "https://drive.google.com/drive/u/1/folders/1JcMQBBF1n9cxayYTAK3HImI_WEvNEJ2U | 2023-01 - Development and Communications - Google Drive\n",
      "https://twitter.com/robbensinger/status/1639040220191678464 | Rob Bensinger üîç on Twitter: \"Actions are definitely not \"where the bad things could happen\", unless you're also treating text outputs as \"actions\". Which you probably should. Talking to people is not in a different magisterium from \"acting on the world\", and unaligned ASI with a text channel is not safe.\" / Twitter\n",
      "https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/ | Injecting some numbers into the AGI debate ‚Äì Windows On Theory\n",
      "https://docs.google.com/document/d/1v14aMi7GhpNhk5ahmqgZVeYCKVvSdf9Bsoz8yfR6MpM/edit | The AI playbook as I see it - Google Docs\n",
      "https://docs.google.com/document/d/17FQtd1G26QGIWenU7I92tqbGNy0E7cnBz594F8lJOpI/edit | Project ideas: ‚ÄúPrimers‚Äù on the internal organizational structure of leading AI labs and/or on x-risk-concerned people‚Äôs social/political capital with AI labs - Google Docs\n",
      "https://github.com/washingtonpost/elex-live-model | washingtonpost/elex-live-model: a model to generate estimates of the number of outstanding votes on an election night based on the current results of the race\n",
      "https://twitter.com/shreyas/status/1628567045800591361 | https://twitter.com/shreyas/status/1628567045800591361\n",
      "https://www.metaculus.com/questions/15602/gpt-5-capable-of-ai-lab-escape/ | GPT-5 Capable of AI Lab Escape  Metaculus\n",
      "https://www3.weforum.org/docs/WEF_Global_Risks_Report_2023.pdf | WEF_Global_Risks_Report_2023.pdf\n",
      "https://www.personalhackathon.com/ | Personal Hackathon - A day dedicated to maximizing your productivity\n",
      "https://docs.google.com/document/d/1Cg2KMqE0utpeakylb1nrvd-rts82W5Izj_MlRZMXo5M/edit | \"Exisential risks\" message testing survey - Google Docs\n",
      "https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer | Why I Am Not (As Much Of) A Doomer (As Some People)\n",
      "https://docs.google.com/document/d/1SllbtZBSPac_rbX0sgLR4clafB9pH_CeuNFJmejiFLc/edit | Critical AI Paper Draft - Google Docs\n",
      "https://open.spotify.com/user/carory | Spotify ‚Äì carory\n",
      "https://osf.io/458cx | OSF\n",
      "https://docs.google.com/document/d/1D2R6dlv3OGebQ5l2QAkDLoBbOP5lS0wXZdCz13jO2JI/edit | Research directions RP AIGS staff might want junior researchers to pursue & might be up for giving guidance on - Google Docs\n",
      "https://twitter.com/Rainmaker1973/status/1644248670160801792 | Massimo on Twitter: \"When traffic cones along a road in New Zealand began mysteriously moving around, the Transport Agency set up a CCTV to pin down the culprits It turned out a Kea parrot moved them to get attention from humans &amp; get fed [read more: https://t.co/U2cecFOeXh] https://t.co/mqGE37IIpr\" / Twitter\n",
      "https://garymarcus.substack.com/p/the-sparks-of-agi-or-the-end-of-science | The Sparks of AGI? Or the End of Science?\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit | Ashwin <> Zach Stein-Perlman\n",
      "https://docs.google.com/document/d/1cXKjfclDeAxPTnU8AfPH_K1F8febDA7B7FaXWvMkLEI/edit#heading=h.b8kzjwotdq3z | [Shareable] Cruxes for belief in 5-year timelines - LAISR discussion - Google Docs\n",
      "https://nymag.com/intelligencer/2023/03/on-with-kara-swisher-sam-altman-on-the-ai-revolution.html | ‚ÄòOn With Kara Swisher‚Äô: Sam Altman on the GPT-4 Revolution\n",
      "https://www.lesswrong.com/posts/QBTdEyL3tDaJY3LNa/ai-kills-everyone-scenarios-require-robotic-infrastructure | AI-kills-everyone scenarios require robotic infrastructure, but not necessarily nanotech - LessWrong\n",
      "https://docs.google.com/document/d/136cR2NyoBxpaKcqmGP4lICXcAOsk4OowIEfM8fulq2g/edit | People doing/setting strategy for field-building should explicitly account for AI crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1Uhj0QUMh6-RjZz9Go7gKiIJnATlzOaY36FPBJYsRzIQ/edit | What is EA? How could it be reformed? - Google Docs\n",
      "https://docs.google.com/document/d/1k7DHNZxIYVQVFnJVolDS4AOfdem81dl9Yl_OYIJzu44/edit | 2023-Q1 RP Board Meeting Agenda - Google Docs\n",
      "https://www.metaculus.com/questions/13074/pro-forecasting-forecasting-owid-discussion/ | [Pro Forecasting] Forecasting OWID Discussion  Metaculus\n",
      "https://docs.google.com/document/d/1Op0u1s9KKLuF0uNaCrg13o0yo97Bs2GOH8PHzNd_06o/edit#heading=h.q4d2fojafhi | [Shareable] Preparing in Parallel for different scenarios - LAISR talk & discussion - Google Docs\n",
      "https://www.nytimes.com/wirecutter/reviews/best-telescopes-for-beginners/ | The Best Telescopes for Beginners\n",
      "https://docs.google.com/document/d/1HNBH3pkmXyq05sbjGBJ4Yzj_I5kX2eQV-3rDvToHbnY/edit | Copy of FTX Public Post draft - Google Docs\n",
      "https://docs.google.com/document/d/1gHzQovSnLHxbRalowex0eCAOVgvN5tafvpG2gEMKNH4/edit | Cost-of-living adjustments - Google Docs\n",
      "https://smile.amazon.com/Hyperfocus-Manage-Attention-World-Distraction/dp/0525522255/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1672612983&sr=8-1&sa-no-redirect=1 | Hyperfocus: How to Manage Your Attention in a World of Distraction: Bailey, Chris: 9780525522256: AmazonSmile: Books\n",
      "https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up | The race of the AI labs heats up  The Economist\n",
      "https://www.pasteurscube.com/notes-on-managing-to-change-the-world/ | Notes on \"Managing to Change the World\"\n",
      "https://www.reddit.com/r/mlscaling/comments/11pnhpf/morgan_stanley_note_on_gpt45_training_demands/ | Morgan Stanley note on GPT-4/5 training demands, inference savings, Nvidia revenue, and LLM economics : mlscaling\n",
      "https://www.wikiwand.com/en/Kaleidoscope_(American_TV_series) | Kaleidoscope (American TV series) - Wikiwand\n",
      "https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/ | How bad a future do ML researchers expect? ‚Äì AI Impacts\n",
      "https://muddyclothes.substack.com/p/is-china-overhyped-as-an-ai-superpower | Is China overhyped as an AI superpower? - by Julian\n",
      "https://docs.google.com/document/d/1idQ5AVMaO94fE26z61kKyVq88WRBGg8RaTqpB9DTmkc/edit#heading=h.s4dbr54ymvcl | [v. C] Theories of victory for AI governance ‚Äì Survey on intermediate goals in AI governance - Google Docs\n",
      "https://www.quora.com/Why-do-some-women-enjoy-being-dominated-during-sex | Why do some women enjoy being dominated during sex? - Quora\n",
      "https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?sd=pf | What did they know, and when did they know it? The Microsoft Bing edition.\n",
      "https://docs.google.com/document/d/1Yg0xcj24B6h_wqSGu2_6sv4CJGKGsLL4OhioKBZBwZw/edit | Will the US or a closely allied government control and/or heavily resource the first successful TAI project?\n",
      "https://docs.google.com/document/d/1NIw_uQyBk3vod8mm52Dvf_V_VjGFngCbd1QHYJ9rE1I/edit#heading=h.jgkd59xkp77g | [SHARED 10-2] Overview of current work on reducing s-risks from threats - Google Docs\n",
      "https://docs.google.com/document/d/1D-99mw8GQXwqWnECC-BC462egl6w_0w9I-Dq5WVx6EE/edit | Delegation Worksheet - Google Docs\n",
      "https://docs.google.com/document/d/1A-W3ahsV3DspgnEk7iRXlyctkL0D0kwgP09OGFRu5BI/edit | Examining pathways from narrow AI to nuclear war - Google Docs\n",
      "https://www.cold-takes.com/ai-safety-seems-hard-to-measure/ | AI Safety Seems Hard to Measure\n",
      "https://www.atlanticcouncil.org/content-series/atlantic-council-strategy-paper-series/risks-opportunities-2023/ | The top 23 risks and opportunities for 2023 - Atlantic Council\n",
      "https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/ | What could an AI-caused existential catastrophe actually look like? - 80,000 Hours\n",
      "https://twitter.com/JgaltTweets/status/1630367483742887937 | (1) JgaltTweets on Twitter: \"The Information: Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival https://t.co/TCPve7nAx3\" / Twitter\n",
      "https://docs.google.com/document/d/1qwKUWu1aa1rikW3zlCPPvPXdS4upsarkJe8-JwcE4tY/edit | You don't have to be that risk-averse to prefer GHW to LT (Final - Shared with Jason) - Google Docs\n",
      "https://docs.google.com/document/d/1bHqfiyi7_xMRFDPJ2P-pPuNg0Cofez-MOXnIdzaEdsI/edit#heading=h.42dwpl3d3ux7 | AA: Summary of Feb 2023 ESS evals plan discn - Google Docs\n",
      "https://docs.google.com/document/d/1Mw1Eogktb2SGKxS8leUdtXb4riczEs5BdHzKuSMsykA/edit#heading=h.dpqa2s578qw0 | Ashwin <> Zach Stein-Perlman - EAG Bay Area notes on slowing AI - Google Docs\n",
      "https://twitter.com/CNBC/status/1637813771832836098 | CNBC on Twitter: \"OpenAI CEO Sam Altman said he's a 'little bit scared' of A.I. https://t.co/Uq1VsLQuBX\" / Twitter\n",
      "https://docs.google.com/document/d/1I6I3qEBhk8hHacJW7ufBZV_-plFq5SDcy_EGw3941ZQ/edit | 2023-02-09 Peter Wildeford - Google Docs\n",
      "https://docs.google.com/document/d/1BZv1lRGmS6k_WsMzOLeu9gVIJc9C6nEQKByT5I0UnyI/edit | Project idea: Backgrounder on AI lab safety processes - Google Docs\n",
      "https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks | GPT-4 and professional benchmarks: the wrong answer to the wrong question\n",
      "https://www.gatesnotes.com/The-Age-of-AI-Has-Begun | The Age of AI has begun  Bill Gates\n",
      "https://twitter.com/finmoorhouse/status/1628924795600633856 | Fin Moorhouse on Twitter: \"Trying to distil some basic points on takeoff speeds: Recent AI advances are surprisingly impressive. How should update our expectations for when transformative AI arrives, and what the world looks like before that point?\" / Twitter\n",
      "https://www.bloomberg.com/news/articles/2023-02-19/iran-nuclear-inspectors-detect-uranium-enriched-to-84-purity?leadSource=uverify%20wall | Iran Nuclear Detection of Uranium Enrichment to 84% Purity - Bloomberg\n",
      "https://nunosempere.com/blog/2023/01/23/my-highly-personal-skepticism-braindump-on-existential-risk/ | My highly personal skepticism braindump on existential risk from artificial intelligence.\n",
      "https://docs.google.com/document/d/1kGeXyq0uXBQ0hnW8-6OzAp75UyDU-W9jL8HfBh1rnVc/edit | Recipe for a Minimum Viable Coalition among top AI labs - Google Docs\n",
      "https://docs.google.com/presentation/d/1CocyPHmi6-FGOP8YOvaBMGALvsHOnwkZL3lPUVYGjng/edit | RP 2023 Dev OKRs in detail\n",
      "https://twitter.com/davidmanheim/status/1635897416103649284 | David Manheim - @davidmanheim@techpolicy.social on Twitter: \"This week (so far) in @metaculus AGI timelines: April 2039 -&gt; September 2036. https://t.co/4TcPGeo0e9 https://t.co/kYRJ63ceSs\" / Twitter\n",
      "https://docs.google.com/document/d/1IShiBdPfWUge-IRy_ZWbbp-RAU0p6HpcZE8OYNlqopc/edit | What should x-risk reducers want AGI companies to do? - Google Docs\n",
      "https://twitter.com/norabelrose/status/1639220383885987840 | (2) Nora Belrose on Twitter: \"Mechanistic interpretability is cool, but I don‚Äôt think it‚Äôs very useful for making trustworthy AI. Building trust in a person means understanding them at a psychological level- their beliefs and values- not at a ‚Äúmechanistic‚Äù level. We need a different kind of interpretability.\" / Twitter\n",
      "https://docs.google.com/document/d/1kU3dhaxWK6DyT9Z5RRTXCPvNb1QLkGcf3GgnYHKtamQ/edit | Marcus Personal Ops Retreat notes 2023 - Google Docs\n",
      "https://wiki.aiimpacts.org/doku.php?id=responses_to_ai:public_opinion_on_ai:surveys_of_public_opinion_on_ai:surveys_of_us_public_opinion_on_ai | Surveys of US public opinion on AI\n",
      "https://twitter.com/JeffLadish/status/1643537554011205632 | Jeffrey Ladish on Twitter: \"Nice framing of AGI capabilities as \"can this AI system accomplish most all tasks that a human could do in T amount of time\". Seems like T is currently somewhere in the minutes to hour range\" / Twitter\n",
      "https://docs.google.com/document/d/1dCakbPEteBwNpUej8Nx5_FPr1z4e0HIij_5OcbEazEc/edit | Untitled document - Google Docs\n",
      "https://www.howilearnedtoloveshrimp.com/about | https://www.howilearnedtoloveshrimp.com/about\n",
      "https://twitter.com/SpacedOutMatt/status/1636703741624631297 | Matt on Twitter: \"Welcome to MRPSBG! We've got earning to give (to Rethink Priorities), selecting an effective career (at Rethink Priorities), effective volunteering (by red-teaming Rethink Priorities reports), and community building (by running a Rethink Priorities report reading group)\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1NgL4-6Q51RUuwvKFraR5fbljTRU9bDmQKHP4EBHkFig/edit | Rethink Priorities OKRs - Google Sheets\n",
      "https://www.forourposterity.com/response-to-tyler-cowen-on-ai-risk/ | Response to Tyler Cowen on AI risk\n",
      "https://twitter.com/daniel_eth/status/1635885011365957632 | Daniel Ethüí° on Twitter: \"Finally getting around to reading this. Will update my reactions as I go\" / Twitter\n",
      "https://twitter.com/harries_matthew/status/1630493459499941892 | Matthew Harries on Twitter: \"I seem to be in a minority of one on this, and I'm aware I don't know what's happening behind closed doors, but based on the public evidence I am very sceptical about the idea that China's language on nuclear threats in its Ukraine paper is a clear win. /1 https://t.co/9dQei78al5\" / Twitter\n",
      "https://twitter.com/leopoldasch | https://twitter.com/leopoldasch\n",
      "https://docs.google.com/document/d/1mQFduF7iEiBPxyqrN1cB9x9h3jmMm736h1hrUhSbqFs/edit | [shared] AI strategy framings - Google Docs\n",
      "https://www.youtube.com/watch?v=Vb5g7jlNzOk | Safety evaluations and standards for AI  Beth Barnes  EAG Bay Area 23 - YouTube\n",
      "https://docs.google.com/forms/d/e/1FAIpQLScnNHu0Z0sbxiuPmKOD8kS-hdLBe92wIiIWmo36Nzrkf3Wynw/viewform | Collective Alignment Survey - AI Objectives Institute\n",
      "https://jchyip.medium.com/fixing-too-much-wip-ba4d254048a3 | Fixing ‚ÄúToo much WIP‚Äù. ‚Äútoo much WIP‚Äù means too many things‚Ä¶  by Jason Yip  Jan, 2023  Medium\n",
      "https://docs.google.com/spreadsheets/d/11Xy9dvYaoP-lTJjA4Pt_TpGeC7PwF_4O7dW298q7jRI/edit | RP Secret Copy of Influence List - Google Sheets\n",
      "https://twitter.com/hlntnr/status/1642910765978996738 | Helen Toner on Twitter: \"I'm working on an piece about how we desperately need to be able to talk about progress in AI in richer terms than \"this is basically AGI\" vs \"this is nothing like AGI.\" Thisüëáis a fantastic example of what we need more of - very worth reading.\" / Twitter\n",
      "https://docs.google.com/document/d/1nZVNE5jLAh0E9n9B2uIe4K-XNLylicnUXmr07jpXtCc/edit | Possible directions for USG-AI project - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1644782487841955841 | Daniel Ethüí° on Twitter: \"Hot take - much LLM skepticism may come from somewhat of a similar place as creationism. In both, there‚Äôs a sense that blind local search could never build something too complicated or impressive. Sure, it may allow for microevolution or stochastic parrots, but not *intelligence*\" / Twitter\n",
      "https://docs.google.com/document/d/1KiInsoeBClHwR3HgSzEvd5kiew9wSbYNtQWL2bs4Xj8/edit | Guidelines for which non-RP people can be added to LT-related Slack channels - Google Docs\n",
      "https://docs.google.com/document/d/1sUQHDICydniPCuM-8E7JzMILtUHJEfWfFGX9PX008MU/edit | Cruxes for setting up a whistleblowing entity - Google Docs\n",
      "https://cdn.openai.com/papers/gpt-4-system-card.pdf | gpt-4-system-card.pdf\n",
      "https://docs.google.com/document/d/1N2Ct9l-gzmk1XHHIuPG8avU-V3AL0kiEeiVjuvpUtRM/edit | (Extra) EA Survey Questions - Google Docs\n",
      "https://manifoldmarkets.notion.site/Manifold-Finances-0f9a14a16afe4375b67e21471ce456b0 | Manifold Finances\n",
      "https://www.redbookmag.com/love-sex/sex/a47424/why-women-like-rough-sex/ | Why Women Like Rough Sex - Why Women Like Being Dominated\n",
      "https://docs.google.com/document/d/1jo0YqxijShA-XChPh56OPL2LW_5c4bJGgjFZ9AWpszA/edit | Generating priors during iterative Jeffrey conditionalization - Google Docs\n",
      "https://drive.google.com/drive/u/0/folders/0B15eCPovYpRPNDZfVVlQeE9od0E?resourcekey=0-p51Vss2OwilGgq4uWaxuwg | Maybe Blog Someday - Google Drive\n",
      "https://www.youtube.com/watch?v=xtNrm-EXRjI | Markus Anderljung Regulating increasingly advanced AI some hypotheses - YouTube\n",
      "https://docs.google.com/document/d/1KJ4qqTAP6f5UnvQaOCpehbnfgvN8uRNHVemTXFyDTZs/edit | Notes worldview diversification - Google Docs\n",
      "https://epochai.org/blog/lit-review | Literature review of Transformative Artificial Intelligence timelines\n",
      "https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1 | https://open.spotify.com/playlist/5HqrL3I4qUbOo1rpCj6Pcg?si=6yJG2apxTkyUtFlzxzyEtw&utm_source=native-share-menu&dd=1\n",
      "https://www.pasteurscube.com/a-world-without-email/ | Notes on \"A World Without Email\", plus my practical implementation\n",
      "https://docs.google.com/document/d/1e2wnyXKxLoSzOXFlAtO_CYjsWLKsJU8LNGqvTjAh3dk/edit#heading=h.a5qpp2nkjksr | _README - Index of Onni's compute governance related files [internal] - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1644588249674059776 | Jeffrey Ladish on Twitter: \"The biggest difference between my interpretation of Bostrom's predictions in Superintelligence and where we currently seem to be headed is the number of individual AI systems / instances. Even when I imagined a multipolar world I never imagined hundreds of millions of AI copies\" / Twitter\n",
      "https://garymarcus.substack.com/p/gpt-5-and-irrational-exuberance | GPT-5 and irrational exuberance - by Gary Marcus\n",
      "https://docs.google.com/document/d/136FNAeBw7oKyv8lUZm8qFEsVM8tQUaQzgDrCtLTf4Fs/edit | Some hot takes on the implementation of transformative AI systems - Google Docs\n",
      "https://docs.google.com/document/d/1fkoaTic9s0vR35DOocRUsQcUU-ki6TK6cGylPyow2eQ/edit | Cross-cause impact model and what it says (and doesn't) about how we should prioritize - Google Docs\n",
      "https://twitter.com/AnthropicAI/status/1641463526291312643 | Anthropic on Twitter: \"Today we are releasing the new Claude App for @SlackHQ, in beta. Now every company in the world has the chance to have a ‚Äúvirtual teammate‚Äù who can help make work more fun and productive. https://t.co/YNpIH5caBP\" / Twitter\n",
      "https://ruyacoffee.com/ | R√ºya Coffee  For the Immigrant Dream\n",
      "https://www.metaculus.com/questions/13931/nuclear-detonation-in-2023/ | Nuclear Detonation in 2023  Metaculus\n",
      "https://thezvi.substack.com/p/ai-practical-advice-for-the-worried | AI: Practical Advice for the Worried - by Zvi Mowshowitz\n",
      "https://www.oneusefulthing.org/p/how-to-use-chatgpt-to-boost-your | How to... use ChatGPT to boost your writing\n",
      "https://docs.google.com/document/d/1hGHIsdK7DAGGFYn1ROT55xLoZlCX9QvWhZLVHTD6EEw/edit | Org descriptions - Google Docs\n",
      "https://docs.google.com/document/d/1s3QGFJ8Ochosksl4JgQCWekJrsY3YFAfGgEiEt6zFpA/edit | How Will the AI Supply Chain Evolve? v4 - Google Docs\n",
      "https://docs.google.com/document/d/1nyRiq5Lt4tzuOn81lLkdrS_aoTGbeBQ4YY5RVuenZ0M/edit | \"Risk awareness moments\" as a concept for thinking about AI governance interventions - Google Docs\n",
      "https://twitter.com/DrJimFan/status/1637868524755632129 | Jim Fan on Twitter: \"Let's talk about the elephant in the room - will LLM take your job? OpenAI &amp; UPenn conclude that ~80% of the U.S. workforce could have &gt; 10% of work affected, and 19% of workers may see &gt; 50% of work impacted. GPT-4 *itself* actively helps in this study. What to make of it?üßµ https://t.co/seuH7aYf17\" / Twitter\n",
      "https://www.governance.ai/research-paper/lessons-atomic-bomb-ord | Lessons from the Development of the Atomic Bomb  GovAI\n",
      "https://smile.amazon.com/Retractable-Keychain/s?k=Retractable+Keychain&sa-no-redirect=1 | Amazon.com : Retractable Keychain\n",
      "https://docs.google.com/document/d/1ZBmcreDIAIaW4vYC0H52bGzx9G74a6jqiWisJjTpYNk/edit | 2023 Fundraising Brainstorm - Google Docs\n",
      "https://docs.google.com/document/d/1fXTIN6goXqEmGA8Hyg5oeD6MK3En7dtF0lTFz8MDxKs/edit | GLT Strategy for 2023 v0.4 2023-03-30\n",
      "https://docs.google.com/document/d/1LNQyT3NOcPodOeks6ccUf-b-MClLiSX8mokQdMQKUtc/edit | WIT Research Agenda Post - Draft 1 - Google Docs\n",
      "https://twitter.com/fianxu/status/1643685995005775873 | Gaia Dempsey on Twitter: \"The last paragraph contains an excellent summary and framing of some of the most important the questions at hand, IMO.\" / Twitter\n",
      "https://twitter.com/colin_fraser/status/1626775880931614721 | Colin Fraser on Twitter: \"Some tips for writing your \"I had a conversation with an LLM bot and it spooked me\" story, if you simply must. 1. You did not have a conversation with a bot. You used a synthetic text generator to author a fictional account of a conversation between you and a fictional bot.\" / Twitter\n",
      "https://twitter.com/ShakeelHashim/status/1638876861475192836 | Shakeel on Twitter: \"This seems right actually -- maybe you could plausibly call GPT-4 a \"general\" intelligence, but what's becoming clear is that a \"general\" intelligence is not the same as \"superpowerful AI\" https://t.co/ncjuNBv8r1\" / Twitter\n",
      "https://docs.google.com/document/d/1cRIjKlYIlAOEUChV-1BU9qzepYVYijKs1tEdxU1k6Hk/edit | [Shareable] OECD AI governance plans - LAISR notes - Google Docs\n",
      "https://rootnodes.substack.com/p/why-didnt-deepmind-build-gpt3 | Why didn't DeepMind build GPT3? - by Jonathan Godwin\n",
      "https://www.eurasiagroup.net/issues/top-risks-2023 | Eurasia Group  The Top Risks of 2023\n",
      "https://docs.google.com/document/d/1H8PJApuO7Q0QRI9YBb-onErks3RfQHvpEdhjf7b94aI/edit# | John and Daniel: Conversation on AI, V4 - Google Docs\n",
      "https://www.overcomingbias.com/p/ai-risk-again | AI Risk, Again - by Robin Hanson - Overcoming Bias\n",
      "https://docs.google.com/document/d/1xE9eee6GDreNVaSdPdw0ewTQmhAbvZjjy6Qy-c630s8/edit | Proposal: Switch AIGS's primary branding to something new and distinct from RP [AIGS Leads discussion notes] - Google Docs\n",
      "https://twitter.com/tristanharris/status/1635357114637111296 | Tristan Harris on Twitter: \"Great articulation of AI risks by @ezraklein. https://t.co/2vmw1aMc4z But what does \"median\" mean? ‚û°Ô∏èThat **50% of AI researchers** believes there is a 10% or greater chance that humanity goes extinct from our inability to control AI. Read that again. https://t.co/wlrGB7QzBD\" / Twitter\n",
      "https://docs.google.com/document/d/1PMkBRjb3DGwvGzrEPNA513Typ8HHHDwIvV9Ej5exous/edit | Information security practices - Google Docs\n",
      "https://github.com/peterhurford/acx_forecasts_2023/blob/main/ACX_Full_Mode.ipynb | acx_forecasts_2023/ACX_Full_Mode.ipynb at main ¬∑ peterhurford/acx_forecasts_2023\n",
      "https://docs.google.com/document/d/1mCHfBSUPOCDktuh52foodKy0hiRC5CzRl4C5sAGHto0/edit | 2023 Strategic Planning: SWOT Brainstorm Document - Google Docs\n",
      "https://docs.google.com/document/d/1CGfcGFpZnVi3XZlFD3oNa9ns2XG7J0N5zT9BYbxM-Fk/edit | 2023 - Q1 - AIGS RM - Job Description [-final] - Google Docs\n",
      "https://docs.google.com/document/d/166Q_elB4DKW7XNfVCMt6-rD7RIhXG4M3a6A1ZiYCFtE/edit#heading=h.x90pohx7jxcg | Owain Evans <> Renan on Owain founding an evals org with RP FS support\n",
      "https://docs.google.com/document/d/1n5i1-VmV8IRDHTybXh70yV-mZB8RpMuu9ZXaDwLGRRs/edit | EAFo/LW Reading List\n",
      "https://twitter.com/swyx/status/1644352579462369280 | swyx üåâ on Twitter: \"Someone wrote up this list of the last 7 days in AI and I am -exhausted-. who is making the AI to keep up with the AI??? https://t.co/wtVZ3bAm5X\" / Twitter\n",
      "https://possibleworldstree.com/ | The Possible Worlds Tree\n",
      "https://docs.google.com/document/d/1wtgZKM6jmOTKj9pVqtDS7tn--oxe8pU5u5-OlhXyQRs/edit | 04a - Hypothetical \"success stories\" to accompany \"Nearcast-based 'deployment problem' analysis\" - Google Docs\n",
      "https://ealifestyles.substack.com/p/this-week-in-effective-altruism?utm_source=twitter&utm_campaign=auto_share&r=242xrl | this week in effective altruism - EA Lifestyles\n",
      "https://docs.google.com/document/d/1NbhmiIzPa3AKucHvdBRAEmZ4YxzpcX8YAqK5AYtV4E0/edit | Personal annual review process [shared] Jan 2020 - Google Docs\n",
      "https://twitter.com/Peter_0_0_g/status/1643137150894972929 | Peter on Twitter: \"@peterwildeford I haven't tried very recently but it did work for me when gpt-4 just came out\" / Twitter\n",
      "https://docs.google.com/document/d/1zeKyneX_8hcmmDq467FuIR9y6Zxz0iQNicOcCz_dcfw/edit | AW Department changes & updates\n",
      "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/ | How we could stumble into AI catastrophe\n",
      "https://docs.google.com/spreadsheets/d/1gBy6iOa2xt5O8FfbImBqOsMgOL3NBorQPsN2uKOfcSM/edit#gid=0 | LAISR 2022 Invitees, with emails (for ops staff) - Google Sheets\n",
      "https://twitter.com/MarkHertling/status/1641470497270509568 | MarkHertling on Twitter: \"Last night, I tweeted that I had been assessing &amp; considering the challenges Ukraine's Army (UA) Commanders were facing in preparing for the ‚Äúspring offensives. I said I'd share some thoughts on what I would be thinking if I were among them. This is that üßµ 1/\" / Twitter\n",
      "https://docs.google.com/document/d/1gn77WcyIeuTK3ZKAgWdD-3VTUYcx4cNhbSSieE1rSN4/edit | RP LT work-in-progress (WiP) sessions: Session notes [internal] - Google Docs\n",
      "https://docs.google.com/document/d/1oInPr-bzqtAULzonDajiT8M10LF50WNfiuaaIkElk4g/edit#heading=h.217anus74gpx | [Shareable] Cost-effectiveness of boosting US AI progress - Google Docs\n",
      "https://docs.google.com/document/d/16nzr8u6XaPIo8WQdVHayqLC3fJV8CxAoND_8mp5biro/edit | What kind of advocacy should we engage in around AGI risk? (hot takes) - Google Docs\n",
      "https://www.metaculus.com/questions/12973/global-co2-emissions/ | Global CO2 Emissions  Metaculus\n",
      "https://docs.google.com/document/d/1CbS0ofRMI83BH-Y8moiaLLchUNRtNglLeqkvrmztxso/edit | memo: moratorium on AI scaling? - Google Docs\n",
      "https://docs.google.com/document/d/1c1IaJxkQcHTy5VgJyWc569mlznWFJI69Wv9b6i6l9Bw/edit | 2023.03.15 (Mar) Chris Byrd <> Shaun Ee - Google Docs\n",
      "https://arxiv.org/abs/2303.16200 | [2303.16200] Natural Selection Favors AIs over Humans\n",
      "https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target | Reward is not the optimization target - AI Alignment Forum\n",
      "https://docs.google.com/document/d/18F1IlGuJryqflWwfhFkJKIGv6l1syDQMu5EaAo3Lb0M/edit | What properties do we wish for in Magma? - Google Docs\n",
      "https://twitter.com/messages/25776739-103418485 | (3) Joel Becker / Twitter\n",
      "https://docs.google.com/document/d/1BWW4A4-HDN5vGcwcrLf0zpjnR3LsIT4CUjOhPFXYk-c/edit | [Shared] Plan for the Summit on Existential Security - Google Docs\n",
      "https://www.cold-takes.com/high-level-hopes-for-ai-alignment/ | High-level hopes for AI alignment\n",
      "https://twitter.com/TheZvi/status/1640371950907162624 | Zvi Mowshowitz on Twitter: \"What is our current best understanding of why Bard is so underwhelming in its core capabilities? How temporary is the gap?\" / Twitter\n",
      "https://twitter.com/alexandrosM/status/1642159313048449025 | Alexandros Marinos üè¥‚Äç‚ò†Ô∏è on Twitter: \"Since I've done my share of mocking, allow me to try and explain. 1. Eliezer has not been correct or precise enough about several of his key predictions about AI developmrnt over the last decade. Yet, he is derisive of others See: https://t.co/SEhNR0NbZd‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1KAIbBXnvMOM_T7qOe5b1mV8bbdMXTlfhjbFw2uQNCf4/edit | AGI risk advocacy: Costs, benefits, and the S-curve model - Google Docs\n",
      "https://manifold.markets/IsaacKing/if-we-survive-general-artificial-in?r=RWxpZXplcll1ZGtvd3NreQ | If we survive general artificial intelligence, what will be the reason?  Manifold Markets\n",
      "https://docs.google.com/document/d/14YxJ6wO6j3Rn95XUdHxomNVi3eLmaJeaPgygqHcscn8/edit#heading=h.e7ui0mg6b3y4 | AR Reflections on the Ops Retreat - Google Docs\n",
      "https://www.wikiwand.com/en/Eagle_Eye | Eagle Eye\n",
      "https://twitter.com/JeffLadish/status/1635942674967728130 | Jeffrey Ladish on Twitter: \"\"can you write me a game in python where I control a pong paddle on the right side of the field and the left side of the field is Conway's game of life\" Gif of the resulting game after some additional instructions: https://t.co/o136APOoUn\" / Twitter\n",
      "https://twitter.com/markets/status/1635731307908005895 | Bloomberg Markets on Twitter: \"Adept has raised $350 million to develop AI tools that can actually execute commands based on human prompts instead of giving written responses https://t.co/OYBwRDdbj3\" / Twitter\n",
      "https://twitter.com/ESYudkowsky/status/1635577836525469697 | (1) Eliezer Yudkowsky on Twitter: \"I don't think people realize what a big deal it is that Stanford retrained a LLaMA model, into an instruction-following form, by **cheaply** fine-tuning it on inputs and outputs **from text-davinci-003**. It means: If you allow any sufficiently wide-ranging access to your AI‚Ä¶\" / Twitter\n",
      "https://github.com/laurakduffy/risk_ambiguity_model | laurakduffy/risk_ambiguity_model\n",
      "https://twitter.com/SSGamblers | Star Spangled Gamblers (@SSGamblers) / Twitter\n",
      "https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous | If interpretability research goes well, it may get dangerous - LessWrong\n",
      "https://docs.google.com/document/d/18hsS6rsQmnZcOZJ7Lz2K9jhgosNtS-NXhle7w_BVRLA/edit | AI Safety - Half Year Summary - Google Docs\n",
      "https://cdn.openai.com/papers/gpt-4.pdf | gpt-4.pdf\n",
      "https://www.metaculus.com/questions/13027/share-living-where-same-sex-marriage-is-legal/ | Share Living Where Same-Sex Marriage is Legal  Metaculus\n",
      "https://docs.google.com/document/d/1FlvPFA7SKpXETleWpPQIs7bWqU6KznH9_DS_VZrLEmM/edit | Talcott notes - Google Docs\n",
      "https://docs.google.com/document/d/1Wu2T0k9MT9JXV5I3EKBeKf_6_W1IqVESM3JcjBF5dv4/edit#heading=h.rjqp4f8kzon9 | Extreme BioSecurity Measures Applicable to AI - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1p7KAFI8_oQVHS3nXNAaWqIPExb87MsBWo9pS98gcQQc/edit | RP AIGS project options spreadsheet - Google Sheets\n",
      "https://docs.google.com/document/d/1U-XKyrYLv_RbqkrUwaz39lyCuaRlXagvfAdWrdbf8iE/edit#heading=h.1t59s1ygweog | Sketching a TAI scenario and backchaining to useful actions - Google Docs\n",
      "https://docs.google.com/document/d/16F2Qmj7KCgtDnT1xA4UNsejdSKj_d4q7r7S01dczJ_U/edit | Lessons on Tech Governance from the International Atomic Energy Agency (IAEA) - Google Docs\n",
      "https://garymarcus.substack.com/p/this-week-in-ai-doublespeak | This Week in AI Doublespeak - by Gary Marcus\n",
      "https://www.rei.com/blog/climb/new-survey-finds-nearly-one-third-of-respondents-have-experienced-sexual-harassment-or-assault-while-climbing?utm_source=Sailthru&utm_medium=email&utm_campaign=Future%20Perfect%20Wednesday:%202/15/23&utm_term=Future%20Perfect | Survey Reveals Sexual Harassment & Assault While Climbing - REI Co-op Journal\n",
      "https://www.rand.org/pubs/testimonies/CTA2654-1.html | Challenges to U.S. National Security and Competitiveness Posed by AI  RAND\n",
      "https://thegradient.pub/othello/ | Large Language Model: world models or surface statistics?\n",
      "https://docs.google.com/document/d/1s3J6_LWBhgp3EZs3fE65iKQK-WQyv4zApbCuO_efr4o/edit | Insights from fundraising in 2022 - Google Docs\n",
      "https://borretti.me/article/and-yet-it-understands | And Yet It Understands\n",
      "https://thezvi.substack.com/p/response-to-tyler-cowens-existential | Response to Tyler Cowen's Existential risk, AI, and the inevitable turn in human history\n",
      "https://docs.google.com/document/d/1wJf3uj_3v9qMj6hnLUhkzHeqRl23-llPCJeNhddH6d4/edit | Prioritizing verifiable claims speedrun - Google Docs\n",
      "https://www.nytimes.com/interactive/2022/02/11/well/strengthen-relationships.html?name=styln-quizzes&region=TOP_BANNER&block=storyline_menu_recirc&action=click&pgtype=Article&variant=undefined | 7 Simple Exercises To Strengthen Your Relationship - The New York Times\n",
      "https://docs.google.com/document/d/1Z-2c2-KGL1tk5qwzHR4aTVoJnPT5JC-5lJ9YdD4HsQk/edit | [draft, v2] Feasibility of on-chip mechanisms for compute governance - Google Docs\n",
      "https://www.youtube.com/watch?v=pTlxm5BjRjA | How to compare welfare across species  Bob Fischer  EAG Bay Area 23 - YouTube\n",
      "https://medium.com/curiouserinstitute/how-to-talk-to-an-ai-part-ii-bing-5a67db73b119 | How To Talk To An AI: Part II ‚Äî Bing  by Rabbit Rabbit  curiouserinstitute  Feb, 2023  Medium\n",
      "https://www.wikiwand.com/en/Corsica | Corsica - Wikiwand\n",
      "https://twitter.com/JeffLadish/status/1643385498092834817 | Jeffrey Ladish on Twitter: \"This is exactly it. I don't pretend to know exactly how this transition will go. I'm confused about agents and goals and optimization. But we are talking about rapidly filling the world with things we don't begin to understand that will be far, far smarter than us\" / Twitter\n",
      "https://www.lesswrong.com/posts/AfGmsjGPXN97kNp57/arguments-about-fast-takeoff | Arguments about fast takeoff - LessWrong\n",
      "https://twitter.com/EMostaque | Emad (@EMostaque) / Twitter\n",
      "https://docs.google.com/document/d/1bw3VHtqUsdseNgcD6INdzhSnT7jr7qVQSzIn9imw7KU/edit | [shared] RP Project Planning Template [LT copy] - Google Docs\n",
      "https://docs.google.com/document/d/1WY2DmyvKrHQmRBQFGo04HTXMnCIJQs1nhm2UkjLTBGw/edit | Post-FTX Public Awareness / Attitudes - Google Docs\n",
      "https://www.youtube.com/watch?v=5XilOLjLeB8 | https://www.youtube.com/watch?v=5XilOLjLeB8\n",
      "https://garymarcus.substack.com/p/the-first-known-chatbot-associated | The first known chatbot associated death - by Gary Marcus\n",
      "https://docs.google.com/document/d/1Bp-95XalxsgQQ1q1-PCW030oXaWUP5Dpkdj4TnbNfF0/edit | [mini-copy for my discussion table] What I think the AI plan is - Google Docs\n",
      "https://twitter.com/mealreplacer/status/1641348042044366848 | john stuart chill on Twitter: \"As many of you have already begun to notice, we are on the cusp of a new era in AI ‚Äî one where a much wider range of actors (e.g the entire general public) will start being exposed to arguments for AI risk. Eliezer even wrote an article for Time magazine! Some misc takes üßµ\" / Twitter\n",
      "https://twitter.com/MatthewJBar/status/1643775707313741824 | Matthew Barnett on Twitter: \"I recently criticized the calls to pause model scaling. However, my arguments were brief. Therefore, I thought it might be valuable to elaborate on my view that we should be cautious about slowing down AI progress. üßµ\" / Twitter\n",
      "https://www.metaculus.com/questions/12997/world-population/ | World Population  Metaculus\n",
      "https://docs.google.com/document/d/1-Kcop51raxTaSpZRUl60N1OhSRIsctXwyZhXRd7-HAI/edit | Preventing and Responding to Sexual Harassment and Violence\n",
      "https://aiguide.substack.com/p/why-the-abstraction-and-reasoning | Why the Abstraction and Reasoning Corpus is interesting and important for AI\n",
      "https://docs.google.com/document/d/18taVUahU3V91ObOok87GqJExoLJbwYTHvkWPqWOTRjw/edit | Ben Garfinkel <> Michael Aird - 2023 meetings\n",
      "https://statmodeling.stat.columbia.edu/2023/04/08/givewells-change-our-mind-contest-cost-effectiveness-and-water-quality-interventions/ | GiveWell‚Äôs Change Our Mind contest, cost-effectiveness, and water quality interventions  Statistical Modeling, Causal Inference, and Social Science\n",
      "https://twitter.com/MatthewJBar/status/1643167977372815360 | https://twitter.com/MatthewJBar/status/1643167977372815360\n",
      "https://twitter.com/NunoSempere/status/1641592261258428420 | Nu√±o Sempere *will be in NYC soon* on Twitter: \"Here is a cool thing: https://t.co/h0AmVPC3x5. It asks you about a topic and then presents you with a Fermi question. When you answer, it gives the guess by a GPT model. https://t.co/rU8OMjXiHP\" / Twitter\n",
      "https://www.planned-obsolescence.org/disagreement-in-alignment/ | Alignment researchers disagree a lot\n",
      "https://docs.google.com/document/d/1u95GHH-72mOWXPPlcTRLw1duYz1mxY-03lwaveMgJcc/edit#heading=h.2st10p4xokyd | EV of the Future and Counterfactual Credit - Google Docs\n",
      "https://twitter.com/messages/25776739-779118444440592384 | Tom Liptay / Twitter\n",
      "https://docs.google.com/document/d/1m0Dx0T6U4Bbf6UTG9RZbAiPU-HX8brDgNn4av-PkEQE/edit#heading=h.9nknxzpqqg8f | Oliver 2023 research project ideas - Google Docs\n",
      "https://docs.google.com/document/d/1uCkTLNNbxLXlnFunKsVYi2bTJZW_tWFaMw4xG4F_JZE/edit | Notes on early warning/outside-in intelligence - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/XvicpERcDFXnsMkfe/risks-from-gpt-4-byproduct-of-recursively-optimizing-ais | Risks from GPT-4 Byproduct of Recursively Optimizing AIs - EA Forum\n",
      "https://docs.google.com/document/d/1cPyHo7Xym0RaDVI55bIKgqQJhztcYV_Bj77fO_i5VZw/edit | X-Risk in the Pre-AGI Transition Period - Google Docs\n",
      "https://docs.google.com/document/d/1fFG8KDct7FVkVMWD8_YG9xesi7dnq1teTLkCmjw6nnU/edit | Potential Youth Movement: ‚ÄúTruly a part of you‚Äù capacity building - Google Docs\n",
      "https://twitter.com/NeelNanda5/status/1641143950932049922 | (2) Neel Nanda on Twitter: \"Great work from @ericjmichaud_! I'm particularly impressed by their galaxy brained clustering approach to find specific LLM capabilities, like \"lines are max 80 chars\" or continuing abstract-ish sequences of numbers. I'd love to see work reverse-engineering the underlying circuit https://t.co/KTCqDLNWkq\" / Twitter\n",
      "https://nunosempere.com/blog/2023/03/10/estimation-sanity-checks/ | Estimation for sanity checks\n",
      "https://twitter.com/JoshuaBlake_/status/1639253089830989827 | (2) Josh on Twitter: \"Metaculus community predictions on AI appear poor, unlike the weighted \"Metaculus\" predictions. Probably a bias due to AI hype within Metaculus's audience, but weighting effectively addresses it. Great analysis!\" / Twitter\n",
      "https://www.anthropic.com/index/core-views-on-ai-safety | Anthropic  Core Views on AI Safety: When, Why, What, and How\n",
      "https://thezvi.substack.com/p/on-the-fli-ai-risk-open-letter | On the FLI AI-Risk Open Letter - by Zvi Mowshowitz\n",
      "https://twitter.com/QualyThe/status/1637817473801105413 | Qualy the lightbulb on Twitter: \"arguing with a rationalist like üòä https://t.co/o9vXAH6MOt\" / Twitter\n",
      "https://docs.google.com/document/d/1VyQJK2dIwvz0yelzT4GjBPXFwdS6PCCwMjFTHTEAAsQ/edit | How does bee learning compare with machine learning? [Public] - Google Docs\n",
      "https://docs.google.com/document/d/1JF-CEwE6M8AELgjetlouWdK4eAVefGLxJKouwhdUTw0/edit | [2023.03.17 (Mar)] Email to Luke (Shaun's second DiD update) - Google Docs\n",
      "https://docs.google.com/document/d/1XQcFKo6PzUns0MAX-618CaQB5eIlRh8RXUCeA8nILss/edit#heading=h.x0hu6vkosc7f | [Shareable] Verifying compute use - LAISR notes - Google Docs\n",
      "https://www.wired.com/story/chatgpt-plugins-openai/ | Now That ChatGPT Is Plugged In, Things Could Get Weird  WIRED\n",
      "https://www.alignmentforum.org/posts/etNJcXCsKC6izQQZj/pivotal-outcomes-and-pivotal-processes | Pivotal outcomes and pivotal processes - AI Alignment Forum\n",
      "https://twitter.com/GoogleColonizer/status/1634972841505624064 | Google Colony Ship on Twitter: \"@peterwildeford @EzraJNewman But in all seriousness, I'd love to know the top 3-5 you are looking at so I can continue my investigation of engineered prompt prefixes on accuracy. Please?\" / Twitter\n",
      "https://docs.google.com/document/d/1qa1QkVQzDMQ-q_xvXuqYLToKwePoCOyPlo-8ydfzEcg/edit | 6219476ee801e140e5433082   Patchd, Inc.  2023-03-02T01:05:24Z - Google Docs\n",
      "https://archive.is/9JNDG | Where Religion and Neoliberal Diversity Tactics Converge\n",
      "https://docs.google.com/document/d/1V3jNnt-6qWxsvvK0OZD0eSxEM0ySozkhUf8WWBR8CBA/edit | Tamper-proofing AI accelerators against nation states - Google Docs\n",
      "https://docs.google.com/document/d/1xiOtTn_3RhvrMHIwRWehbI-Sx3DU0AoveemMF9LQi3c/edit | Onni Aarne's research agenda for 2023 - Google Docs\n",
      "https://docs.google.com/document/d/1fE9BXRjoyhkIunafPzEBQIH3tPelBzllSXY5ojDQ9O8/edit | Project idea: How far ahead of China is the US in AI (if at all)? - Google Docs\n",
      "https://docs.google.com/document/d/1fu2pT5TDdjxlL526ELCuZZP0FIVGkQ7fBj-s7vVVX88/edit | Success Without Dignity - Google Docs\n",
      "https://docs.google.com/document/d/1cgyL0QbR26XWqbR8GoUOe2nMcAy_rXK1eKKhrwBHyc8/edit | EA Scandal Risk Write-up 2 - Google Docs\n",
      "https://laion.ai/blog/petition/ | Petition for keeping up the progress tempo on AI research while securing its transparency and safety.  LAION\n",
      "https://twitter.com/ESYudkowsky/status/1635570989097680902 | (1) Eliezer Yudkowsky on Twitter: \"AI hype busters: What would you bet at 9-1 cannot *possibly* be done before April of 2024, 2025, or 2028? (Concrete verifiable tasks only.)\" / Twitter\n",
      "https://docs.google.com/document/d/1jbeY5yQr38AmJxKYuMLaJ6lTZxR0AalJcAg-sR4bhhs/edit | The field of existential security and AI governance should convene a Pugwash on AGI safety - Google Docs\n",
      "https://docs.google.com/document/d/1_WDmuiyCxByAMGiZmlimZe9U9FR4xo2u2xNs_IvTTKI/edit | ph-pw Peter Hartree & Peter Wildeford calls - Google Docs\n",
      "https://www.wikiwand.com/en/Edge_of_Tomorrow | Edge of Tomorrow - Wikiwand\n",
      "https://www.bryantresearch.co.uk/insights/institutional-change?fbclid=IwAR2kEV1sDJpgiiTKhWLAz4JqY3WTwdqShDuVg_4Z-ZMiv7h_TpXwhNj1YG4 | Bryant Research - Institutional Change\n",
      "https://docs.google.com/document/d/1Y1UQr7cItiOpLIrq_7tD1TFM6AzQxVwAebQi9jFZpmg/edit | [Forum version] Main project summary - Google Docs\n",
      "https://docs.google.com/document/d/1idfbvEpsxrFTGflCErTPZ_NiXjeqPhfwBrJBce1P_Yw/edit#heading=h.mj0jmgv3ic64 | Will Humanity Choose Its Future? v4 - Google Docs\n",
      "https://twitter.com/TaylorWWebb/status/1641172201792761856 | (1) Taylor Webb on Twitter: \"Major update to our paper on emergent analogy in LLMs, with a number of additional tests and behavioral experiments, and a preliminary test of GPT-4. https://t.co/mvzvIJh1dI\" / Twitter\n",
      "https://thefuturesociety.org/new-year-new-tfs/ | New year. New TFS. - The Future Society\n",
      "https://www.danieldewey.net/risk/ | About this site\n",
      "https://www.wpeebles.com/Gpt | Learning to Learn with Generative Models of Neural Network Checkpoints\n",
      "https://dpaleka.substack.com/p/language-models-rely-on-meaningful | Language models rely on meaningful abstractions\n",
      "https://www.wikiwand.com/en/Chess_2:_The_Sequel | Chess 2: The Sequel - Wikiwand\n",
      "https://www.reddit.com/r/CPTSD/comments/11fl8s4/comment/jak7abx/?utm_source=reddit&utm_medium=web2x&context=3 | (4) Did any of the abusers or people who caused chaos in your life that contributed to the ptsd ever change or recognise what they did? : CPTSD\n",
      "https://twitter.com/robbensinger/status/1643342330290913280 | Rob Bensinger üîç on Twitter: \"I've been citing https://t.co/jVrdg2mIgz to explain why the situation with AI looks doomy to me. But that post is relatively long, and emphasizes specific open technical problems over \"the basics\". Here are 10 things I'd focus on if I were giving \"the basics\" on why I'm worried:\" / Twitter\n",
      "https://docs.google.com/document/d/1RwIFccaSHPgDWV5dmsYEhd1R-Rk8fAF7A45L4dzI9v4/edit | Social capital with AI labs\n",
      "https://www.google.com/search?q=2024+eclipse&rlz=1C5CHFA_enUS925US925&oq=2024+ecl&aqs=chrome.0.0i131i433i512l2j69i57j0i512l7.1363j0j1&sourceid=chrome&ie=UTF-8 | 2024 eclipse - Google Search\n",
      "https://www.planned-obsolescence.org/the-training-game/ | Playing the training game\n",
      "https://docs.google.com/document/d/1Dl6LBB3hBOULijJCazOsOvWTwwr2p3sqACOQ-ySkABs/edit | Potential Things for Paid Board Member - Google Docs\n",
      "https://github.com/rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop | rethinkpriorities/RP-Visualising-Uncertainty-Jamie-Elsey-Workshop: Code to accompany the visualising uncertainty workshop\n",
      "https://twitter.com/sleepinyourhat/status/1600989810952265729 | (1) Sam Bowman on Twitter: \"This is the clearest and most insightful contribution to the Large Language Model Discourse in NLP that I've seen lately. You should read it! A few reactions downthread...\" / Twitter\n",
      "https://www.metaculus.com/questions/12961/total-global-fatalities-from-terrorism/ | Total Global Fatalities from Terrorism  Metaculus\n",
      "https://www.wikiwand.com/en/Ryan_Gosling | Ryan Gosling - Wikiwand\n",
      "https://docs.google.com/document/d/1qVXta8izrX3gmPVSX-QjuDTCg3TSkjbrWkKPm6PdBPQ/edit | RP Copy of Projects Alex would be excited about - March 2023\n",
      "https://docs.google.com/document/d/1nurdcWC_GvnQb6fsUAc_JuVgcWVD-zof_cM7sjwFbaQ/edit | [for LT department] Luke Muehlhauser <> Michael Aird - 2023-Feb-03 - AI strategy stuff, what OP wants in hires, incubation/entrepreneurship, misc - Google Docs\n",
      "https://docs.google.com/document/d/1fNQ5ycBbZL-Qo0LuXBM0otPPUHGpXW_F98WNlFjekGE/edit | DiD Redrafted Proposal for Jonas - Google Docs\n",
      "https://docs.google.com/document/d/1U9PneUggobFhnIcxwiYXcr24lcPfshEL7-eVGeDYesY/edit | Team Actions - Google Docs\n",
      "https://gcrpolicy.substack.com/?utm_source=homepage_recommendations&utm_campaign=301184 | GCR Policy‚Äôs Newsletter  Substack\n",
      "https://www.oneusefulthing.org/p/thinking-companion-companion-for | Thinking companion, companion for thinking\n",
      "https://courageous-entremet-8a84d8.netlify.app/ | JEID Report\n",
      "https://docs.google.com/document/d/1e0dlTw724dCpZKVuw53s2lWoMMlY9SGBvKCWeBhMdNM/edit | Some hot takes from Marcus that we should consider - Google Docs\n",
      "https://twitter.com/benparr/status/1635684322261729282 | Ben Parr on Twitter: \"üö® HUGE news in AI: Google just launched Generative AI across ALL of Google Workspace -- Gmail, Docs, Sheets, Slides, Images -- EVERYTHING. They made a video showing off the new AI's capabilities. It's AWESOME. https://t.co/bL9uxafrvW\" / Twitter\n",
      "https://docs.google.com/document/d/1DILawtvpFAdndd5PUtcK-q-vObs3vblNqvuVKgvOZ3M/edit | Some research projects I‚Äôm considering for 2023 - Google Docs\n",
      "https://github.com/peterhurford/cross-cause-model | peterhurford/cross-cause-model\n",
      "https://www.metaculus.com/questions/12991/us-gdp-per-hour-worked-productivity/ | US GDP Per Hour Worked (Productivity)  Metaculus\n",
      "https://docs.google.com/document/d/1c-KwX1vHZ8SINoQ2PyCjgYBQiu3cj6aUMSbhGe6wqtQ/edit | Marie's misc. thoughts on GLT doing an LT incubator - Google Docs\n",
      "https://twitter.com/YosarianTwo/status/1635780666632687617 | Yosarian2 on Twitter: \"Holy shit. GPT-4, on it's own; was able to hire a human TaskRabbit worker to solve a CAPACHA for it and convinced the human to go along with it. https://t.co/xVuQnyUUry\" / Twitter\n",
      "https://docs.google.com/document/d/1sdHc3RJYZVPCHnkGgvF3nBuxReaDRz7wohKn-aqhIes/edit | Some thoughts on why cybersecurity matters for AI risk\n",
      "https://docs.google.com/document/d/16tKLPjad1W9fF7KXu42rUFVmokapFVzTJszMNBuS3Uk/edit | Auditing Org Project: Lessons for GLT - Google Docs\n",
      "https://docs.google.com/document/d/1G3MsnzEmMQ11RzJeGe8WChbFRIHhi_yWVDW_tW1EdD0/edit | Coordinating AI development around a moving bright line - Google Docs\n",
      "https://docs.google.com/document/d/1Cw7uFMoA-qMfGDEqDqtvEU0osfenPZjzEjskA6T-XEA/edit | Research note: AI for Chemical & Materials Engineering (ACME) - Google Docs\n",
      "https://twitter.com/finmoorhouse/status/1628924814625996800 | https://twitter.com/finmoorhouse/status/1628924814625996800\n",
      "https://twitter.com/JeffLadish/status/1639194473350717442 | Jeffrey Ladish on Twitter: \"AI takeover is very likely üßµ This is true even if AI alignment turns out to be relatively easy. I do not think it will be easy, but this would not change the conclusion All you need to conclude AI takeover is that future AI systems will be very powerful and agentic...\" / Twitter\n",
      "https://docs.google.com/document/d/1lC-rIXME-GD1AImZ80b9eP61sroZy8mooLnSeHNgYzM/edit | Brainstorming on RP as a brand\n",
      "https://docs.google.com/document/d/1xvHKqFh3ei1PKwreYl2NqoFADJ_YJEGkSvfH_Yhm8hY/edit | [DRAFT] Report: how much are ML-focused companies spending on compute? - Google Docs\n",
      "https://docs.google.com/document/d/1YAJ0uVLDHb887LQKMd0HNSF167eksCjSkhKVo9rvEfg/edit | [West] Thoughts on recent PRC statements on international AI ethics and governance - Google Doc\n",
      "https://twitter.com/dylan522p/status/1628797563007811585 | Dylan Patel on Twitter: \"Meta's internal data shows that they are growing compute and datacenter infrastructure faster than Google and Microsoft! A higher percentage of their capex is spent on servers, and so compute energy footprint is growing faster, despite lower spend. Their PUE is &lt;1.1, so it's not‚Ä¶ https://t.co/Nikto4prZV\" / Twitter\n",
      "https://docs.google.com/document/d/1DIExQFqzkJdngxPUPn1txvBNUuBJeSrE19hwgLUZAgs/edit | PW Self Reflection Nov 2022 - Google Docs\n",
      "https://confido.institute/ | https://confido.institute/\n",
      "https://arxiv.org/abs/2303.09387 | [2303.09387] Characterizing Manipulation from AI Systems\n",
      "https://github.com/marcus-a-davis/cross-cause-model | marcus-a-davis/cross-cause-model\n",
      "https://docs.google.com/document/d/1zHDK232ClJwvc2U76aRw2prM5PBmSq-qCFeCqiikWp8/edit | US Tilting [Shared] - Google Docs\n",
      "https://twitter.com/mattyglesias/status/1635936611937517583 | Matthew Yglesias on Twitter: \"A lot of talk about how tech is viewed by non-tech people, but this survey has 31% of active machine learning researchers saying AI work is going to make the world worse. Median respondent says 5% odds of human extinction. https://t.co/BxwFnevki7 https://t.co/nxx1dCnSYI\" / Twitter\n",
      "https://docs.google.com/document/d/1xHmHPsfrYgUhjpCYotzVE78l1RWS7ddtjU85A6GIYUY/edit | Will misaligned APS systems seek power dangerously if deployed? - Google Docs\n",
      "https://docs.google.com/document/d/1EtQjv-YFS3LD8YfW8RpmlD03XmIZrStTBEXerLqWp0o/edit#heading=h.ssso4t7fjkoa | Deliberative Decision Making Procedures (v1) - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1adck_yCKsTYRl6j4WZ8dT5bJbJxS58FadHJiaYx8EPM/edit | Survey team time allocations - Google Sheets\n",
      "https://docs.google.com/presentation/d/1wTGG3lxJ3ljRmhhbAjutcJO7WKr_EZA0ZwrzX9la0D0/edit | Existential Security Summit - Opening Talk - Google Slides\n",
      "https://www.reuters.com/technology/europol-sounds-alarm-about-criminal-use-chatgpt-sees-grim-outlook-2023-03-27/?taid=6421c93d5b63c60001e3e35a&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | Europol sounds alarm about criminal use of ChatGPT, sees grim outlook  Reuters\n",
      "https://www.metaculus.com/tournament/climate/ | Climate Tipping Points  Metaculus\n",
      "https://docs.google.com/document/d/1vfdg4bqXjH_t3ABCiLvNja4H6ix5gdQAFCKphLoXV6o/edit | Key alignment questions for high level strategy - Google Docs\n",
      "https://github.com/peterhurford/future-assessment-model/blob/main/(3A)%20Initial%20TAI%20Spend%20Model.ipynb | future-assessment-model/(3A) Initial TAI Spend Model.ipynb at main ¬∑ peterhurford/future-assessment-model\n",
      "https://twitter.com/JgaltTweets/status/1625922883531702287 | JgaltTweets on Twitter: \"Here is the new AI risk poll from Monmouth: https://t.co/sFPjtA6dIX\" / Twitter\n",
      "https://www.metaculus.com/questions/3608/will-the-majority-of-leading-cosmologists-in-2030-agree-that-the-evidence-points-to-an-accelerating-universe/ | Cosmologists Favor Universe Acceleration  Metaculus\n",
      "https://github.com/peterhurford/acx_forecasts_2023 | peterhurford/acx_forecasts_2023: Forecasts for ACX's 2023 Question Set\n",
      "https://docs.google.com/document/d/1aBZaTkFp6APk8KPX6r23VhteAOsixn4o4DeAkYEy20o/edit#heading=h.7q6dvnlrhmy0 | 2022.11.29 AI Reference Classes New [Shared with External Advisors] - Google Docs\n",
      "https://simonwillison.net/2023/Feb/24/impressions-of-bing/ | Thoughts and impressions of AI-assisted search from Bing\n",
      "https://twitter.com/robbensinger/status/1639454866019090434 | Rob Bensinger üîç on Twitter: \"Eliezer described \"If Artificial General Intelligence has an okay outcome, what will be the reason?\" as the \"most important prediction market\": https://t.co/XrJMcuvK8k My initial thoughts on the scenarios (white background), vs. the market's probabilities (grey background): https://t.co/SLYKGMOX1N\" / Twitter\n",
      "https://docs.google.com/document/d/17Dd7kdgx6TGExC6UtrwiXl4UkrJzTBx8LDmZsdILF9I/edit | AIGS strategy proposal for Q2 2023 [AIGS Leads discussion notes] - Google Docs\n",
      "https://twitter.com/StephenLCasper/status/1642198614817554434 | https://twitter.com/StephenLCasper/status/1642198614817554434\n",
      "https://docs.google.com/document/d/1IH3WaAABQzwXO1pVr9Jn-jxtlbWJTxPPpWQYAjONnHY/edit#heading=h.xy9jocxxa277 | Conjecture Questions - Google Docs\n",
      "https://www.politico.com/news/magazine/2023/04/08/tennessee-descent-statehouse-mag-00091090 | No One Should Be That Shocked by What‚Äôs Happening in Tennessee - POLITICO\n",
      "https://openai.com/blog/our-approach-to-ai-safety | Our approach to AI safety\n",
      "https://docs.google.com/document/d/1hYo758MviVBd_C_OTaFZ4jfG2ZzUyU6dO-WdfCWv81Q/edit | [STUB] Mechanisms for Coordinating Resource Allocation - Google Docs\n",
      "https://docs.google.com/presentation/d/1yRLDkc7sxGa5eNPB6_IGoEy7dvoPVS6K0EYTd_VceF0/edit | IR Game Rules Intro - Google Slides\n",
      "https://instituteforprogress.substack.com/p/institute-for-progress-ifp-first?r=7o6sh&utm_medium=ios&utm_campaign=post | Institute for Progress (IFP) ‚Äî First Year in Review\n",
      "https://docs.google.com/document/d/1nxylL1-BwIrg7-G0vDk3K4COpAIpjmIAfwkaN5V1fwk/edit | AIs and moral patienthood - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1642417794083069952 | Daniel Ethüí° on Twitter: \"This is my answer to the question ‚Äúwhy might an AI attempt takeover before it was confident it could win?‚Äù and correspondingly one reason I think we‚Äôll likely get bad warning shots before X-risk\" / Twitter\n",
      "https://www.brookings.edu/research/exploring-the-impact-of-language-models/ | Exploring the impact of language models on cognitive automation with David Autor, ChatGPT, and Claude\n",
      "https://www.youtube.com/watch?v=Iv9vphCwsaU | https://www.youtube.com/watch?v=Iv9vphCwsaU\n",
      "https://twitter.com/leopoldasch/status/1643384705088364544 | Leopold Aschenbrenner on Twitter: \"GPT-4 can encode secret messages (and hide them from a user) (!!)\" / Twitter\n",
      "https://docs.google.com/document/d/1Qr-saZ3ojrGhIx-b5W-oc3FSPndKhm5oduHb93CcjaQ/edit | Maybe things that affect timelines tend to more importantly affect late-stage pace & polarity? - Google Docs\n",
      "https://twitter.com/JeffLadish/status/1628503073755906049 | Jeffrey Ladish on Twitter: \"I think the AI situation is pretty dire right now. And at the same time, I feel pretty motivated to pull together and go out there and fight for a good world / galaxy / universe @So8res has a great post called \"detach the grim-o-meter\", where he recommends not feeling obligated‚Ä¶\" / Twitter\n",
      "https://docs.google.com/document/d/1kT_u3P70_FONgTiTpEIVHnfh-08MIbFo_SD_5xbUTbc/edit | Operations Department Strategy - Google Docs\n",
      "https://twitter.com/emollick/status/1644532127793311744 | Ethan Mollick on Twitter: \"It is pretty amazing that a single prompt can have GPT-4 generate ideas, select one, give the next development steps, create a marketing pitch, and describe a UX. And one more prompt creates the start of the Python code needed for a rapid prototype. Not perfect, but really lowers‚Ä¶ https://t.co/gWU49p7asN\" / Twitter\n",
      "https://twitter.com/EThulin/status/1626945965050724352 | (1) Erik Thulin on Twitter: \"@peter_wilde_alt @tobias_haeberli After posting this I came across this CNBC article. Not sure how unique the information is, so not sure if worry updating on, but folks they interviewed seem to rate FAIR highly. https://t.co/l6MQOt9dzg\" / Twitter\n",
      "https://docs.google.com/document/d/1Max_9mYi7uAy8e4LZMi7trQbCe1lsMi0ZLHCJXYpa_s/edit | FTX Crisis Community Views [preliminary] - Google Docs\n",
      "https://docs.google.com/document/d/1OL5wELOWm-Hc09GojijMYh6xopcpV9JJ9mDPTKrAS1U/edit | Estimating the cost curve for AIGS research\n",
      "https://docs.google.com/document/d/1NA06JZz1gBLa9O4N3_1tlTvBLWy6X19Z--2gzQ_qkdk/edit | USG & natsec AI interest trends [WiP] - Google Docs\n",
      "https://www.alignmentforum.org/s/fSMbebQyR4wheRrvk | The Causes of Power-seeking and Instrumental Convergence - AI Alignment Forum\n",
      "https://lspace.swyx.io/p/ok-foomer | Irresponsible Foomerism - by swyx - L-Space Diaries\n",
      "https://twitter.com/DrJimFan/status/1629213930441814016 | Jim Fan on Twitter: \"OpenAI just dropped their ‚ÄúAGI roadmap‚Äù üëÄ I read through it. Key takeaways: Short term: - OpenAI will become increasingly cautious with the deployment of their models. This could mean that users as well as use cases may be more closely monitored and https://t.co/VxLIZiyR9z‚Ä¶\" / Twitter\n",
      "https://gist.github.com/davidad/1d5d0b1395d77473a0862b9823993672 | takeoff_scenario_davidad_20230220.json\n",
      "https://arxiv.org/abs/2211.03157 | [2211.03157] Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control\n",
      "https://docs.google.com/document/d/1e9vWPSCfuMD_elWVFdVdLJhqwWSiQBQKHu-8mvfxAHk/edit | How GLT can work with Mike McCormick and possible strategy updates from that - Google Docs\n",
      "https://docs.google.com/document/d/1OMeHukuwa9ghOe_ZaPusNMnBwzkDSq7yRto_IkGl5tM/edit | [final draft] Project idea solicitation plan - Google Docs\n",
      "https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets | Predictive Performance on Metaculus vs. Manifold Markets - EA Forum\n",
      "https://docs.google.com/document/d/1E94xR3U2kxdBKql0gZtnhzxHiN0lJ2yByAaXGd9VE5M/edit | Ashwin: Red-teaming the evals/regulation plan [RP copy] - Google Docs\n",
      "https://docs.google.com/document/d/1IPQwJqTbNWRCLML6mOYsOlMQGYK6bIqJ8Odkot0uOQI/edit | How will China‚Äôs effective GPU price-performance compare to the US‚Äôs in 2028 if export controls remain? - Google Docs\n",
      "https://docs.google.com/document/d/19qoI35NZzkvNghinKZh1ad0shLH-zjEL2rW_xynS16k/edit#heading=h.8ekeme61qpqb | Ashwin's timelines hot takes: PATCH-like scenarios - Google Docs\n",
      "https://docs.google.com/document/d/1LmIGgIoOf5nSNf1DK7dikrdefekK8NJW3BZhO-Y4SeA/edit | Forecast of available funding for AI-safety people during crunch time - Google Docs\n",
      "https://docs.google.com/document/d/1J4TK6twjcF3hop5ZoEVR-_FVnnRdABFSm0WZkuuhU6c/edit | EPE'22 Process Debrief - Google Docs\n",
      "https://nunosempere.com/blog/2023/03/15/fit-beta/ | Find a beta distribution that fits your desired confidence interval\n",
      "https://docs.google.com/document/d/1D8r5E9TRynywGNOHwYmE15Ne7FP2mq60WaJEl8UXl0U/edit | The Case For Collaborative Speed Runs - Google Docs\n",
      "https://docs.google.com/document/d/1Y9P87JK5w6dRTeCxKjWiRt44_h9lkLOde8FMFOOEIr4/edit#heading=h.b8kzjwotdq3z | [Shareable] Red-teaming longtermist AI governance - LAISR session - Google Docs\n",
      "https://twitter.com/birchlse/status/1628736918362923008 | Jonathan Birch on Twitter: \"I've written an @aeonmag piece on animal and AI sentience with @KristinAndrewz. It's the first time I've written about what I see as the hardest problem in the AI case, the \"gaming problem\". üßµ(1/5) https://t.co/pCOijaMI5D\" / Twitter\n",
      "https://docs.google.com/document/d/1XIT-avqFFFO9RnzSJz1BOT3Rw_MzsAwJipxLEoe4YWU/edit | Key points from my conversations w/ people about longtermist incubation - Google Docs\n",
      "https://docs.google.com/document/d/1_Z5LXkGT1aKTzZH6E8XIBJ683tTJp7_9SA5NvgLabcQ/edit | SH - memos for Summit on Existential Security\n",
      "https://docs.google.com/document/d/1ZI1EclVd013DblT9Ek0SkOtkFPh23B3VnekppcunHDw/edit | The Role of Activism in Nuclear Arms Control (kcl) - 17/04/2020 - Google Docs\n",
      "https://docs.google.com/document/d/1btLsQqXy5eiaqYKlWEg7FSXbisAblw1PgQtVCJz5l3c/edit | Good cop bad cop in AI safety advocacy - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1637930811617071104 | Daniel Ethüí° on Twitter: \"@peterwildeford I think it‚Äôs more-or-less that but for cognitive work. I overwhelmingly expect this will have a huge effect on which jobs humans do, but it‚Äôs not clear to me unemployment will be very high\" / Twitter\n",
      "https://twitter.com/dpaleka/status/1641742172759396352 | Daniel Paleka on Twitter: \"What happened this month in AI/ML safety research. üßµ (1/8)\" / Twitter\n",
      "https://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/ | The Prospect of an AI Winter\n",
      "https://www.eagoodgovernance.com/organizations | Organizations ‚Äî EA Good Governance Project\n",
      "https://docs.google.com/document/d/13nQfzNRJrB1-hMxxQgCjp6TIrdLvSIJFDH7X9xd8AWk/edit | Caleb/Renan on movement building research - Google Docs\n",
      "https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/ | Date of Artificial General Intelligence  Metaculus\n",
      "https://docs.google.com/document/d/1T3lW_rMui2cmApgmW2_Q5Fq1MKEIImcHkS4FdbMLZQU/edit | An Open Agency Architecture for Safe Transformative AI - Google Docs\n",
      "https://docs.google.com/document/d/1qw1p3pElVVjg1Hsjtk4VkbMtLvnYi1vRZDc0hBzjU-w/edit | Sexual norms, what should happen in each case\n",
      "https://aiguide.substack.com/ | AI: A Guide for Thinking Humans  Melanie Mitchell  Substack\n",
      "https://www.youngmoney.co/p/infinite-games | Infinite Games\n",
      "https://docs.google.com/spreadsheets/d/108xc4uUGFlcgSdLK9hlQ_knXo-8DzhMNxUa6Wux-UTs/edit | DRAFTING RP 2023 Draft Budget - Google Sheets\n",
      "https://aisnakeoil.substack.com/p/a-misleading-open-letter-about-sci | A misleading open letter about sci-fi AI dangers ignores the real risks\n",
      "https://tellingthefuture.substack.com/p/new-year-new-forecasts | New Year, New Forecasts - by Robert de Neufville\n",
      "https://docs.google.com/document/d/1kKNiwm-B9vzkm4imFI1ibebWlDi6CgbwzJiFcBGUJPw/edit#heading=h.ti0ljcr7nv6c | [Shareable] LAISR Q&A with people who know about US policymaking - Google Docs\n",
      "https://docs.google.com/document/d/1dAJRHDgEgDA20k6YsGkzPVWk-BAyzKcmA6bfH20-ajc/edit | [*MASTER*] Independent researcher infrastructure (last updated: 2023-02-22)\n",
      "https://twitter.com/MelMitchell1 | (7) Melanie Mitchell (@MelMitchell1) / Twitter\n",
      "https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai | How to reform effective altruism after Sam Bankman-Fried - Vox\n",
      "https://docs.google.com/document/d/1tN6pmDqxlwBjzwp5n_3pqii9EHsDJqCloiNtGDXyfYE/edit | Theories of victory in AI governance: relevant readings, people, & notes - Google Docs\n",
      "https://docs.google.com/document/d/13NW35AVd2Xl7Ka5iImdD89cqzgN9nX2FKCjdDBFanZM/edit | 2023 Ops Retreat Notes\n",
      "https://globalprioritiesinstitute.org/effective-altruism-risk-and-human-extinction-richard-pettigrew-university-of-bristol/ | Effective altruism, risk, and human extinction - Richard Pettigrew (University of Bristol) - Global Priorities Institute\n",
      "https://docs.google.com/document/d/1Fp3OLyZsdgUZwWsIv_ANUgPFV8W5KllOTePsxRyDhyg/edit#heading=h.lkb1ldi62gk0 | Notes on AI Short Timelines Preparation - Google Docs\n",
      "https://aiimpacts.org/rohin-shah-on-reasons-for-ai-optimism/ | Rohin Shah on reasons for AI optimism ‚Äì AI Impacts\n",
      "https://haltingthoughts.wordpress.com/2021/06/03/winners-curse-vs-bandit-algorithm/ | Winners Curse vs Bandit Algorithm  haltingthoughts\n",
      "https://twitter.com/dpaleka/status/1630961114375761922 | Daniel Paleka on Twitter: \"No one sees ChatGPT for the first time and thinks \"just some n-gram correlations\" or \"no real knowledge inside\". Those unintuitive beliefs trickle down from some experts, who should know better than to teach their controversial theories as established fact: üßµ (1/12)\" / Twitter\n",
      "https://twitter.com/daniel_eth/status/1639253621077594113 | https://twitter.com/daniel_eth/status/1639253621077594113\n",
      "https://www.thetimes.co.uk/article/rogue-ai-could-kill-everyone-3bsfttpmv | Rogue AI ‚Äòcould kill everyone‚Äô  News  The Times\n",
      "https://twitter.com/CasinoOrgSteveB/status/1631783405376487425 | Steve Bittenbender on Twitter: \"NEW PREDICTIT UPDATE: In a court filing today before the Fifth Circuit, the CFTC said it WITHDREW its Aug. 2022 withdrawal letter &amp; issued a new letter yesterday. The new letter details the CFTC's claims the exchange violated the 2014 no-action letter More to come...\" / Twitter\n",
      "https://thezvi.substack.com/p/ai-3 | AI #3 - by Zvi Mowshowitz - Don't Worry About the Vase\n",
      "https://docs.google.com/document/d/1Psa11UEeLNsJ8XpT8R44GeyW0nhUfuDmZK6JA72mP_A/edit | v2 AI Safety Bounties - Google Docs\n",
      "https://docs.google.com/document/d/1w4LSZSzdPWsTLQ0_cghoJ1JvLliEn0cSC1koG_aEm3A/edit | Info on EA hubs (offices, accommodation, people to talk to, etc.) - Google Docs\n",
      "https://twitter.com/ProfPaulPoast/status/1642128750509797377 | Paul Poast on Twitter: \"Are China and Russia in a military alliance? Yes. Here's why. [THREAD] https://t.co/b9uhXRXBfC\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1jPU9hNNmqaVtLl76WUpDZ48fISwhbt264x1mchfMEH0/edit | LT Department Project Status Sheet - Feb 2023 - Google Sheets\n",
      "https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08 | https://twitter.com/NathanpmYoung/status/1635559188444205061?t=ReG_XPb_Ek5TwZWR8AuSbw&s=08\n",
      "https://drive.google.com/drive/u/0/folders/1lZIWI5kSRyilKzRWkBhsiKpfCVvPdmSl | Notes from Sessions - Google Drive\n",
      "https://www.washingtonpost.com/archive/opinions/1987/04/12/sexpionage-why-we-cant-resist-those-kgb-sirens/900e1e59-1a7b-455f-93cf-22e67394512b/ | SEXPIONAGE WHY WE CAN'T RESIST THOSE KGB SIRENS - The Washington Post\n",
      "https://docs.google.com/document/d/1bue7VzQPZ9Uy7drOShVdF1h0_uSAB9wQsSA4gcBvPGg/edit | Takeaways from EAGx Cambridge convos about GLT‚Äôs strategy (mostly entrepreneurship stuff) - Google Docs\n",
      "https://docs.google.com/document/d/1rbF7L5zUnRuzZu3TOhUw6JssgD8yhPHsFgYzlX_4F4A/edit | Ryan's thoughts on the future of EA (Feb 2023) - Google Docs\n",
      "https://www.beren.io/2023-01-21-gradient-hacking-extremely-difficult/ | Gradient Hacking is extremely difficult.\n",
      "https://twitter.com/hunnaminjowl/status/1641827858015469568 | https://twitter.com/hunnaminjowl/status/1641827858015469568\n",
      "https://docs.google.com/presentation/d/19P_ZEZRaJRRAGm1WHgZHe94YwTUXy2FhzQhfxA6t2ns/edit | How / how much should RP plan & prepare for crunch time actions? [MA lightning talk - 2022 LT retreat] - Google Slides\n",
      "https://twitter.com/NathanpmYoung/status/1640302031855403010 | Nathan üîç on Twitter: \"What questions would you like about AI that resolve in the next two years? I'd like to write some. Some examples: https://t.co/ezG76Di5X2\" / Twitter\n",
      "https://docs.google.com/document/d/1vE8CrN2ap8lFm1IjNacVV2OJhSehrGi-VL6jITTs9Rg/edit | Appendices for \"Important, actionable research questions for the most important century\" - Google Docs\n",
      "https://docs.google.com/document/d/1eKyGWByio3qLQS-35iONMvfPUQHxsU1HfNLEalznifs/edit | Report on the Future of Political Prediction Markets - Google Docs\n",
      "https://docs.google.com/document/d/1PmUuUro7BN_5qJgsZgvTzu64nEk1Zdcu8Wv58cDs9FA/edit | Robert de Neufville ‚Äì Evaluation (EAIF) ‚Äì 63d3561a97b4f8799801fb48 - Google Docs\n",
      "https://gwern.net/tool-ai | Why Tool AIs Want to Be Agent AIs ¬∑ Gwern.net\n",
      "https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/ | In defense of prompt engineering\n",
      "https://twitter.com/JgaltTweets/status/1643496690740068357 | (1) JgaltTweets on Twitter: \"I'd like to see a variation on this in which participants are presented with 10-20 actual &amp; potential dangers and asked to rank them according to how much of a threat they think they pose to the human race; should include things like climate change, nukes, terrorism, aliens, etc\" / Twitter\n",
      "https://twitter.com/SarahShoker/status/1633294865172951040 | Sarah Shoker on Twitter: \"Writing on the development of nuclear weapons programs, Scott Sagan noted that scientists lobbied their governments to advance their own exciting research goals. Speaking the language of 'security' is a way to build bureaucratic coalitions and get funding approval.\" / Twitter\n",
      "https://www.wikiwand.com/en/Poker_Face_(TV_series) | Poker Face (TV series) - Wikiwand\n",
      "https://docs.google.com/document/d/1uVi0jGpFU6qstOGTVrC8ZRnARa79HDw7L6t_A0nVWOg/edit | EA Crisis Management - Google Docs\n",
      "https://twitter.com/jungofthewon/status/1635725465901219841 | Jungwon on Twitter: \"We‚Äôre ‚Äúpivoting‚Äù Elicit with GPT-4 üòâ Elicit in 2022 took unstructured text in papers and structured it into a table. Elicit in 2023 will take this structured text and enable you to ‚Äúpivot‚Äù it, grouping it by concepts. Sign up here: https://t.co/9hyYcQHB04 https://t.co/yWpV7Pg3VB\" / Twitter\n",
      "https://fivethirtyeight.com/features/chatgpt-thinks-americans-are-excited-about-ai-most-are-not/ | ChatGPT Thinks Americans Are Excited About AI. Most Are Not.  FiveThirtyEight\n",
      "https://indianexpress.com/article/technology/reddit-users-are-jailbreaking-chatgpt-and-calling-it-dan-do-anything-now/ | Reddit users are jailbreaking ChatGPT and calling it DAN ‚Äî Do Anything Now  Technology News,The Indian Express\n",
      "https://www.youtube.com/watch?v=MGAgeNI8iyo | GiveWell's new interventions  Olivia Larsen  EAG Bay Area 23 - YouTube\n",
      "https://www.erichgrunewald.com/posts/against-llm-reductionism/ | Against LLM Reductionism\n",
      "https://docs.google.com/document/d/1G-er_obrsYa20vSpRoOS7Yra5XXDguPKJn7opFMWmlE/edit | Ben Garfinkel <> Marie Buhl ‚Äì 2023/01/27 - Google Docs\n",
      "https://docs.google.com/document/d/1mWa6pM65MqVnWgpMLSv0IejP526_0OjGCMbNbDz89jg/edit | Mike McCormick <> Renan/Linch on LT entrepreneurialism - Google Docs\n",
      "https://docs.google.com/spreadsheets/d/1jdYBDLrhBgVaf1WqjIlFiksyTemD-U9eIka1Amtwkno/edit | 2023 Jan Lights - Google Sheets\n",
      "https://docs.google.com/document/d/1xM3bb2MQlg7NX59OEHsuryhNNcgD_juqY6MfKgXO1MY/edit | Asana Adoption Project Overview - Google Docs\n",
      "https://twitter.com/daniel_eth/status/1635803908533805056 | Daniel Ethüí° on Twitter: \"So GPT-4 is able to prompt injection attack itself‚Ä¶\" / Twitter\n",
      "https://twitter.com/emollick/status/1629621976951140352 | Ethan Mollick on Twitter: \"Bing AI is proving very helpful for reasons too complicated to get into right now (but which involved a time machine) https://t.co/017eiWXqSU\" / Twitter\n",
      "https://github.com/tadamcz/timing-spend-down-copy-for-rethink-priorities | tadamcz/timing-spend-down-copy-for-rethink-priorities: A copy shared with some rethink priorities staff for my job application.\n",
      "https://intelligence.org/2023/03/21/deep-deceptiveness/ | Deep Deceptiveness - Machine Intelligence Research Institute\n",
      "https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/ | Racing through a minefield: the AI deployment problem\n",
      "https://twitter.com/peterwildeford/status/1637936005482176517 | Peter Wildeford on Twitter: \"My forecast is that conditional on (a) no human intervention just do whatever GPT4 says (no human selecting/filtering either) (b) place at least 50 bets (c) wait 6 months that GPT4's @ManifoldMarkets account will be 60% likely to be negative (less M at end than at beginning)\" / Twitter\n",
      "https://twitter.com/douglasmack/status/1638705593258061826 | (1) Doug Mack on Twitter: \"30 years after this was published, it still might be my favorite lede of all time https://t.co/vfxH2I0zOs\" / Twitter\n",
      "https://docs.google.com/spreadsheets/d/1cYRidzI3AIIUKgTgCnGqHiT1kMjT5P0xKWe4kvumK6I/edit | RP Future Org Charts - Google Sheets\n",
      "https://docs.google.com/document/d/1MQgr-sRAyYMb0NXJlHG8O0fsKozhy-sorvp5VLuInc0/edit | Why aren't there more on-ramps to longtermism from climate change? - Google Docs\n",
      "https://onthinktanks.org/ | On Think Tanks  Independent research, ideas and advice\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tabs)\n",
    "print_tabs(tabs, label='Shuffled all tabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875f10-ecdd-43fd-b849-196c6bd1977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
